<!doctype html><html lang=zh-cn><head><title>Kubernetes 实战-踩坑记录（持续更新） · Yiran's Blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Yiran Zhou"><meta name=description content="背景 链接到标题 在对现有服务进行容器话改造的过程中，随着对 K8S 使用程度越来越深，也渐渐的遇到了一些坑，所以开一篇博客，记录自己所遇到的坑，应该会长期更新。
更新记录 链接到标题 2019.07.13 02:00 来自加班中的 yiran 2019.07.19 06:52 早起不想去公司的 yiran coredns 无法解析域名 链接到标题 在 Kubernetes 环境中，使用 kubeadm 工具部署的集群，会自动部署 coredns 作为集群的域名服务，每当我们创建了自己的 service，都可以通过域名直接访问，不用再考虑自己多个 Pod 的 IP 不同如何连接的问题。
最近遇到多个环境出现无法解析域名的问题，具体现象如下：
集群部署完成后，部署 daemonset 资源，每个节点均运行一个 busybox； 在 busybox 中对 kubernetes 默认域名进行解析，查看解析结果。 正常情况应该是所有的 busybox 都可以正常解析才对，但是最近几个环境中均出现了 3 个node 中1个node 上的 pod 无法解析的问题，示例代码如下：
daemonset.yaml
apiVersion: &#34;extensions/v1beta1&#34; kind: &#34;DaemonSet&#34; metadata: name: &#34;ds&#34; namespace: &#34;default&#34; spec: template: metadata: labels: app: ds spec: tolerations: - key: node-role."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Kubernetes 实战-踩坑记录（持续更新）"><meta name=twitter:description content="背景 链接到标题 在对现有服务进行容器话改造的过程中，随着对 K8S 使用程度越来越深，也渐渐的遇到了一些坑，所以开一篇博客，记录自己所遇到的坑，应该会长期更新。
更新记录 链接到标题 2019.07.13 02:00 来自加班中的 yiran 2019.07.19 06:52 早起不想去公司的 yiran coredns 无法解析域名 链接到标题 在 Kubernetes 环境中，使用 kubeadm 工具部署的集群，会自动部署 coredns 作为集群的域名服务，每当我们创建了自己的 service，都可以通过域名直接访问，不用再考虑自己多个 Pod 的 IP 不同如何连接的问题。
最近遇到多个环境出现无法解析域名的问题，具体现象如下：
集群部署完成后，部署 daemonset 资源，每个节点均运行一个 busybox； 在 busybox 中对 kubernetes 默认域名进行解析，查看解析结果。 正常情况应该是所有的 busybox 都可以正常解析才对，但是最近几个环境中均出现了 3 个node 中1个node 上的 pod 无法解析的问题，示例代码如下：
daemonset.yaml
apiVersion: &#34;extensions/v1beta1&#34; kind: &#34;DaemonSet&#34; metadata: name: &#34;ds&#34; namespace: &#34;default&#34; spec: template: metadata: labels: app: ds spec: tolerations: - key: node-role."><meta property="og:title" content="Kubernetes 实战-踩坑记录（持续更新）"><meta property="og:description" content="背景 链接到标题 在对现有服务进行容器话改造的过程中，随着对 K8S 使用程度越来越深，也渐渐的遇到了一些坑，所以开一篇博客，记录自己所遇到的坑，应该会长期更新。
更新记录 链接到标题 2019.07.13 02:00 来自加班中的 yiran 2019.07.19 06:52 早起不想去公司的 yiran coredns 无法解析域名 链接到标题 在 Kubernetes 环境中，使用 kubeadm 工具部署的集群，会自动部署 coredns 作为集群的域名服务，每当我们创建了自己的 service，都可以通过域名直接访问，不用再考虑自己多个 Pod 的 IP 不同如何连接的问题。
最近遇到多个环境出现无法解析域名的问题，具体现象如下：
集群部署完成后，部署 daemonset 资源，每个节点均运行一个 busybox； 在 busybox 中对 kubernetes 默认域名进行解析，查看解析结果。 正常情况应该是所有的 busybox 都可以正常解析才对，但是最近几个环境中均出现了 3 个node 中1个node 上的 pod 无法解析的问题，示例代码如下：
daemonset.yaml
apiVersion: &#34;extensions/v1beta1&#34; kind: &#34;DaemonSet&#34; metadata: name: &#34;ds&#34; namespace: &#34;default&#34; spec: template: metadata: labels: app: ds spec: tolerations: - key: node-role."><meta property="og:type" content="article"><meta property="og:url" content="https://zdyxry.github.io/2019/07/13/Kubernetes-%E5%AE%9E%E6%88%98-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-07-13T09:34:45+00:00"><meta property="article:modified_time" content="2019-07-13T09:34:45+00:00"><link rel=canonical href=https://zdyxry.github.io/2019/07/13/Kubernetes-%E5%AE%9E%E6%88%98-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.a1f1da6f0baa626de1763fc8157fdea088797379b7bbeb845799f2fffd5d0c82.css integrity="sha256-ofHabwuqYm3hdj/IFX/eoIh5c3m3u+uEV5ny//1dDII=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.593028e7f7ac55c003b79c230d1cd411bb4ca53b31556c3abb7f027170e646e9.css integrity="sha256-WTAo5/esVcADt5wjDRzUEbtMpTsxVWw6u38CcXDmRuk=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=/images/yiran.png sizes=32x32><link rel=icon type=image/png href=/images/yiran.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.101.0"></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>Yiran's Blog</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=/tags/>Tags</a></li><li class=navigation-item><a class=navigation-link href=/friends/>Friends</a></li><li class=navigation-item><a class=navigation-link href=/about/>About</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://zdyxry.github.io/2019/07/13/Kubernetes-%E5%AE%9E%E6%88%98-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/>Kubernetes 实战-踩坑记录（持续更新）</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2019-07-13T09:34:45Z>July 13, 2019</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
阅读时间：3 分钟</span></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/Kubernetes/>Kubernetes</a></span></div></div></header><nav id=TableOfContents><ul><li><a href=#背景>背景</a><ul><li><a href=#更新记录>更新记录</a></li></ul></li><li><a href=#coredns-无法解析域名>coredns 无法解析域名</a></li><li><a href=#flannel-oom>Flannel OOM</a></li><li><a href=#nginx-ingress>Nginx Ingress</a></li><li><a href=#docker-稳定性>Docker 稳定性</a></li><li><a href=#helm-values-为空更新错误>Helm values 为空更新错误</a></li><li><a href=#flannel-网卡丢失>Flannel 网卡丢失</a></li><li><a href=#总结>总结</a></li></ul></nav><div class=post-content><h2 id=背景>背景
<a class=heading-link href=#%e8%83%8c%e6%99%af><i class="fa fa-link" aria-hidden=true title=链接到标题></i>
<span class=sr-only>链接到标题</span></a></h2><p>在对现有服务进行容器话改造的过程中，随着对 K8S 使用程度越来越深，也渐渐的遇到了一些坑，所以开一篇博客，记录自己所遇到的坑，应该会长期更新。</p><h3 id=更新记录>更新记录
<a class=heading-link href=#%e6%9b%b4%e6%96%b0%e8%ae%b0%e5%bd%95><i class="fa fa-link" aria-hidden=true title=链接到标题></i>
<span class=sr-only>链接到标题</span></a></h3><ul><li>2019.07.13 02:00 来自加班中的 yiran</li><li>2019.07.19 06:52 早起不想去公司的 yiran</li></ul><h2 id=coredns-无法解析域名>coredns 无法解析域名
<a class=heading-link href=#coredns-%e6%97%a0%e6%b3%95%e8%a7%a3%e6%9e%90%e5%9f%9f%e5%90%8d><i class="fa fa-link" aria-hidden=true title=链接到标题></i>
<span class=sr-only>链接到标题</span></a></h2><p>在 Kubernetes 环境中，使用 kubeadm 工具部署的集群，会自动部署 coredns 作为集群的域名服务，每当我们创建了自己的 service，都可以通过域名直接访问，不用再考虑自己多个 Pod 的 IP 不同如何连接的问题。</p><p>最近遇到多个环境出现无法解析域名的问题，具体现象如下：</p><ol><li>集群部署完成后，部署 daemonset 资源，每个节点均运行一个 busybox；</li><li>在 busybox 中对 <code>kubernetes</code> 默认域名进行解析，查看解析结果。</li></ol><p>正常情况应该是所有的 busybox 都可以正常解析才对，但是最近几个环境中均出现了 3 个node 中1个node 上的 pod 无法解析的问题，示例代码如下：</p><p>daemonset.yaml</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=font-weight:700>apiVersion</span>: <span style=font-style:italic>&#34;extensions/v1beta1&#34;</span>
</span></span><span style=display:flex><span><span style=font-weight:700>kind</span>: <span style=font-style:italic>&#34;DaemonSet&#34;</span>
</span></span><span style=display:flex><span><span style=font-weight:700>metadata</span>:
</span></span><span style=display:flex><span>  <span style=font-weight:700>name</span>: <span style=font-style:italic>&#34;ds&#34;</span>
</span></span><span style=display:flex><span>  <span style=font-weight:700>namespace</span>: <span style=font-style:italic>&#34;default&#34;</span>
</span></span><span style=display:flex><span><span style=font-weight:700>spec</span>:
</span></span><span style=display:flex><span>  <span style=font-weight:700>template</span>:
</span></span><span style=display:flex><span>    <span style=font-weight:700>metadata</span>:
</span></span><span style=display:flex><span>      <span style=font-weight:700>labels</span>:
</span></span><span style=display:flex><span>        <span style=font-weight:700>app</span>: ds
</span></span><span style=display:flex><span>    <span style=font-weight:700>spec</span>:
</span></span><span style=display:flex><span>      <span style=font-weight:700>tolerations</span>:
</span></span><span style=display:flex><span>      - <span style=font-weight:700>key</span>: node-role.kubernetes.io/master
</span></span><span style=display:flex><span>        <span style=font-weight:700>effect</span>: NoSchedule
</span></span><span style=display:flex><span>      <span style=font-weight:700>containers</span>:
</span></span><span style=display:flex><span>      - <span style=font-weight:700>name</span>: <span style=font-style:italic>&#34;apply-sysctl&#34;</span>
</span></span><span style=display:flex><span>        <span style=font-weight:700>image</span>: <span style=font-style:italic>&#34;busybox:1.28.4&#34;</span>
</span></span><span style=display:flex><span>        <span style=font-weight:700>imagePullPolicy</span>: IfNotPresent
</span></span><span style=display:flex><span>        <span style=font-weight:700>command</span>:
</span></span><span style=display:flex><span>        - <span style=font-style:italic>&#34;/bin/sh&#34;</span>
</span></span><span style=display:flex><span>        - <span style=font-style:italic>&#34;-c&#34;</span>
</span></span><span style=display:flex><span>        - |<span style=font-style:italic>
</span></span></span><span style=display:flex><span><span style=font-style:italic>          set -o errexit
</span></span></span><span style=display:flex><span><span style=font-style:italic>          set -o xtrace
</span></span></span><span style=display:flex><span><span style=font-style:italic>          while true
</span></span></span><span style=display:flex><span><span style=font-style:italic>          do
</span></span></span><span style=display:flex><span><span style=font-style:italic>            sleep 2s
</span></span></span><span style=display:flex><span><span style=font-style:italic>            date
</span></span></span><span style=display:flex><span><span style=font-style:italic>            echo &#34;diu~&#34;
</span></span></span><span style=display:flex><span><span style=font-style:italic>          done</span>          
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>[root@node11 21:28:40 ~]$for i in <span style=font-style:italic>`</span>kubectl get pod  -o wide  |grep ds | awk <span style=font-style:italic>&#39;{print $1}&#39;</span><span style=font-style:italic>`</span>;<span style=font-weight:700>do</span> kubectl exec $i nslookup kubernetes;echo ;<span style=font-weight:700>done</span>
</span></span><span style=display:flex><span>Server:    10.96.0.10
</span></span><span style=display:flex><span>Address 1: 10.96.0.10
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>nslookup: can<span style=font-style:italic>&#39;t resolve &#39;</span>kubernetes<span>&#39;</span>
</span></span><span style=display:flex><span>command terminated with exit code 1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Server:    10.96.0.10
</span></span><span style=display:flex><span>Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Name:      kubernetes
</span></span><span style=display:flex><span>Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Server:    10.96.0.10
</span></span><span style=display:flex><span>Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Name:      kubernetes
</span></span><span style=display:flex><span>Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local
</span></span></code></pre></div><p>在第一个节点的 Pod 解析时失效，最后命令执行 1min 超时退出。</p><p>经过查看发现节点的 NetFilter 相关系统配置未生效，导致 iptables 相关功能失效，具体可以参考 <a href=https://github.com/kubernetes/kubernetes/issues/21613>issue</a>。</p><p>解决方式：</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>echo <span style=font-style:italic>&#39;1&#39;</span> &gt; /proc/sys/net/bridge/bridge-nf-call-iptables
</span></span></code></pre></div><h2 id=flannel-oom>Flannel OOM
<a class=heading-link href=#flannel-oom><i class="fa fa-link" aria-hidden=true title=链接到标题></i>
<span class=sr-only>链接到标题</span></a></h2><p>在配置好集群业务后，发现业务时不时的出现中断情况，最开始排查业务自身问题，未发现 Pod 出现重启或异常的日志，开始排查 k8s 状态，发现在节点 <code>/var/log/messages</code> 日志中，Flannel 一直处于 OOM 状态，惨不忍睹。</p><p>之前还略微惊奇，Flannel 默认的计算资源中，内存只要 50MiB，且上限也是 50MiB，没有给自己留一丝余地，看到 <a href=https://github.com/coreos/flannel/issues/963>issue</a> 中的描述，感觉这个不是一个偶发事件，最终我将 Flannel 的内存调整为 250MiB 后，未出现 OOM 情况。</p><p>issue 中提到的 <code>kubectl patch</code> 命令未自动生效，我通过更新 ds 配置，然后依次手动删除节点上的 Flannel Pod 使其生效。</p><h2 id=nginx-ingress>Nginx Ingress
<a class=heading-link href=#nginx-ingress><i class="fa fa-link" aria-hidden=true title=链接到标题></i>
<span class=sr-only>链接到标题</span></a></h2><p>Nginx Ingress 有多个版本，在编写 Ingress 规则的时候一定要看清自己集群中的 Nginx Ingress 版本，我最开始就是因为这个看错了文档。。</p><p>主要的版本有： <code>kubernetes/ingress-nginx</code> , <code>nginxinc/kubernetes-ingress with NGINX</code> 和 <code>nginxinc/kubernetes-ingress with NGINX PLUS</code> ，具体的对比规则可以在 <a href=https://github.com/nginxinc/kubernetes-ingress/blob/master/docs/nginx-ingress-controllers.md>Github</a> 中了解。</p><p>在 <code>kubernetes/ingress-nginx</code> 中，默认 <code>ssl-redirect</code> 参数是 <code>true</code> ，如果自己的服务不支持 https，那么需要显示的声明该参数为 false 才可以，这里需要注意一下。</p><p>在配置 nginx 参数的时候，要注意语法，正确的书写方式如下：</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=font-weight:700>apiVersion</span>: extensions/v1beta1
</span></span><span style=display:flex><span><span style=font-weight:700>kind</span>: Ingress
</span></span><span style=display:flex><span><span style=font-weight:700>metadata</span>:
</span></span><span style=display:flex><span>  <span style=font-weight:700>annotations</span>:
</span></span><span style=display:flex><span>    <span style=font-weight:700>kubectl.kubernetes.io/last-applied-configuration</span>: |<span style=font-style:italic>
</span></span></span><span style=display:flex><span><span style=font-style:italic>      </span>      {<span style=font-style:italic>&#34;apiVersion&#34;</span>:<span style=font-style:italic>&#34;networking.k8s.io/v1beta1&#34;</span>,<span style=font-style:italic>&#34;kind&#34;</span>:<span style=font-style:italic>&#34;Ingress&#34;</span>,<span style=font-style:italic>&#34;metadata&#34;</span>:{<span style=font-style:italic>&#34;annotations&#34;</span>:{<span style=font-style:italic>&#34;kubernetes.io/ingress.class&#34;</span>:<span style=font-style:italic>&#34;nginx&#34;</span>,<span style=font-style:italic>&#34;nginx.ingress.kubernetes.io/proxy-read-timeout&#34;</span>:<span style=font-style:italic>&#34;3600&#34;</span>,<span style=font-style:italic>&#34;nginx.ingress.kubernetes.io/proxy-send-timeout&#34;</span>:<span style=font-style:italic>&#34;3600&#34;</span>,<span style=font-style:italic>&#34;nginx.ingress.kubernetes.io/ssl-redirect&#34;</span>:<span style=font-style:italic>&#34;true&#34;</span>,<span style=font-style:italic>&#34;nginx.ingress.kubernetes.io/use-regex&#34;</span>:<span style=font-style:italic>&#34;true&#34;</span>,<span style=font-style:italic>&#34;nginx.org/websocket-services&#34;</span>:<span style=font-style:italic>&#34;websockify&#34;</span>},<span style=font-style:italic>&#34;name&#34;</span>:<span style=font-style:italic>&#34;websockify&#34;</span>,<span style=font-style:italic>&#34;namespace&#34;</span>:<span style=font-style:italic>&#34;default&#34;</span>},<span style=font-style:italic>&#34;spec&#34;</span>:{<span style=font-style:italic>&#34;rules&#34;</span>:[{<span style=font-style:italic>&#34;http&#34;</span>:{<span style=font-style:italic>&#34;paths&#34;</span>:[{<span style=font-style:italic>&#34;backend&#34;</span>:{<span style=font-style:italic>&#34;serviceName&#34;</span>:<span style=font-style:italic>&#34;websockify&#34;</span>,<span style=font-style:italic>&#34;servicePort&#34;</span>:8000},<span style=font-style:italic>&#34;path&#34;</span>:<span style=font-style:italic>&#34;/websockify&#34;</span>}]}}]}}
</span></span><span style=display:flex><span>    <span style=font-weight:700>kubernetes.io/ingress.class</span>: nginx
</span></span><span style=display:flex><span>    <span style=font-weight:700>nginx.ingress.kubernetes.io/proxy-read-timeout</span>: <span style=font-style:italic>&#34;3600&#34;</span>
</span></span><span style=display:flex><span>    <span style=font-weight:700>nginx.ingress.kubernetes.io/proxy-send-timeout</span>: <span style=font-style:italic>&#34;3600&#34;</span>
</span></span></code></pre></div><p>相关 issue 链接： <a href=https://github.com/kubernetes/ingress-nginx/issues/2007>https://github.com/kubernetes/ingress-nginx/issues/2007</a></p><h2 id=docker-稳定性>Docker 稳定性
<a class=heading-link href=#docker-%e7%a8%b3%e5%ae%9a%e6%80%a7><i class="fa fa-link" aria-hidden=true title=链接到标题></i>
<span class=sr-only>链接到标题</span></a></h2><p>在修改 Docker 配置后，需要重启 Docker.service 使配置生效，在一次重启操作中，直接导致物理节点宕机，自动重启了。。。</p><p>重启后观察物理节点日志，未发现异常日志，目前待复现调查，很坑很诡异。</p><h2 id=helm-values-为空更新错误>Helm values 为空更新错误
<a class=heading-link href=#helm-values-%e4%b8%ba%e7%a9%ba%e6%9b%b4%e6%96%b0%e9%94%99%e8%af%af><i class="fa fa-link" aria-hidden=true title=链接到标题></i>
<span class=sr-only>链接到标题</span></a></h2><p>今天在给应用编写 Helm Charts 的时候，在 Values 中通过 resources.requests.cpu 方式指定了 cpu 和内存，在测试的时候忘记填写具体数值了，像这面这样：</p><p>values:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=font-style:italic># Default values for test.</span>
</span></span><span style=display:flex><span><span style=font-style:italic># This is a YAML-formatted file.</span>
</span></span><span style=display:flex><span><span style=font-style:italic># Declare variables to be passed into your templates.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>resources</span>:
</span></span><span style=display:flex><span>  <span style=font-weight:700>limits</span>:
</span></span><span style=display:flex><span>   <span style=font-weight:700>cpu</span>:
</span></span><span style=display:flex><span>   <span style=font-weight:700>memory</span>:
</span></span><span style=display:flex><span>  <span style=font-weight:700>requests</span>:
</span></span><span style=display:flex><span>   <span style=font-weight:700>cpu</span>:
</span></span><span style=display:flex><span>   <span style=font-weight:700>memory</span>:
</span></span></code></pre></div><p>在 helm templates 中定义 daemonset，指定使用 resources 字段。</p><p>直接执行 helm 命令安装成功了：</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>[root@node11 20:44:09 test]$helm install . --name-template test
</span></span><span style=display:flex><span>NAME: test
</span></span><span style=display:flex><span>LAST DEPLOYED: 2019-07-15 20:44:18.151073881 +0800 CST m=+0.092592446
</span></span><span style=display:flex><span>NAMESPACE: default
</span></span><span style=display:flex><span>STATUS: deployed
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NOTES:
</span></span><span style=display:flex><span>1. Get the application URL by running these commands:
</span></span><span style=display:flex><span>  export POD_NAME=<span style=font-weight:700>$(</span>kubectl get pods -l <span style=font-style:italic>&#34;app=test,release=test&#34;</span> -o jsonpath=<span style=font-style:italic>&#34;{.items[0].metadata.name}&#34;</span><span style=font-weight:700>)</span>
</span></span><span style=display:flex><span>  echo <span style=font-style:italic>&#34;Visit http://127.0.0.1:8080 to use your application&#34;</span>
</span></span><span style=display:flex><span>  kubectl port-forward $POD_NAME 8080:80
</span></span></code></pre></div><p>我们查看创建出来的 daemonset 资源状态：</p><p>daemonset/test</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>Name</span>:           test
</span></span><span style=display:flex><span><span style=font-weight:700>Selector</span>:       app=test
</span></span><span style=display:flex><span><span style=font-weight:700>Node-Selector</span>:  &lt;none&gt;
</span></span><span style=display:flex><span><span style=font-weight:700>Pods Status</span>:  3 Running / 0 Waiting / 0 Succeeded / 0 Failed
</span></span><span style=display:flex><span><span style=font-weight:700>Pod Template</span>:
</span></span><span style=display:flex><span>  <span style=font-weight:700>Labels</span>:  app=test
</span></span><span style=display:flex><span>  <span style=font-weight:700>Containers</span>:
</span></span><span style=display:flex><span>   <span style=font-weight:700>test</span>:
</span></span><span style=display:flex><span>    <span style=font-weight:700>Image</span>:      harbor.zdyxry.com/test/test:0.1.2
</span></span><span style=display:flex><span>    <span style=font-weight:700>Port</span>:       10402/TCP
</span></span><span style=display:flex><span>    <span style=font-weight:700>Host Port</span>:  10402/TCP
</span></span><span style=display:flex><span>    <span style=font-weight:700>Command</span>:
</span></span><span style=display:flex><span>      /bin/sh
</span></span><span style=display:flex><span>      -c
</span></span><span style=display:flex><span>    <span style=font-weight:700>Args</span>:
</span></span><span style=display:flex><span>      gunicorn -b :10402 -k gevent test.main:flask_app -w 2 --timeout 40 --pid /var/run/test.pid
</span></span><span style=display:flex><span>    <span style=font-weight:700>Limits</span>:
</span></span><span style=display:flex><span>      <span style=font-weight:700>cpu</span>:     0
</span></span><span style=display:flex><span>      <span style=font-weight:700>memory</span>:  0
</span></span><span style=display:flex><span>    <span style=font-weight:700>Requests</span>:
</span></span><span style=display:flex><span>      <span style=font-weight:700>cpu</span>:        0
</span></span><span style=display:flex><span>      <span style=font-weight:700>memory</span>:     0
</span></span><span style=display:flex><span>    <span style=font-weight:700>Environment</span>:  &lt;none&gt;
</span></span></code></pre></div><p>这时候我在检查资源的时候发现自己忘记设置资源了，我计划通过更新 values 数值来更新 daemonset：</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=font-style:italic># Default values for test.</span>
</span></span><span style=display:flex><span><span style=font-style:italic># This is a YAML-formatted file.</span>
</span></span><span style=display:flex><span><span style=font-style:italic># Declare variables to be passed into your templates.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>resources</span>:
</span></span><span style=display:flex><span>  <span style=font-weight:700>limits</span>:
</span></span><span style=display:flex><span>   <span style=font-weight:700>cpu</span>: 100m
</span></span><span style=display:flex><span>   <span style=font-weight:700>memory</span>: 100Mi
</span></span><span style=display:flex><span>  <span style=font-weight:700>requests</span>:
</span></span><span style=display:flex><span>   <span style=font-weight:700>cpu</span>: 100m
</span></span><span style=display:flex><span>   <span style=font-weight:700>memory</span>: 100Mi
</span></span></code></pre></div><p>执行 helm upgrade 时候报错：</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>[root@node11 20:49:36 test]$helm upgrade test .
</span></span><span style=display:flex><span>Error: UPGRADE FAILED: error validating <span style=font-style:italic>&#34;&#34;</span>: error validating data: [unknown object type <span style=font-style:italic>&#34;nil&#34;</span> in DaemonSet.spec.template.spec.containers[0].resources.limits.cpu, unknown object type <span style=font-style:italic>&#34;nil&#34;</span> in DaemonSet.spec.template.spec.containers[0].resources.limits.memory, unknown object type <span style=font-style:italic>&#34;nil&#34;</span> in DaemonSet.spec.template.spec.containers[0].resources.requests.cpu, unknown object type <span style=font-style:italic>&#34;nil&#34;</span> in DaemonSet.spec.template.spec.containers[0].resources.requests.memory]
</span></span></code></pre></div><p>根据报错信息可以看到这个字段之前是 <code>nil</code> ，现在我们要更新为有效类型更新失败，只能通过 <code>helm uninstall</code> 卸载后再次安装修复该问题。</p><p>这个问题只在 daemonset 类型下会出现。</p><h2 id=flannel-网卡丢失>Flannel 网卡丢失
<a class=heading-link href=#flannel-%e7%bd%91%e5%8d%a1%e4%b8%a2%e5%a4%b1><i class="fa fa-link" aria-hidden=true title=链接到标题></i>
<span class=sr-only>链接到标题</span></a></h2><p>在通常情况下，我们的 k8s 节点都只有单一的网络环境，也就是有一块网卡，在部署 Flannel 插件的时候，默认会找默认路由所在的网卡，并将其绑定在上面。</p><p>由于内部测试环境较为特殊，我将其绑定在一个 ovs port 上，这个具体配置在 flannel yaml 中：</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>      <span style=font-weight:700>containers</span>:
</span></span><span style=display:flex><span>      - <span style=font-weight:700>name</span>: kube-flannel
</span></span><span style=display:flex><span>        <span style=font-weight:700>image</span>: quay.io/coreos/flannel:v0.11.0-amd64
</span></span><span style=display:flex><span>        <span style=font-weight:700>command</span>:
</span></span><span style=display:flex><span>        - /opt/bin/flanneld
</span></span><span style=display:flex><span>        <span style=font-weight:700>args</span>:
</span></span><span style=display:flex><span>        - --ip-masq
</span></span><span style=display:flex><span>        - --kube-subnet-mgr
</span></span><span style=display:flex><span>        - --iface=port-storage  <span style=font-style:italic># 在这里我强制指定了 iface</span>
</span></span></code></pre></div><p>正常运行时时没有问题的，但是对 ovs port 进行了 <code>ifdown</code> 操作后，在 OS 层面就无法找到这个 ovs port 了，flannel 默认的 <code>flannel.1</code> 这个 link 也丢失了，当我尝试 <code>ifup</code> ovs port，这个 port 正常恢复工作了，但是 <code>flannel.1</code> 无法自动恢复，目前找到的办法是手动重建 flannel pod。</p><p>猜测这个动作在 flannel 的init 相关步骤执行的，在之后 container 正常运行时没有考虑 <code>flannel.1</code> 不存在的情况。</p><h2 id=总结>总结
<a class=heading-link href=#%e6%80%bb%e7%bb%93><i class="fa fa-link" aria-hidden=true title=链接到标题></i>
<span class=sr-only>链接到标题</span></a></h2><p>使用经验通常是踩了一个又一个坑过来的~</p></div><footer><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//zdyxry.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}(),document.addEventListener("themeChanged",function(){document.readyState=="complete"&&DISQUS.reset({reload:!0,config:disqus_config})})</script></footer></article></section></div><footer class=footer><section class=container>©
2016 -
2023
Yiran Zhou
·
技术支持 <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-G0433XDZ3V"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-G0433XDZ3V",{anonymize_ip:!1})}</script></body></html>