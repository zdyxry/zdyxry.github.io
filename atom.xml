<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Yiran's Blog</title><link>https://zdyxry.github.io/</link><description>Recent content on Yiran's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 30 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://zdyxry.github.io/atom.xml" rel="self" type="application/rss+xml"/><item><title>Weekly Issue 2023-07-30</title><link>https://zdyxry.github.io/2023/07/30/Weekly-Issue-2023-07-30/</link><pubDate>Sun, 30 Jul 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/07/30/Weekly-Issue-2023-07-30/</guid><description>文章 链接到标题 技术 链接到标题 新的网络性能优化技术 —— BIG TCP | Oilbeater 的自习室
现有的 GRO 和 TSO 可以将数据包拆分和组装的工作交给网卡来做，内核按照64k 处理数据包，可以带来 10倍的性能提升。主流网卡驱动只支持 TCP 的 Offload。[[BIG TCP]] 要做的事情就是让内核里处理的这个数据包变的更大，之前内核处理的数据包大小为 64K 的主要限制在于 IP 包的头部有个长度字段，这个字段长度为 16bit，因此理论上一个 IP 包最大长度就是 64K。在 IPv6 通过 hop-by-hop 来获取数据包长度，在 IPv4 通过直接从内核的 skb-&amp;gt;len 计算真实的数据包长度。
Why is DNS still hard to learn?
为什么 [[DNS]] 很难学习，日常工作中遇到 DNS 问题都很头痛，加上国内特色网络，更麻烦。
Breaking: AWS Begins Charging For Public IPv4 Addresses - Last Week in AWS Blog
[[Azure]]和[[GCP]] 之后，[[AWS]] 开始对 [[IPv4]] 地址收费。前段时间我的 [[bandwagonhost ]] VPS 续费了，续费的理由是，我已经在市面上找不到比它更便宜的 [[IPv4]] 地址了。</description></item><item><title>Weekly Issue 2023-07-23</title><link>https://zdyxry.github.io/2023/07/23/Weekly-Issue-2023-07-23/</link><pubDate>Sun, 23 Jul 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/07/23/Weekly-Issue-2023-07-23/</guid><description>文章 链接到标题 技术 链接到标题 Incident Review for Site-wide Outage for GitLab.com - Stale Terraform Pipeline #15997 (#15999) · Issues · GitLab.com / GitLab Infrastructure Team / production · GitLab
[[Gitlab]] 对[[Terraform]] 使用不当导致故障的[[事故分析]]。在变更请求过程中,触发了一个过期的Terraform流水线。这导致一个过时的Terraform计划被应用到生产环境。同样的操作之前多次执行都没有问题。导致这次故障的原因是应用变更到生产环境有较长延迟(约3周)。用于资源重建的已知良好的流水线变得过时,并且由于最近的更改而导致配置漂移。
[[Atlantis]] 的存在是有道理的，它在前面拦一道，可以有效避免一些平时不容易注意到，但是一但发生会造成 S0 级别事故的 TF 灾难。 对抗人的不精确性的简单办法其实就是增加流程的安全性。 from: @kivinsae
额外的故事： [[Gitlab]] 因为自身故障，导致团队协作无法使用 [[Gitlab]]，只能去使用 Google Doc。
A Failed SaaS Postmortem · Matt Layman
作者在尝试做一个项目时，使用了自己不那么熟悉的技术栈，并且在软件依赖的更新上花费了大量的时间，又忽略了最终用户的感受，导致结果是不好的。在 MVP 阶段，应该保持技术栈简单，使用自己最熟悉的技术，来达到用户的期望。
https://www.redpoint.com/infrared/100/
[[Redpoint]] 选出的100 家做基础设施的[[公司]]。按类别划分：安全、数据 &amp;amp; AI、DevOps。
Golang 中预分配 slice 内存对性能的影响| Oilbeater 的自习室</description></item><item><title>Weekly Issue 2023-07-16</title><link>https://zdyxry.github.io/2023/07/16/Weekly-Issue-2023-07-16/</link><pubDate>Sun, 16 Jul 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/07/16/Weekly-Issue-2023-07-16/</guid><description>文章 链接到标题 技术 链接到标题 Towards Technical CEOs
[[Shopify]] CEO 给 llama.cpp 项目提了一个 PR，技术型老板可以让他们看到更多信息，技术敏感很重要，可以快速了解当前的趋势。有一个技术型老板应该很开心吧。
https://ricardoanderegg.com/posts/makefile-python-project-tricks/
[[Python]] 项目中使用 [[Makefile]] 的一些技巧，如 venv 设置，help message 输出，PYTHONPATH 设置等。
答案在代码中：“实现需求”的双重含义 | Piglei
是否能通过读代码来轻松还原需求 的能力很重要，有时候写一些隐式的条件判断，很容易在后续修改的时候就产生 regression 。
Building a tiny 6-drive M.2 NAS with the Rock 5 model B | Jeff Geerling
使用 Rock5 配合 6个 M.2 的磁盘组成的小型 NAS。（我一直觉得没有那么多数据要存储
RSS Vs Atom Feeds In 2023: Unveiling The Ultimate Winner
作为用户其实我不是很关心 rss /atom 具体差异，Atom 中提供了哪些新的属性对我来说改善真的不大，毕竟现在各个阅读器的阅读体验永远也比不了源站点，只要能稳定长久的提供就可以了，很多资源都没办法做到稳定长久的提供订阅地址，没有资格谈论 rss vs atom 这个话题。</description></item><item><title>Weekly Issue 2023-07-09</title><link>https://zdyxry.github.io/2023/07/09/Weekly-Issue-2023-07-09/</link><pubDate>Sun, 09 Jul 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/07/09/Weekly-Issue-2023-07-09/</guid><description>文章 链接到标题 技术 链接到标题 Google Search&amp;rsquo;s Death by a Thousand Cuts
上周在搜索的时候收到了 [[Reddit]] 事件的影响，互联网越来越封闭，如何有效的获取信息已经是一个有门槛的事情了。
https://blog.webp.se/golang-libvips-cgo-zh/
[[Golang]] 跨平台编译的问题以及解决方式。如果一定要用 CGO，还是提供 container 方式吧。
https://xeiaso.net/blog/nosleep
避免在[[单元测试]]中引入 sleep ，如果需要需要通知机制，可以使用其他方式，比如 channel。
MPTCP: 一个在 Go 1.21中的被忽略的新特性
[[Golang]] 1.21 增加 [[MPTCP]] 支持。
它允许一个连接同时使用多个网络接口。
如果连接绑定到链路速度，则使用多个链接可能会增加连接的吞吐量。请注意，如果连接绑定到 CPU，则使用多个链路会导致连接性能下降。
它提高对链接故障的恢复能力。
TCP 拥塞控制对数据延迟的影响 | 卡瓦邦噶！
通过实际问题了解[[TCP]] [[拥塞控制]]。 通过人为使用 ip route 设置 initcwnd 调整。
开源不等于免费：Red Hat 调整 CentOS 项目带来的思考
继续 [[RedHat]] 事件，这篇文章写的很好，把 [[centos]] 背景，不同的产品带来的优势、对 RedHat 的影响都交代的很清楚。如果没有 [[centos]]， [[RHEL]]也不会有今天这样的影响力。
Cloud Dependencies Need to Stop F-ing Us When They Go Down - The New Stack</description></item><item><title>Weekly Issue 2023-07-02</title><link>https://zdyxry.github.io/2023/07/02/Weekly-Issue-2023-07-02/</link><pubDate>Sun, 02 Jul 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/07/02/Weekly-Issue-2023-07-02/</guid><description>文章 链接到标题 技术 链接到标题 How to use GitHub Copilot: Prompts, tips, and use cases | The GitHub Blog
[[copilot]] 的一些技巧，总结下来就是假象在结对编程，尽可能的细粒度告诉对方当下的想法。
Monitoring is a Pain
关于 [[monitor]] 的一些思考，包含 Logs，Metrics，Traces 。
日志级别和格式混乱,没有共识。日志被用于各种用途,从调试到业务分析,使其变得极为关键，存储成本高昂,大多数日志从未被使用。
Metrics 很好，但是当前 [[prometheus]] 生态在后续的扩展上没有那么容易。
Backup and Restore Containers With Kubernetes Checkpointing API | by Martin Heinz | Better Programming
[[kubernetes]] [[Pod]] checkpoint 方式，后续应该可以作为 Pod Live Migration 的前置动作。
I&amp;rsquo;m done with Red Hat (Enterprise Linux) | Jeff Geerling
[[RedHat]] 事情继续发酵，目前官方态度很明确，不会进行改动。这篇文章有些后有趣的描述。比如：</description></item><item><title>Weekly Issue 2023-06-25</title><link>https://zdyxry.github.io/2023/06/25/Weekly-Issue-2023-06-25/</link><pubDate>Sun, 25 Jun 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/06/25/Weekly-Issue-2023-06-25/</guid><description>文章 链接到标题 技术 链接到标题 MTU 和 UDP (以及基于 UDP 的协议) | 卡瓦邦噶！
如果你要基于 UDP 实现一个协议，就要自己处理超过 [[MTU]] 的问题。
最后是 QUIC，这个最具有代表性。它的处理方法是：
QUIC 的实现应该（RFC 用的是 SHOULD）使用 PMTUD，并且应该记录每一个 source ip + dest ip 的 MTU
但是如果没有 PMTUD 的话，也可以认为 MTU=1280，协议设置 max_udp_payload_size = 1200 bytes，如此，按照上面的算法的话，IPv4 的 header 最多可以有 52 bytes，IPv6 的 header 可以有 32 bytes，正常情况下也够用
如果链路上连 1280 的 PDU 都支持不了，QUIC 就会这个 UDP 无法使用（和端口连不上等同），然后会 fallback 到 TCP
The case of the supersized shebang [LWN.net]
shebang 截断方式的改动导致NixOS 无法正常工作。 [[Perl]] 解释器会重新读取 shebang 。</description></item><item><title>使用 Notion 实现稍后阅读</title><link>https://zdyxry.github.io/2023/06/22/%E4%BD%BF%E7%94%A8-Notion-%E5%AE%9E%E7%8E%B0%E7%A8%8D%E5%90%8E%E9%98%85%E8%AF%BB/</link><pubDate>Thu, 22 Jun 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/06/22/%E4%BD%BF%E7%94%A8-Notion-%E5%AE%9E%E7%8E%B0%E7%A8%8D%E5%90%8E%E9%98%85%E8%AF%BB/</guid><description>Notion 链接到标题 在 Pocket 数据分析和总结 中提到，我的稍后阅读工具从 Pocket 迁移到了 Notion，正好今天解决了一个之前没有解决的问题（随机阅读），觉得现在已经很符合我的需求了，分享一下。
使用 Notion Database 存储所有的文章，每篇文章的基本属性设置：
URL # 对应链接地址 Created Time # 创建时间 Read Time # 阅读时间 Read # checkbox 类型，用于标记是否阅读 Tags # Multi-select 类型，用于标记文章关联 tag Rand # 根据文章信息生成随机数 添加 链接到标题 Notion 官方提供了浏览器插件：Notion Web Clipper，当使用浏览器时，可以直接点击插件，会要求设置标题，所属 Workspace，所属 Page/Database。其中标题会自动提取当前链接的标题，所属 Workspace 和 Page/Database 设置一次即可，后续会自动填充上一次配置。
如果使用手机浏览信息，可以通过对应应用的“分享”功能，iOS/Android 都可以，选择文章，分享，选择 Notion ，所需填写的内容与浏览器插件一致，使用默认设置填充的内容即可。
展示 链接到标题 Notion Database 可以自定义属性是否需要展示，可以选择性的在不同的 View 中展示需要的属性，便于后续阅读和编辑。
我自己设置了4个 View：
未读 已读 全部 随机未读 统一展示的属性有：
Title # 用于查看链接标题 URL # 可以直接点击链接跳转 Read(checkbox) # 可以快速标记是否已读 Created Time # 查看收藏时间 Tags # 查看当前链接关联 Tag，可以根据 Tag 快速过滤 通常在列表模式下就够用了，在阅读的时候跳转都链接阅读（理论阅读体验最佳），阅读完成后标记已读。但是稍后阅读中存在一种情况，即原链接已经失效了，这个时候就需要在 Notion 中查看原链接内容，Notion 抓取的内容目前可以保证的有文字和部分图片，抓取后的格式没有保证，但基本的可读性是可以做到的，日常使用场景：博客、微信公众号、PDF 链接都是可以的。</description></item><item><title>Weekly Issue 2023-06-18</title><link>https://zdyxry.github.io/2023/06/18/Weekly-Issue-2023-06-18/</link><pubDate>Sun, 18 Jun 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/06/18/Weekly-Issue-2023-06-18/</guid><description>文章 链接到标题 技术 链接到标题 我的 ETH 被盗了 - forecho&amp;rsquo;s Blog
私钥直接提交到了 [[github]]，导致 [[ETH]] 被盗。在开发过程中尽量使用环境变量来获取一些敏感信息，有时候写 demo 代码的时候可能图方便就直接 hardcode 了，但可能带来的影响是很容易忽略的。
也有人推荐使用 [[git-secrets]] 在提交代码之前检查是否存在敏感信息。
云SLA是不是安慰剂？
然而，SLA 被有意地与服务的真实可靠性相混淆：用户不应该将 SLA 视作来服务可用性的可靠预测指标 —— 甚至是过去可用性水平的真实记录。对于厂家来说，****SLA 并不是真正的可靠性承诺或历史战绩，而是一种营销工具****，旨在让买家相信云厂商可以托管关键业务应用。
所以，SLA 对用户来说不是兜底损失的保险单。在最坏的情况下，它是吃不了兜着走的哑巴亏。在最好的情况下，它才是提供情绪价值的安慰剂。
文章中提到的是单个云服务商的 [[SLA]]，现在很多应用都同时在使用很多的 [[PaaS]] 提供的服务，这个时候很难计算自己应用的[[SLA]] 是多少。
How the data center site selection process works at Dropbox - Dropbox
[[Dropbox]] 如何选择 [[IDC]]。
确认需求：
电源、机柜空间、可上线时间。根据需求联系市场上活跃的供应商。 了解供应商能力：
基础设施设计规范，包含电源、冷却、容错能力。 承重能力，需要考虑各个机柜的重量。 网络设计，流量出入，有哪些可选运营商。 挖掘细节：
UPS 能力。 是否可以按照预期施工。 监控报警是否完备。 实际走访
根据线下参观，确认实际细节是否匹配。 为一些关键能力打分：机柜空间、电力、冷却、网络、安全、地域灾害（是否处于洪水和地震区域）、运维支持、后勤。 谈判租约
租金：电力成本、空间成本、优惠减免。 I booted Linux 292,612 times | Richard WM Jones</description></item><item><title>Weekly Issue 2023-06-11</title><link>https://zdyxry.github.io/2023/06/11/Weekly-Issue-2023-06-11/</link><pubDate>Sun, 11 Jun 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/06/11/Weekly-Issue-2023-06-11/</guid><description>文章 链接到标题 技术 链接到标题 OAuth Authentication with Flask in 2023 - miguelgrinberg.com
[[Flask]] 实现[[OAuth]] 示例，介绍了如何配置 Provider，如何设置 callback url ，如何使用 authorization code 获取 access token 流程。代码很清理，不到 200行，很适合了解 [[OAuth]] 。
代码地址： GitHub - miguelgrinberg/flask-oauth-example: Example code from my &amp;ldquo;OAuth Authentication with Flask&amp;rdquo; article.
Trailing Dots in Domain Names
关于域名中最后的 . 介绍和说明：如果是 www.example.com. ，那么就是绝对域名；如果是 www.example.com 那么就是相对域名，在应用了每个DNS搜索列表中总是隐含的&amp;quot;. &amp;ldquo;后，变成了www.example.com. ；如果输入 www 并且 DNS 搜索域中包含 example.com ，那么会得到 www.example.com.
DNS Lookups in Kubernetes
[[kubernetes]] 中 [[DNS]] 解析的优先级，可以直接硬编码 FQDN 来减少无效解析。</description></item><item><title>Weekly Issue 2023-06-04</title><link>https://zdyxry.github.io/2023/06/04/Weekly-Issue-2023-06-04/</link><pubDate>Sun, 04 Jun 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/06/04/Weekly-Issue-2023-06-04/</guid><description>文章 链接到标题 技术 链接到标题 Prometheus 的 Summary 和 Histogram
[[prometheus]] 的 Summary 类型和 Histogram 类型。之前内部实现网络监控功能的时候，使用了 Histogram ，Bucket 的划分粒度比较重要，如果划分的不好那么结果的偏差可能会比较大。
记一次 BUG 定位：时钟偏移引起 K8S 鉴权失败 | 三点水
[[kubernetes]] 节点时钟不一致导致的[[JWT]] 校验不通过问题。
B 节点的时间比 A 节点快 1min30s;
任务被调度到 B 节点，B 节点的 kubelet 为 Pod 生成 SA token，token 的 nbf 时间为 B 节点的当前时间。（这里应该是创建 token 的请求会发往 B 的 apiserver，目前没找到方法验证）;
B 节点里需要访问 apiserver，会访问 kubernetes.default，请求被路由到节点 A;
A 节点在校验 JWT 时发现 token 的 nbf 在 A 节点当前时间+ 1min 之后，拒绝请求;</description></item><item><title>Weekly Issue 2023-05-28</title><link>https://zdyxry.github.io/2023/05/28/Weekly-Issue-2023-05-28/</link><pubDate>Sun, 28 May 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/05/28/Weekly-Issue-2023-05-28/</guid><description>文章 链接到标题 技术 链接到标题 一个十万行的 trackback | 卡瓦邦噶！
从 PEP 3134 中发现，Python3 已经把和一个 Exception 有关的 traceback，局部变量等放到 Exception 对象中了。这里也说，你不能明确地指定一个 Python Exception 的 traceback。按照我们上面中代码的行为看，就是，Python 在 raise Exception 的时候，会把当前的 stack 写到 traceback 中，但是如果当前已经有 traceback 了的话，就会把之前的 traceback 保留住。（但是没有找到相关资料和代码，欢迎读者补充）
[[Python2]] 和 [[Python3]]关于 Exception 的处理有很大的不一样，之前学习 raise 的差异时看到过类似讨论： python - Difference between &amp;ldquo;raise&amp;rdquo; and &amp;ldquo;raise e&amp;rdquo;? - Stack Overflow
The Many Layers of Packaging — Sedimental
非常精彩的[[包管理器]] 的讨论，往往讨论 [[Python]] 的分发方式时，容易跑偏（比如：我用 venv 去打包，为啥不直接用 [[Container]]），这篇文章从不同的层面去讨论，讲的很好。
[译] NAT 穿透是如何工作的：技术原理及企业级实践（Tailscale, 2020）</description></item><item><title>Weekly Issue 2023-05-21</title><link>https://zdyxry.github.io/2023/05/21/Weekly-Issue-2023-05-21/</link><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/05/21/Weekly-Issue-2023-05-21/</guid><description>文章 链接到标题 技术 链接到标题 Slack Said It Had 100% Uptime. Did It Really? - Metrist
[[Slack]] 报告自己的在线时间是100%，但是实际上不是这样， [[Slack]] 自己对于停机时间的定义有些狭隘，也许是为了 100% 看着好看，说出去比较好听，但是实际上作为 [[Slack]] 的用户体验并不是这样的，部分用户确实是经历了停机时间的。作为 [[SaaS]] 服务商应该以用户体验为准。
像[[metrist]] 这类产品，如果各家服务商自己的 status 页面提供了 RSS 接口，是不是就可以被替代了。
几种使用Go发送IP包的方法
操作 IP packet 的方式。
Sandboxing and Workload Isolation · Fly
有 [[Container]] 的情况下还是用 [[Container]]，没有的话推荐使用 systemd-nspawn ，毕竟 [[systemd]] 是现在的事实标准，不需要额外的依赖。
Investigating the impact of HTTP3 on network latency for search - Dropbox
[[Dropbox]] 关于 [[HTTP/3]] 的测试数据，在可能发生数据包丢失的网络环境中， [[HTTP/3]]针对 head-of-line blocking 的处理显著降低了延迟。</description></item><item><title>单口喜剧与冒犯</title><link>https://zdyxry.github.io/2023/05/20/%E5%8D%95%E5%8F%A3%E5%96%9C%E5%89%A7%E4%B8%8E%E5%86%92%E7%8A%AF/</link><pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/05/20/%E5%8D%95%E5%8F%A3%E5%96%9C%E5%89%A7%E4%B8%8E%E5%86%92%E7%8A%AF/</guid><description>碎碎念 链接到标题 最近单口喜剧连续微博霸榜，事情发展的太快，导致都来不及有一个完整的思考，写一篇博客记录一下自己的想法。
观众看单口喜剧的目的是什么，是为了获得快乐，获得快乐的方式是观看单口喜剧演员的表演，表演或是文本或是互动。部分单口喜剧带有观点，但是通常观点是穿插在笑点中的，如果一场演出全是观点没有笑点，那不是单口喜剧，那是演讲。
冒犯，意思是指言语或行为没有礼貌，冲撞了对方。每个人的成长经历、生活环境以及敏感程度是不同的，冒犯是一个完全主观上的概念，冒犯的主体很重要，谁来发起冒犯，会得到完全不同的响应，这是与双方的身份地位有直接关系。如果我感觉到被言语冒犯，那我可以提出，你刚刚冒犯到我，注意这里是言语上的沟通，不是利用强权去反击（比如威尔史密斯的拳头）。冒犯是言论自由的附带伤害。
“（单口）喜剧是冒犯的艺术”？
前面提到，观看单口喜剧的目的是获得快乐，如果演员去冒犯特定的个体或某个群体，那么观众中会有人觉得被冒犯，那么他会在这个时间点获得快乐么？如果是我，不会的。在我看来，冒犯是一种迎合，一种技巧，用来快速拉近距离的技巧，通过冒犯一部分群体来拉近另一部分群体距离的技巧，而技巧是服务于内容的，如果演员只有冒犯没有内容，没办法把通过冒犯导致距离拉远的观众拉回来，迎接的很有可能是冷场。
那段录音中，现场气氛好不好？好，很多人会说不好笑，那是因为只听了录音，线下演出应该用现场观众的反应来评判，而不是单独拿其中的一个段子评价是否好笑。如果把《特大新闻》搬到现在，截取其中“xx出事儿了”的一分钟录音，好笑么？是冒犯么？不同的人有不同的定义，我们不能一边夸20年前的人真敢说，一边消灭现在还在说话的人，拿“喜剧是冒犯的艺术”这句话来回应这件事的，就是懒。
单口喜剧，是一个剧，剧里说了什么，剧里演了什么，都是剧本身。</description></item><item><title>单口喜剧专场观看记录</title><link>https://zdyxry.github.io/2023/05/17/%E5%8D%95%E5%8F%A3%E5%96%9C%E5%89%A7%E4%B8%93%E5%9C%BA%E8%A7%82%E7%9C%8B%E8%AE%B0%E5%BD%95/</link><pubDate>Wed, 17 May 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/05/17/%E5%8D%95%E5%8F%A3%E5%96%9C%E5%89%A7%E4%B8%93%E5%9C%BA%E8%A7%82%E7%9C%8B%E8%AE%B0%E5%BD%95/</guid><description> 碎碎念 链接到标题 现在能持续带来快乐的事物不多，对我来说单口喜剧是一个明确的答案。最早是 2018 年在北京看单立人的拼盘演出，带来的快乐简单而直接，最近的舆论情形，很多演员见不到了，很多专场也可能再也看不到了，看一场少一场，尽量多看看吧。
单口喜剧 链接到标题 Storm-《牵手失败》，2020/09/16，上海，喜剧联盒国，Bilibili。 小鹿-《真娘们儿》，2020/10/17，上海，单立人喜剧，创邑SPACE源。 刘旸教主-《庄谐不二》，2021/05/16，上海，单立人喜剧，优酷。 郝雨-《咋就不对劲》，2021/10/10，上海，单立人喜剧，上海话剧艺术中心。 孙书恒-《鸟儿》，2021/12/27，上海，-，微博。 Storm-《上上》，2022/02/27，上海，喜剧联盒国，Bilibili。 刘旸教主-《天生有意思》，2022/04/29，上海，单立人喜剧，Bilibili。 六兽-《大兽儿》，2022/04/29，上海，单立人喜剧，Bilibili。 王十七-《方心未艾》，2023/01/08，上海，喜剧联盒国，喜剧盒子。 宁家宇-《两句》，2023/03/19，上海，喜剧联盒国，尽情空间。 Storm-《请回答1987》，2023/04/03，上海，喜剧联盒国，Bilibili。 刘旸教主-《伊卡洛斯》，2023/04/23，上海，单立人喜剧，YOUNG剧场。 宋万博-《看呐，这人》，2023/04/29，无锡，大发喜剧，书码头。 宋万博-《天生非此》，2023/04/29，无锡，大发喜剧，书码头。 梁彦增-《鸽子的芳心》，2023/06/22，上海，猫头鹰喜剧，THE BOXX。 子龙-《作乐》，2023/07/29，常州，有点意思俱乐部，希尔顿酒店。</description></item><item><title>Weekly Issue 2023-05-14</title><link>https://zdyxry.github.io/2023/05/14/Weekly-Issue-2023-05-14/</link><pubDate>Sun, 14 May 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/05/14/Weekly-Issue-2023-05-14/</guid><description>文章 链接到标题 技术 链接到标题 使用 FFMPEG 编辑视频
使用 [[ffmpeg]] 合并、裁剪视频。
Cilium 基于 eBPF 实现 socket 加速
使用BPF_MAP_TYPE_SOCKHASH 存储 socket 信息, BPF_PROG_TYPE_SOCK_OPS 拦截系统中 socket 建立连接操作 , BPF_PROG_TYPE_SK_MSG 拦截系统中 sendmsg 系统调用，提取 key，将数据直接重定向到对端 socket。
使用 eBPF socket 加速之后，吞吐量和发送消息大小呈线性关系。这是因为当应用程序发送较大的消息时，几乎没有额外的开销，但是当发送消息比较小时，使用 TCP/IP 协议栈，反而吞吐量会大于 eBPF socket 加速之后的吞吐量，这是由于 TCP/IP 栈默认开启了 Nagle 算法。Nagle 的算法是用来解决小数据包在慢速网络中泛滥导致拥塞的问题，在该算法中只要有一个 TCP 段在小于 TCP MSS 大小的情况下未被确认，就会进行批处理传输数据操作。这种批处理导致一次传输更多的数据并分摊开销，所以能超过 eBPF socket 加速之后吞吐量。但是随着发送消息越来越大，超过 MSS，TCP/IP 栈就会失去其批处理优势，在这些大数据包发送大小下，eBPF socket 加速凭借其低开销远远超过启用 Nagle 算法的 TCP/IP 栈的吞吐量。
你真的会使用 ChatGPT 吗？ | 第一章：Guidelines for Prompting
感觉有点像 How-To-Ask-Questions-The-Smart-Way/README-zh_CN.</description></item><item><title>Weekly Issue 2023-05-07</title><link>https://zdyxry.github.io/2023/05/07/Weekly-Issue-2023-05-07/</link><pubDate>Sun, 07 May 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/05/07/Weekly-Issue-2023-05-07/</guid><description>文章 链接到标题 技术 链接到标题 You&amp;rsquo;re Allowed To Make Your Own Tools
编写一些工具来让自己的工作/生活更舒适。
Quick tip: A time-saving Makefile for your Go projects – Alex Edwards
[[Golang]] 项目的[[Makefile]] 模板，包含常用的 tidy、lint、test、build。 可以用 [[Just]] 和[[Task]] 来替代，配合阅读： Taskfile vs Justfile :: Thanh&amp;rsquo;s Islet
Electron：厌恶，理解与成为 | pengx17
[[AFFiNE]]放弃了使用[[Tauri]] ，重新使用了[[Electron]] 。提到了一些 [[Tauri]]的问题：
Tauri在一些疑难杂症和跨平台方案上存在一些不一致的问题，这需要我们付出更多的精力和时间去解决。 我们对于Rust的掌握程度还不够熟练，这导致我们在应用开发的过程中经常会遇到一些看似简单的问题，但却卡住了很久。 Enhance Your Internet Privacy in 2023 - GeekPlux
合理的使用 [[CloudFlare]] 1.1.1.1 和 iCloud 代理来保护隐私。
生活 链接到标题 又想到了一点风险，记录下来。 - Xiaowen.Z Deployed
郭嘉基于政策有效性、金融安全等考量，通过利率管制、牌照准入等手段，保障商业银行超乎寻常的利润水平；而商业银行作为回报，要在郭嘉有需要的时候，牺牲经营业绩和股东利益，支持和服务郭嘉政策落地。这种不成文的默契以动态的方式一轮轮的持续下去，构成了中国特色社会主义金融业的底层逻辑。
书影 链接到标题 《深入理解 Linux 网络》，阅读了第三章，感觉学到不少。</description></item><item><title>Weekly Issue 2023-04-30</title><link>https://zdyxry.github.io/2023/04/30/Weekly-Issue-2023-04-30/</link><pubDate>Sun, 30 Apr 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/04/30/Weekly-Issue-2023-04-30/</guid><description>文章 链接到标题 技术 链接到标题 服务端性能优化&amp;ndash;最大QPS推算及验证 - huangyingsheng - 博客园
关于 [[QPS]] 的计算方式，最大 QPS，最佳线程数。单线程𝑄𝑃𝑆=1000𝑚𝑠/𝑅𝑇。最佳线程数 = (RT/CPU Time) x CPU 核数 x CPU利用率 。
绕过 Cloudflare 指纹护盾 | Sxyazi’s blog
貌似很多站点都会检测 [[Golang]] 的 Cipher Suites，之前应该是[[v2ray]] 提到过类似问题。通过使用 GitHub - refraction-networking/utls: Fork of the Go standard TLS library, providing low-level access to the ClientHello for mimicry purposes. 可以进行更改。
配合阅读：为什么用 Go 访问某网站始终会 503 Service Unavailable ？ | 无辄的栈
How to Gracefully Close Channels -Go 101</description></item><item><title>Weekly Issue 2023-04-23</title><link>https://zdyxry.github.io/2023/04/23/Weekly-Issue-2023-04-23/</link><pubDate>Sun, 23 Apr 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/04/23/Weekly-Issue-2023-04-23/</guid><description>文章 链接到标题 技术 链接到标题 2023 年 KCD 大连站活动后记 （2023-04-15） - 马全一/马道长
真正的后记来了，从离开腾讯后确实没有怎么关注云原生领域的发展。从当前的感觉来看，这个领域已经没有特别地创新。不知道是真的进入落地阶段，还是已经进入自嗨、回魂还是僵死。正好第二天转机到阿姆斯特丹参加 KubeCon ，是一个近距观察的机会。
Load Balancing
常见负载均衡策略讲解，图文并茂，包含轮询，加权轮询，最小连接数，以及Peak EWMA 。
配合阅读： Beyond Round Robin: Load Balancing for Latency | Linkerd 不同策略之间的差异与其说是算法上的差异，不如说是用于做出平衡决策的信息上的差异。
Pricing v3, plans, packages, and debugging · Tailscale
[[TailScale]] 更改了自己的定价策略，在现有用户数据的支持下，解释做出这样变更的原因。免费团队支持3个用户，100个设备。
nohup,setsid与disown的不同之处 - 暗无天日
nohup 会关闭进程的stdin，当进程尝试读取输入时，只会得到EOF。disown命令会将命令从bash的job list中删除。 这样，当bash收到SIGHUP信号后，并不会将SIGHUP信号发送给该命令。
若调用setsid函数的进程就是一个进程组的组长，则该函数会返回出错。 为了解决这种情况，通常函数需要先fork，然后父进程退出，由子进程执行setsid。 由于子进程继承的是父进程的进程组ID，而其PID是新分配的ID，因此这两者不可能相等，即子进程不可能是进程组的组长。 这种情况下，由于父进程先于子进程退出，因此子进程的父进程会有init进程接管。 而这就是sid命令的实现原理。
Kubernetes 1.27: Query Node Logs Using The Kubelet API | Kubernetes
[[kubernetes]] 可以通过 kubelet API 获取 Host 节点上的日志。这个功能是 [[openshift]] 贡献的。</description></item><item><title>Weekly Issue 2023-04-16</title><link>https://zdyxry.github.io/2023/04/16/Weekly-Issue-2023-04-16/</link><pubDate>Sun, 16 Apr 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/04/16/Weekly-Issue-2023-04-16/</guid><description>文章 链接到标题 技术 链接到标题 Database Architects: The Great CPU Stagnation
[[CPU]] 性能的快速增长已经消失，作者分别通过 Cores/$, (Cores*GHz * IPC)/$ 和 B transistors/$ 来进行比较，验证近5年来的发展速度缓慢。
个人网盘使用经验
大家真的有那么多东西需要存储么？感觉我日常需要的更多的是备份场景，不需要一个随时可以读写的NAS。
CodePilot | Synchronization Patterns in Go
[[Golang]] 中实现同步机制的一些方式，Mutex,Semaphore, Channel.
David Klee - vNUMA and You - YouTube
合理的配置 [[vNUMA]]来保证应用可以更好的运行，前提是你明确的知道你的应用需要多少计算资源。
实用 Web API 规范 | Log4D
[[API]] 设计规范。之前也看过一些公司的设计规范，但是很难去实际实施。
不想当作家的程序员写不出 Redis | 程序员的喵
[[redis]] 作者的一些故事。
运行良好的复杂系统往往由简单设计演化而来，而一个从开头设计的复杂系统往往不行，通过打补丁的方式通常也无法解决
Uptime Guarantees — A Pragmatic Perspective
应该追求什么级别的 [[SLA]]？理论上越高越好，但实际上从成本考虑，可能适合产品的才是最好的，需要评估宕机带来的直接损失，来确定自己可以容忍的时间，99.99% 比 99.5% 要付出的精力、成本多得多。有时候故障可能与技术实现无关，可能与运营有关。
实际的例子：Github Action Q1 故障次数达到了 55次，但是不影响大家持续的使用它，可能会带来抱怨，但是说带来的实际损失，可能也无法进行准确的评估。</description></item><item><title>Weekly Issue 2023-04-09</title><link>https://zdyxry.github.io/2023/04/09/Weekly-Issue-2023-04-09/</link><pubDate>Sun, 09 Apr 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/04/09/Weekly-Issue-2023-04-09/</guid><description>文章 链接到标题 技术 链接到标题 Read Every Single Error | Pulumi Blog
阅读每一条错误日志，人力是有限的，如果不能持续保持错误率的提高，那么随着 API 调用的增加，注定 Oncall 精力是不够的：(API Call Volume) * (Error Rate) * (Time to Triage an Error) &amp;lt; On-Call Attention 。SRE 模型和错误预算是高级时尚，而跳过步骤直接进入高级阶段并不总是有益的。相反，最好使用合适规模的工具和流程。
Sure you can hire and split systems out into separate on-call rotations to increase capacity, but our goal is to scale exponentially with respect to humans, not linearly!
引用推友的话:
最核心就是有人盯着这个事情，我们内部 sentry alert 数量从去年每分钟 300 多，今年变成 20 多，就是每周一把异常报错最多的 top5 项目拉出来，让项目负责的工程师看看具体是怎么回事。</description></item><item><title>Weekly Issue 2023-04-02</title><link>https://zdyxry.github.io/2023/04/02/Weekly-Issue-2023-04-02/</link><pubDate>Sun, 02 Apr 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/04/02/Weekly-Issue-2023-04-02/</guid><description>文章 链接到标题 技术 链接到标题 Weka Violates MinIO&amp;rsquo;s Open Source Licenses
[[Minio]] 再次撤销许可，上一次是 [[Nutanix]]。这篇报道We object! MinIO says no more open license for Weka – Blocks and Files 中提到，有用户说 [[Minio]] 每年通过许可协议收取 7位数的收益。
Why I Will Never Use Alpine Linux Ever Again | Martin Heinz | Personal Website &amp;amp; Blog
不再使用 [[alpine]] 的原因：不支持 DNS-over-TCP；很多依赖 C 的工具/库都会受到 musl 和 glibc 差异的影响。
关于 [[alpine]] DNS 问题的另一篇文章： Does Alpine resolve DNS properly? | Purplecarrot
我的AI阅读助手 · BMPI</description></item><item><title>Shell 携带通配符执行顺序</title><link>https://zdyxry.github.io/2023/04/01/Shell-%E6%90%BA%E5%B8%A6%E9%80%9A%E9%85%8D%E7%AC%A6%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/</link><pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/04/01/Shell-%E6%90%BA%E5%B8%A6%E9%80%9A%E9%85%8D%E7%AC%A6%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/</guid><description>背景 链接到标题 这周有同事在 Slack 问了一个问题： 发现在v505和v503的集群主机上 sudo的配置有一点点小问题：普通用户使用sudo时 shell中的 wildcard不生效 。
环境状态大概是这样的： 系统存在普通用户 yiran ，并配置了 sudo 权限，同时系统存在 /var/log/libvirt/qemu/ 路径，其中 libvirt 和 qemu 的目录 owner 是 root，权限是700， qemu 下存在很多以 .log 为结尾的文件，owner 是 root，权限是 600，具体示例如下：
[yiran@node11 11:09:35 ~]$id yiran uid=1002(yiran) gid=1002(yiran) groups=1002(yiran) [yiran@node11 11:09:40 ~]$sudo ls -l /var/log/ |grep libvirt drwx------. 3 root root 4096 Sep 16 2022 libvirt [yiran@node11 11:09:45 ~]$sudo ls -l /var/log/libvirt |grep qemu drwx------. 2 root root 319488 Mar 26 03:07 qemu [yiran@node11 11:09:48 ~]$sudo ls -l /var/log/libvirt/qemu/ |egrep *.</description></item><item><title>Weekly Issue 2023-03-26</title><link>https://zdyxry.github.io/2023/03/26/Weekly-Issue-2023-03-26/</link><pubDate>Sun, 26 Mar 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/03/26/Weekly-Issue-2023-03-26/</guid><description>文章 链接到标题 技术 链接到标题 Tracking the Fake GitHub Star Black Market with Dagster, dbt and BigQuery | Dagster Blog
如何识别 [[github]]中的含有虚假star 的项目。
由一个子网掩码配置错误所想到的 | 卡瓦邦噶！
[[子网掩码]]错误配置可能出现的现象。在机房中倒是经常会遇到类似的配置错误的环境。
突破难关：Docker镜像和容器的区别以及构建的最佳实践 | MoeLove
[[容器]] 镜像的最佳实践。其中提到关于包管理的部分需要谨慎使用。
37signals Dev — De-cloud and de-k8s — bringing our apps back home
[[37Signals]] 将服务从[[公有云]] 和 [[kubernetes]] 迁移出来的记录，使用到之前开源的 [[mask]] 工具。
We updated our RSA SSH host key | The GitHub Blog
[[github]]因为短暂的泄漏了自己的私钥，进行了对应的更新。
如何高效地协作开发：一些 Google 的实践
在 Google 的三年多里，我们团队的 project manager 对于工程师来说存在感一直比较低，项管不会过多干预个人的工作计划。每个工程师都相当于自己的项管，工程师之间会互相就优先级进行沟通达成共识和妥协。这样的好处是工作量小但 block 了其他人的事情会被快速完成；实际做事情的人用专业的语言沟通，不需第三者传话，也不容易造成误解；一些重要但不紧急的事情，比如重构、还技术债，也可以由工程师在日常工作中穿插地推进。</description></item><item><title>证书 CommonName 和 subjectAltName 的关系</title><link>https://zdyxry.github.io/2023/03/25/%E8%AF%81%E4%B9%A6-CommonName-%E5%92%8C-subjectAltName-%E7%9A%84%E5%85%B3%E7%B3%BB/</link><pubDate>Sat, 25 Mar 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/03/25/%E8%AF%81%E4%B9%A6-CommonName-%E5%92%8C-subjectAltName-%E7%9A%84%E5%85%B3%E7%B3%BB/</guid><description>背景 链接到标题 因为产品中的 HTTPS 所用证书是自签发证书，不满足一些场景的安全要求，需要导入用户证书。本身这个变更很容易，只需要按照Nginx 官方文档 配置下指定证书即可，但遇到了一个特殊的场景：集群存在3个节点，每个节点用户配置了相应的 Domain Name，其中集群中存在 VIP(Virtual IP Address) ，用户给对应的 VIP 配置了相应的 Domain Name。用户在签发证书时，使用的 CN(CommonName) 是 VIP 对应的 Domain Name，subjectAltName 是集群中3个节点的 Domain Name。此时如果通过各个节点相应的 Domain Name 访问，证书有效，但是通过 VIP 对应的 Domain Name 访问，证书无效（因环境特殊，未能看到具体错误提示）。
印象中 CommonName 必须指定对应的 Domain Name，subjectAltName 是 CommonName 的补充，所以这个现象感觉不合理，然后查阅了相关资料进行调查。
GPT4 链接到标题 在调查之前，按照现在的主流操作，遇事不决先问 GPT，于是得到了如下答复，也符合我的理解：
问：
在 https 证书中，如果 CommonName 一定存在于 SubjectAltName 中么？如果同时存在 CommonName 和 SubjectName ，使用哪个作为唯一标识校验？
答：
在HTTPS证书中，CommonName（CN）和Subject Alternative Name（SAN）是用于标识证书所表示的域名的字段。在早期的SSL/TLS证书中，CommonName通常用于表示证书关联的单个域名。然而，随着时间的推移，Subject Alternative Name扩展被广泛采用，它允许证书关联多个域名和子域名。
从技术上讲，CommonName不一定需要出现在Subject Alternative Name列表中。但是，实际上，许多现代浏览器和客户端会首先检查Subject Alternative Name字段，如果没有找到匹配的域名，才会检查CommonName字段。因此，为了确保证书的兼容性和正确性，建议将CommonName包含在Subject Alternative Name字段中。</description></item><item><title>Weekly Issue 2023-03-18</title><link>https://zdyxry.github.io/2023/03/18/Weekly-Issue-2023-03-18/</link><pubDate>Sat, 18 Mar 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/03/18/Weekly-Issue-2023-03-18/</guid><description>文章 链接到标题 技术 链接到标题 After four years of SMR storage, here&amp;rsquo;s what we love—and what comes next - Dropbox
与 [[Backblaze]] 不同， [[Dropbox]] 目前大量使用[[SMR]] 磁盘。密度高，省电，服务器数量减少，维修成本降低。
简单聊聊 IaC：Infrastructure as Code - Manjusaka
最近在使用 [[Packer]]配合 [[terraform]] 来帮助我自动的创建一些环境（虚拟机），我的创建是 [[vSphere]] 已经存在，如果只是创建新的虚拟机，那不会遇到太多问题，但是如果我想要针对某一个[[vSphere]] 集群中的所有主机增加一个 vswitch，然后新创建的虚拟机关联的是对应的 vswitch，这个需求就很难做到，首先想要从集群获取到所有主机，就需要先 import resource，而 import resource 和 code 中定义的 resource 中的状态是有很大差别的，所以import resouce 之后，需要去更新 code 中定义的对应 resource，然后继续后续步骤，整体流程一点也不 [[IaC]] ，社区中有一些自动 import resource 并生成 code 的项目，但是对于各个 provider 的支持力度有限，感觉这个场景应该在 [[terraform]] 中做，而不是去适配。
[Ipmitool-devel] GitHub account suspended | IPMItool</description></item><item><title>Weekly Issue 2023-03-12</title><link>https://zdyxry.github.io/2023/03/12/Weekly-Issue-2023-03-12/</link><pubDate>Sun, 12 Mar 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/03/12/Weekly-Issue-2023-03-12/</guid><description>文章 链接到标题 技术 链接到标题 苹果：为了安全让 M2 吃灰 | 程序员的喵
[[MacOS]] [[SIP]] 严重影响性能。
简而言之 SIP 会在我们跑任软件之前，把你的执行文件做一个校验和，然后通过网络请求发送到让人敬畏的苹果服务器，就是为了检测是否是恶意软件！
谈谈我对 ChatGPT 应用的 prompt 的看法 |
提到了一些 [[Prompt]] 小技巧。昨天内部同事在 [[slack]] 接入了 [[ChatGPT]] ，在没有合适的 [[Prompt]] 情况下，几乎是不可用的。
Python is two languages now, and that&amp;rsquo;s actually great
作者认为 [[Python]] 现在分为 untyped Python 和 typed Python ，并会永远的持续下去。最近公司的项目在从 [[Python2]] 迁移至[[Python3]] ，如果之后选择 library，那肯定会优先选择 type hints 的。
The pains of GitOps 1.0 | Codefresh
对于 [[GitOps]]管理的资源后续因为 auto-scale 等配置引发的不一致情况，[[Argo]] 通过custom diff 来避免，[[terraform]] 通过 ignore_changes ，来避免。</description></item><item><title>Friends</title><link>https://zdyxry.github.io/friends/</link><pubDate>Sun, 05 Mar 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/friends/</guid><description>Jiajun的编程随想
格物致知
玻璃齿轮 - SlassGear
CosPotato&amp;rsquo;s Blog</description></item><item><title>Weekly Issue 2023-03-05</title><link>https://zdyxry.github.io/2023/03/05/Weekly-Issue-2023-03-05/</link><pubDate>Sun, 05 Mar 2023 00:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/03/05/Weekly-Issue-2023-03-05/</guid><description>文章 链接到标题 技术 链接到标题 Coding 102: Writing code other people can read - Stack Overflow Blog
关于代码风格的示例，写出可读代码。
HTTPS 隐私安全的一些实践 | Laisky&amp;rsquo;s Blog
[[HTTPS]] 相关概念介绍。
Introducing MRSK - YouTube
[[MRSK]] 介绍，通过 DSL 和 [[docker]] 运行 [[container]] app。
Kubernetes is a beast. Running it yourself on your own hardware is not for the faint of heart. It&amp;rsquo;s a fine option if you want to run on someone else&amp;rsquo;s platform, either transparently like Render or explicitly on AWS/GCP, but if you&amp;rsquo;d like the freedom to move between cloud and your own hardware, or even mix the two, MRSK is much simpler.</description></item><item><title>Weekly Issue 2023-02-26</title><link>https://zdyxry.github.io/2023/02/26/Weekly-Issue-2023-02-26/</link><pubDate>Sun, 26 Feb 2023 19:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/02/26/Weekly-Issue-2023-02-26/</guid><description>文章 链接到标题 技术 链接到标题 Nix Is Fighting The Last War
[[Nix]] 注定是一个小众的解决方式。
Tcpdump 从 TCP_option_address 中根据真实 IP 过滤 | 卡瓦邦噶！
[[tcpdump]] 抓取 [[LVS]] 转发前的真实 IP 地址。
How Levels.fyi scaled to millions of users with Google Sheets as a backend
早起通过[[Google]][[Sheets]] 配合 [[Lambda]] 和 API Gateway 快速验证产品可行性，后续根据需要来切换到后端服务加数据库形式。
FOSDEM 2023 - I was wrong about Flatpak, AppImage, and Snap (Containerised Apps Presentation) - YouTube
讨论了AppImage、Snap和 Flatpak ，2017年以及现状，结论是使用 Flatpak 让生活更美好。
K8S 生态周报| Cilium 和 Istio 的新版本带来众多新特性 | MoeLove</description></item><item><title>Weekly Issue 2023-02-19</title><link>https://zdyxry.github.io/2023/02/19/Weekly-Issue-2023-02-19/</link><pubDate>Sun, 19 Feb 2023 19:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/02/19/Weekly-Issue-2023-02-19/</guid><description>文章 链接到标题 技术 链接到标题 uBlue · GitHub 计划基于[[Fedora]][[coreos]] 的发行版，依托于 [[ostree]] 的 [[NativeContainer]] 能力，可以很方便的使用 [[Container]]来构建自己的 Desktop。
FOSDEM 2023 - blkhash - fast disk image checksums
用来计算[[image]] checksum 的工具，比 [[SHA]] 更快，支持 format 探测等。
https://newsletter.pragmaticengineer.com/p/real-world-eng-8
[[Khan]] 将内部服务从 [[Python]] 迁移至 [[Golang]]的过程和思考，根本需求是[[Python2]] 的问题，100 人规模的开发团队，共花费 3.5 年时间完成重写。
Moving to Go will undeniably be more effort than moving to Python 3, but the performance win alone makes it worth it.
Can We Stop With Those Horrible “System Overview” Dashboards Already?</description></item><item><title>Weekly Issue 2023-02-12</title><link>https://zdyxry.github.io/2023/02/12/Weekly-Issue-2023-02-12/</link><pubDate>Sun, 12 Feb 2023 19:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/02/12/Weekly-Issue-2023-02-12/</guid><description>文章 链接到标题 技术 链接到标题 Some random thoughts on Generative AI | Reorx’s Forge
[[ChatGPT]] 大大降低了大家的使用门槛，只要你有想法，就可以快速POC。
Cloud Backup Best Practices for SMBs
云应用的[[备份]]实践，借机推广[[Snapshooter]]。
设计师如何入门前端
最后我想说，无论是设计工具还是[[前端]]代码，都只是实现创意的工具。最终能够限制创意的，只有不够开放和好奇的大脑。
Kubernetes 证书管理系列（一） | MoeLove
[[证书]]管理是个非常麻烦的事情，[[openssl]] 的命令行也是用过的命令工具里面比较难用的几个之一了。
Cloud Backup Best Practices for SMBs
云应用的[[备份]]实践，借机推广[[Snapshooter]]。
Supabase Clippy: ChatGPT for Supabase Docs
[[Supabase]] 在文档网站提供[[ChatGPT]] 功能，来辅助用户搜索。如何构建：将完整文档拆分为多份，使用 [[OpenAI]] API 将其作为输入，使用[[pgvector]] 存储到[[Postgres]] 中，获取用户问题，在[[Postgres]] 中获取问题相关的文档，讲这些文档作为[[GPT-3]] 上下文，返回给用户。
Bad Observability - SquaredUp
关于可观测需要避开的点：
Forgetting the customer; Environment inconsistency; Not understanding your ecosystem; No consistent trace ID; The big dumb metric; Bad sampling intervals; Misunderstanding metrics; Lazy synthetic transactions; A plague of dashboards; Unnecessary alerts; Hoarding data; Disconnected data; Throwing tools at a problem; Mandating tools; The chosen few;</description></item><item><title>Weekly Issue 2023-02-04</title><link>https://zdyxry.github.io/2023/02/04/Weekly-Issue-2023-02-04/</link><pubDate>Sat, 04 Feb 2023 19:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/02/04/Weekly-Issue-2023-02-04/</guid><description>文章 链接到标题 技术 链接到标题 The only thing worse than cloud pricing is the enterprisey alternatives
涉及到金钱的东西总是让人头大。企业服务的定价确实很玄幻，透明度很低。
OpenLens 6.3.0 - No Logs or Shell buttons · Issue #6823 · lensapp/lens · GitHub
[[Lens]] 删除了部分功能引发了大家对其所有权的担忧，官方在推 Desktop 版本。
Linux Load Averages: Solving the Mystery
[[Linux]][[负载]] 解释说明，其中关于TASK_UNINTERRUPTIBLE 的历史进行了调查，文章末尾提供了 性能检查列表
协议栈源端口选择性能衰减问题 - 撸代码 - LuCode.net
自kernel 4.2开始，端口资源的分配策略改了，目前奇数端口留给bind，偶数端口留给connect为了均衡资源的占用，但是显然，这种策略不适合本文所述的特殊场景，并且对于bind而言，也存在性能衰减的问题。
依次尝试去获取，当然每次获取的起点是随机的。很明显，当我们完全占用偶数组的端口后，所有后续的connect调用，所需的源端口应该位于奇数组中，然而该函数依旧会尝试完整遍历偶数组资源，这也就是__inet_check_established耗时占比这么高的原因。
Introducing Hermes, An Open Source Document Management System
[[hashicorp]] 开源的基于 [[Google Workspace]] 的文档管理系统。
iPotato | Fly.io 初体验之博客搬家</description></item><item><title>Weekly Issue 2023-01-29</title><link>https://zdyxry.github.io/2023/01/29/Weekly-Issue-2023-01-29/</link><pubDate>Sun, 29 Jan 2023 19:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/01/29/Weekly-Issue-2023-01-29/</guid><description>文章 链接到标题 技术 链接到标题 iptables详解（1）：iptables概念-朱双印博客
[[朱双印]] 关于 [[iptables]] 的基本介绍。
领英上的David Masover: #opentowork | 747 条评论
来自 [[Google]]真实事件，真正的 [[SRE]]，和这种人工作应该很幸福。
为什么镜像可以 pull 下来但是在 manifest inspect 的时候提示 no such manifest？—— Docker Buildx Attestations 检修记
[[Buildkit]] 新特性引发的兼容性问题。
Buildx v0.10 enables support for a minimal SLSA Provenance attestation, which requires support for OCI-compliant multi-platform images. This may introduce issues with registry and runtime support (e.g. GCR and Lambda). You can optionally disable the default provenance attestation functionality using provenance: false.</description></item><item><title>Weekly Issue 2023-01-22</title><link>https://zdyxry.github.io/2023/01/22/Weekly-Issue-2023-01-22/</link><pubDate>Sun, 22 Jan 2023 19:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/01/22/Weekly-Issue-2023-01-22/</guid><description>文章 链接到标题 技术 链接到标题 重构荷兰政府那个那个非常有效的代码
最近的热门讨论，编写一个根据百分比生成进度条的函数。
Cloud Spend Breakdown
[[37Signals]] 发布了2022 公有云服务的账单，其中关于数据存储和数据相关服务占比达到了70% ，这部分是最难迁移出来了，期待后续。
What&amp;rsquo;s what with Wolfi, the Linux &amp;ldquo;undistribution,&amp;rdquo; and ARM | Open Source Watch
对[[Wolf]] 项目的介绍，用来应对供应链攻击。
State of Infrastructure-from-Code 2023 - Klotho
[[IaC]] 之后谈论[[IfC]] ，在IaC 场景下，开发人员通常需要考虑业务应用程序和基础设施两种应用。
[[IfC]] 通过分析业务应用代码来推断所需的基础资源，然后自动创建并维护，不需要手动指定。目前已有的方向是通过 SDK、通过代码注释、两者结合、通过新的编程语言实现。预测 [[IfC]] 会在之后愈发流行。 [[IfC]] 创建的资源如何管理？如何保证应用程序没有滥用资源？
How to use interfaces in Go | jordan orelli
关于 [[Golang]] [[interface]] 使用上的总结。
How to improve Python packaging, or why fourteen tools are at least twelve too many | Chris Warrick</description></item><item><title>Weekly Issue 2023-01-15</title><link>https://zdyxry.github.io/2023/01/15/Weekly-Issue-2023-01-15/</link><pubDate>Sun, 15 Jan 2023 19:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2023/01/15/Weekly-Issue-2023-01-15/</guid><description>文章 链接到标题 技术 链接到标题 Deploy Kubernetes on Equinix Metal - Kubeadm via Userdata and Cloud-config
[[Equinix]] 通过 [[cloud-init]] 配合 [[kubeadm]] 部署 [[kubernetes]] 集群。
Buf | Introducing buf curl - Call your gRPC endpoints with the simplicity of buf
[[bufbuild]] 的 [[grpc]] 命令行。
Scaling Kubernetes to Thousands of CRDs
[[Crossplane]] 管理上千个 [[CRD]] 遇到的问题和改进方式。（现在好像一个 [[kubernetes]] 集群里面的 CRD 上百也不稀奇。
简洁的 Bash Programming 技巧 - 团子的小窝
[[Bash]] 中 -- 后面的参数不会被当做选项解析。
How Docker 2.0 went from $11M to $135M in 2 years</description></item><item><title>2022 年读书记录</title><link>https://zdyxry.github.io/2022/12/31/2022-%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 31 Dec 2022 15:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/12/31/2022-%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</guid><description> 年终总结 链接到标题 2016 计划读 5 本，实际读 13 本。 2017 计划 32 本，实际读完 23 本。 2018 计划 30 本，实际25本。 2019 计划 30 本，实际 43 本。 2020 计划 30 本，实际 40 本。 2021 计划 50 本，实际 47 本。 2022 计划 50本，实际 45 本。 已读 链接到标题 《候场》 《你不知道的JavaScript（上卷）》 《工作、消费主义和新穷人》 《开端》 《海边的房间》 《投资中最简单的事》 《认知觉醒》 《大话设计模式》 《啤酒事典》 《卧底经济学1》 《Python工匠》 《全职高手》 《一日三秋》 《Kubernetes网络权威指南：基础、原理与实践》 《心理罪》 《远程工作革命》 《假面的告白》 《历史深处的忧虑》 《诡秘之主》 《JavaScript权威指南（原书第7版）》 《幽默感》 《NUTANIX超融合基础架构权威指南》 《置身事内》 《分析与思考》 《决胜B端》 《搞定》 《潜规则（修订版）》 《从零开始的女性主义》 《如何阅读一本书》 《职场妈妈不下班》 《将夜（全十册）》 《应得的权利》 《大道朝天》 《暴雨下在病房里》 《Terraform：多云、混合云环境下实现基础设施即代码（第2版）》 《毫无意义的工作》 《士兵突击》 《可能性的艺术》 《九州·缥缈录》 《关于那个人的备忘录》 《人类的群星闪耀时》 《克拉拉与太阳》 《社会工程》 《100 Go Mistakes and How to Avoid Them》 《李淼罪案故事：如坠深渊》</description></item><item><title>2022 新冠感染记录</title><link>https://zdyxry.github.io/2022/12/27/2022-%E6%96%B0%E5%86%A0%E6%84%9F%E6%9F%93%E8%AE%B0%E5%BD%95/</link><pubDate>Tue, 27 Dec 2022 21:01:41 +0000</pubDate><guid>https://zdyxry.github.io/2022/12/27/2022-%E6%96%B0%E5%86%A0%E6%84%9F%E6%9F%93%E8%AE%B0%E5%BD%95/</guid><description>新冠感染记录 链接到标题 Day0 2022/12/18 链接到标题 浑身酸痛，发烧，无法睡觉。
Day1 2022/12/19 链接到标题 抗原阳性，体温 38.2，嗓子痛，吃了 999 感冒灵，一整天都在昏睡。
Day2 2022/12/20 链接到标题 体温 38.4，嗓子痛，吃了 999 感冒灵，一整天都在昏睡。
Day3 2022/12/21 链接到标题 抗原阳性，体温 36.6，嗓子痛，精神没有恢复，身体感觉还不错。
Day4 2022/12/22 链接到标题 抗原阳性，体温 36.6。恢复上班，感觉效率不太高。
Day5 2022/12/23 链接到标题 抗原阳性，体温 36.6，感觉效率恢复了，开始轻微咳嗽。
Day6 2022/12/24 链接到标题 抗原阳性，体温 36.2，咳嗽，有痰。
Day7 2022/12/25 链接到标题 抗原阳性，体温 36.4，开始流鼻涕，有痰。
Day8 2022/12/26 链接到标题 抗原阳性，体温 36.5，流鼻涕，有痰。
Day9 2022/12/27 链接到标题 抗原弱阳性，体温 36.2， 流鼻涕，有痰。
Day10 2022/12/28 链接到标题 抗原阴性，体温 36.2，流鼻涕，有痰。</description></item><item><title>《100 Go Mistakes and How to Avoid Them》摘要</title><link>https://zdyxry.github.io/2022/12/24/100-Go-Mistakes-and-How-to-Avoid-Them%E6%91%98%E8%A6%81/</link><pubDate>Sat, 24 Dec 2022 09:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/12/24/100-Go-Mistakes-and-How-to-Avoid-Them%E6%91%98%E8%A6%81/</guid><description>1. Go: Simple to learn but hard to master 链接到标题 Go is a modern programming language that enables developer productivity, which is crucial for most companies today. Go is simple to learn but not easy to master. This is why we need to deepen our knowledge to make the most effective use of the language. Learning via mistakes and concrete examples is a powerful way to be proficient in a language.</description></item><item><title>Weekly Issue 2022-12-11</title><link>https://zdyxry.github.io/2022/12/11/Weekly-Issue-2022-12-11/</link><pubDate>Sun, 11 Dec 2022 19:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/12/11/Weekly-Issue-2022-12-11/</guid><description>文章 链接到标题 技术 链接到标题 dracut-shutdown: unpack the initramfs to /run/initramfs - Linux Man Pages (8)
[[systemd]] shutdown 与[[dracut-shutdown]] 的调用关系。
我 EKS 内的 Pod 怎么连不上某个 EC2 了？奇怪的 Docker Compose 桥接网络 Debug 记 想到了公司最近内部新添加了网段是 172.16，也跟 [[docker]] 是重叠的。
TSMC founder Morris Chang says globalization &amp;lsquo;almost dead&amp;rsquo; -Nikkei Asia
globalization and free trade are almost dead
From 20MB to 20TB: 40 Years of HDD Technology - StorageNewsletter
[[HDD]] 40 年时间容量从 20MB 到 20TB。</description></item><item><title>Weekly Issue 2022-12-04</title><link>https://zdyxry.github.io/2022/12/04/Weekly-Issue-2022-12-04/</link><pubDate>Sun, 04 Dec 2022 19:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/12/04/Weekly-Issue-2022-12-04/</guid><description>文章 链接到标题 技术 链接到标题 聊聊 Docker 的存储驱动 Overlay2 | MoeLove [[overlayfs]] 介绍。
Ask HN: Azure has run out of compute – anyone else affected? | Hacker News [[azure]] 德国无法扩容更多容量，看评论(各家)都已经遇到很多次了。
Linux RT 进程引发内核频繁卡死的优化方案
经过查看内核 RT 实现，发现 RT 进程是有相关的占用时间设置的 /proc/sys/kernel/sched_rt_runtime_us ,sched_rt_runtime_us 的默认值为 950000，代表 RT 进程可以占用 95% 的 CPU 时间片，剩余 5% 用于响应其他请求，而这里比较诡异的是为什么 sched_rt_runtime_us 明明设置了 950000 这个值，surfaceflinger 这个程序为什么还能将 CPU 使用到 100% 呢？
经过代码分析和社区 issues 查找，**发现引发该问题的罪魁祸首是 RT_RUNTIME_SHARE 这个特性，该特性可以使 RT 任务长期占用 100% CPU, 从而使诸如 kworkers 等相关的内核任务无法获取到 CPU 资源，造成内核卡死。**而客户使用的内核版本恰好是 5.</description></item><item><title>Weekly Issue 2022-11-27</title><link>https://zdyxry.github.io/2022/11/27/Weekly-Issue-2022-11-27/</link><pubDate>Sun, 27 Nov 2022 19:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/11/27/Weekly-Issue-2022-11-27/</guid><description>文章 链接到标题 技术 链接到标题 搭建旁路由 - Jiajun的编程随想 使用[[Debian]] 配合 [[Clash]] 搭建旁路由。
Will Twitter Fail? [[Twitter]] 会失败么？会因为什么原因失败？感觉在系统不上线新功能的前提下，不会发生宕机。
What a Broken Wheel Taught Google Site Reliability Engineers - The New Stack 一些看似不相关的事情产生的影响，有趣。
quobix: M.A.R.V.I.N [[vmware]] [[VXRail]] 的故事，从零到一。
Risk in the Wild – DevelopSense
Most testing is motivated by the intention to go from speculation about suspected risk to evidence of actual risk.
Rakuten dumps Red Hat, turns to “true” open-source Linux OS, Digital Platforms &amp;amp; Services | TelecomTV 乐天从RHEL 迁移至 Rocky</description></item><item><title>Weekly Issue 2022-11-20</title><link>https://zdyxry.github.io/2022/11/20/Weekly-Issue-2022-11-20/</link><pubDate>Sun, 20 Nov 2022 23:50:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/11/20/Weekly-Issue-2022-11-20/</guid><description>文章 链接到标题 技术 链接到标题 K8S 生态周报| 基础库放弃维护，上游社区如何选择？ | MoeLove
GoGo Protobuf 停止维护(很久)了，很多 [[protobuf]] 的示例项目和生产项目都是使用这个。
Welcome to the Supercloud (and Developer Week 2022)
Efficient compute and storage, a global network that’s everywhere everyone is, bound together by software that turns the globe into a single cloud. The Supercloud.
Scaling Mastodon is Impossible | Armin Ronacher&amp;rsquo;s Thoughts and Writings
从中心化/去中心化，[[Mastodon]] 协议和托管者的法律风险角度，讨论 [[Mastodon]] 替代 [[Twitter]] 的可能性。
Sapling: Source control that’s user-friendly and scalable</description></item><item><title>Weekly Issue 2022-11-13</title><link>https://zdyxry.github.io/2022/11/13/Weekly-Issue-2022-11-13/</link><pubDate>Sun, 13 Nov 2022 23:50:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/11/13/Weekly-Issue-2022-11-13/</guid><description>文章 链接到标题 技术 链接到标题 2022 年里做前端是怎样一种体验 - rxliuli blog
感觉 2016年和2022年之间发生了什么了不得的事情，各种名词给变了一圈了。
Modern Python Environments - dependency and workspace management 对 pyenv ,pip + venv, poetry, pipenv 进行了比较。
Python Tools for Managing Virtual Environments 除了针对 venv，virtualenv介绍之外，还比较了 Pyflow、Poetry、Hatch 等较新的 project management 工具。
Why add another Python manager? pyflow 讲述为什么需要一个 Python 管理器。
The state of Python Packaging
关于 Python 包管理演进的3篇文章。
Python Meetup 第3期 | Python最新语言特征
49分38秒开始，[[PDM]] 作者讲解 PEP582 及 PDM 实现。
Debian 系统上捉摸不定的 Python</description></item><item><title>Weekly Issue 2022-11-06</title><link>https://zdyxry.github.io/2022/11/06/Weekly-Issue-2022-11-06/</link><pubDate>Sun, 06 Nov 2022 23:50:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/11/06/Weekly-Issue-2022-11-06/</guid><description>文章 链接到标题 技术 链接到标题 编写可维护的单元测试代码
介绍 GoConvey 和 testify 两种单测框架。公司内部用 Ginkgo 比较多。
2022 年 10 月 25 日 Cloudflare 服务部分故障
[[CloudFlare]] 故障复盘，在引入 opentracing 时清理了部分 header 信息，导致上游逻辑判断错误。
Give Your Tail a Nudge
[[Nudge]] 对于 [[FCFS]] 的优化：
The intuition behind the Nudge algorithm is that we’d like to basically stick to FCFS, which we know is great for handling the extreme tail (high 𝑡), while at the same time incorporating a little bit of prioritization of small jobs, which we know can be helpful for the mean and lower 𝑡.</description></item><item><title>Weekly Issue 2022-10-30</title><link>https://zdyxry.github.io/2022/10/30/Weekly-Issue-2022-10-30/</link><pubDate>Sun, 30 Oct 2022 23:50:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/10/30/Weekly-Issue-2022-10-30/</guid><description>文章 链接到标题 技术 链接到标题 Python 工匠：语句、表达式和海象操作符
关于复制表达式的使用场景介绍。
如果是一个私人脚本，也许我会愿意把代码写成上面那样。但在多人参与的真实项目里，我目前可能更愿意用一段平平无奇的 for 循环替代它。很多时候，相比“聪明”的代码，“笨”代码才是我们更需要的东西，它们能为项目的参与者省去许多沟通和维护上的成本。 LINUX PID 1 和 SYSTEMD
关于 init 进程的演进。
How Salesforce Built a Cloud-Native Task Execution Service
关于 [[Salesforce]] 的 [[Hyperforce]] 介绍。
深入（彻底）理解闭包实现原理
使用 Golang 来讲解闭包。
生活 链接到标题 A &amp;ldquo;real&amp;rdquo; day in the life of an SRE.
I decide to take a break for breakfast. I am a little annoyed with myself for not having got any &amp;lsquo;real&amp;rsquo; work done before my first break.</description></item><item><title>Weekly Issue 2022-10-23</title><link>https://zdyxry.github.io/2022/10/23/Weekly-Issue-2022-10-23/</link><pubDate>Sun, 23 Oct 2022 23:50:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/10/23/Weekly-Issue-2022-10-23/</guid><description>文章 链接到标题 技术 链接到标题 电信宽带 ipv6 折腾记
运营商配置变化太快。
Be Lean, Go Far: leveraging Kubernetes for an elastic right-sized platform
将业务迁移到 kubernetes 后所做的资源分配调度优化，需要 GKE 背景知识。
You can only improve what you measure
GitHub Copi­lot inves­ti­ga­tion
关于 [[github]] [[copilot]] 调查，除了讨论[[copilot]] 会导致开源协议的错误引入之外，还讨论 [[copilit]] 让用户只关心自己想要的内容(代码)，而不关心背后的社区。
Web 玩具项目技术栈
采用 [[Next.js]] [[Supabase]] [[Fly.io]] 运行个人项目，成本为0 。
关于swap 的一些补充
误解1: swap 是虚拟内存，虚拟内存肯定比物理内存慢嘛 误解2: 但是没有交换区的话，虚拟内存地址都有物理内存对应嘛 误解3： 不是内存快用完的时候才会交换的么？惰性分配有什么好处？那么内核什么时候会开始回收内存？
Why we&amp;rsquo;re leaving the cloud
Basecamp 谈论为什么不使用公有云。AWS 利润率达到 30%。
之前阅读过类似的文章：
Use One Big Server</description></item><item><title>《毫无意义的工作》读书笔记</title><link>https://zdyxry.github.io/2022/10/22/%E6%AF%AB%E6%97%A0%E6%84%8F%E4%B9%89%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Sat, 22 Oct 2022 13:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/10/22/%E6%AF%AB%E6%97%A0%E6%84%8F%E4%B9%89%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>总结 链接到标题 Q：Why？为什么要读这本书？ 在豆瓣看到过有人推荐，之前阅读过 《工作、消费主义和新穷人》来对工作、消费背后的介绍产生了兴趣。 Q：Who？这本书是谁写的？ 大卫·格雷伯（David Graeber），美国著名人类学家、社会学家，“占领华尔街”主要参与者，先后任耶鲁大学副教授、伦敦政治经济学院教授，师承人类学家马歇尔·萨林斯。出版有《债：5000年债务史》，受到《21世纪资本论》作者托马斯·皮凯蒂的高度赞誉。 Q：What？这本书讲了什么？这是哪类书？用一句话或一段话概述整本书的内容。 讲解什么是狗屁工作，狗屁工作的分类、成因、影响以及如何应对。 Q：将书中重要篇章列举出来，它们是如何组成整体的架构的？ 1-2章节讲解了狗屁工作的定义和分类，3-5 章节讲解狗屁工作对个人和社会的影响，6-7章节讲解如何应对狗屁工作。 Q：有没有重要的概念或者关键词你想在这里强调一下？ “狗屁工作的核心：虚伪和无目标感” “第一，工作带给人最重要的东西一是金钱，以便支付各种账单开销，二是给世界做出积极贡献的机会；第二，以上两者成反比，即你的工作越是对他人有帮助、有好处，带来的社会价值越高，那么这份工作带给你的酬劳往往就越低。” “人类工作越来越辛苦是因为人类创造了某种奇怪的施虐受虐逻辑论证法，通过这种逻辑论证，我们觉得只有在工作时不断感受痛苦，才能赋予我们那些隐秘的消费主义愉悦感以合理性。在这种理念的驱使下，工作占据了我们越来越多的时间，于是人们不再享有“生活”这件奢侈品” Q：How？这本书提供了什么行动建议？有什么方法或观点是可以实际在生活中使用的？ 生活中尽量摆脱虚伪，无论目标是明确的还是模糊的，让自己有一个目标。 Q：Think？读完这本书有什么感想，是否同意作者观点？是否有疑问？ 判定自己是否在从事狗屁工作，是否真的创造价值以及价值的体现，只能通过主观判定，不需要他人评判。同样很多人对”效率“的追求可能是虚假的，因为效率的提高可能会导致他本身的价值降低。之前看到豆瓣上有一个”FIRE生活“ 小组，里面的人追求的是一定程度的财富自由之后，做一些自己想做的事情，来享受生活，如果从创造价值的角度考虑，这类人创造了什么社会价值么？在保持低物欲的极简生活状态下，他们可能也是不受社会欢迎的”新穷人“吧。或许这个问题就不应该存在，不在意创造价值？ Q：Todo？读完这本书之后，有什么需要做得事情么？ 对能说出”工作是良药，能医治一切困扰人的疾苦。“ 的托马斯·卡莱尔产生了好奇。 笔记 链接到标题 第一章：什么是狗屁工作 链接到标题 “狗屁工作是一份毫无意义且往往有害的定期领薪水的职业，其无意义或有害程度是如此之高，乃至从事这份职业的人都无法为其找出合适的存在理由。虽然要从事这份工作有一个条件，即从事者不得不假装这份工作的存在是完全合理的。”
“狗屎工作”往往是蓝领工作，从事者按小时拿钱；而“狗屁工作”往往是白领工作，从事者拿的是月薪。从事“狗屎工作”的人经常受到侮辱，他们不仅工作辛苦，而且正因为工作辛苦而被人瞧不起，但是起码他们知道自己做的事情是有用的。那些从事“狗屁工作”的人则常被荣誉和声望围绕，他们被视作专业人士，他们得到人们的尊重，且收入颇丰，他们被认为是有成就的人，是有理由为自己的成就感到自豪的人。但是他们内心知道：他们什么成就都没有；他们感觉自己什么都没做就能够支付各种消遣玩乐的费用，并用这些填满自己的整个人生；他们感觉这一切都基于某个谎言——他们的感觉没有错。”
“我曾想过，如需将一个人彻底摧毁，残暴无比地折磨他，用杀人狂魔听了都会颤抖、都会吓得魂飞魄散的方式击垮他，那么只需要给他安排一份毫无意义的工作，一份毫无意义到甚至荒谬的工作”
第二章：狗屁工作的种类 链接到标题 “在研究中，我发现把狗屁工作分成五个类别会很有帮助。这五大类别分别是：随从（flunky）、打手（goon）、拼接修补者（duct taper）、打钩者（box ticker）和分派者（taskmaster）。”
“大型机构中，上级的重要性几乎永远是跟他手下干活的人数挂钩的。这反过来更刺激了组织阶梯中处于上位的那些人不断扩充自己的队伍，至于招来的下属具体做什么，则完全是以后再考虑的事情了。更多情况下，这些上级还会无视岗位过剩的情况，根本不会花精力去精简队伍。后面会提到，诸如银行、医疗耗材公司等大公司有时会聘请顾问来提升公司效率。根据这些顾问的反馈，当管理层了解到效率的提升需要仰仗自动化，而自动化会造成他们手底下的员工数量骤减时，这些管理人员便沉默了，不仅场面陷入尴尬，随之而来的还有对顾问毫不掩饰的敌意。效率提升方案一旦被执行，这些管理人员就什么都不是了，成了光杆司令了。没有了随从，那他们还能当谁的“上级”？”
“巴勃罗的主要观点是，人们越来越依赖免费软件，软件行业的领薪岗位也越来越多地设置给了拼接工作。程序员下班后很乐意利用业余时间无偿开发些程序，因为这些涉及核心技术的工作内容本身就令人满足，但同时也意味着他们越来越没有动力去考虑自己开发的程序是否最终能和其他人开发的其他程序相兼容，那么这批程序员在白天上班的时候，就得花费更多时间去从事拼接工作（有偿），把这些本不兼容的程序拼接起来。巴勃罗的这个观点非常重要，后文中我会详细讨论此种情况可能带来的影响，不过现在，我们仅对拼接工作概念本身进行展开。”
“起码存在一类人真的意识不到自己从事了狗屁工作。当然，首席执行官从事的还真的不是狗屁工作，他们确实改变了这个世界，不管这种改变是好是坏。他们只是对自己创造的各类狗屁工作视而不见而已。”
第三章：论精神暴力(上)&amp;ndash;为什么狗屁工作从事者说他们不快乐 链接到标题 “工作场所是法西斯式的。这里狂热而排他，你的生命被吞噬；老板将原本属于你的每分每秒全部抢过来，并占为己有，好似恶龙将金子秘藏。” &amp;mdash;&amp;mdash;努里
“而且他根本找不到任何办法从自己的工作中解读出哪怕一丝丝意义来，这一点最终把他逼疯。养家糊口这样的理由他也没办法用，因为他还没有成家。埃里克所在的阶级是以劳动为荣的阶级，这个阶级的人们制造、维护和修理东西，并以此为荣，这个阶级的人们觉得一切理应如此。于是自然而然，埃里克觉得上了大学进入专业领域之后，自己将要从事更加高大上的劳动。可现实恰恰是因为他“不具备”某项能力，反而获得了这份工作。他一次次尝试辞职，公司却一次次给他加薪。辞职不行，那出格行不行？还是不行。不管他做了多么过分的事情，公司还是留着他。他试过挑明公司的问题，也试过拙劣地扮演别人想要他扮演的角色，可这一切都是徒劳。”
“狗屁工作的核心：虚伪和无目标感”
“公众关于工作的大量讨论都是基于一个假设，即经济学家提出的模型是正确的。人们必须被强迫才会去工作，如果要救济穷人以防他们饿死，那么这种救济也必须用最为羞辱和麻烦的方式给予，不然他们就会产生依赖，再也没有找正经工作的动力了。[1]这里暗含着一个假设：如果人类有机会做寄生虫，那他们会毫不犹豫地去做。”
“然而哪怕是最自私的人最终也会发现，比起辛苦万分还不赚钱地劳作，整天坐着啥都不干而只看电视的命运会让人更难以忍受。”
“雇用你的时候，你感到自己是因为有用才获得了这个岗位，结果却发现事实完全不是如此，但又不得不配合表演，假装自己是有用的，假装这个岗位是有用的。这种先让你产生自己有用的错觉，然后再被全然否定的经历，不仅仅是对自尊感的摧毁，还直接动摇了自我意识的根基。一个人一旦停止对世界产生有意义的影响，那这个人就不复存在了。”
“你现在的时间是我的，我花钱不是养闲人的”
“一个社会父权化程度越高，男性和女性越是隔离，男性就越不清楚女性的工作情况。若是女性不见了，男性自然也不大可能替代她们去完成她们的工作。（与此形成对比，女性往往很清楚男性的工作内容，因此男性一旦因为某种原因消失，女性是能够从容应对的。正是出于这个原因，历史上经常出现一种情况：虽然某社会中大量男性因战争或贸易需要长期离开，但这个社会的生活并没有怎么被打乱。）父权制社会下，女性工作若是有人监管，那监管的人同样也会是女性。”
“由天体决定的绝对时间，就这么进入了尘世，并开始控制管理人类的日常事务，哪怕是最私人的小事。然而时间既是确定的坐标，也是一种资产。时钟鼓励所有人都以中世纪商人的方式去看待时间：时间成了一份有限的资产，需要像对待金钱那样细细规划预算，小心支配。”
“这类工作往往不是拿计件工资而是领固定月薪的，甚至都没有上级跟在他们屁股后面盯着。其实很多情况下正是如此。然而这类装模作样的游戏终究不是人们自主选择的，而是人们受到权力压迫的表现，因此不可避免地会让人意志消沉。”
第四章：论精神暴力(下)&amp;ndash;身处狗屁岗位有何感受 链接到标题 “疑问：太多人因领了工资却没有实际事情可做而感到愤怒、难以忍受、倍感压迫，这到底是为什么？况且工作环境往往还相当不错。我认为这个问题的答案揭示了关于人性的某些真相。这些真相大都被经济科学忽视了，甚至连大众常识中那些较为愤世嫉俗的部分都没能包含它们。人是依赖社交的存在，如果失去了和他人经常接触的机会，就会开始萎缩，甚至肉体上也开始衰弱。人类之所以觉得自己是自主存在，是与世界和他人分离的独立体，很大程度上是因为人们觉得自己可以按照可预测的方式对世界和他人产生影响。一旦被剥夺这种拥有力量的感觉，人类就什么也不是了。”
“当你在工作中，仅有的挑战是要接受根本没有任何挑战这件事；你施展才能的唯一方式，是变着花样掩饰自己无法施展才能这个现状；你需要消化自己已然成了寄生虫和大骗子这个事实，虽然你的初衷绝非如此，但痛苦会随之而来。在此种情况下，你必须非常自信，绝不能开始自我怀疑。（而这种自信本质上是有害的，毕竟，你之所以会深陷此类处境，不正是源自你上级那愚蠢又过分的自信吗？）”
“当一个人的狗屁工作不是什么都不做在那儿假装忙碌，而是真的很忙，但是忙的事情所有人都知道（但是不能说出来）是没有任何意义的，他就会被一种紧张感包围。这种紧张感会不断聚积，在这种情况下，人们往往会变得很有攻击性、很任性。”
第五章：狗屁工作为什么会激增 链接到标题 “某种程度上我们可以说，整个金融业就是一场骗局，因为整个行业表面上是针对商贸和制造领域的潜在赢利机会进行的各种操作，但事实上，这两个领域几乎没有被涉及。金融业绝大部分的利润来自同政府合谋生产、交易和操纵各种各样的债务。在本书中，我真正想说的是，就和金融业充满了烟雾幻境和假象一样，伴随着金融业繁荣而兴起的信息岗位，大部分工作也不过是魔术师的骗局而已。”
“政府在创造和维持狗屁工作中扮演的角色”
“总统先生到底说了什么？他承认了恺撒医疗集团或蓝十字蓝盾等医疗保险机构的几百万个岗位是没必要存在的。他甚至承认了社会主义化医保制度比现有的市场化医保制度更有效，因为前者可以减少不必要的文书工作，还可以避免数十家有竞争关系的私营医保公司精力的重复消耗。但他同时表示，正是为了保住这几百万个无用岗位，我们不能采用社会主义化医保制度。他坚持表示，维持现有市场化医保制度的一个原因正是这个制度的低效性。因为维持几百万个基本上毫无用处的办公室岗位要好过绞尽脑汁寻找相应数量的其他什么岗位让这些办事员来做。”
“对狗屁工作激增原因的几种错误解释”
“第一类观点认为，那些在私营企业工作却有着类似想法的人是没有道理的。因为在市场经济中面临竞争的私营企业绝不可能花钱去雇人什么都不做，他们的岗位肯定存在某种用途，只不过他们自己并没有理解而已。”
“第二类观点则承认在私营领域确实也存在毫无意义的岗位，甚至承认这样的岗位在激增。但是他们坚持认为，私营领域中的狗屁工作必然是政府干预的产物。”
“所以哪怕这些岗位最初设立的时候并不是“随从岗位”（估计大部分都不是），但这些人最终却纷纷沦为了随从，并一直这么“随从”下去了。当然，在任何大公司，大家都在担心自动化带来的威胁。我听说，有些公司的程序员上班时穿的文化衫上印着“走开点，不然我写一小段Shell[5]脚本就没你什么事了”，但是在这个案例以及其他类似的案例中，我们发现这种担忧袭向了公司的高层。这些高管一直颇为得意他们残酷无情的行事风格（比如，他们都掺和过私募股权投资业务，不管掺和的形式如何）。他们靠着这股无情吞掉了其他公司，并借着精兵简政、提高效率等名头甩给这些公司巨额债务。正是这些高管，面对自己内部机构臃肿的现象，却非常骄傲。事实上，如果西蒙判断无误，这些高管之所以这么做是因为这就是大型银行的本质：大型银行就是由大批封建随从和少数封建领主构成的，每位高管享受领主般的待遇[…]”
“而工业资本主义的到来则显然改变了这一切，20世纪兴起的管理主义更是加剧了这种改变。金融化资本主义之下，情况不仅没有好转，反而更加严重了。“效率”意味着赋予经理、监督人和其他各种所谓“效率专家”越来越多的权力，这样真正从事生产的人就几乎没有任何自主权了。[4]与此同时，管理者的队伍似乎也在无休无止地壮大着。”
“在任何以占有和分配商品为基础的政治经济体制中，非常多人从事的工作就是在整个系统中来回传送各种资源，而不是真正去创造、推进或维修这些商品，这一庞大的群体往往会将自己分成非常多的等级（起码有3个级别，有时候能达到10个、12个甚至更多）。然后我们还可以推论，在这些等级中，仆从和下级之间的界限往往很模糊，毕竟“服从上级”是经常出现在职位描述中的关键内容。大部分重要玩家自己既是领主又是封臣。”</description></item><item><title>Weekly Issue 2022-10-16</title><link>https://zdyxry.github.io/2022/10/16/Weekly-Issue-2022-10-16/</link><pubDate>Sun, 16 Oct 2022 23:50:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/10/16/Weekly-Issue-2022-10-16/</guid><description>文章 链接到标题 技术 链接到标题 Startup Ideas I&amp;rsquo;ve Considered
无代理可观测性平台、机器学习基础设施、表格系统、安全、VPN、BaaS、版本控制。
为你的 Python 应用选择一个最好的 Docker 映像
如何选择 容器 镜像是一个需要仔细调研权衡的问题，从各方面考虑 alpine 不是一个好选择。
Infrastructure Defined Software
Puppet 2009, Salt 2011, Ansible 2012 CloudFormation 2011, Terraform 2014 Pulumi 2017, AWS CDK 2019 下一步是什么？ 白话Kubernetes入门实践
k8e 作者关于 kubernetes 的一系列文章，持续更新中。
Why Linkerd doesn&amp;rsquo;t use Envoy
将 Cloudflare 连接到互联网的代理——Pingora 的构建方式
为什么 Linkerd 不使用 envoy. - 复杂度、资源消耗、安全。 - But what if we have a requirement to use Envoy? I would argue that’s not a real requirement.</description></item><item><title>Weekly Issue 2022-09-25</title><link>https://zdyxry.github.io/2022/09/25/Weekly-Issue-2022-09-25/</link><pubDate>Sun, 25 Sep 2022 23:50:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/09/25/Weekly-Issue-2022-09-25/</guid><description>文章 链接到标题 技术 链接到标题 How I’m a Productive Programmer With a Memory of a Fruit Fly
通过 [[doc2dash]] 来制作 [[Dash]] 文档。
用 CFSSL 从零构建一套 PKI
使用 [[cfssl]] 代替 [[openssl]] 管理证书。
SUB-NUMA CLUSTERING
介绍 Sub-NUMA-Clustering ，目前来看除非是性能特别敏感的场景，其他场景没什么用。服务器如果启用了一些[[虚拟化]]的高级选项，可能会导致 Sub-NUMA-CLustering 开启，从而导致节点的 [[NUMA]] 数量超过预期。
Going originless with Cloudflare Workers – Building a Todo app – Part 1: The API
使用 [[CloudFlare]] 全家桶： Workers，D1 来构建一个 Todo APP。
Systemd support is now available in WSL!
[[WSL]] 支持 systemd，是时候再给 [[WSL]] 一次机会了。</description></item><item><title>Weekly Issue 2022-09-18</title><link>https://zdyxry.github.io/2022/09/18/Weekly-Issue-2022-09-18/</link><pubDate>Sun, 18 Sep 2022 23:50:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/09/18/Weekly-Issue-2022-09-18/</guid><description>文章 链接到标题 技术 链接到标题 Kubernetes overstretched
这几年抱怨 k8s 的也不少. 一方面是 k8s 越来越成为事实上的标准(借“Cloud Native”之风), 在各大中小厂落地. 很多人被潮流裹挟不得不用, 心里未必愿意. 场景未必适合, 加上心不甘情不愿, 遇到麻烦就容易不满. 另一方面, 为了进一步提升适用范围和可定制性, k8s 开放出了越来越复杂的插件机制: custom apiserver, scheduler-extender, volume provisioner, federation, edge proxy, knative, etc.. 最初方便扩展的开放性, 反而带来了越来越高的复杂度. 在我看来, 在90%的场景下, 大部分开发者其实用不着, 也最好别碰这些东西; 剩下10%的特殊需求, 最好交给专门的云厂商做. 但不贴上高级词汇, 怎么向公司体现自身价值呢? 于是也跟在后面亦步亦趋, 做出不伦不类的东西, 结果越改越难用.如果要上升一下, 就是工具有自己的舒适区. 工具原来是为哪种场景设计的, 就最适合在相应的场景下使用. 突破界限做成一个普适的东西, 多半会增加痛苦. 然而古往今来能被滥用的技术, 就没有不被滥用的. 可扩展性越高越会被滥用, 就像性能越高越会被用户往死里捅一样. No good deed goes unpunished, as always.
Traditional Packaging is not Suitable for Modern Applications</description></item><item><title>Weekly Issue 2022-09-11</title><link>https://zdyxry.github.io/2022/09/11/Weekly-Issue-2022-09-11/</link><pubDate>Sun, 11 Sep 2022 23:50:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/09/11/Weekly-Issue-2022-09-11/</guid><description>文章 链接到标题 技术 链接到标题 容器技术之发展简史
容器技术以及公有云容器功能支持历史。
如何编写低耦合可维护的 Python 代码
通过观察者模式和装饰器模式来编写可维护代码。
CPU 是如何与内存交互的?
How to send raw network packets in Python with tun/tap
如何使用 [[Python]] 发送读取 [[TUN]] 设备数据。
What&amp;rsquo;s Inside Of a Distroless Container Image: Taking a Deeper Look
如何选择基础 [[Container]] [[image]] 一直是一个比较重要的考虑，比如很多人不推荐的 [[alpine]]，小而美，但是 [[musl]] 不那么美。很多人推荐使用标准发行版，但是又觉得大小太大不利于分发。 [[Distroless]] 是一个可以看到的方向，但是我个人在不能完全确定自己的项目中是否依赖了某些隐式的内容时，应该还是会使用标准发行版，比如[[Debian]] 或者 [[Fedora]]。
In Pursuit of Better Container Images: Alpine, Distroless, Apko, Chisel, DockerSlim, oh my!
博主在 [[Twitter]] 上发起了一些关于 [[Container]] [[image]] 的投票，一些人表面关注 CVE，实际上还是更关注镜像大小。 [[alpine]] 是目前大多数项目的选择，但是已经出现了一些替代品。</description></item><item><title>Weekly Issue 2022-09-04</title><link>https://zdyxry.github.io/2022/09/04/Weekly-Issue-2022-09-04/</link><pubDate>Sun, 04 Sep 2022 10:50:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/09/04/Weekly-Issue-2022-09-04/</guid><description>文章 链接到标题 技术 链接到标题 什么时候你第一次读懂了「云技术」？
通过具体的工业场景解释什么是云。
wifi有关的一些问题
关于 Wifi 概念以及计算方式的讲解。
可扩展服务设计原则 checklist
开发应用的基本设计原则，包含基本原则、整体设计、自动化管理、依赖管理、发布周期、测试、审计、监控告警
有赞TCP网络编程最佳实践
在net.ipv4.tcp_retries2默认配置下，可能还是一直等到15min左右才能感知到网络异常。
Introducing vSphere 8!
问：当你安装了 vSphere 8，你实际安装了多少个 ESXi 和多少个虚拟机？
Kubernetes 1.25: cgroup v2 graduates to GA
[[kubernetes]] 正式支持 [[cgroup]] v2 。kubelet 和 container runtime 使用 systemd 来做 cgroup 管理。
cgroup v2 offers several improvements over cgroup v1, such as the following:
Single unified hierarchy design in API Safer sub-tree delegation to containers Newer features like Pressure Stall Information Enhanced resource allocation management and isolation across multiple resources Unified accounting for different types of memory allocations (network and kernel memory, etc) Accounting for non-immediate resource changes such as page cache write backs Linux IO</description></item><item><title>如何平(优）滑（雅）的抛弃 CentOS7</title><link>https://zdyxry.github.io/2022/08/28/%E5%A6%82%E4%BD%95%E5%B9%B3%E4%BC%98%E6%BB%91%E9%9B%85%E7%9A%84%E6%8A%9B%E5%BC%83-CentOS7/</link><pubDate>Sun, 28 Aug 2022 13:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/08/28/%E5%A6%82%E4%BD%95%E5%B9%B3%E4%BC%98%E6%BB%91%E9%9B%85%E7%9A%84%E6%8A%9B%E5%BC%83-CentOS7/</guid><description>背景 链接到标题 2023/03/01 更新：目前已正式使用，符合预期。
CentOS 7 自身的生命周期截止到 2024年6月30日。在2020年底，CentOS 社区宣布修改现有的发布模式，将 CentOS 从作为 RHEL 的下游改为 CentOS Stream，即 RHEL 的上游，更导致 CentOS8的生命周期短的可怜，这让社区中原本就对 CentOS 不满的开发者/使用者不满，从而出现了抛弃 CentOS 转投其他发行版的情况。
大家选择使用 CentOS ，虽然都在说稳定，但是我理解更看重的是 RedHat 在身后背书，CentOS 作为 RHEL 的下游，所有的软件版本都是经过 RedHat 测试验证的，且后期维护也是有 RedHat 的身影在，不担心维护的问题。
CentOS 原有的模式也是有问题的，用户很难参与到 RHEL 的研发周期。用户发现了 CentOS 某个版本存在问题，想要给 CentOS 进行贡献，让 CentOS 下一个版本修复该问题。此时只有一条路，就是贡献给开源组件自身，但是这样也只是存在修复的可能，最终是否可能修复还是看 RedHat 开发人员的决定（毕竟 RHEL/CentOS 中存在大量开源组件自身不包含，但是 RHEL/CentOS 通过 rpm spec 中进行 Patch 的方式包含的 Patch）。在引入了 CentOS Stream 之后，用户就可以通过贡献给 CentOS 社区，来保证 CentOS 下一个版本包含该 Patch，至于 RHEL 是否包含，用户并不关心，那是 RedHat 关心的问题。
Fedora 更关注于上游社区最新的代码，包含最丰富的功能，作为先驱者；CentOS Stream 作为 RHEL 的上游，提供稳定可靠的持续交付版本，保证更多的贡献者可以参与进来；RHEL 给企业用户使用，有 RedHat 提供完整的维护服务。</description></item><item><title>Weekly Issue 2022-08-28</title><link>https://zdyxry.github.io/2022/08/28/Weekly-Issue-2022-08-28/</link><pubDate>Sun, 28 Aug 2022 10:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/08/28/Weekly-Issue-2022-08-28/</guid><description>文章 链接到标题 技术 链接到标题 Steam Deck, Linux Container and the Arch Community
关于 [[Steam Deck]] OS 的介绍，底层是 [[Arch]] Linux，采用的是 A/B 升级方式，应用采用 [[Flatpak]] 方式进行安装升级(保证安全性)。现在关于这种 OS 比较轻，应用采用容器化的模式应该是很成熟了。
Global Code Time Report
编码时间报告。平均每天编码时间少于 1 小时，周三是编码时间最多的，很少有开发人员每天编码时间超过 2 小时。
(A few) Ops Lessons We All Learn The Hard Way
一些“经验”教训。比如：在某个你没有在意过的服务，会解析 DNS来完成某项工作。关掉 TCP 53 可能会有奇怪的事情发生。正在查看的源代码不是在生产中运行的代码。如果一周内没有完成故障复盘，那有可能永远也无法完成。没有人知道你在做什么。
Slacker: Fast Distribution with Lazy Docker Containers
76%的时间花费在镜像的拉取。容器真正运行需要的有效数据只占用镜像大小的 6%。
镜像大小中，低层级(&amp;lt;9)的数据占到了镜像大小的一半以上。
Kubernetes 中 Descheduler 组件的使用与扩展
Descheduler 通过触发 Pod 的驱逐，来保证集群内资源分布均衡，达到 DRS效果。作者提出了 Descheduler 改进后的评估方式。</description></item><item><title>Weekly Issue 2022-08-21</title><link>https://zdyxry.github.io/2022/08/21/Weekly-Issue-2022-08-21/</link><pubDate>Sun, 21 Aug 2022 23:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/08/21/Weekly-Issue-2022-08-21/</guid><description>文章 链接到标题 技术 链接到标题 与 CentOS 社区委员对话后 CentOS 时代
[[centos]] stream 之前的阶段，用户很难参与到 [[RHEL]] 的研发阶段，无法直接通过 [[centos]] 贡献代码，来保证下一个版本的 [[centos]] 包含自己所发现的问题修复，只能通过贡献给组件自身，然后由 RedHat 开发人员决定是否包含在下一个版本中。在 [[centos stream]] 之后的阶段，用户可以直接贡献给 [[centos]]，保证 [[centos]] 包含问题修复，至于 [[RHEL]] 是否修复，由 RedHat 自身决定。
关于 Fedora、Stream，还有 RHEL 未来的发展计划是什么？
从社会组织的维度： Fedora：主题是如何提高对 Fedora 的贡献，如何使得社区更多样化； CentOS Stream：和 Fedora 差不多，提高社区贡献和使社区更多样化，另外就是发展 SIG（特殊兴趣小组），充分发挥 SIG 的作用； RHEL：进一步繁荣包括社区、合作伙伴、客户的 RHEL 生态 从代码的维度： Fedora： 集成上游社区最新最好的代码，功能最丰富，做业界的引领者； 面向特定的场景，做特色的发行版，如 Fedora IoT 就是面向物联网场景的 Fedora 操作系统。 CentOS Stream： RHEL 稳定可靠的持续交付版，用户可以提前看到即将发布的 RHEL 版本； 基于稳定的代码基础，通过社区发展 SIG，在特定领域创新。 RHEL： 我们面向客户的销售团队有很多关于产品的介绍，但我今天不是来为产品做广告的。我相信红帽大中华区的同事们可以给您很好的支持。 面试题：开发新功能和重构老代码之间怎么选？
对于所有商业公司来说，第一原理永远是商业，不是产品也不是技术。</description></item><item><title>Weekly Issue 2022-08-14</title><link>https://zdyxry.github.io/2022/08/14/Weekly-Issue-2022-08-14/</link><pubDate>Sun, 14 Aug 2022 13:00:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/08/14/Weekly-Issue-2022-08-14/</guid><description>文章 链接到标题 技术 链接到标题 2022-31: Databend 的工程效率实践
[[Databend]] 效率工程介绍，使用 SaaS 来完成大部分工作，Self Host Github Runner 尽量使用 [[AWS]] 内部服务，来减免流量费用。
效率工程体会：
摆正定位 渐进变更 公开透明 Improving the Experience of Making Envoy Route Changes
[[Lyft]] 针对 [[envoy]] 配置方式进行的改进，原有存在的问题：
原有路由配置使用[[Jinja]] 模版进行维护，无法进行很好的语法检查和验证，现已替换为 [[Golang]]
原有 [[envoy]] API 在配置平面和控制平面都被引用，当 [[envoy]] 升级时，都需要考虑兼容性问题，现在只在控制平面引用
原有Route table check tool 无法进行很好的分发（为啥一个 binary 会不好分发呢？），改为内部检查工具，并添加了 CI 检测结果。
容器 CPU 和 Memory 限制行为简述
关于 CPU 和 Memory cgroup 基本配置参数介绍。
Avoiding CPU Throttling in a Containerized Environment</description></item><item><title>Weekly Issue 2022-08-07</title><link>https://zdyxry.github.io/2022/08/07/Weekly-Issue-2022-08-07/</link><pubDate>Sun, 07 Aug 2022 23:59:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/08/07/Weekly-Issue-2022-08-07/</guid><description>文章 链接到标题 技术 链接到标题 2022-30: 如何维护一个开源项目
明确自己的项目预期，后续的发展路线以及如何与开发者沟通。
How Our Bare Metal Cloud Keeps up with All the New OS Releases
[[Equinix]] 如何进行发行版的快速验证工作的介绍。之前一直是手动测试验证(无法想象)，现在通过 [[BuildKite]] ，通过 DSL 来描述 OS 内容，使用 [[virt-customize]] 来进行配置改动，改动完整后，推送到 S3，进行自动化测试，最终推送给客户。
采用 [[Buildkite]] 的原因：
支持动态 pipeline，可以进行条件判断 允许 pipeline 进行交互输入 可以自定义运行形态(环境) 不同架构可以共用一套 Pipeline [[BuildKite]] 学习成本不低。
程序 Hot reload config 的实现方式
监听文件(我自己比较常用的方式) 每次都reload 监听HUP 信号 10 Kubernetes Security Context settings you should understand
关于 [[kubernetes]] 安全配置的一些方法(感觉大部分人都用不上)
The people of the cloud</description></item><item><title>Weekly Issue 2022-07-31</title><link>https://zdyxry.github.io/2022/07/31/Weekly-Issue-2022-07-31/</link><pubDate>Sun, 31 Jul 2022 23:59:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/07/31/Weekly-Issue-2022-07-31/</guid><description>文章 链接到标题 技术 链接到标题 一些 System Design 面试的建议
明确需求；定义系统接口和业务 Entity；画一个架构图；讨论具体细节。
A Checklist Manifetsy
维护自己的检查清单可以对所做内容更有掌控感。
Alerts, what are they good for?
如何设置报警规则？在我司通常是依靠经验拍脑袋。作者提出了一个可以量化的规则来 评估规则：
影响：越严重则数值越大
频率：发生频率越高，则数值越大
可恢复性：如果涉及到的问题所需要手动工作量越大，则数值越大
最终计算方式为(i+f)*r ，作者给出了数值建议：
1–19 ignore
20–49 alert
50–79 evaluate the event. is it rated properly and if yes, what improvements can be made if any. The below example of US East 1 going down is a worse case scenario that relies on DR however, with good monitoring, can be detected and actioned</description></item><item><title>Weekly Issue 2022-07-24</title><link>https://zdyxry.github.io/2022/07/24/Weekly-Issue-2022-07-24/</link><pubDate>Sun, 24 Jul 2022 18:55:00 +0000</pubDate><guid>https://zdyxry.github.io/2022/07/24/Weekly-Issue-2022-07-24/</guid><description>文章 链接到标题 技术 链接到标题 如何劫持 docker.io 的镜像流量到私有仓库
通过修改Client 受信证书将 docker.io 流量转发到内部其他 registry。
问题：所有 Client 都需要进行证书配置。如果证书这环节出了问题，会引发较大安全问题。
周刊（第22期）：图解一致性模型
通过发布朋友圈作为示例来描述：顺序一致性、线性一致性、因果一致性。
顺序一致性条件：
条件1：每个进程的执行顺序要和该进程的程序执行顺序保持一致。
条件2：对变量的读写要表现得像FIFO一样先入先出，即每次读到的都是最近写入的数据。
线性一致性条件，在顺序一致性的基础上，增加：
条件3：不同进程的事件，如果在时间上不重叠，即不是并发事件，那么要求这个先后顺序在重排之后保持一致。
因果一致性是更弱的一致性，只要满足happen-before关系即可。由于happen-before关系实际上是由Lamport时钟定义的，这是一种逻辑时钟，所以不同的读者看到的先后顺序可能会有点反直觉，但是只要满足happen-before关系就是正确的。
工程效能CI/CD之流水线引擎的建设实践
美团内部 CI/CD 发展过程。在 jenkins 阶段遇到了调度瓶颈、资源管理瓶颈，Jenkins 多集群方式管理困难，转为自研。
spf13 Google &amp;ndash;&amp;gt;
spf13 从 [[Google]] 离职加入了Two Sigma
When I first joined there was so much to learn about both Go and working within Google. My learning had slowed down dramatically. I was torn. I loved the team and the work we were doing, but was feeling personally stagnant.</description></item><item><title>Weekly Issue 2022-07-17</title><link>https://zdyxry.github.io/2022/07/18/Weekly-Issue-2022-07-17/</link><pubDate>Mon, 18 Jul 2022 22:03:36 +0000</pubDate><guid>https://zdyxry.github.io/2022/07/18/Weekly-Issue-2022-07-17/</guid><description>文章 链接到标题 Side Project 成本最小化运维
现成的 SaaS &amp;gt; 基于库实现 &amp;gt; 自己从软件方面实现 &amp;gt; 使用新的开源项目额外部署系统来实现。现在的各个 SaaS 已经非常成熟了，大部分场景都可以涵盖到，不建议把时间花费在运维维护工作上。
Setting the Number of Cores per CPU in a Virtual Machine
关于 [[vmware]] ESXi 虚拟机 CPU 配置说明
When you define the number of logical processors (vCPUs) for a VM, prefer the cores-per-socket configuration. Continue until the count exceeds the number of CPU cores on a single NUMA node on the ESXi server. Use the same logic until you exceed the amount of memory that is available on a single NUMA node of your physical ESXi server.</description></item><item><title>Pocket 数据分析和总结</title><link>https://zdyxry.github.io/2022/07/05/Pocket-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%92%8C%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 05 Jul 2022 19:50:44 +0000</pubDate><guid>https://zdyxry.github.io/2022/07/05/Pocket-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%92%8C%E6%80%BB%E7%BB%93/</guid><description>背景 链接到标题 自己一直使用 pocket 作为稍后阅读收藏夹，最近觉得 Pocket 的搜索结果不能满足我的需求，于是寻找替代品，最终打算用 Notion Web Clipper 配合 Notion 来作为替代，自己虽然是 Notion 的 Team Plan 但是一直没找到合适的场景使用 Notion ，主要是觉得 Notion 的数据不可控，所以无法作为一个笔记软件来用，但是如果作为只信息管理工具应该是足够的，试用了几天觉得也满足需求，于是开始把 Pocket 数据迁移到 Notion 中。在迁移过程中，发现 Pocket API 中的数据比较多，于是打算简单分析下自己这么多年使用的数据，看看能否发现什么。数据是我自己的 Pocket 数据，通过官方 API 获取的，时间跨度从 2017年12月29日持续到 2022年6月28日。
数据 链接到标题 已读比例：63% 未读 774 已读 1370 收藏链接 404 比例 未读 774，其中链接无法访问数量 35，4.5% 已读 1370，其中链接无法访问数量 88，6.4% 条目添加标签（tag）比例 未读 774， 其中添加标签数量 247，31.9% 已读 1370， 其中添加标签数量 686，50% 平均每天添加稍后阅读条目：1.3 篇 平均每天阅读条目：0.9 篇 阅读时间 最长阅读耗时：999 天 最短阅读耗时：9s 平均阅读耗时：109天 最长未读间隔：1649 天 总结 链接到标题 已读比例符合我的预期，最开始使用 Pocket 的时候，通常会将其作为一个“收藏夹”，而不是一个“阅读列表”，所以会导致添加的条目并不是一篇文章，哪怕“稍后” 也不会轻易的读完，后期已经将收藏类的需求放到了笔记中，这种症状缓解了很多。 404 比例，之前在Twitter 上单独说过，如果一篇文章没有及时阅读，在现在的网络时代，要随时做好它消失不见的准备，虽然现在已经有很多 WebArchive 的方式，但终归是不方便。这也是我对 Pocket 不满意的一点，我用了这么久都没有搞清楚什么页面它会保存文字，什么页面会只保存一个链接。还是要及时阅读，即使不能阅读，也最好保存完整页面便于后续整理。 平时使用过程经常面临一个困扰：我记忆中看过一篇文章，但是我找不到它。此时我会尝试各种我认为的关键词去找，但是往往是搜索不到，看这个 tag 比例 也能看出一些端倪，现在我会针对每一个阅读条目都添加标签（一个或者多个），来尽量减少这种情况出现。 平均每天添加 1.</description></item><item><title>MacOS 使用 Hammerspoon 进行窗口管理</title><link>https://zdyxry.github.io/2022/06/18/MacOS-%E4%BD%BF%E7%94%A8-Hammerspoon-%E8%BF%9B%E8%A1%8C%E7%AA%97%E5%8F%A3%E7%AE%A1%E7%90%86/</link><pubDate>Sat, 18 Jun 2022 10:47:07 +0000</pubDate><guid>https://zdyxry.github.io/2022/06/18/MacOS-%E4%BD%BF%E7%94%A8-Hammerspoon-%E8%BF%9B%E8%A1%8C%E7%AA%97%E5%8F%A3%E7%AE%A1%E7%90%86/</guid><description>背景 链接到标题 最近把公司电脑从 Windows 换到了 MacOS， 在重新配置 OS 阶段，发现在 MacOS 上进行窗口管理比较痛苦，自己之前的个人 MaCOS 一直使用的是Moom 来进行管理，但是使用功能很有限，加上现在 MacOS 自身的窗口提示会与 Moom 冲突，所以决定更换一个。我个人对于窗口管理的需求就是方便的在不同显示器切换，焦点窗口全屏、半屏、1/3 屏转换快速。对于平铺式窗口管理觉得学习成本和适应成本可能有些高，不打算折腾，之前看到 disksing 使用 Hammerspoon 进行窗口管理的文章： 适合程序员的桌面窗口管理方案 ，打算尝试一下。
Hammerspoon 链接到标题 Hammerspoon 是一个开源的自动化工具，可以实现很多功能，包含不限于：窗口管理、桌面管理、Wifi 触发器、时钟管理等等，所有功能都是通过 Lua 语言来实现的。用户可以自己编写 Lua，或者使用 Spoons 中提供的一些 Lua 模块来简化配置。
官网包含了一个简单的 Window resize 示例，还是比较好理解的，先找到当前focuse 窗口，然后找到当前窗口大小，调整大小为目标值，重新设置窗口：
hs.hotkey.bind({&amp;#34;cmd&amp;#34;, &amp;#34;alt&amp;#34;, &amp;#34;ctrl&amp;#34;}, &amp;#34;Left&amp;#34;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.</description></item><item><title>Celery/Kombu MongoDB 连接异常调查记录</title><link>https://zdyxry.github.io/2022/05/09/Celery/Kombu-MongoDB-%E8%BF%9E%E6%8E%A5%E5%BC%82%E5%B8%B8%E8%B0%83%E6%9F%A5%E8%AE%B0%E5%BD%95/</link><pubDate>Mon, 09 May 2022 14:44:42 +0000</pubDate><guid>https://zdyxry.github.io/2022/05/09/Celery/Kombu-MongoDB-%E8%BF%9E%E6%8E%A5%E5%BC%82%E5%B8%B8%E8%B0%83%E6%9F%A5%E8%AE%B0%E5%BD%95/</guid><description>背景 链接到标题 产品组件 JobCenter 使用 Celery 实现异步任务中心，同时会运行 job-center-worker （celery worker） 和 job-center-scheduler(celery beat) 两个进程，使用 MongoDB 作为 Backend 存储 message 等信息（Celery 官方已说明不再维护对 MongoDB 的支持）。其中 MongoDB 配置了 ReplicaSet 保证高可用。
近期 Celery/Kombu 中遇到了 No free channel ids 问题，经过排查在这个 PR 中解决了该问题，在考虑 cherry-pick 的工作量和可维护性考虑，最终将产品中的 celery 和 kombu 组件从 3.x 统一升级到了 4.x 版本。
测试同学反馈近期在进行可靠性测试时，发现将 MongoDB 节点的存储网络 ifdown 会导致 JobCenter hang. 针对该问题进行调查。
调查 链接到标题 Celery 链接到标题 先尝试复现该问题，首先尝试 ifdown Primary 节点存储网络，现象复现；尝试 ifdown Secondary 节点存储网络，无法复现； 尝试 stop MongoDB service 替代 ifdown，Primary 或 Secondary 均无法复现。推测与 MongoDB 连接处理有关。</description></item><item><title>Yum 寻找 Best Package 评分机制</title><link>https://zdyxry.github.io/2022/04/29/Yum-%E5%AF%BB%E6%89%BE-Best-Package-%E8%AF%84%E5%88%86%E6%9C%BA%E5%88%B6/</link><pubDate>Fri, 29 Apr 2022 23:04:16 +0000</pubDate><guid>https://zdyxry.github.io/2022/04/29/Yum-%E5%AF%BB%E6%89%BE-Best-Package-%E8%AF%84%E5%88%86%E6%9C%BA%E5%88%B6/</guid><description>背景 链接到标题 公司产品最终交付形态是 ISO，在涉及一个产品的多个 OEM 场景时，会选择在标准版本的基础上，删除某些软件包，新增某些软件包的形式来减少构建时间。产品的 BaseOS 是 CentOS，包管理器是 RPM 系，也就需要使用 rpm / yum 等命令来实现。 其中新增某些软件包是使用 yumdownloader 来完成的。在 Yum Repository 中会包含同一软件包的多个版本，预期 yumdownloader 会下载 Yum Repository 中某个软件最新版本的包，比如 yumdownloader zbs-5.1.2* ，则会下载 zbs-5.1.2 大版本的最新 release 版本。
但是最近发现，从某个版本开始 yumdownloader 没有下载最新的软件包，反而停在了一个两个月之前构建的版本，于是开始调查原因。
Yumdownloader 链接到标题 yumdownloader 工具集是由 yum-utils 提供，同时还提供了 repotrack，repoquery, reposync 等有用的工具。yumdownloader 使用方式是 yumdownloader $pkg 即可。在 yum-utils 中会大量引用 yum module，因此需要同时查找两个 Git repo。
yum-utils 代码仓库地址： https://github.com/rpm-software-management/yum-utils/blob/master/yumdownloader.py
yum 代码仓库地址：https://github.com/rpm-software-management/yum
下载逻辑 链接到标题 def main(self): # Add command line option specific to yumdownloader self.</description></item><item><title>使用 init 进程运行 Container</title><link>https://zdyxry.github.io/2022/03/05/%E4%BD%BF%E7%94%A8-init-%E8%BF%9B%E7%A8%8B%E8%BF%90%E8%A1%8C-Container/</link><pubDate>Sat, 05 Mar 2022 15:10:39 +0000</pubDate><guid>https://zdyxry.github.io/2022/03/05/%E4%BD%BF%E7%94%A8-init-%E8%BF%9B%E7%A8%8B%E8%BF%90%E8%A1%8C-Container/</guid><description>背景 链接到标题 关注过 Bare Metal 相关项目的同学应该都了解过系统的启动流程、如何快速的置备一台物理服务器等之类的实现方式，通常都需要运行一个 LiveOS 来实现某些动作。 在 Tinkerbell 项目中，使用 Linuxkit 来作为 LiveOS，Plunder 项目中使用 BOOTy 来作为 LiveOS。前几天 @thebsdbox 将 BOOTy 中的一部分抽离了出来，作为 ginit 展示主要的实现方式，可以更好的让我们理解安装环节中的具体细节。 今天来看一下这个项目。
如果安装一个 CentOS，那么通常是会通过 kernel + initramfs.img 启动，initramfs.img 中会包含 systemd 、anaconda、dracut 等一些列组件，然后通过 systemd 指定不同的 Target 所属/依赖/顺序来完成最终 Anaconda 调用。Anaconda 通过解析 /proc/cmdline 中的 KickStart 参数来决定自己的安装方式。
ginit 项目展示了以下内容：
制作 initramfs.img 通过 Container image 制作一个 RAW image 通过 QEMU 使用 RAW image 和 Linux Kernel 来运行一个虚拟机 ginit 自动运行 Container 中 entrypoint 指令 流程演示 链接到标题 通过 Container image 制作一个 RAW image 链接到标题 RAW image 中最终不会包含 Kernel 部分，以 Nginx Container 为例。提取 nginx:latest image 中的 Entrypoint ，通过 dd 置备一个 RAW image，并格式化为 ext4 ，raw image 作为 loop 设备挂载到本地，通过 docker export 将 Nginx Image 拷贝到挂载点下，卸载挂载点，最终 RAW image 包含了 Nginx Container 的所有内容。这里的 RAW image 因为不包含 kernel，所以无法直接启动，只是作为后续动作的依赖。</description></item><item><title>编写一个友好的命令行工具</title><link>https://zdyxry.github.io/2022/02/26/%E7%BC%96%E5%86%99%E4%B8%80%E4%B8%AA%E5%8F%8B%E5%A5%BD%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Sat, 26 Feb 2022 19:50:44 +0000</pubDate><guid>https://zdyxry.github.io/2022/02/26/%E7%BC%96%E5%86%99%E4%B8%80%E4%B8%AA%E5%8F%8B%E5%A5%BD%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid><description>背景 链接到标题 关于命令行设计的一点总结。
有用的帮助信息 链接到标题 提供的命令行中所有的命令、子命令、选项都有明确的帮助信息，便于用户在使用过程中查看。帮助信息查看方式最好统一，比如统一使用 -h 格式、 COMMAND help 或者 COMMAND --help 。
尽量使用 Flags 而不是 Args 链接到标题 命令行可以接受 2 种类型的参数输入：Flags 和 Args。Flags 需要更多的输入，但会使命令行更清晰。我在实现一个命令行时，通常会将必选项设置为 Args ，将可选项设置为 Flags，但是有时候会导致用户在使用过程中觉得传递参数方式不统一，而且当 Args 有多个时（是的，我之前设计的一个命令行输入的 Args 多达 5 个）用户敲着敲着就不知道自己该输入什么了。如果在后续对命令行进行重构时，为了保证接口的兼容性，Args 通常是需要保证不变的，而 Flags 没有这个困扰。
明确显示当前版本 链接到标题 在使用过程中，如果遇到了问题，那么通常需要上报命令行版本反馈，需要明确给出当前命令行所指定的版本。通常会有 -v, -V, --version, version 等子命令，其中 -v 和 -V 有可能会跟 verbose 混淆，建议将版本作为一个独立的子命令 version 来实现。
针对 stdint, stdout, stderr 正确处理 链接到标题 如果已知一个命令行的执行耗时较长，那么用户通常执行命令时会选择将 stdout 重定向到指定文件中，便于后续查看执行过程输出，留存。但是如果在执行过程中出现异常，那么尽量将异常信息通过 stderr 输出，及时暴露给用户。默认情况下 stdout 被重定向之后，stderr 仍会打印在终端中。
明确的错误信息 链接到标题 当用户在执行命令过程中遇到错误，需要尽可能的显示多的、有用的信息出来：错误码、错误描述、错误信息。给出的信息是人类友好的，毕竟针对错误进行调试的是我们自己。尽量保证自己的命令行提供调试模式（类似于 Shell 中的 set -x ），便于 debug。</description></item><item><title>基于 Yamux 的内网穿透简易实现</title><link>https://zdyxry.github.io/2022/02/09/%E5%9F%BA%E4%BA%8E-Yamux-%E7%9A%84%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0/</link><pubDate>Wed, 09 Feb 2022 11:57:51 +0000</pubDate><guid>https://zdyxry.github.io/2022/02/09/%E5%9F%BA%E4%BA%8E-Yamux-%E7%9A%84%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0/</guid><description>基于 Yamux 的内网穿透简易实现 链接到标题 Server 链接到标题 模拟真实服务器，假设运行在内网环境，端口 8881。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; ) func main() { http.HandleFunc(&amp;#34;/hello&amp;#34;, HelloHandler) fmt.Println(&amp;#34;Server started at port 8881&amp;#34;) log.Fatal(http.ListenAndServe(&amp;#34;:8881&amp;#34;, nil)) } func HelloHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, &amp;#34;Hello, there\n&amp;#34;) } Hub 链接到标题 运行在公网环境的 Hub，用于 Agent 连接，并保持会话。端口 8882。
提供 session 管理机制，主要用来保存 Yamux session 和 Agent 对应关系。 每个内网可以运行多个 Agent，每次新建连接会从已有的 Agent session 列表中随机选择一个 session，并通过创建一个新的 Yamux Stream 机制复用连接。
type SessionManager interface { AddSession(key string, sess *yamux.</description></item><item><title>2021 年读书记录</title><link>https://zdyxry.github.io/2021/12/31/2021-%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 31 Dec 2021 09:01:41 +0000</pubDate><guid>https://zdyxry.github.io/2021/12/31/2021-%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</guid><description> 年终总结 链接到标题 2016 计划读 5 本，实际读 13 本。 2017 计划 32 本，实际读完 23 本。 2018 计划 30 本，实际25本。 2019 计划 30 本，实际 43 本。 2020 计划 30 本，实际 40 本。 2021 计划 50 本，实际 47 本。 已读 链接到标题 《Linux C编程一站式学习》 《现代操作系统：原理与实现》 《封锁》 《指数基金投资》 《指数基金投资指南》 《小狗钱钱》 《富爸爸穷爸爸》 《The Almanack of Naval Ravikant》 《让时间陪你慢慢变富》 《韭菜的自我修养》 《labuladong的算法小抄》 《人人都能用英语》 《仿制药的真相》 《Kubernetes源码剖析》 《如何高效学习》 《你的第一本保险指南》 《跑步圣经》 《当我谈跑步时我谈些什么》 《柴犬绅士》 《咖啡新规则》 《深度休息》 《爱上跑步的13周》 《金阁寺》 《UNIX传奇》 《间客》 《工薪族财务自由说明书》 《分布式缓存》 《剑指Offer》 《商业的本质和互联网》 《哈利·波特》 《Go语言编程》 《卡片笔记写作法》 《图解网络硬件》 《喜剧这回事》 《gRPC与云原生应用开发》 《HTTP/2 in Action 中文版》 《代码整洁之道》 《李诞脱口秀工作手册》 《娱乐至死》 《深入浅出 HTTPS：从原理到实战》 《骆驼祥子》 《沉默的大多数》 《智能时代》 《被看见的力量》 《拒看新聞的生活藝術》 《JavaScript DOM编程艺术 （第2版）》 《非暴力沟通》</description></item><item><title>DHCP lease 生命周期</title><link>https://zdyxry.github.io/2021/12/18/DHCP-lease-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</link><pubDate>Sat, 18 Dec 2021 18:42:08 +0000</pubDate><guid>https://zdyxry.github.io/2021/12/18/DHCP-lease-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</guid><description>背景 链接到标题 昨天配合一个同事排查虚拟机 IP 发生了变化的问题，正好整理一下 DHCP lease 生命周期以及变化流程。
DHCP lease 生命周期 链接到标题 Allocation：一个客户端开始时没有有效的租约，因此也没有 DHCP 分配的地址。它通过一个分配过程获得一个租约。 Reallocation：如果一个客户端已经有了一个来自现有租约的地址，那么当它重启或关闭后启动时，它将与授予它租约的 DHCP 服务器联系，以确认租约并获得操作参数。这有时被称为重新分配；它与完全分配过程相似，但时间更短。 Normal Operation：一旦租约被激活，客户端就会正常工作，在租约周期内使用其分配的IP地址和其他参数。客户端被称为与租约和地址绑定。 Renewal：在租约时间的某一部分过期后，客户端将试图联系最初授予租约的服务器，以更新租约，这样它就可以继续使用其 IP 地址。 Rebinding：如果与最初的租约服务器续约失败（例如，因为该服务器已经下线），那么客户端将尝试重新绑定到任何活跃的 DHCP 服务器，试图在任何允许它这样做的服务器上延长其当前租约。 Release：客户端可以在任何时候决定它不再希望使用它被分配的IP地址，并可以终止租约，释放 IP 地址。 Allocation 流程 链接到标题 - 1.客户端创建 DHCPDISCOVER 消息 客户端开始处于INIT（初始化）状态。它没有IP地址，甚至不知道网络上是否有 DHCP 服务器或在哪里。为了找到一个，它创建了一个 DHCPDISCOVER 消息，包括以下信息。 - 在消息的 CHAddr 字段中包含自己的硬件地址，用来识别自身。 - 一个随机的交易标识符，放在 XID 字段中，这被用来识别以后的消息是同一事务的一部分。 - 另外，客户可以使用 `Requested IP Address` DHCP 选项请求一个特定的IP地址，使用IP地址 `Lease Time` 选项请求一个特定的租约长度，或通过在报文中加入`Parameter Request List`选项请求特定的配置参数。 - 2.客户端发送 DHCPDISCOVER 消息 客户端在本地网络上广播 DHCPDISCOVER 消息。客户端过渡到 SELECTING 状态，在那里等待对其消息的回复。 - 3.</description></item><item><title>CentOS 执行 grub2-mkconfig 导致磁盘只读</title><link>https://zdyxry.github.io/2021/10/02/CentOS-%E6%89%A7%E8%A1%8C-grub2-mkconfig-%E5%AF%BC%E8%87%B4%E7%A3%81%E7%9B%98%E5%8F%AA%E8%AF%BB/</link><pubDate>Sat, 02 Oct 2021 07:30:09 +0000</pubDate><guid>https://zdyxry.github.io/2021/10/02/CentOS-%E6%89%A7%E8%A1%8C-grub2-mkconfig-%E5%AF%BC%E8%87%B4%E7%A3%81%E7%9B%98%E5%8F%AA%E8%AF%BB/</guid><description>背景 链接到标题 最近遇到了一个故障，在集群软件升级过程中，发现某一个磁盘分区变为只读，导致存储应用识别该磁盘不可用。调查发现集群升级过程中，会重新生成每个节点的 GRUB 配置文件，在执行 grub2-mkconfig 过程中导致的磁盘分区只读。记录下 grub2-mkconfig 命令执行到真正磁盘只读指令下发的流程。
调查 链接到标题 grub2-mkconfig 链接到标题 在执行 grub2-mkconfig 命令时，如果没有指定配置 GRUB_DISABLE_OS_PROBER=true 时，则 GRUB 会调用 os-prober （/etc/grub.d/30_os-prober）用于扫描其他操作系统进行后续配置。
os-prober 链接到标题 os-prober 是用来探测其他磁盘中存在操作系统的情况。通常由各个发行版本提供，源码地址：https://salsa.debian.org/installer-team/os-prober 。
CentOS 默认包含的 os-prober 与源码版本并不相同，包含了一些额外的配置，通过 RPM changelog 可以查看：
Name : os-prober Version : 1.58 Release : 9.el7 Architecture: x86_64 Install Date: Wed 18 Aug 2021 03:44:43 PM CST Group : System Environment/Base Size : 97946 License : GPLv2+ and GPL+ Signature : RSA/SHA256, Mon 21 Nov 2016 03:50:19 AM CST, Key ID 24c6a8a7f4a80eb5 Source RPM : os-prober-1.</description></item><item><title>Linux audit buffer 配置</title><link>https://zdyxry.github.io/2021/08/15/Linux-audit-buffer-%E9%85%8D%E7%BD%AE/</link><pubDate>Sun, 15 Aug 2021 08:49:59 +0000</pubDate><guid>https://zdyxry.github.io/2021/08/15/Linux-audit-buffer-%E9%85%8D%E7%BD%AE/</guid><description>背景 链接到标题 最近遇到了一个 case，一台主机处于挂起状态，当时主机的 IPMI console 显示日志 ： audit: backlog limit exceeded ，由于一些原因，导致没有及时的发送 NMI 信号触发 kernel core dump，所以只能根据已有信息进行排查，记录下 audit buffer 相关配置的学习。
Audit 链接到标题 Linux kernel 在 2.6 引入 audit，为了能够更好的记录系统中的各种安全事件，比如文件修改事件和系统调用事件。
配置方法 链接到标题 /etc/audit 目录下
控制规则：设置 audit 系统的一些行为以及修改其默认设置 文件系统规则：审计文件，记录特殊文件或目录的访问情况 系统调用规则：记录一些特殊应用程序的系统调用行为 buffer 配置 链接到标题 当事件无法被正确记录时，会打印一些异常日志：
``` audit: audit_backlog=321 &amp;gt; audit_backlog_limit=320 audit: audit_lost=44395 audit_rate_limit=0 audit_backlog_limit=320 audit: backlog limit exceeded ``` 根据 audit 的flag 配置决定，当 flag ==1 时，打印提示日志；当 flag ==2 时，kernel panic。 默认flag = 1 。</description></item><item><title>Container Optimized OS(COS) 简单对比</title><link>https://zdyxry.github.io/2021/07/30/Container-Optimized-OSCOS-%E7%AE%80%E5%8D%95%E5%AF%B9%E6%AF%94/</link><pubDate>Fri, 30 Jul 2021 21:39:04 +0000</pubDate><guid>https://zdyxry.github.io/2021/07/30/Container-Optimized-OSCOS-%E7%AE%80%E5%8D%95%E5%AF%B9%E6%AF%94/</guid><description>背景 链接到标题 之前简单调研过一些 Container Optimized OS，进行了一些简单的对比，最近又被同事问到了，整理一下发出来。
COS 链接到标题 结论 链接到标题 如果让我来选择一个 COS 作为 BaseOS 来进行定制，那我会根据以下几个条件来进行选择：
是否支持 OSTree 是否有明星公司做背后支持，如 RedHat、VMware 社区活跃度 根据以上几个条件，如果是我自己使用的话，我会选择 Fedora CoreOS，或者 VMware Photo（OSTree） 。</description></item><item><title>Gunicorn 信号处理</title><link>https://zdyxry.github.io/2021/06/27/Gunicorn-%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/</link><pubDate>Sun, 27 Jun 2021 18:55:41 +0000</pubDate><guid>https://zdyxry.github.io/2021/06/27/Gunicorn-%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/</guid><description>背景 链接到标题 最近在项目中使用到了 Gunicorn 的 Graceful Shutdown 功能，阅读代码学习一下 Gunicorn 的信号处理。
Master 链接到标题 Gunicorn 启动入口：
WSGIApplication(&amp;#34;%(prog)s [OPTIONS] [APP_MODULE]&amp;#34;).run() BaseApplication().run() Arbiter(self).run() Master 主要控制逻辑实现在 Arbiter 中，包括信号处理和主循环逻辑。在调用 Arbiter().run() 会最终调用到 Arbiter.init_signals() ，在该函数中会将 Master 中定义的需要处理的信号函数进行相应的注册：
Arbiter().run(): Arbiter().start() Arbiter().init_signals() # 初始化 Master 信号处理 # initialize all signals for s in self.SIGNALS: # &amp;#34;HUP QUIT INT TERM TTIN TTOU USR1 USR2 WINCH&amp;#34; signal.signal(s, self.signal) signal.signal(signal.SIGCHLD, self.handle_chld) 所有定义的信号处理函数都是 Aribiter().signal() ，该函数将接收到的信号存放在 Arbiter.SIG_QUEUE 中，最多保留 5 个信号，然后触发 Arbiter().wakeup() ，在 Arbiter().wakeup() 中，向 Arbiter.</description></item><item><title>OSTree 背景介绍</title><link>https://zdyxry.github.io/2021/05/22/OSTree-%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D/</link><pubDate>Sat, 22 May 2021 09:00:15 +0000</pubDate><guid>https://zdyxry.github.io/2021/05/22/OSTree-%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D/</guid><description>背景 链接到标题 前段时间对 OSTree 做了一些简单的了解，进行了内部分享，好久没更新博客，把 PPT 整理出来水一篇。
仓库地址： https://github.com/zdyxry/ostree-share/ PPT： https://github.com/zdyxry/ostree-share/blob/master/ostree-intro.md
（Marp 真的好用，用 Markdown 写草稿，然后短时间就可以转换成 PPT</description></item><item><title>《现代操作系统：原理与实现》读书笔记</title><link>https://zdyxry.github.io/2021/01/17/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Sun, 17 Jan 2021 10:42:48 +0000</pubDate><guid>https://zdyxry.github.io/2021/01/17/%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>第1章　操作系统概述 链接到标题 操作系统有两个职责：对硬件进行管理和抽象，为应用提供服务并进行管理。
从硬件的角度来看，操作系统核心功能是将优先的，离散的资源高效的抽象为无限的、连续的资源。
从应用的角度来看，操作系统提供了不同层次，不同功能的接口，还提供了不同类型的访问控制。还负责对应用生命周期的管理，包括应用的加载、启动、切换、调度、销毁等。
API vs ABI
API 是指应用编程接口，它定义了两层软件之间的源码层面的交互接口。
ABI 是指应用二进制接口，即在某个特定体系结构下两层软件之间二进制层面的交互接口，包括如何定义二进制文件格式、应用之间的调用约定、数据模式等。
第2章　硬件结构 链接到标题 冯诺依曼结构包括三个主要部分：
中央处理单元（CPU）：主要负责运算和逻辑控制，按照程序中的指令进行计算，并且根据条件执行程序中的不同部分 存储器（memory unit）：负责存储程序指令和数据，以及保存程序执行的中间结果和最终结构。在现代计算机中，存储器通常包括寄存器、cpu 缓存、内存等存储层次。 输入输出（I/O）：负责与外界进行交互，从外界获得输入，将结果向外界输出。 指令集架构（ISA）是 CPU 和软件之间的桥梁。ISA 包含指令集、特权级、寄存器、执行模式、安全扩展、性能加速扩展等方面。
指令集是 ISA 的重要组成部分，通常包含一系列不同功能的指令，用于数据搬移、计算、内存访问、过程调用等。
AArch64 属于精简指令集计算机（RISC）。AArch64 每跳指令的长度固定为 4 字节，指令类型包括：
数据搬移指定（mov）； 寄存器计算指令（add，sub）； 内存读写指令（ldr，str）； 跳转指令（b）； 过程调用指令（bl，ret）； 特权指令（msr，mrs）。 特权级也是 ISA 的重要组成部分。AArch64 中的特权级被称为异常级别（Exception Level，EL），共有四种特权级：
EL0：最低的特权级，应用程序通常运行在该特权级，也成为用户态 EL1：操作系统通常运行在该特权级，也成为内核态 EL2：在虚拟化场景下需要，虚拟机监控器（VMM，也称为 Hypervisor）通常运行在该特权级 EL3：和安全特性 TrustZone 相关，负责普通世界（normal word）和安全世界（secure world）之间的切换 一般来说，EL0 切换到 EL1 的可能场景有三种：
应用程序需要调用操作系统提供的系统调用，此时应用程序会通过执行 svc（特权调用 supervisor call）指令将 CPU 特权级从 EL0 切换到 EL1 应用程序执行了一条指令，而该指令触发了异常（exception），该异常导致 CPU 特权级从 EL0 切换到了 EL1。例如，应用在执行一条访存指令时，触发了缺页异常（page fault），从而切换到操作系统内核进行处理 应用程序在执行的过程中，CPU 收到了一个来自外设的中断（interrupt），该中断也会导致 CPU 特权级从 EL0 切换到 EL1 前两种成为同步的 CPU 特权级切换，因为都是由于 CPU 正在执行的指令所导致的，第三种 CPU 发生的切换并不是由于指令导致的，属于异步的 CPU 特权级切换。 在发生特权级切换时，CPU 负责保存当前执行状态，以便操作系统内核在处理异常是使用并在处理结束后能够恢复应用程序的执行，CPU 保存的主要状态包括：</description></item><item><title>Podman(Docker) Compose 学习记录</title><link>https://zdyxry.github.io/2021/01/09/PodmanDocker-Compose-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 09 Jan 2021 18:56:30 +0000</pubDate><guid>https://zdyxry.github.io/2021/01/09/PodmanDocker-Compose-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid><description>Compose 链接到标题 最近因为一些需求可能需要用到 Compose，看了看 Podman Compose 和 Docker Compose，记录一下。
Compose 主要功能：
环境隔离(docker) 一组服务的起停控制 服务之间的依赖管理 Podman compose 链接到标题 项目地址：https://github.com/containers/podman-compose
用爱发电的项目，所有的实现都在 podman_compose.py 中，由于 Podman 没有一个好用的 client ，所以 compose 中所有的 Podman 相关的交互都是通过命令行来完成的，目前处于一个非常早期的状态，最基本的服务依赖都没有实现，不建议使用。
Docker compose 链接到标题 cli/ # 命令行解析 config/ # 配置文件格式、校验方式、辅助函数 const.py # constants container.py # 使用 docker client 对 container 命令及属性进行封装 errors.py # error code network.py # 网络相关配置 parallel.py # 并发操作封装 progress_stream.py # stream 相关 project.py # project，project 与 service 是一对多的关系 service.</description></item><item><title>cgroups notification API demo</title><link>https://zdyxry.github.io/2021/01/01/cgroups-notification-API-demo/</link><pubDate>Fri, 01 Jan 2021 18:28:00 +0000</pubDate><guid>https://zdyxry.github.io/2021/01/01/cgroups-notification-API-demo/</guid><description>cgroups notification API demo 链接到标题 package main import ( &amp;#34;flag&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;os&amp;#34; &amp;#34;path/filepath&amp;#34; &amp;#34;golang.org/x/sys/unix&amp;#34; ) func main() { cgName := flag.String(&amp;#34;cgName&amp;#34;, &amp;#34;yiran&amp;#34;, &amp;#34;cgroup path&amp;#34;) flag.Parse() level := &amp;#34;critical&amp;#34; cgDir := filepath.Join(&amp;#34;/sys/fs/cgroup/memory/&amp;#34;, *cgName) evName := &amp;#34;memory.pressure_level&amp;#34; fmt.Printf(&amp;#34;cgroup name is: %s\n&amp;#34;, *cgName) fmt.Printf(&amp;#34;cgroup path is: %s\n&amp;#34;, cgDir) fmt.Printf(&amp;#34;cgroup event name is: %s\n&amp;#34;, evName) evFile, err := os.Open(filepath.Join(cgDir, evName)) if err != nil { panic(err) } fd, err := unix.Eventfd(0, unix.EFD_CLOEXEC) if err !</description></item><item><title>2020 年终总结</title><link>https://zdyxry.github.io/2020/12/31/2020-%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/</link><pubDate>Thu, 31 Dec 2020 08:42:51 +0000</pubDate><guid>https://zdyxry.github.io/2020/12/31/2020-%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/</guid><description>2020 链接到标题 减重 70 斤，身体达到近 10 年最健康的状态。</description></item><item><title>2020年读书记录</title><link>https://zdyxry.github.io/2020/12/28/2020%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</link><pubDate>Mon, 28 Dec 2020 09:03:03 +0000</pubDate><guid>https://zdyxry.github.io/2020/12/28/2020%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</guid><description> 年终总结 链接到标题 2016 计划读 5 本，实际读 13 本。 2017 计划 32 本，实际读完 23 本。 2018 计划 30 本，实际25本。 2019 计划 30 本，实际 43 本。 2020 计划 30 本，实际 40 本。 已读 链接到标题 《时间的秩序》 《肠子的小心思》 《饮食的迷思》 《认知天性》 《Linux/UNIX系统编程手册》 《码农翻身》 《庆余年》 《凤凰项目》 《编程珠玑》 《了不起的我》 《见识》 《重来》 《重来2》 《Unix/Linux编程实践教程》 《漫画数据库》 《程序员修炼之道》 《Flask Web开发：基于Python的Web应用开发实战》 《HTTP权威指南》 《计算机网络（第7版）》 《程序员的数学》 《把时间当作朋友》 《KVM Virtualization Cookbook》 《Go语言学习笔记》 《UNIX网络编程》 《现代操作系统（原书第4版）》 《基本无害》 《宇宙尽头的餐馆》 《生命，宇宙以及一切》 《再会，谢谢所有的鱼》 《畅游日本（第3版）》 《基本穿搭》 《囚徒健身》 《蛤蟆先生去看心理医生》 《天生有罪》 《数据密集型应用系统设计》 《高效能人士的七个习惯》 《咖啡咖啡》 《TCP/IP网络编程》 《献给阿尔吉侬的花束》 《囚徒增肌》</description></item><item><title>2020 第39周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/09/26/2020-%E7%AC%AC39%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 26 Sep 2020 17:08:07 +0000</pubDate><guid>https://zdyxry.github.io/2020/09/26/2020-%E7%AC%AC39%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1588. Sum of All Odd Length Subarrays 链接到标题 处理当长度为 1 时特殊情况，其他都遍历长度为奇数情况然后求和。
class Solution: def sumOddLengthSubarrays(self, arr: List[int]) -&amp;gt; int: res = 0 for i in range(len(arr)+1): if i % 2: if i == 1: res += sum(arr) else: j = 0 while j + i &amp;lt;= len(arr): res += sum(arr[j:j+i]) j += 1 return res 1592. Rearrange Spaces Between Words 链接到标题 统计空格出现的次数，然后求出平均空格数进行字符串拼接。
class Solution: def reorderSpaces(self, text: str) -&amp;gt; str: cnt=text.</description></item><item><title>2020 第38周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/09/20/2020-%E7%AC%AC38%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sun, 20 Sep 2020 07:45:55 +0000</pubDate><guid>https://zdyxry.github.io/2020/09/20/2020-%E7%AC%AC38%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1582. Special Positions in a Binary Matrix 链接到标题 直接遍历二维数组之后，如果某个位置是 1，再去统计每行的和和每列的和是否为 1 时间复杂度太高，可以先统计每行每列的和，然后再遍历二维数组。
class Solution: def numSpecial(self, mat: List[List[int]]) -&amp;gt; int: m, n, ans = len(mat), len(mat[0]), 0 row, col = [0] * m, [0] * n for i in range(m): for j in range(n): if mat[i][j]: row[i] += 1 col[j] += 1 pool = [j for j in range(n) if col[j] == 1] for i in range(m): if row[i] !</description></item><item><title>2020 第37周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/09/13/2020-%E7%AC%AC37%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sun, 13 Sep 2020 10:51:05 +0000</pubDate><guid>https://zdyxry.github.io/2020/09/13/2020-%E7%AC%AC37%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1572. Matrix Diagonal Sum 链接到标题 对角线之和，需要注意当行为奇数和偶数时候的去重处理。
class Solution: def diagonalSum(self, mat: List[List[int]]) -&amp;gt; int: n = len(mat) if n == 1: return mat[0][0] ans = 0 for i in range(n): if i != n-1-i: ans += mat[i][i] ans += mat[i][n-1-i] else: ans += mat[i][i] return ans 1576. Replace All ?&amp;rsquo;s to Avoid Consecutive Repeating Characters 链接到标题 题目中说的是不能出现连续相同的字符，整个字符串中是可以出现重复字符的，只需要遍历字符串，然后判断前后是否相同替换。
class Solution: def modifyString(self, s: str) -&amp;gt; str: l = list(s) alphabet = list(string.</description></item><item><title>2020 第36周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/09/06/2020-%E7%AC%AC36%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sun, 06 Sep 2020 15:04:19 +0000</pubDate><guid>https://zdyxry.github.io/2020/09/06/2020-%E7%AC%AC36%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1566. Detect Pattern of Length M Repeated K or More Times 链接到标题 判断数组中是否存在连续长度为 m 且重复次数为 k 的字符串，直接对 arr 进行切片判断。
class Solution: def containsPattern(self, arr: List[int], m: int, k: int) -&amp;gt; bool: i = 0 while i &amp;lt; len(arr): p = arr[i:i+m] if p * k == arr[i:i+m*k]: return True i += 1 return False 1567. Maximum Length of Subarray With Positive Product 链接到标题 给你一个整数数组 nums ，请你求出乘积为正数的最长子数组的长度。使用数组记录数值为负数的索引值，当数字为 0 时则重置数组，当负数数量为偶数时，则更新最大值，最大值为当前索引减去第一个非 0 数字索引，如果负数数量为奇数时，则最大值为当前索引减去第一个负数索引。</description></item><item><title>2020 第35周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/08/29/2020-%E7%AC%AC35%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 29 Aug 2020 18:42:34 +0000</pubDate><guid>https://zdyxry.github.io/2020/08/29/2020-%E7%AC%AC35%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1560. Most Visited Sector in a Circular Track 链接到标题 在中间走过多少圈，对于各个扇区来说是相同的，只需要考虑起点和终点的位置关系。
class Solution: def mostVisited(self, n: int, rounds: List[int]) -&amp;gt; List[int]: s, d = rounds[0], rounds[-1] if s &amp;lt;= d: return list(range(s, d+1)) else: return list(range(1, d+1)) + list(range(s, n+1)) 1557. Minimum Number of Vertices to Reach All Nodes 链接到标题 如果某个节点出现在到达节点，那么这个节点一定不在结果中，相反则一定在结果中。
class Solution: def findSmallestSetOfVertices(self, n: int, edges: List[List[int]]) -&amp;gt; List[int]: return list(set(range(n)) - set(e[1] for e in edges)) 1558. Minimum Numbers of Function Calls to Make Target Array 链接到标题 一共有两种操作：1.</description></item><item><title>2020 第34周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/08/23/2020-%E7%AC%AC34%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sun, 23 Aug 2020 16:37:12 +0000</pubDate><guid>https://zdyxry.github.io/2020/08/23/2020-%E7%AC%AC34%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1550. Three Consecutive Odds 链接到标题 判断数组是否存在连续 3 个奇数的情况存在，直接遍历判断，使用变量记录当前奇数个数。
class Solution: def threeConsecutiveOdds(self, arr: List[int]) -&amp;gt; bool: cnt = 0 for i in arr: if i &amp;amp; 1: cnt += 1 else: cnt = 0 if cnt == 3: return True return False 1551. Minimum Operations to Make Array Equal 链接到标题 一道数学题，等差数列求和公式变形。
n=3 最小操作数是 2 n=4 最小操作数是 1 + 3 n=5 最小操作数是 2 + 4 n=6 最小操作数是 1 + 3 + 5 n=7 最小操作数是 2 + 4 + 6 class Solution: def minOperations(self, n: int) -&amp;gt; int: return n*n // 4 410.</description></item><item><title>ARM 服务器适配总结</title><link>https://zdyxry.github.io/2020/08/22/ARM-%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%80%82%E9%85%8D%E6%80%BB%E7%BB%93/</link><pubDate>Sat, 22 Aug 2020 15:09:04 +0000</pubDate><guid>https://zdyxry.github.io/2020/08/22/ARM-%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%80%82%E9%85%8D%E6%80%BB%E7%BB%93/</guid><description>背景 链接到标题 上一次写 ARM 服务器相关的是在大半年以前了，当时适配工作做得神烦，最近在折腾 ARM 上 KVM 虚拟化相关的事情，目标是虚拟化功能最小代码改动同时兼容 x86 和 ARM，记录一下目前的一点经验总结。
硬件配置：
华为泰山服务器 Kunpeng 920 软件配置：
CentOS 7.6 kernel-4.18.0-193.1.2.el7.aarch64 libvirt-4.5.0 qemu-2.12.0 信息获取 链接到标题 Architecture 链接到标题 如果产品之前都是 x86 架构下的，在适配 ARM 时往往需要进行架构判断，此时可以通过 arch 来获取，在 ARM 架构显示 aarch64 ，在 x86 架构下显示 x86_64 。
aarch64 等价于 arm64。
AArch64 or ARM64 is the 64-bit extension of the ARM architecture.
KVM module 链接到标题 在 x86 上我们可以直接通过 lsmod |grep kvm 查看到 KVM module 情况:
[root@node90 19:24:30 ~]$lsmod |grep kvm kvm_intel 188644 82 kvm 621480 1 kvm_intel 但是在 arm 上是没有加载 KVM module 的，此时想要知道 KVM 配置是否正确，可以通过 dmesg 中查看 KVM 相关日志：</description></item><item><title>2020 第33周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/08/16/2020-%E7%AC%AC33%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sun, 16 Aug 2020 10:27:06 +0000</pubDate><guid>https://zdyxry.github.io/2020/08/16/2020-%E7%AC%AC33%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1544. Make The String Great 链接到标题 使用栈来记录最终结果，如果栈顶和当前字符相同，那么出栈，否则入栈。
class Solution: def makeGood(self, s: str) -&amp;gt; str: stack = [] for i in s: if stack and ((ord(stack[-1])-32) == ord(i) or (ord(stack[-1])+32) == ord(i)): stack.pop() else: stack.append(i) return &amp;#39;&amp;#39;.join(stack) 1545. Find Kth Bit in Nth Binary String 链接到标题 找出第 N 个二进制字符串中的第 K 位，其中二进制字符串的生成是按照特定规律的，可以直接暴力模拟生成二进制字符串，找出第 N 个，这种方法不会超时，但是不好。考虑使用递归求解，每个二进制字符串的左半部分，都是上一个二进制字符串，那么需要判断 K 在第 N 个字符串中的左边还是右边，如果是中间就直接返回 1 ；如果是左边，那么就找 N-1 个二进制字符串中 K 个；如果是右边，那么就找 N-1 个二进制字符串中的 K 对称位置，并将结果取反。
class Solution: def findKthBit(self, n: int, k: int) -&amp;gt; str: if (n == 1): return &amp;#39;0&amp;#39; l = (1 &amp;lt;&amp;lt; n) - 1 mid = (l &amp;gt;&amp;gt; 1) + 1 if k == mid: return &amp;#39;1&amp;#39; elif k &amp;lt; mid: return self.</description></item><item><title>2020 第32周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/08/08/2020-%E7%AC%AC32%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 08 Aug 2020 16:17:20 +0000</pubDate><guid>https://zdyxry.github.io/2020/08/08/2020-%E7%AC%AC32%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1534. Count Good Triplets 链接到标题 数据规模很小，暴力循环解。
class Solution: def countGoodTriplets(self, arr: List[int], a: int, b: int, c: int) -&amp;gt; int: if len(arr) &amp;lt; 3: return 0 ans = 0 for i in range(0, len(arr)): for j in range(i+1, len(arr)): for k in range(j+1, len(arr)): if abs(arr[i] - arr[j]) &amp;lt;= a and abs(arr[j] - arr[k]) &amp;lt;= b and abs(arr[i] - arr[k]) &amp;lt;= c: ans += 1 return ans 1535. Find the Winner of an Array Game 链接到标题 每回合游戏都在数组的前两个元素（即 arr[0] 和 arr[1] ）之间进行。比较 arr[0] 与 arr[1] 的大小，较大的整数将会取得这一回合的胜利并保留在位置 0 ，较小的整数移至数组的末尾。当一个整数赢得 k 个连续回合时，游戏结束，该整数就是比赛的 赢家 。</description></item><item><title>通过 grub 修复系统无法正确引导问题</title><link>https://zdyxry.github.io/2020/08/02/%E9%80%9A%E8%BF%87-grub-%E4%BF%AE%E5%A4%8D%E7%B3%BB%E7%BB%9F%E6%97%A0%E6%B3%95%E6%AD%A3%E7%A1%AE%E5%BC%95%E5%AF%BC%E9%97%AE%E9%A2%98/</link><pubDate>Sun, 02 Aug 2020 09:10:39 +0000</pubDate><guid>https://zdyxry.github.io/2020/08/02/%E9%80%9A%E8%BF%87-grub-%E4%BF%AE%E5%A4%8D%E7%B3%BB%E7%BB%9F%E6%97%A0%E6%B3%95%E6%AD%A3%E7%A1%AE%E5%BC%95%E5%AF%BC%E9%97%AE%E9%A2%98/</guid><description>背景 链接到标题 最近在将一个节点的 kernel 从 4.18 版本降级到 4.14 后，发现系统无法启动，直接进入到了 GRUB 提示符界面，记录下修复过程。
现象 链接到标题 因为 kernel 4.18 版本和 4.14 的 打包方式发生了比较大的变化，4.18 版本多出了 kernel-core 和 kernel-modules 两个 rpm：
4.14
[root@sh-workstation Packages]# ls |grep ^kernel kernel-4.14.0-115.el7a.0.1.aarch64.rpm kernel-headers-4.14.0-115.el7a.0.1.aarch64.rpm kernel-tools-4.14.0-115.el7a.0.1.aarch64.rpm kernel-tools-libs-4.14.0-115.el7a.0.1.aarch64.rpm 4.18
kernel-4.18.0-147.8.1.el7.aarch64.rpm kernel-core-4.18.0-147.8.1.el7.aarch64.rpm kernel-modules-4.18.0-147.8.1.el7.aarch64.rpm kernel-tools-4.18.0-147.8.1.el7.aarch64.rpm kernel-tools-libs-4.18.0-147.8.1.el7.aarch64.rpm 在没有官方 yum repo 的情况下，降级就比较麻烦，我直接尝试 rpm -Uvh kernel-4.14*.rpm ，然后将 4.18 的 kernel-core 和 kernel-modules 卸载掉，然后重启后，发现系统直接进入到了 GRUB 提示符界面，无法正常启动，只能寻求修复办法。
修复方式 链接到标题 当时系统启动后，显示的是 grub&amp;gt; 提示符，说明此时已经加载了 grub 程序，但是没有找到 grub.cfg 配置文件中的指定kernel 和 initramfs。</description></item><item><title>2020 第31周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/08/01/2020-%E7%AC%AC31%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 01 Aug 2020 07:26:24 +0000</pubDate><guid>https://zdyxry.github.io/2020/08/01/2020-%E7%AC%AC31%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1523. Count Odd Numbers in an Interval Range 链接到标题 数学题，数据范围是10^9，O(n) 会超时，统计 high 中有多少个奇数，减去 low-1 中的奇数个数，需要考虑边界条件：low/high 自身为奇数情况。
class Solution: def countOdds(self, low: int, high: int) -&amp;gt; int: res = high // 2 if high % 2 == 1: res += 1 if low - 1 &amp;gt;= 0: res -= (low - 1) // 2 if (low - 1) % 2 == 1: res -= 1 return res 1528. Shuffle String 链接到标题 按照指定顺序调整字符串，直接定义一个新的长度为 len(s)字符串，然后按照 indices 的索引顺序进行对应调整。</description></item><item><title>2020 第30周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/07/26/2020-%E7%AC%AC30%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sun, 26 Jul 2020 09:36:03 +0000</pubDate><guid>https://zdyxry.github.io/2020/07/26/2020-%E7%AC%AC30%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1518. Water Bottles 链接到标题 小学数学题，用几个空瓶子可以换一瓶新的，问最后能喝到几瓶，在小学场景下可以先借再喝，在这道题没有这种场景，所以正常计算就好。
class Solution: def numWaterBottles(self, numBottles: int, numExchange: int) -&amp;gt; int: res = numBottles while numBottles &amp;gt;= numExchange: cnt = numBottles // numExchange res += cnt numBottles = numBottles - (cnt * numExchange) numBottles += cnt return res 1108. Defanging an IP Address 链接到标题 将 IPv4 地址 &amp;ldquo;1.1.1.1&amp;rdquo; 转换为 &amp;ldquo;1[.]1[.]1[.]1&amp;rdquo; ，不知道这道题的意义在哪里。。
class Solution: def defangIPaddr(self, address: str) -&amp;gt; str: return address.replace(&amp;#39;.&amp;#39;, &amp;#39;[.]&amp;#39;) 1519. Number of Nodes in the Sub-Tree With the Same Label 链接到标题 题目很绕，最好自己根据给的 edges 和 labels 构建出对应的树，了解是如何构建的，最终要求的 ans 中 ans[i] 表示第 i 个节点的子树中与节点 i 标签相同的节点数，记录所有节点的相邻节点，从 0 节点开始 dfs，如果节点已经访问过，则跳过对应节点，最终汇总 ans[i] 中的数值。</description></item><item><title>2020 第29周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/07/19/2020-%E7%AC%AC29%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sun, 19 Jul 2020 11:19:38 +0000</pubDate><guid>https://zdyxry.github.io/2020/07/19/2020-%E7%AC%AC29%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1509. Minimum Difference Between Largest and Smallest Value in Three Moves 链接到标题 要返回最大值与最小值之间的差最小，那么先对其进行排序，三次操作相当于删除三个数字，依次判断删除三个数字之后剩余的数字最大值最小值差最小。
class Solution: def minDifference(self, nums: List[int]) -&amp;gt; int: nums.sort() return min(b - a for a, b in zip(nums[:4], nums[-4:])) 1512. Number of Good Pairs 链接到标题 如果一组数字 (i,j) 满足 nums[i] == nums[j] 且 i &amp;lt; j ，就可以认为这是一组 好数对 ，返回好数对的数目。 只要一个数字出现次数多余一次，那么这个数就可以凑成好数对，然后进行组合。
class Solution: def numIdenticalPairs(self, A: List[int]) -&amp;gt; int: return sum(k * (k - 1) / 2 for k in collections.</description></item><item><title>2020 第28周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/07/11/2020-%E7%AC%AC28%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 11 Jul 2020 21:50:54 +0000</pubDate><guid>https://zdyxry.github.io/2020/07/11/2020-%E7%AC%AC28%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1502. Can Make Arithmetic Progression From Sequence 链接到标题 判断是否可以组成等差数列，将数组排序后，比较两两数字差是否一致。
class Solution: def canMakeArithmeticProgression(self, arr: List[int]) -&amp;gt; bool: if len(arr) == 2: return True arr.sort(reverse=True) diff = arr[0] - arr[1] pre = arr[1] for i in arr[2:]: if pre - i != diff: return False pre = i return True 1503. Last Moment Before All Ants Fall Out of a Plank 链接到标题 标签是“脑筋急转弯”，蚂蚁只要在一个点碰到，那么就会调换方向，但是蚂蚁始终是蚂蚁，因此可以忽略掉这个条件，直接找到最大值就可以了。
再次怀疑自己智商。
class Solution: def getLastMoment(self, n: int, left: List[int], right: List[int]) -&amp;gt; int: time = 0 if left: time = max(time, max(left)) if right: time = max(time, n - min(right)) return time 939.</description></item><item><title>2020 第27周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/07/04/2020-%E7%AC%AC27%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 04 Jul 2020 09:17:15 +0000</pubDate><guid>https://zdyxry.github.io/2020/07/04/2020-%E7%AC%AC27%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1492. The kth Factor of n 链接到标题 计算 n 的第 k 个因子，i 从 1 开始递增，如果 i 可以被 n 整除，则 k&amp;ndash;，当 k == 0 时， i为所求值。
class Solution: def kthFactor(self, n: int, k: int) -&amp;gt; int: for i in range(1, n+1): if n % i == 0: k -= 1 if k == 0: return i return -1 1493. Longest Subarray of 1&amp;rsquo;s After Deleting One Element 链接到标题 用 cnt1 记录删除一个元素之后当前最长全为 1 的数组长度，用 cnt2 记录当前最长全为 1 的数组长度。</description></item><item><title>2020 第26周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/06/28/2020-%E7%AC%AC26%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sun, 28 Jun 2020 21:57:10 +0000</pubDate><guid>https://zdyxry.github.io/2020/06/28/2020-%E7%AC%AC26%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1486. XOR Operation in an Array 链接到标题 遍历进行异或操作。
class Solution: def xorOperation(self, n: int, start: int) -&amp;gt; int: ans = 0 for i in range(n): ans ^= start + 2 * i return ans 1487. Making File Names Unique 链接到标题 一道实际环境中会遇到的场景，使用哈希表记录已有的文件名，如果该文件已经存在在哈希表中，那么循环判断文件名 + () 数字是否也在哈希表中，如果还在，那么数字 + 1，直到数字不在。然后将结果记录到返回列表中。
class Solution: def getFolderNames(self, names: List[str]) -&amp;gt; List[str]: nameMap = {} # baseName : largest k suffix res = [] for n in names: if n in nameMap: # find k k = nameMap[n] + 1 while ( n + &amp;#34;(&amp;#34; + str(k) + &amp;#34;)&amp;#34; ) in nameMap: k += 1 nameMap[n] = k n = n + &amp;#34;(&amp;#34; + str(k) + &amp;#34;)&amp;#34; # with suffix is now considered a base name nameMap[n] = 0 # first time seeing this base name res.</description></item><item><title>2020 第25周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/06/20/2020-%E7%AC%AC25%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 20 Jun 2020 06:53:40 +0000</pubDate><guid>https://zdyxry.github.io/2020/06/20/2020-%E7%AC%AC25%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1476. Subrectangle Queries 链接到标题 二维数组的更新与查找。
class SubrectangleQueries: def __init__(self, rectangle: List[List[int]]): self.rect = rectangle self.rows, self.cols = len(self.rect), len(self.rect[0]) def updateSubrectangle(self, row1: int, col1: int, row2: int, col2: int, newValue: int) -&amp;gt; None: for i in range(row1, row2 + 1): for j in range(col1, col2 + 1): self.rect[i][j] = newValue def getValue(self, row: int, col: int) -&amp;gt; int: return self.rect[row][col] # Your SubrectangleQueries object will be instantiated and called as such: # obj = SubrectangleQueries(rectangle) # obj.</description></item><item><title>从北京转到上海生活两周感受</title><link>https://zdyxry.github.io/2020/06/13/%E4%BB%8E%E5%8C%97%E4%BA%AC%E8%BD%AC%E5%88%B0%E4%B8%8A%E6%B5%B7%E7%94%9F%E6%B4%BB%E4%B8%A4%E5%91%A8%E6%84%9F%E5%8F%97/</link><pubDate>Sat, 13 Jun 2020 22:09:05 +0000</pubDate><guid>https://zdyxry.github.io/2020/06/13/%E4%BB%8E%E5%8C%97%E4%BA%AC%E8%BD%AC%E5%88%B0%E4%B8%8A%E6%B5%B7%E7%94%9F%E6%B4%BB%E4%B8%A4%E5%91%A8%E6%84%9F%E5%8F%97/</guid><description>背景 链接到标题 最近一个月除了每天还刷刷题之外，没有更新其他播客，因为搬家到了上海（借口）。从毕业开始就在北京工作，算下来也4年多的时间了，想着趁着还能折腾，换个城市感受一下，正好公司在上海也有办公室，就直接转过来了，到今天已经工作了两周，写一下感受，扯一扯。
租房 链接到标题 需求 链接到标题 因为在5月份的时候疫情消停了一段时间，我就开始了远程看房的计划，因为有深圳同事也要转到上海，就计划一起合租，那么目标就是两居室。我们通过 Notion 协作写清楚需求（是的，还有猫的需求），然后各自开始了远程找房。
# yiran 的需求 - 步行 30min 可到达公司 - 民水民点 - 厨房可用 - 周围有商超 - 不临街 ## 同事的需求 - 希望是有电梯的(骑车穿锁鞋很难下楼) - 避免石膏墙 - 询问一下居住证的问题 ## 猫的需求 - 最好是有防盗网的窗户 - 阳光 - 够大 # 避免 - 窗户有树 了解中介 链接到标题 如果个人在上海本地，那么还有可能通过豆瓣等平台找到房东直接签约没有中介费，但是像我这种时间紧任务重的，就放弃了这种方式选择中介。上海租房与北京租房最主要的不同就是中介费，北京是租客需要支付一个月的租金，而上海是租客与房东共支付一个月的租金作为中介费，所以租客只需要支付50% 的租金即可，这点比北京友好很多，所以我们开始也是倾向于通过中介与房东签约的房子。
中介主要是链家，我爱我家的房源很少，且质量不高，贝壳上还有些其他的小中介，因为担心有其他隐患，最后还是选择的链家。
看房 链接到标题 主要看了两天的时间，第一天看了很多公司周围的板楼，后来才知道这类房子叫“老公房”，房子质量很差，且隔音很是问题，无法接受，于是第二天开始看一些距离公司地铁20min 可达的房子，在看的时候发现我忽略了一个比较重要的点，就是猫，同事养了两只猫，但是我看房子时忽略了房东不让养宠物的可能，直到我看了一个各方面都符合要求的房子后，想要与房东签约，才想到这点，房东果断拒绝了，后续也看了几个房子各方面都很好，但是不让养宠物而错过的，也是没有办法。
自如 链接到标题 在看了两天之后，发现房子质量比较好的房东，都不同意租客养宠物，换位思考可以理解，因为时间比较紧张，把目光选择了自如，自如的收费与北京相同，没有差别，照片都是真实的，但是我还是线下去看了房子，确保没有问题，期间发现了一些在自如网站上无法发现的问题：
隔音，部分房子隔音很差 周围环境，发现部分房子周围存在基建施工情况，看形式不是几天可以完工的 老旧小区改造，在北京吃过亏，租的房子是老房子，恰逢政府进行小区改造，两个月没有卫生间的日子还是太难过了 总结 链接到标题 如果当地有朋友，还是通过朋友那里了解到租房坑是最直接的方式 要确认好自己的需求，尤其是宠物这种可能会一票否决的事项更是要第一时间提出，否则白白浪费一个小时看房 找中介看房基本上不会按照自己的计划来安排时间的，每个中介都会拉着你去看几个类似的房子，所以做时间规划的时候最好要留有余地 实在没有选择就找自如吧，至少是有基本保证，但是要注意上海这边属于南方，宽带很可能没有联通选项 附一张 Notion 的看房列表：</description></item><item><title>2020 第24周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/06/13/2020-%E7%AC%AC24%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 13 Jun 2020 07:38:57 +0000</pubDate><guid>https://zdyxry.github.io/2020/06/13/2020-%E7%AC%AC24%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1470. Shuffle the Array 链接到标题 重新排列数组，使用 zip 对两个切分后的数组进行聚合
class Solution: def shuffle(self, nums: List[int], n: int) -&amp;gt; List[int]: res = [] for i, j in zip(nums[0:n],nums[n:]): res+=[i,j] return res 1471. The k Strongest Values in an Array 链接到标题 找到与“中位数”数值相差最大的 k 个数字，先将数组排序，找到“中位数”，分别从开头和结尾两边进行比较，找到最大的 k个数。
class Solution: def getStrongest(self, arr: List[int], k: int) -&amp;gt; List[int]: arr.sort() i, j = 0, len(arr) - 1 median = arr[(len(arr) - 1) // 2] while len(arr) + i - j &amp;lt;= k: if median - arr[i] &amp;gt; arr[j] - median: i = i + 1 else: j = j - 1 return arr[:i] + arr[j + 1:] 1472.</description></item><item><title>2020 第23周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/06/06/2020-%E7%AC%AC23%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 06 Jun 2020 13:25:41 +0000</pubDate><guid>https://zdyxry.github.io/2020/06/06/2020-%E7%AC%AC23%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1460. Make Two Arrays Equal by Reversing Sub-arrays 链接到标题 比较两个列表是否可以通过翻转等价，统计列表中字母出现的次数判断，或者可以直接排序判断。
class Solution: def canBeEqual(self, target: List[int], arr: List[int]) -&amp;gt; bool: c = collections.Counter(target) for a in arr: c[a] -= 1 if c[a] &amp;lt; 0: return False return True 1464. Maximum Product of Two Elements in an Array 链接到标题 找到数组中最大的两个数字，分别将其数值 -1 然后相乘返回。可以直接升序排序后取最后两个数字。
func maxProduct(nums []int) int { max:=0 secondMax:=0 for i:=0;i&amp;lt;len(nums);i++{ e:=nums[i] if e&amp;gt;max{ secondMax = max max = e }else if e&amp;gt;secondMax{ secondMax = e } } return (max-1)*(secondMax-1) } 1461.</description></item><item><title>2020 第22周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/06/01/2020-%E7%AC%AC22%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Mon, 01 Jun 2020 05:44:57 +0000</pubDate><guid>https://zdyxry.github.io/2020/06/01/2020-%E7%AC%AC22%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1455. Check If a Word Occurs As a Prefix of Any Word in a Sentence 链接到标题 切分句子然后遍历判断是否为前缀，需要返回索引 + 1。
class Solution: def isPrefixOfWord(self, sentence: str, searchWord: str) -&amp;gt; int: for idx, w in enumerate(sentence.split(&amp;#39; &amp;#39;)): if w.startswith(searchWord): return idx + 1 else: return -1 1456. Maximum Number of Vowels in a Substring of Given Length 链接到标题 滑动窗口，使用字典统计每个元音出现的次数，每次更新最大值。
class Solution: def maxVowels(self, s: str, k: int) -&amp;gt; int: d = {&amp;#39;a&amp;#39;: 0, &amp;#39;e&amp;#39;: 0, &amp;#39;i&amp;#39;: 0, &amp;#39;o&amp;#39;: 0, &amp;#39;u&amp;#39;: 0} for c in s[:k]: if c in d: d[c] += 1 res = sum(d.</description></item><item><title>2020 第21周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/05/22/2020-%E7%AC%AC21%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 22 May 2020 22:28:29 +0000</pubDate><guid>https://zdyxry.github.io/2020/05/22/2020-%E7%AC%AC21%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1446. Consecutive Characters 链接到标题 判断最长连续相同字符的长度，记录下当前字母，然后比较与 flag 是否相同，如果相同则 +1，不相同则重置为 1。
也可以通过 itertools.groupby 来实现（新学习的。。）
class Solution: def maxPower(self, s: str) -&amp;gt; int: if len(s) == 1: return 1 tmp = s[0] cnt = 1 max_cnt = 0 for i in s[1:]: if i == tmp: cnt += 1 else: tmp = i cnt = 1 max_cnt = max(max_cnt, cnt) return max_cnt 1447. Simplified Fractions 链接到标题 遍历分子与分母，求最大公约数，如果最大公约数为1，则将结果保存下来。分母从 2 开始计算。
func simplifiedFractions(n int) []string { ret := []string{} for i := 2; i &amp;lt;= n; i++ { for j := 1; j &amp;lt; i; j++ { if gcd(i, j) == 1 { ret = append(ret, fmt.</description></item><item><title>2020 第20周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/05/16/2020-%E7%AC%AC20%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 16 May 2020 10:17:49 +0000</pubDate><guid>https://zdyxry.github.io/2020/05/16/2020-%E7%AC%AC20%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1441. Build an Array With Stack Operations 链接到标题 遍历数组，比较当前值与目标值是否相同，如果相同，则在结果追加 Push ，如果不同，则追加 Push, Pop 。
class Solution: def buildArray(self, target: List[int], n: int) -&amp;gt; List[str]: res = [] keep = 0 for num in range(1, n+1): res.append(&amp;#34;Push&amp;#34;) keep += 1 if num not in target: res.append(&amp;#34;Pop&amp;#34;) keep -= 1 if keep == len(target): break return res 1442. Count Triplets That Can Form Two Arrays of Equal XOR 链接到标题 求子数组中是否存在左侧部分异或值与右侧部分异或值相等的情况，a==b -&amp;gt; a ^ b = 0，也就是是否存在子数组所有元素异或值为0 的情况，如果存在，那么子数组所有的元素都可以符合条件。</description></item><item><title>PyInstaller 与 RPM 配合使用踩坑</title><link>https://zdyxry.github.io/2020/05/13/PyInstaller-%E4%B8%8E-RPM-%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%E8%B8%A9%E5%9D%91/</link><pubDate>Wed, 13 May 2020 20:35:50 +0000</pubDate><guid>https://zdyxry.github.io/2020/05/13/PyInstaller-%E4%B8%8E-RPM-%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%E8%B8%A9%E5%9D%91/</guid><description>背景 链接到标题 最近公司一个项目用到了 pyinstaller 打包 Python 环境，又因为公司内部发布的最小粒度是 rpm，发现这俩工具配合起来默认配置会有坑，然后搜索下来几乎没看到有人提到，可能用 pyinstaller 和用 rpm 的完全是两类人吧 - -。
准备 链接到标题 先列一下官方默认例子的输出结果：
root@localhost:/tmp/demo $ pwd /tmp/demo root@localhost:/tmp/demo $ ls demo.py root@localhost:/tmp/demo $ pyinstaller demo.py 63 INFO: PyInstaller: 3.6 63 INFO: Python: 3.6.8 65 INFO: Platform: Linux-3.10.0-862.el7.x86_64-x86_64-with-centos-7.5.1804-Core 65 INFO: wrote /tmp/demo/demo.spec 67 INFO: UPX is not available. 70 INFO: Extending PYTHONPATH with paths [&amp;#39;/tmp/demo&amp;#39;, &amp;#39;/tmp/demo&amp;#39;] ... 来看一下生成文件的目录结构：
. ├── build │ └── demo ├── demo.py ├── demo.</description></item><item><title>2020 第19周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/05/08/2020-%E7%AC%AC19%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 08 May 2020 07:48:12 +0000</pubDate><guid>https://zdyxry.github.io/2020/05/08/2020-%E7%AC%AC19%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1436. Destination City 链接到标题 使用 set() 来计算每个城市是否处于起始和终止，集合差为终点站。
class Solution: def destCity(self, paths: List[List[str]]) -&amp;gt; str: a = set() b = set() for path in paths: x, y = path a.add(x) b.add(y) b = b - a assert len(b) == 1 return b.pop() 1432. Max Difference You Can Get From Changing an Integer 链接到标题 分别求出给定数字可以转换的最大值和最小值，然后求差，最大值是将数字从前向后遍历，当数值不为9时，将其替换为 9；最小值要求首位不能为 0，则需要特殊判断，如果首位不为1，则将其替换为1，如果首位为1，则遍历后续数字，如果数字不为0，则替换为0，需要注意此时首位为1，如果数字为1然后替换为0会出现首位为0 情况，因此需要判断数字不为0且不为1，然后替换为 0。
class Solution: def maxDiff(self, num: int) -&amp;gt; int: a = b = str(num) for digit in a: if digit !</description></item><item><title>2020 第18周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/05/01/2020-%E7%AC%AC18%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 01 May 2020 06:43:57 +0000</pubDate><guid>https://zdyxry.github.io/2020/05/01/2020-%E7%AC%AC18%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1422. Maximum Score After Splitting a String 链接到标题 求出左侧 0 数量和右侧 1 数量之和最多的情况，遍历一次，每次更新最大值，注意要保证字符串始终被切分为 2 个子字符串。
class Solution: def maxScore(self, s: str) -&amp;gt; int: right = s.count(&amp;#39;1&amp;#39;) left = 0 score = 0 for idx in range(len(s) - 1): if s[idx] == &amp;#39;1&amp;#39;: score = max(score, (left + right - 1)) right -= 1 else: score = max(score, (left + 1 + right)) left += 1 return score 1423. Maximum Points You Can Obtain from Cards 链接到标题 先假设所有的数字都是从左侧获取的，然后依次遍历 k 个数值，每次遍历将左侧数字剔除，将右侧数字加入，比较最大值。</description></item><item><title>在终端输入命令后系统做了什么</title><link>https://zdyxry.github.io/2020/04/25/%E5%9C%A8%E7%BB%88%E7%AB%AF%E8%BE%93%E5%85%A5%E5%91%BD%E4%BB%A4%E5%90%8E%E7%B3%BB%E7%BB%9F%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88/</link><pubDate>Sat, 25 Apr 2020 15:18:03 +0000</pubDate><guid>https://zdyxry.github.io/2020/04/25/%E5%9C%A8%E7%BB%88%E7%AB%AF%E8%BE%93%E5%85%A5%E5%91%BD%E4%BB%A4%E5%90%8E%E7%B3%BB%E7%BB%9F%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88/</guid><description>背景 链接到标题 无论是使用 VNC 连接还是 SSH 连接，每天都在用终端去执行命令，今天来了解下在执行命令后，系统具体做了什么，如何做的。
Shell 链接到标题 shell 是一个程序，也是一种编程语言，一个管理进程和运行程序的程序，在 Linux 中有很多 shell 可选，比如 bash、zsh、fish 等等，shell 主要有 3 个功能：
运行程序 管理输入和输出 可编程 运行程序很容易理解，在终端上输入的每个命令都是一个可执行程序，我们在 shell 中输入并执行程序；管理输入和输出，在 shell 中可以使用 &amp;lt; &amp;gt; | 符合控制输入、输出重定向，可以告诉 shell 将进程的输入和输出连接到一个文件或者其他的进程；编程，shell 是一种编程语言，可以进行变量赋值、循环、条件判断等操作。
如何运行程序 链接到标题 shell 永远在等待用户输入，输入完成按下回车键后，开始执行相应命令（程序），然后等待程序执行完成后打印相应输出，伪代码：
while (! end_of_input) get command execute command wait for command to finish 在 shell 中因为需要执行其他的程序，需要用到 execvp ，execvp 会将指定的程序复制到调用它的进程，将指定的字符串组作为参数传递给程序，然后运行程序。这里存在一个问题， execvp 的执行过程是内核将程序加载到当前进程，替换当前进程的代码和数据，然后执行，那么原有进程的状态都被替换掉，在执行完程序就直接退出，不会再回到原程序等待下次输入。
为了保证我们在执行程序后回到 shell 中，需要每次创建新的进程来执行程序，调用 fork 指令，进程调用 fork 后，内核分配新的内存块和内核数据结构，复制原进程到新的进程，向运行进程添加新的进程，将控制返回给两个进程。通过 fork 返回值来判断当前进程是否为父进程或子进程。
shell 作为父进程通过调用 fork 创建子进程后，子进程通过 execvp 加载指定程序执行，父进程需要等待子进程退出，需要用到 wait ，在父进程 fork 出子进程后，父进程执行 wait 等待子进程执行，在调用时会传递一个整型变量地址，子进程执行完成后调用 exit 退出，内核将子进程的退出状态保存在这个变量中，用于父进程感知子进程退出状态。</description></item><item><title>2020 第17周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/04/24/2020-%E7%AC%AC17%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 24 Apr 2020 20:47:03 +0000</pubDate><guid>https://zdyxry.github.io/2020/04/24/2020-%E7%AC%AC17%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1417. Reformat The String 链接到标题 重新格式化字符串，使得字母与数字交叉连接，先分别找出字母与数据，使用 zip_longest 来生成交叉后的元组，然后拼接得到目标字符串。
class Solution: def reformat(self, s: str) -&amp;gt; str: a=re.findall(r&amp;#39;\d&amp;#39;,s) b=re.findall(r&amp;#39;[a-z]&amp;#39;,s) if abs(len(a)-len(b))&amp;gt;1: return &amp;#39;&amp;#39; a,b=sorted([a,b],key=len) return &amp;#39;&amp;#39;.join(map(&amp;#39;&amp;#39;.join,itertools.zip_longest(b,a,fillvalue=&amp;#39;&amp;#39;))) 1414. Find the Minimum Number of Fibonacci Numbers Whose Sum Is K 链接到标题 参考：https://leetcode-cn.com/problems/find-the-minimum-number-of-fibonacci-numbers-whose-sum-is-k/solution/tan-xin-jian-dan-zheng-ming-by-wyjoutstanding/
判定性：保证K一定能由斐波那契数组成，数据归纳法可证明
最小性：什么样的组合能最短？
相邻合并：2个相邻的数可合并为二者的和，长度-1，因为f(n)=f(n-1)+f(n-2)。满足该条件的组合必定是间隔出现，但是又可能重现重复的值，这对于编程很不利。 重值转换：两个相同的值一定可以转换为两个不同的值，因为f(n)+f(n)=f(n)+f(n-1)+f(n-2)=f(n+1)+f(n-2)，一个比f(n)大，一个更小，这是等价转换，不会减小组合长度，但是会带来一个很好的性质，即单调递增性质。 因此，重复使用以上两个操作后的组合数列，必定是一个无相邻值的递增数列，由于数列均为正数且和为K，因此值越大个数自然越小。
问：
那会不会出现一种情况呢，就是如果减去最大的斐波那契数的话，剩下的数只能拆分成两个斐波那契数，而如果减去第二大的斐波那契数或者更小的斐波那契数的话，剩下的数刚好是斐波那契数？
答：
可用反证法，假设总和为k，且f(m-1)&amp;lt;k&amp;lt;f(m)
那么对应你的第一种情况是k=f(m-1)+f(i)+f(j)，1&amp;lt;=f(i),f(j)&amp;lt;=f(m-2)；
对应你的第二种情况是k=f(m-2)+f(l)，其中,1&amp;lt;=f(l)&amp;lt;=f(m-3)。
假设你说的情况成立，那么以上两个等式必定相等，即f(m-1)+f(i)+f(j)=f(m-2)+f(l)，
因为f(m-1) = f(m-2) + f(m-3), f(l)&amp;lt;=f(m-3)，而f(i)和f(j)均不可能为0，因此等式不可能成立。
（左侧恒大于右侧，只有消去f(i)和f(j)才有可能取等）
当第二个等式的f(m-2)取更小值时更不可能成立。因此，推翻假设。
class Solution: def findMinFibonacciNumbers(self, k: int) -&amp;gt; int: ls=self.fib(k) res=0 while k: if k&amp;gt;=ls[-1]: k-=ls[-1] res+=1 else: ls.</description></item><item><title>文件系统基本概念及常用操作解释</title><link>https://zdyxry.github.io/2020/04/18/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E8%A7%A3%E9%87%8A/</link><pubDate>Sat, 18 Apr 2020 14:24:23 +0000</pubDate><guid>https://zdyxry.github.io/2020/04/18/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E8%A7%A3%E9%87%8A/</guid><description>背景 链接到标题 前段时间一个朋友问我删除文件和格式化有什么区别，最近正好在读《Unix Linux 编程实践教程》这本书，其中第4章是来讲文件系统相关的，本文是对其中内容进行部分摘要来解释。
Unix 文件系统的内部结构 链接到标题 从用户角度看，Unix 系统中的硬盘上的文件组成一棵目录树，每个目录能包含文件或其他目录，目录树的深度几乎没有限制，子目录下可以包含其他文件和子目录（套娃）。文件内容放置在对应的目录中，对应的目录内容放置在上层目录中。
文件系统是对硬盘设备的一种多层次的抽象，主要包含以下三层。
第一层：从硬盘到分区 链接到标题 一个硬盘能够存储大量的数据，硬盘可以被划分为多个区域，也就是硬盘分区，每个分区在系统中都可以看作是独立的硬盘。
第二层：从磁盘到块序列 链接到标题 一个硬盘由许多磁性盘片组成，每个盘片的表面都被划分为很多同心圆，这些同心圆被成为磁道，每个磁道有进一步被划分为扇区，每个扇区可以存储一定字节数的数据，例如每个扇区有 512字节空间。扇区是磁盘上的基本存储单元，磁盘都包含大量的扇区。
为磁盘块编号是一种很重要的方法，给每个磁盘块分配连续的编号使得操作系统能够计算磁盘上的每个块，可以一个磁盘接一个磁盘的从上到下给所有的块编号，还可以一个磁道接一个磁道的从外向里给所有的块编号，一个将磁盘扇区编号的系统使得我们可以把磁盘视为一系列块的组合。
第三层：从块序列到三个区域的划分 链接到标题 文件系统可以用来存储文件内容、文件属性（文件所有者、日期等）和目录，这些不同类型的数据是如何存储在编号的磁盘块上的呢?
文件系统区域划分 链接到标题 一部分成为数据区，用来存放文件真正的内容。另一部分成为 i-node 表，用来存放文件属性。第三部分成为超级块（superblock），用来存放文件系统自身的信息。文件系统由这 3 部分组合而成，其中任一部分都是由很多有序磁盘块组成的。
超级块 链接到标题 文件系统的第一个块被成为超级块。这个块中存放文件系统自身的结构信息，比如记录了每个区域的大小。超级块也存放未被使用的磁盘块信息，不同的文件系统的超级块信息不同，可以通过 debugfs 等类似命令查看。
i-node 表 链接到标题 文件系统的下一个部分被成为 i-node 表，每个文件都有一些属性，如大小、文件所有者和最近修改时间等等，这些属性被记录在一个被成为 i-node 的结构中，所有的 i-node 都有相同的大小，并且 i-node 表是这些 i-node 结构组成的一个列表。文件系统中每个文件都有一个 i-node。
数据区 链接到标题 文件系统的第 3 个部分是数据区。文件的真正内容保存在这个区域。磁盘上所有块的大小都是一样的。如果文件包含了超过一个块的内容，则文件内容会存放在多个磁盘块中。一个较大的文件很容易分布在上千个独立的磁盘块中。
常见操作过程解释 链接到标题 创建文件 链接到标题 当我们创建一个文件的时候，主要操作有以下 4个：
存储属性 文件属性的存储：内核先找到一个空的 i-node，把文件的信息记录到 i-node 中。 存储数据 文件内容的存储：内核从未被使用的数据块列表中找出足够的数据块，然后将数据从缓冲区复制到对应的数据块中。 记录分配情况 文件内容按照顺序存放在数据块中。内核在 i-node 的磁盘分布区记录了上述的块序列。磁盘分布区是一个磁盘块序号的列表。 添加文件名到目录 内核将文件 i-node 编号和对应的文件名添加到目录文件。文件名和 i-node 编号之间的对应关系将文件名和文件内容及文件属性进行了关联。 如果创建一个大文件该如何做？一个大文件需要多个磁盘块，在 i-node 中存放磁盘块分配列表，但是长度是固定的，也就是文件大小是有上限的，如何尽可能的支持更大的文件？</description></item><item><title>2020 第16周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/04/18/2020-%E7%AC%AC16%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 18 Apr 2020 05:34:09 +0000</pubDate><guid>https://zdyxry.github.io/2020/04/18/2020-%E7%AC%AC16%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1408. String Matching in an Array 链接到标题 先按照单词长度进行排序，然后遍历判断当前单词是否被其他单词包含，要注意最终结果应该是去重之后的。
Golang 中可以直接使用 strings.Contains 判断。
type ByLen []string func (a ByLen) Len() int { return len(a) } func (a ByLen) Less(i, j int) bool { return len(a[i]) &amp;lt; len(a[j]) } func (a ByLen) Swap(i, j int) { a[i], a[j] = a[j], a[i] } func stringMatching(words []string) []string { sort.Sort(ByLen(words)) res := []string{} for i := range words { for j := i + 1; j &amp;lt; len(words); j++ { if strings.</description></item><item><title>runc nsenter 源码阅读</title><link>https://zdyxry.github.io/2020/04/12/runc-nsenter-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link><pubDate>Sun, 12 Apr 2020 14:57:29 +0000</pubDate><guid>https://zdyxry.github.io/2020/04/12/runc-nsenter-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</guid><description>背景 链接到标题 最近在阅读 runc 的实现，发现在 runc 中比较重要的一个逻辑是在设置 namespace 过程中的 nsenter 模块，其中逻辑有些绕，也发现了一段很长很有意思的注释，分享一下。
What 链接到标题 什么是 nsenter，nsenter 是 runc 中的一个 package，它包含了一个特殊的构造函数，用来在 Go runtime 启动之前做一些事情，比如 setns()。nsenter 会引入 C 并使用 cgo 实现相关逻辑。在cgo中，如果在 C 的 import 后紧跟注释，则在编译程序包的 C 语言实现部分时，该注释将用作 header。因此，每次 import nsenter 时，nsexec()都会调用 C 函数。
在 runc 中只有 init.go import 了 nsenter。
Why 链接到标题 容器技术最关键的就是 namespace 和 cgroup，其中 namespace 是通过 setns() 函数来实现的，但是 setns() 有一个问题： A multithreaded process may not change user namespace with setns(). 。而 go runtime 是多线程的，所以需要在 go runtime 启动前执行 setns() 设置好 namespace，然后再走 go 相关实现流程。</description></item><item><title>2020 第15周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/04/10/2020-%E7%AC%AC15%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 10 Apr 2020 20:44:44 +0000</pubDate><guid>https://zdyxry.github.io/2020/04/10/2020-%E7%AC%AC15%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1403. Minimum Subsequence in Non-Increasing Order 链接到标题 对数组进行排序，然后依次取出当前最大值，比较当前取出数值和与剩余数值和，如果大于，则返回取出数字。
class Solution: def minSubsequence(self, nums: List[int]) -&amp;gt; List[int]: N = len(nums) total = sum(nums) nums.sort() ret = [] t = 0 while True: x = nums.pop() t += x ret.append(x) if t * 2 &amp;gt; total: return ret 1400. Construct K Palindrome Strings 链接到标题 构造指定个数的回文字符串，检查出现次数为奇数的字母次数是否超过了k即可。可以直接用 Counter 计算。
class Solution: def canConstruct(self, s: str, k: int) -&amp;gt; bool: digit_count = {} if len(s) &amp;lt; k: return False elif len(s) == k: return True else: odd = 0 for i in set(s): digit_count[i] = s.</description></item><item><title>fsck 是如何工作的</title><link>https://zdyxry.github.io/2020/04/05/fsck-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84/</link><pubDate>Sun, 05 Apr 2020 09:08:33 +0000</pubDate><guid>https://zdyxry.github.io/2020/04/05/fsck-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84/</guid><description>背景 链接到标题 在平时会遇到不少系统崩溃之后文件系统异常的情况，通常我们会通过 fsck 工具进行修复，今天来了解下 fsck 做了什么，是怎么做的。
工作负载示例 链接到标题 假设现在存在一种工作负载，将单个数据块附加到原有文件。通过打开文件，调用 lseek() 将文件偏移量移动到文件末尾，然后在关闭文件之前，向文件发出单个 4KB 写入来完成追加。
假定磁盘上使用标准的简单文件系统结构，包括一个 inode 位图（inode bitmap，只有 8 位，每个 inode 一个），一个数据位图（databitmap，也是 8 位，每个数据块一个），inode（总共 8 个，编号为 0 到 7，分布在 4 个块上），以及数据块（总共 8 个，编号为 0～7）。以下是该文件系统的示意图：
查看图中的结构，可以看到分配了一个 inode（inode 号为 2），它在 inode 位图中标记，单个分配的数据块（数据块 4）也在数据中标记位图。inode 表示为 I [v1]，因为它是此 inode 的第一个版本。它将很快更新（由于上述工作负载）。再来看看这个简化的 inode。在 I[v1]中，可以看到：
owner : remzi permissions : read-write size : 1 pointer : 4 pointer : null pointer : null pointer : null 在这个简化的 inode 中，文件的大小为 1（它有一个块位于其中），第一个直接指针指向块 4（文件的第一个数据块，Da），并且所有其他 3 个直接指针都被设置为 null（表示它们未被使用）。当然，真正的 inode 有更多的字段。</description></item><item><title>2020 第14周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/04/03/2020-%E7%AC%AC14%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 03 Apr 2020 21:49:38 +0000</pubDate><guid>https://zdyxry.github.io/2020/04/03/2020-%E7%AC%AC14%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1394. Find Lucky Integer in an Array 链接到标题 找幸运数字，可以维护一个数组，然后统计出现过的次数，也可以直接使用 collections.Counter 实现。
class Solution(object): def findLucky(self, arr): &amp;#34;&amp;#34;&amp;#34; :type arr: List[int] :rtype: int &amp;#34;&amp;#34;&amp;#34; cnt = [0] * 501 for a in arr: cnt[a] += 1 for i in range(500, 0, -1): if cnt[i] == i: return i return -1 1395. Count Number of Teams 链接到标题 遍历数组，假设当前数值是中间位置，因为要考虑到倒序排序，所以要找到左边比当前数值小的和比当前数值大的，找到右边比当前数值小的和比当前数值大的，然后进行排列组合。
class Solution(object): def numTeams(self, rating): &amp;#34;&amp;#34;&amp;#34; :type rating: List[int] :rtype: int &amp;#34;&amp;#34;&amp;#34; n = len(rating) ans = 0 for i in range(1,n-1): l1,r1= 0,0 l2,r2 =0,0 for j in range(i-1,-1,-1): if rating[j] &amp;lt; rating[i]: l1 += 1 else: l2 += 1 for j in range(i+1,n): if rating[j] &amp;gt; rating[i]: r1 += 1 else: r2 += 1 ans += l1*r1 + l2*r2 return ans 1396.</description></item><item><title>2020 第13周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/03/27/2020-%E7%AC%AC13%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 27 Mar 2020 22:27:32 +0000</pubDate><guid>https://zdyxry.github.io/2020/03/27/2020-%E7%AC%AC13%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1387. Sort Integers by The Power Value 链接到标题 给定一个区间，让你求出这个区间内所有数字的权重，然后按照权重进行排序，权重计算方式为：
如果 x 是偶数，那么 x = x / 2 如果 x 是奇数，那么 x = 3 * x + 1 在计算过程中，肯定会有重复计算，所以使用 dict 记录已经计算过的数值权重。当计算完成后，对结果进行排序，优先使用权重排序，如果权重相同，则按照数值本身大小进行排序，取第 k 个。
class Solution(object): def getKth(self, lo, hi, k): &amp;#34;&amp;#34;&amp;#34; :type lo: int :type hi: int :type k: int :rtype: int &amp;#34;&amp;#34;&amp;#34; self.memo = {} def helper(n): if n==1: return 0 if n in self.memo: return self.memo[n] if n%2: ans=helper((n*3+1)/2)+2 else: ans=helper(n/2)+1 self.</description></item><item><title>论文阅读 《Pingmesh: A Large-Scale System for Data Center Network Latency Measurement and Analysis》</title><link>https://zdyxry.github.io/2020/03/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Pingmesh-A-Large-Scale-System-for-Data-Center-Network-Latency-Measurement-and-Analysis/</link><pubDate>Thu, 26 Mar 2020 20:24:09 +0000</pubDate><guid>https://zdyxry.github.io/2020/03/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Pingmesh-A-Large-Scale-System-for-Data-Center-Network-Latency-Measurement-and-Analysis/</guid><description>背景 链接到标题 在我们内部产品中，一直有关于网络性能数据监控需求，我们之前是直接使用 ping 命令收集结果，每台服务器去 ping (N-1) 台，也就是 N^2 的复杂度，稳定性和性能都存在一些问题，最近打算对这部分进行重写，在重新调研期间看到了 Pingmesh 这篇论文，Pingmesh 是微软用来监控数据中心网络情况而开发的软件，通过阅读这篇论文来学习下他们是怎么做的。
数据中心自身是极为复杂的，其中网络涉及到的设备很多就显得更为复杂，一个大型数据中心都有成百上千的节点、网卡、交换机、路由器以及无数的网线、光纤。在这些硬件设备基础上构建了很多软件，比如搜索引擎、分布式文件系统、分布式存储等等。在这些系统运行过程中，面临一些问题：如何判断一个故障是网络故障？如何定义和追踪网络的 SLA？出了故障如何去排查？
基于这几点问题，微软设计开发了 Pingmesh，用来记录和分析数据中心的网络情况。在微软内部 Pingmesh 每天会记录 24TB 数据，进行 2k 亿次 ping 探测，通过这些数据，微软可以很好的进行网络故障判定和及时的修复。
数据中心网络 链接到标题 常见的数据中心网络拓扑：
网络延时计算方式：server A 发送消息到 server B 接受消息的时间。最终使用 RTT 时间，RTT 一个好处是绝对时间，与时钟不相关。
在大多数情况下，大家不会去关心延时具体是什么导致的，都是直接归结于网络原因，让网络团队去排查，实际上是浪费了很多人力成本。延时变高有很多原因：CPU 繁忙、服务自身 Bug、网络原因等等。往往丢包会伴随着延时升高，因为丢包意味着会发生重传，所以丢包也是需要观察的重点。
因为 Pingmesh 运行在微软内部，所以依托于微软自己的基础架构，有自动化管理系统 Autopilot，有大数据系统 Cosmos，也有类似于 SQL 的脚本语言 SCOPE。
设计 链接到标题 根据上面的需求，Pingmesh 先评估了现有的开源工具，不符合的原因有很多，大多数工具都是以命令行形式呈现，一般是出现故障了去使用工具排查，而且工具提供的数据也不全面，有可能正在运行工具问题已经解决了。当然这并不是说已有的工具没有用，只能说不适合 Pingmesh。
Pingmesh 是松耦合设计，每个组件都是可以独立运行的，分为 3 个组件。在设计的时候需要考虑几点：
因为要运行在所有的 server 上，所以不能占用太多的计算资源或网络资源 需要是灵活配置的且高可用的的 记录的数据需要进行合理的汇总分析 Pingmesh 架构设计：
Controller 链接到标题 Controller 主要负责生成 pinglist 文件，这个文件是 XML 格式的，pinglist 的生成是很重要的，需要根据实际的数据中心网络拓扑进行及时更新。</description></item><item><title>2020 第12周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/03/20/2020-%E7%AC%AC12%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 20 Mar 2020 20:08:24 +0000</pubDate><guid>https://zdyxry.github.io/2020/03/20/2020-%E7%AC%AC12%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1380. Lucky Numbers in a Matrix 链接到标题 给一个二维数组，分别求每行最小值，每列最大值，然后找到幸运数字。（遇到二维数组善用 zip 来解决
class Solution(object): def luckyNumbers (self, matrix): &amp;#34;&amp;#34;&amp;#34; :type matrix: List[List[int]] :rtype: List[int] &amp;#34;&amp;#34;&amp;#34; mins = {min(rows) for rows in matrix} maxes = {max(columns) for columns in zip(*matrix)} return list(mins &amp;amp; maxes) 1381. Design a Stack With Increment Operation 链接到标题 相比与 stack 多了一个 inc 操作，一般想法是每次遇到 inc 操作，那么我们遍历一次，将对应值进行加操作就可以了，但是这个操作是 O(n) 的，我们可以使用一个辅助 list ，保存 inc 的数值，当 pop 的时候，进行相加处理。
以示例展示处理过程：
[&amp;#34;CustomStack&amp;#34;,&amp;#34;push&amp;#34;,&amp;#34;push&amp;#34;,&amp;#34;pop&amp;#34;,&amp;#34;push&amp;#34;,&amp;#34;push&amp;#34;,&amp;#34;push&amp;#34;,&amp;#34;increment&amp;#34;,&amp;#34;increment&amp;#34;,&amp;#34;pop&amp;#34;,&amp;#34;pop&amp;#34;,&amp;#34;pop&amp;#34;,&amp;#34;pop&amp;#34;] [[3],[1],[2],[],[2],[3],[4],[5,100],[2,100],[],[],[],[]] stack, inc [1], [0] [1,2], [0] [1], [0] [1,2], [0,0] [1,2,3], [0,0,0] [1,2,3], [0,0, 100] [1,2,3], [0, 100, 100] [1,2], [0,200] [1], [200] class CustomStack(object): def __init__(self, maxSize): self.</description></item><item><title>理解网卡混杂模式</title><link>https://zdyxry.github.io/2020/03/18/%E7%90%86%E8%A7%A3%E7%BD%91%E5%8D%A1%E6%B7%B7%E6%9D%82%E6%A8%A1%E5%BC%8F/</link><pubDate>Wed, 18 Mar 2020 19:49:04 +0000</pubDate><guid>https://zdyxry.github.io/2020/03/18/%E7%90%86%E8%A7%A3%E7%BD%91%E5%8D%A1%E6%B7%B7%E6%9D%82%E6%A8%A1%E5%BC%8F/</guid><description>背景 链接到标题 我自己会在虚拟机验证一些网络配置，比如在虚拟机内部创建 OVS Bridge 之类的操作。当 Hypervisor 是 vSphere ESXi 时，通常需要在 ESXi 的虚拟交换机上开启混杂模式，今天来说一说网络的混杂模式。
网卡工作模式 链接到标题 网卡有以下几种工作模式，通常网卡会配置广播和多播模式：
广播模式（Broad Cast Model）:它的物理地址地址是 0Xffffff 的帧为广播帧，工作在广播模式的网卡接收广播帧。它将会接收所有目的地址为广播地址的数据包，一般所有的网卡都会设置为这个模式 多播传送（MultiCast Model）：多播传送地址作为目的物理地址的帧可以被组内的其它主机同时接收，而组外主机却接收不到。但是，如果将网卡设置为多播传送模式，它可以接收所有的多播传送帧，而不论它是不是组内成员。当数据包的目的地址为多播地址，而且网卡地址是属于那个多播地址所代表的多播组时，网卡将接纳此数据包，即使一个网卡并不是一个多播组的成员，程序也可以将网卡设置为多播模式而接收那些多播的数据包。 直接模式（Direct Model）:工作在直接模式下的网卡只接收目地址是自己 Mac 地址的帧。只有当数据包的目的地址为网卡自己的地址时，网卡才接收它。 混杂模式（Promiscuous Model）:工作在混杂模式下的网卡接收所有的流过网卡的帧，抓包程序就是在这种模式下运行的。网卡的缺省工作模式包含广播模式和直接模式，即它只接收广播帧和发给自己的帧。如果采用混杂模式，网卡将接受同一网络内所有所发送的数据包，这样就可以到达对于网络信息监视捕获的目的。它将接收所有经过的数据包，这个特性是编写网络监听程序的关键。 混杂模式 链接到标题 混杂模式（promiscuous mode）是计算机网络中的术语。是指一台机器的网卡能够接收所有经过它的数据流，而不论其目的地址是否是它。
一般计算机网卡都工作在非混杂模式下，此时网卡只接受来自网络端口的目的地址指向自己的数据。当网卡工作在混杂模式下时，网卡将来自接口的所有数据都捕获并交给相应的驱动程序。网卡的混杂模式一般在网络管理员分析网络数据作为网络故障诊断手段时用到，同时这个模式也被网络黑客利用来作为网络数据窃听的入口。在Linux操作系统中设置网卡混杂模式时需要管理员权限。在Windows操作系统和Linux操作系统中都有使用混杂模式的抓包工具，比如著名的开源软件Wireshark。
查看网卡是否开启混杂模式 链接到标题 [root@node1 21:06:51 ~]$ifconfig ens192 ens192: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500 inet 192.168.17.88 netmask 255.255.240.0 broadcast 192.168.31.255 inet6 fe80::20c:29ff:fe99:4eb2 prefixlen 64 scopeid 0x20&amp;lt;link&amp;gt; ether 00:0c:29:99:4e:b2 txqueuelen 1000 (Ethernet) RX packets 163692 bytes 10031607 (9.5 MiB) RX errors 0 dropped 110 overruns 0 frame 0 TX packets 1751 bytes 175974 (171.</description></item><item><title>2020 第11周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/03/13/2020-%E7%AC%AC11%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 13 Mar 2020 21:09:45 +0000</pubDate><guid>https://zdyxry.github.io/2020/03/13/2020-%E7%AC%AC11%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1370. Increasing Decreasing String 链接到标题 题目描述很复杂，但其实就是排序和字典，先顺序遍历再反向遍历。（熟练使用 Counter）
Python 链接到标题 class Solution(object): def sortString(self, s): &amp;#34;&amp;#34;&amp;#34; :type s: str :rtype: str &amp;#34;&amp;#34;&amp;#34; set_s = set() for c in s: set_s.add(c) characters = sorted(set_s) d = collections.Counter(s) res = &amp;#34;&amp;#34; while sum(d.values()) != 0: for c in characters: if c in s and d[c] &amp;gt; 0: res += c d[c] -= 1 for c in characters[::-1]: if c in s and d[c] &amp;gt; 0: res += c d[c] -= 1 return res Golang 链接到标题 func sortString(s string) string { sMap := make(map[string]int, len(s)) for _, c := range s { sMap[string(c)]++ } chars := []string{} for c, _ := range sMap { chars = append(chars, string(c)) } sort.</description></item><item><title>SR-IOV 基本概念</title><link>https://zdyxry.github.io/2020/03/12/SR-IOV-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link><pubDate>Thu, 12 Mar 2020 23:04:27 +0000</pubDate><guid>https://zdyxry.github.io/2020/03/12/SR-IOV-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid><description>背景 链接到标题 上周了解了 RDMA 的基础概念之后，发现在 KVM 平台无需其他配置就可使用，但是在 vSphere 场景下，需要面临一个取舍，其中的一个选择就是 SR-IOV ，今天来了解下 SR-IOV 。
SR-IOV 链接到标题 SR-IOV 全称 Single Root I/O Virtualization，是 Intel 在 2007年提出的一种基于硬件的虚拟化解决方案。
在虚拟化场景中，CPU 与内存是最先解决的，但是 I/O 设备一直没有很好的解决办法，Intel 有 VT-d（Virtualization Technology for Directed I/O）可以将物理服务器的 PCIe 设备直接提供给虚拟机使用，也就是我们常说的“直通”（passthrough），但是直通面临一个问题是 PCIe 设备只能给一个虚拟机使用，其他虚拟机就只能干瞪眼，这肯定是不行的，所以有了 SR-IOV，一个物理设备可以虚拟出多个虚拟设备给虚拟机使用。
SR-IOV 是一种规范，使得单根端口下的单个快速外围组件互连 (PCIe) 物理设备显示为管理程序或客户机操作系统的多个单独的物理设备，既有直通设备的性能优势，又可以支持多个虚拟机，一举两得。
SR-IOV 使用 physical functions (PF) 和 virtual functions (VF) 为 SR-IOV 设备管理全局功能。
PF 包含SR-IOV 功能的完整PCIe设备，PF 作为普通的PCIe 设备被发现、管理和配置 。PF 通过分配VF 来配置和管理 SR-IOV 功能。禁用SR-IOV后，主机将在一个物理网卡上创建一个 PF。 VF 是轻量级 PCIe 功能（I/O 处理）的 PCIe 设备，每个 VF 都是通过 PF 来生成管理的，VF 的具体数量限制受限于 PCIe 设备自身配置及驱动程序的支持，启用S​​R-IOV后，主机将在一个物理NIC上创建单个PF和多个VF。 VF的数量取决于配置和驱动程序支持。 每个 SR-IOV 设备都可有一个 PF(Physical Functions)，并且每个 PF 最多可有64,000个与其关联的 VF(Virtual Function)。PF 可以通过寄存器创建 VF，这些寄存器设计有专用于此目的的属性。一旦在 PF 中启用了 SR-IOV，就可以通过 PF 的总线、设备和功能编号（路由 ID）访问各个 VF 的 PCI 配置空间。</description></item><item><title>2020 第10周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/03/06/2020-%E7%AC%AC10%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 06 Mar 2020 21:10:06 +0000</pubDate><guid>https://zdyxry.github.io/2020/03/06/2020-%E7%AC%AC10%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1365. How Many Numbers Are Smaller Than the Current Number 链接到标题 对数组升序排序，遍历排序后数组，判断是否与前一数字相同，若相同则该数字结果与前一结果相同，否则为当前索引。
class Solution(object): def smallerNumbersThanCurrent(self, nums): &amp;#34;&amp;#34;&amp;#34; :type nums: List[int] :rtype: List[int] &amp;#34;&amp;#34;&amp;#34; nums2 = sorted(nums) mapping = {} for i, num in enumerate(nums2): if i &amp;gt; 0 and nums2[i] == nums2[i-1]: mapping[nums2[i]] = mapping[nums2[i-1]] else: mapping[nums2[i]] = i res = [] for num in nums: res.append(mapping[num]) return res 1366. Rank Teams by Votes 链接到标题 考察排序，通过 dict 或者 list 统计所有字母的投票数值，然后进行排序，优先按照票数排序，如果票数相同，则按照字母序排序。</description></item><item><title>systemd 常用操作及配置</title><link>https://zdyxry.github.io/2020/03/06/systemd-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%8F%8A%E9%85%8D%E7%BD%AE/</link><pubDate>Fri, 06 Mar 2020 21:02:49 +0000</pubDate><guid>https://zdyxry.github.io/2020/03/06/systemd-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%8F%8A%E9%85%8D%E7%BD%AE/</guid><description>背景 链接到标题 现在大多数 Linux 发行版是由 systemd 来进行系统管理了， systemd 也是越来越复杂，但是常用的操作就那么多，今天来说说自己常用的操作及配置。
操作 链接到标题 daemon-reload 链接到标题 在给系统新增服务的时候，通常要不断的改 test.service 配置文件，在改配置文件后，通常需要执行 systemctl daemon-reload 来重新加在 systemd 配置。
no-page 链接到标题 通常使用 journalctl 查看服务日志，但是当日志超过当前行可显示最大字符数时，默认会将日志截断，此时可以使用 journalctl -u &amp;lt;service&amp;gt; --no-page 来让日志自动折行。
disk-usage 链接到标题 systemd 日志配置文件在 /etc/systemd/journald.conf ，那么如果我想查看一个服务的日志占用空间，可以用 journalctl -u &amp;lt;servie&amp;gt; --disk-usage 命令查看。
poweroff 链接到标题 Linux 下关机命令有很多， init,shutdown,poweroff ，但是如果你注意过会发现以下事实：
root@localhost:~ $ ll `which init` lrwxrwxrwx. 1 root root 22 8月 22 2019 /usr/sbin/init -&amp;gt; ../lib/systemd/systemd root@localhost:~ $ ll `which poweroff` lrwxrwxrwx.</description></item><item><title>DMA &amp; RDMA 基本概念</title><link>https://zdyxry.github.io/2020/03/02/DMA-RDMA-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link><pubDate>Mon, 02 Mar 2020 19:56:16 +0000</pubDate><guid>https://zdyxry.github.io/2020/03/02/DMA-RDMA-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid><description>背景 链接到标题 最近公司的存储系统要支持 RDMA 了，但是我连 RDMA 具体是啥还不清楚，今天花点时间来学习下相关知识。
在了解 RDMA 之前，需要先知道 DMA 是什么，所以会一点点说。
P.S. 本文部分内容截取自 《OSTEP》。
DMA 链接到标题 系统架构 链接到标题 先来看一个典型的系统架构，其中，CPU 通过某种内存总线（memory bus）或互连电缆连接到系统内存。图像或者其他高性能 I/O 设备通过常规的I/O 总线（I/O bus）连接到系统，在许多现代系统中会是 PCI 或它的衍生形式。最后，更下面是外围总（peripheral bus），比如 SCSI、SATA 或者 USB。它们将最慢的设备连接到系统，包括磁盘、鼠标及其他类似设备。
为什么会用这样的分层架构？因为物理布局及造价成本。越快的总线长度越短，因此高性能的内存总线没有足够的空间来接太多设备。另外，在工程上高性能总线的造价非常高。所以，系统的设计采用了这种分层的方式，这样可以让要求高性能的设备（比如显卡）离 CPU 更近一些，低性能的设备离 CPU 远一些。将磁盘和其他低速设备连到外围总线的好处很多，其中较为突出的好处就是你可以在外围总线上连接大量的设备。
标准设备 链接到标题 现在来看一个标准设备（不是真实存在的），通过它来帮助我们更好地理解设备交互的制。从图 中，可以看到一个包含两部分重要组件的设备。 第一部分是向系统其他部分展现的硬件接口（interface）。同软件一样，硬件也需要一些接口，让系统软件来控它的操作。因此，所有设备都有自己的特定接口以及典型交互的协议。 第二部分是它的内部结构（internal structure）。这部分包含设备相关的特定实现，负责具体实现设备展示给系统的抽象接口。非常简单的设备通常用一个或几个芯片来实现它们的功能。更复杂的设备会包含简单的 CPU、一些通用内存、设备相关的特定芯片，来完成它们的工作。例如，现代 RAID 控制器通常包含成百上千行固件（firmware，即硬件设备中的软件），以实现其功能。
标准协议 链接到标题 在图 36.2 中，一个（简化的）设备接口包含 3 个寄存器：一个状态（status）寄存器，可以读取并查看设备的当前状态；一个命令（command）寄存器，用于通知设备执行某个具体任务；一个数据（data）寄存器，将数据传给设备或从设备接收数据。通过读写这些寄存器，操作系统可以控制设备的行为。
我们现在来描述操作系统与该设备的典型交互，以便让设备为它做某事。协议如下：
While (STATUS == BUSY) ; // wait until device is not busy Write data to DATA register Write command to COMMAND register (Doing so starts the device and executes the command) While (STATUS == BUSY) ; // wait until device is done with your request 该协议包含 4 步：</description></item><item><title>2020 第9周 LeetCode 记录</title><link>https://zdyxry.github.io/2020/02/28/2020-%E7%AC%AC9%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 28 Feb 2020 19:35:45 +0000</pubDate><guid>https://zdyxry.github.io/2020/02/28/2020-%E7%AC%AC9%E5%91%A8-LeetCode-%E8%AE%B0%E5%BD%95/</guid><description>1300. Sum of Mutated Array Closest to Target 链接到标题 对 arr 进行降序排序，将 arr 中的最小值乘以 arr 长度与 target比较，若比 target 小，则将其丢弃，并将其从 target 中减去。 若 arr 为空，则表示 arr 中最大值乘以 arr 长度仍比 target 小，则返回 arr 中的最大值。 若 arr 不为空，则表示 arr 中存在大于目标值的数值，取 target 除以此时 arr 长度（arr 中所有数值均大于目标值），最终值四舍五入得到目标值。
class Solution(object): def findBestValue(self, arr, target): &amp;#34;&amp;#34;&amp;#34; :type arr: List[int] :type target: int :rtype: int &amp;#34;&amp;#34;&amp;#34; arr.sort(reverse = True) while arr and target &amp;gt;= arr[-1]*len(arr): temp = arr[-1] target -= arr.</description></item><item><title>zipstreamer 源码阅读</title><link>https://zdyxry.github.io/2020/02/21/zipstreamer-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link><pubDate>Fri, 21 Feb 2020 19:33:08 +0000</pubDate><guid>https://zdyxry.github.io/2020/02/21/zipstreamer-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</guid><description>背景 链接到标题 在之前的一篇博客《HTTP Content-Length 学习》 中提到自己踩了一个坑，就是 content-length 与实际大小不匹配导致文件下载失败，在解决过程中用到了 zipstreamer ，今天来看看 zipstreamer 是如何工作的。
zipfile 链接到标题 Python 标准库中提供了 zipfile 用来对 Zip 文件进行操作，可以进行 Zip 的创建、写入、读取、解压等动作，但是 zipfile 只能对文件进行操作，没办法传入 stream，所以能做的操作有限。
示例 链接到标题 import zipfile def test(): for i in range(1, 4): f = open(&amp;#34;file&amp;#34; + str(i) + &amp;#34;.txt&amp;#34;, &amp;#39;w&amp;#39;) f.write(str(i)) f.close() f = zipfile.ZipFile(&amp;#39;filename.zip&amp;#39;, &amp;#39;w&amp;#39;, zipfile.ZIP_DEFLATED) f.write(&amp;#39;file1.txt&amp;#39;) f.write(&amp;#39;file2.txt&amp;#39;) f.write(&amp;#39;file3.txt&amp;#39;) f.close() f = zipfile.ZipFile(&amp;#39;filename.zip&amp;#39;) f.extractall() f.close() if __name__ == &amp;#34;__main__&amp;#34;: test() zipstreamer 链接到标题 在提供文件下载接口时，有一个比较常见的需求是传过来一个 stream，然后我们要将 stream 作为 Zip 中的一个文件转发出去，实时下载，这时候就需要 zipstreamer 来实现了。</description></item><item><title>K8s drain 命令源码阅读</title><link>https://zdyxry.github.io/2020/02/15/K8s-drain-%E5%91%BD%E4%BB%A4%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link><pubDate>Sat, 15 Feb 2020 11:22:13 +0000</pubDate><guid>https://zdyxry.github.io/2020/02/15/K8s-drain-%E5%91%BD%E4%BB%A4%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</guid><description>背景 链接到标题 之前写过一篇 《Kubernetes 实战-平滑移除节点》 讲如何从 K8s 集群中移除节点的，今天来看看 kubectl drain 命令具体做了什么，怎么实现的。
kubectl 链接到标题 drain 相关命令都属于 kubectl 的自命令，因此需要先看下 kubectl 的入口，K8s 使用 cobra 作为命令行构建组建（我自己使用 cobra 觉得不怎么好用，而且文档也不清晰。。），统一入口在 cmd/kubectl/kubectl.go ，实际的处理逻辑在 pkg/kubectl/cmd/cmd.go 中
... groups := templates.CommandGroups{ { Message: &amp;#34;Basic Commands (Beginner):&amp;#34;, ... }, { Message: &amp;#34;Deploy Commands:&amp;#34;, ... }, { Message: &amp;#34;Cluster Management Commands:&amp;#34;, Commands: []*cobra.Command{ certificates.NewCmdCertificate(f, ioStreams), clusterinfo.NewCmdClusterInfo(f, ioStreams), top.NewCmdTop(f, ioStreams), drain.NewCmdCordon(f, ioStreams), drain.NewCmdUncordon(f, ioStreams), drain.NewCmdDrain(f, ioStreams), taint.NewCmdTaint(f, ioStreams), }, }, ... } groups.</description></item><item><title>HTTP Content-Length 学习</title><link>https://zdyxry.github.io/2020/02/07/HTTP-Content-Length-%E5%AD%A6%E4%B9%A0/</link><pubDate>Fri, 07 Feb 2020 22:54:14 +0000</pubDate><guid>https://zdyxry.github.io/2020/02/07/HTTP-Content-Length-%E5%AD%A6%E4%B9%A0/</guid><description>背景 链接到标题 之前提供了一个用于下载文件的 API，使用到了 Content-Length 字段并踩了个坑： Content-Length 与实际的数据大小不一致。今天来学习下这个字段相关的知识。
Content-Length 链接到标题 Content-Length 是一个实体消息首部，用来指明发送给接收方的消息主体的大小，即用十进制数字表示的八位元组的数目。
当客户端向服务器发送一个请求时，服务器可以很清楚的知道内容大小，然后通过Content-length消息首部字段告诉客户端需要接收多少数据。除了使用 Transfer-Encoding，当Content-Length 存在是必须与实际传输的数据大小一致，如果前者大，则会导致请求一直等待直至超时；如果后者大，则会导致数据被截断，在最近版本的 Chrome 中，会直接提示 net::ERR_CONTENT_LENGTH_MISMATCH 报错导致加载失败。
package main import ( &amp;#34;net/http&amp;#34; ) func main() { http.HandleFunc(&amp;#34;/&amp;#34;, func(w http.ResponseWriter, r *http.Request) { w.Header().Set(&amp;#34;Content-Length&amp;#34;, &amp;#34;20&amp;#34;) //w.Header().Set(&amp;#34;Content-Length&amp;#34;, &amp;#34;12&amp;#34;) w.WriteHeader(200) w.Write([]byte(&amp;#34;hello world\n&amp;#34;)) }) http.ListenAndServe(&amp;#34;:8080&amp;#34;, nil) } Request URL: http://127.0.0.1:8080/ Request Method: GET Status Code: 200 OK Remote Address: 127.0.0.1:8080 Referrer Policy: no-referrer-when-downgrade Content-Length: 12 Content-Type: text/plain; charset=utf-8 Date: Fri, 07 Feb 2020 14:36:40 GMT X-DNS-Prefetch-Control: off Transfer-Encoding 链接到标题 Transfer-Encoding 消息首部指明了将 entity 安全传递给用户所采用的编码形式。Transfer-Encoding 是一个逐跳传输消息首部，即仅应用于两个节点之间的消息传递，而不是所请求的资源本身。一个多节点连接中的每一段都可以应用不同的Transfer-Encoding 值。</description></item><item><title>Server-Sent Events 简单使用</title><link>https://zdyxry.github.io/2020/02/03/Server-Sent-Events-%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 03 Feb 2020 07:36:46 +0000</pubDate><guid>https://zdyxry.github.io/2020/02/03/Server-Sent-Events-%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</guid><description>背景 链接到标题 最近在刷 Twitter 的时候，发现 Twitter 会实时更新已加载页面的内容，以为是 Websocket，看了下请求发现是 Server-sent events，之前没有了解过这个，今天来学习一下。
Server-sent events 链接到标题 引用维基百科：
Server-Sent Events (SSE) is a server push technology enabling a client to receive automatic updates from a server via HTTP connection. The Server-Sent Events EventSource API is standardized as part of HTML5[1] by the W3C.
SSE 通常与 Websocket 相比较：
SSE 提供单向通信，Websocket 提供双向通信； SSE 是通过 HTTP 协议实现的，Websocket 是单独的协议； 实现上来说 SSE 比较容易，Websocket 复杂一些； 对浏览器来说，IE/Edge 不支持 SSE，其它的都是支持的。 SSE 有最大连接数限制 WS 可以传输二进制数据和文本数据，而 SSE 只有文本数据 SSE 使用场景：</description></item><item><title>使用 Raft 实现 VIP 功能</title><link>https://zdyxry.github.io/2020/01/17/%E4%BD%BF%E7%94%A8-Raft-%E5%AE%9E%E7%8E%B0-VIP-%E5%8A%9F%E8%83%BD/</link><pubDate>Fri, 17 Jan 2020 22:48:28 +0000</pubDate><guid>https://zdyxry.github.io/2020/01/17/%E4%BD%BF%E7%94%A8-Raft-%E5%AE%9E%E7%8E%B0-VIP-%E5%8A%9F%E8%83%BD/</guid><description>背景 链接到标题 在部署应用时想要应用是高可用，通常会在应用前放置一个 HAProxy，当任何一个 Server 故障，HAProxy 会自动切换，但是 HAProxy 也存在单点故障，因此需要多个 HAProxy 来保证业务不中断，这时候我们需要另一个软件配合：Keepalived。通常我用 Keepalived 仅用来提供 VIP，保证当一个 Keepalived 故障，VIP 自动在其他 Keepalived 节点配置。
Keepalived 有一个问题是 virtual route ID 必须是同一网段内唯一的，当我们想要在一个网段内部署多个集群时，就需要人为的介入去分配 virtual route ID，不方便。这次来使用 Raft 自己实现 VIP 逻辑。
hashicorp/raft 链接到标题 Raft 有很多开源实现，其中 Hashicorp 实现的 Raft 库 已经被 Consul 等软件使用，且接口友善，选择使用它来实现。在 Github 上有很多 Raft 的使用示例，比较简单且完整的是 otoolep/hraftd，我们来看看他是怎么使用的。
otoolep/hraftd 链接到标题 main.go 链接到标题 在 main.go 中主要做了 4 件事情：store.New, store.Open, http.New, http.Start，先来看看程序是如何启动的：
func init() { // 设置命令行参数 flag.BoolVar(&amp;amp;inmem, &amp;#34;inmem&amp;#34;, false, &amp;#34;Use in-memory storage for Raft&amp;#34;) .</description></item><item><title>ThinkPad T480 &amp; Ubuntu 19.10 连接多显示器方式</title><link>https://zdyxry.github.io/2020/01/12/ThinkPad-T480-Ubuntu-19.10-%E8%BF%9E%E6%8E%A5%E5%A4%9A%E6%98%BE%E7%A4%BA%E5%99%A8%E6%96%B9%E5%BC%8F/</link><pubDate>Sun, 12 Jan 2020 20:26:35 +0000</pubDate><guid>https://zdyxry.github.io/2020/01/12/ThinkPad-T480-Ubuntu-19.10-%E8%BF%9E%E6%8E%A5%E5%A4%9A%E6%98%BE%E7%A4%BA%E5%99%A8%E6%96%B9%E5%BC%8F/</guid><description>背景 链接到标题 平时工作使用的电脑是 ThinkPad T480，之前一直安装的 Win10，连接多显示器很正常，没有问题，后来重装为了 Ubuntu，发现连接多显示器很诡异，在我的这套设备之上，如果想要正常使用，需要按照一个奇怪的顺序，记录一下。
硬件设备 链接到标题 设备类型 设备 型号 笔记本 ThinkPad T480 拓展坞 联想/闪联 USB-C 集线器 C120 连接线 山泽 HDMI 数字高清线 SM-8855 连接线 VGA 高清视频线 显示器 DELL 24 寸 U2412Mb 显示器 DELL 24 寸 U2417H （不要问我为啥 Type-C 遍地走的现在，还在用 VGA，现在这套还是东拼西凑出来的。。。
软件 链接到标题 设备接口 链接到标题 T480 作为 ThinkPad 的 T 系列产品，接口还是很丰富的：
2 x USB 3.1 Gen 1** (one Always On) 1 x USB 3.1 Gen 1** Type-C (Power Delivery, DisplayPort, Data transfer) x USB 3.</description></item><item><title>为什么 flannel.1 丢失后不会自动重建</title><link>https://zdyxry.github.io/2020/01/03/%E4%B8%BA%E4%BB%80%E4%B9%88-flannel.1-%E4%B8%A2%E5%A4%B1%E5%90%8E%E4%B8%8D%E4%BC%9A%E8%87%AA%E5%8A%A8%E9%87%8D%E5%BB%BA/</link><pubDate>Fri, 03 Jan 2020 22:20:37 +0000</pubDate><guid>https://zdyxry.github.io/2020/01/03/%E4%B8%BA%E4%BB%80%E4%B9%88-flannel.1-%E4%B8%A2%E5%A4%B1%E5%90%8E%E4%B8%8D%E4%BC%9A%E8%87%AA%E5%8A%A8%E9%87%8D%E5%BB%BA/</guid><description>背景 链接到标题 在用 K8s 的同学应该多少都使用过 Flannel 作为自己的网络插件，不讨论性能稳定性，在复杂的网络环境配置中 Flannel 的要求应该是最低的，所以我通常使用 Flannel 作为 让 K8s Ready 的最后一步。
在使用过程中，遇到过多次 flannel.1 这个 link 消失的情况，查看官方 Issue 中有人提到过： flannel.1 is deleted by service network restart, and never recreated again. ，但是这个 Issue 从 2017年创建一直到现在都处于 Open 状态，看上去社区也不打算去解决，其实不只是重启网络，如果没有特殊指定的话，找到默认网关所在的网卡，直接 ifdown ，flannel.1 也会丢失，并且不会重建，那为什么会出现这个问题，今天来看一看。
CNI Flannel Plugin 链接到标题 我们常说的 Flannel 分为两部分：CNI Flannel Plugin 及 Flannel。
CNI Flannel Plugin 是 Flannel CNI 插件的具体接口实现， CNI 要求实现的 cmdAdd cmdDel cmdCheck 都是在这里实现的，来看看具体的调用流程：
func cmdAdd(args *skel.CmdArgs) error { // 从标准输入加载配置 n, err := loadFlannelNetConf(args.</description></item><item><title>2019 年终总结</title><link>https://zdyxry.github.io/2019/12/31/2019-%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 31 Dec 2019 09:21:48 +0000</pubDate><guid>https://zdyxry.github.io/2019/12/31/2019-%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/</guid><description>2019 链接到标题 2019 年就要结束了，今年用数据记录了很多，可以很好的支撑我做一个年终总结碎碎念。
读书观影 链接到标题 一整年都是两点一线：家里和公司，没有什么特别大的变化，周末的时间也都给了书和电影。
读书记录之前已经发过了，上半年看的比较多，下半年忙起来时间上少了很多，加上看的书的质量也比上半年高，所以看的比较细，用了很多时间去查相关资料。因为年后有些计划，所以集中把自己刚刚工作的时候买的纸质书（一直没看）清理了一下，愈发觉得刚工作的自己真是个愣头青，买的书都是水书，还是应该多看些经典书籍，需要更多思考的书。
电影看的多，至少豆瓣上标记的数量很吓人，周末基本上都会看几部。今年看的种类都比较阴暗，自己本意是放松一下的，看着看着心情更加沉重了。电影是另外一种了解世界的方式，我们可以看到不同的人，不同的风景，同时也会代入思考如果是自己会怎么做。在现实世界很多观点无法表述的现在，还是很有趣的。
书籍推荐：
《操作系统导论》 《图解密码技术（第3版）》 《编码的奥秘》 电影推荐：
《平衡》 《电话亭》 《婚姻故事》 习惯 链接到标题 2019 年算是养成了 2 个好习惯：刷题和写博客。
因为自己一直习惯早起（6点钟左右），以前都是当天要做什么工作，早上起来做一些准备之类的事情，有两点不好：一是把自己的时间都给了工作，导致自己会有种抵触；二是不规律，我喜欢规律。
所以从 4 月份开始，每天早上会做一道 LeetCode 题，目前一直坚持到现在。要说刷题有带给我什么质的变化么，那显然是没有的，但是我上面提到的两点不好，在刷题这里都消失了。刷题让我去认真的学习数据结构和算法，去了解一道题的不同种解法（往往会冒出“这tm的真是个人才”的感叹），而且会让我的生活更加规律，能从工作中抽出来，强烈推荐大家去试试。像我从 Easy 开始分类的做，最开始不会花费太长时间，做不出来就看看其他人怎么做，后续就会有些自己的想法。但是最近我做 Medium 的题耗时就比之前长好多了，有些题及时看着答案也要想很久，导致我又起的更早了。。
2019 年自己定了每周更新一篇博客的目标，目标完成。一开始写博客是为了记录下自己的踩坑经历和一些经验分享，随后是自己发现一些新东西的时候自己学习了解的过程。要锻炼自己对外输出的能力，保证自己能够有逻辑的输出自己的观点，哪怕不能有逻辑的说出来，至少要有逻辑的写出来。
开销 链接到标题 没有买什么新玩具，也没有什么特别大的开支，当然也没有存到什么钱。
真实物品 链接到标题 主要的开销在吃饭和房租，年初买了一个 iPad 用来看 PDF，毕竟无论是 Kindle 还是手机都不能很好的阅读，iPad 看 PDF 的效果是很好的，我也用它来看了一些书，但是有个问题是完整在 iPad 看完的书不到 10本，也是一个 买前生产力，买后bilibili 的例子了。
虚拟物品 链接到标题 自己平时需要跑一些 crontab 做事情，所以有一个祖传搬瓦工一直在供着，但是今年上网格外的困难，搬瓦工 IP 被封，所以又在 Azure 上搞了一个 VPS，目前看上去这套东西运转的还算顺利。
趁着年底活动，买了 RescueTime 的会员，估计明年会买 Pocket，毕竟重度用户。
P.S. 从带给自己生活感受的提升上，VPS 性价比可太高了。</description></item><item><title>记一次 libcgroup 配置失败（二）</title><link>https://zdyxry.github.io/2019/12/25/%E8%AE%B0%E4%B8%80%E6%AC%A1-libcgroup-%E9%85%8D%E7%BD%AE%E5%A4%B1%E8%B4%A5%E4%BA%8C/</link><pubDate>Wed, 25 Dec 2019 21:49:06 +0000</pubDate><guid>https://zdyxry.github.io/2019/12/25/%E8%AE%B0%E4%B8%80%E6%AC%A1-libcgroup-%E9%85%8D%E7%BD%AE%E5%A4%B1%E8%B4%A5%E4%BA%8C/</guid><description>背景 链接到标题 前几天同事找到我，说有一台服务器上的 cgroup 没有创建出来，导致其他程序出现了问题，记录一下。
现象 链接到标题 在我们的服务器上，通常会通过 libcgconfig 来进行 cgroup 的配置，供其他服务使用。结果发现对应的 cgroup 没有创建出来，于是查看 cgconfig.service 的状态，发现是异常退出的：
报错信息比较重要的是这一条：
failed to set /sys/fs/cgroup/cpuset/zbs/cpuset.mems: Invalid argument。
调查 链接到标题 检查下 /etc/cgconfig.conf 中的配置是否正确：
group . { cpuset { cpuset.memory_pressure_enabled = &amp;#34;1&amp;#34;; } } group zbs { cpu { cpu.rt_runtime_us = &amp;#34;950000&amp;#34;; cpu.rt_period_us = &amp;#34;1000000&amp;#34;; } cpuset { cpuset.cpus = &amp;#34;0,1,2,3,4,5&amp;#34;; cpuset.mems = &amp;#34;0-1&amp;#34;; cpuset.cpu_exclusive = &amp;#34;1&amp;#34;; cpuset.mem_hardwall = &amp;#34;1&amp;#34;; } } ... 配置看上去没啥问题，这里的 cpuset.mems 指定的是 NUMA Node ID。</description></item><item><title>Kubernetes 实战-Cluster API 升级流程</title><link>https://zdyxry.github.io/2019/12/22/Kubernetes-%E5%AE%9E%E6%88%98-Cluster-API-%E5%8D%87%E7%BA%A7%E6%B5%81%E7%A8%8B/</link><pubDate>Sun, 22 Dec 2019 16:53:55 +0000</pubDate><guid>https://zdyxry.github.io/2019/12/22/Kubernetes-%E5%AE%9E%E6%88%98-Cluster-API-%E5%8D%87%E7%BA%A7%E6%B5%81%E7%A8%8B/</guid><description>背景 链接到标题 之前已经介绍过 ClusterAPI 及相应实现方式，但是针对使用 ClusterAPI 部署的 K8s 集群社区中一直没有升级方案，其中 vmware 实现了一个简单的升级工具，可以在社区没实现之前提供使用，今天来看下这个工具是如何实现的。
cluster-api-upgrade-tool 链接到标题 项目地址：https://github.com/vmware/cluster-api-upgrade-tool
因为这只是一个单独的工具，因此代码结构比较简单：
yiran@t480:~/go/src/github.com/vmware/cluster-api-upgrade-tool master ✔ $ tree . . ├── CODE-OF-CONDUCT.md ├── CONTRIBUTING.md ├── Dockerfile ├── go.mod ├── go.sum ├── hack │ └── tools │ ├── go.mod │ ├── go.sum │ └── main.go ├── LICENSE.txt ├── main.go # 命令行入口 ├── Makefile ├── NOTICE.txt ├── pkg │ ├── internal │ │ └── kubernetes │ │ ├── client.go # 获取 client │ │ └── pod_exec.</description></item><item><title>Kubernetes 实战-高可用集群部署（无LB）</title><link>https://zdyxry.github.io/2019/12/19/Kubernetes-%E5%AE%9E%E6%88%98-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%97%A0LB/</link><pubDate>Thu, 19 Dec 2019 21:38:16 +0000</pubDate><guid>https://zdyxry.github.io/2019/12/19/Kubernetes-%E5%AE%9E%E6%88%98-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%97%A0LB/</guid><description>背景 链接到标题 之前写过一篇《Kubernetes 实战-高可用集群部署》 博客讲 K8S 高可用配置，当时采用的方式是使用 keepalived 配合 HAProxy 自建 LB 的方式，但是最近发现无论是 Kubespray 还是 Rancher RKE 都没有采用这种方式，而是在 worker node 上配置 nginx/haproxy 代理 APIServer 达到目的。今天来手动配置下这种方式，了解下注意事项。
本文配置方式参考 Kubespray，主要是想加深自己对这方面的理解，如果只是单纯的想要搭建环境，那么直接使用 Kubespray 就好。
环境 链接到标题 IP role 192.168.17.11 ControlPlane1 192.168.17.12 ControlPlane2 192.168.17.13 ControlPlane3 192.168.17.14 WorkerNode1 准备工作 链接到标题 软件安装 链接到标题 这部分准备工作与之前一样，没什么不同，因此不详细说明，需要安装 kubectl,kubeadm,kubelet 。
部署 链接到标题 ControlPlane1 链接到标题 kubeadm 配置文件如下：
[root@install1 17:55:09 tmp]$cat kubeadm.yaml --- apiServer: {} apiVersion: kubeadm.k8s.io/v1beta1 certificatesDir: &amp;#34;&amp;#34; clusterName: test controlPlaneEndpoint: &amp;#34;192.168.17.11:6443&amp;#34; controllerManager: {} dns: type: &amp;#34;&amp;#34; etcd: {} imageRepository: registry.</description></item><item><title>邻居发现协议（NDP）简易实现</title><link>https://zdyxry.github.io/2019/12/11/%E9%82%BB%E5%B1%85%E5%8F%91%E7%8E%B0%E5%8D%8F%E8%AE%AENDP%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0/</link><pubDate>Wed, 11 Dec 2019 21:29:59 +0000</pubDate><guid>https://zdyxry.github.io/2019/12/11/%E9%82%BB%E5%B1%85%E5%8F%91%E7%8E%B0%E5%8D%8F%E8%AE%AENDP%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0/</guid><description>背景 链接到标题 在做节点管理时，经常面临节点自动扫描，自动关联等功能，这时候需要 NDP 来帮助我们来完成，关于 NDP 的实现有几种方式，今天来聊一下这个。
邻居发现协议（NDP） 链接到标题 引用维基百科的介绍：
The Neighbor Discovery Protocol (NDP, ND)[1] is a protocol in the Internet protocol suite used with Internet Protocol Version 6 (IPv6). It operates at the link layer of the Internet model (RFC 1122), and is responsible for gathering various information required for internet communication, including the configuration of local connections and the domain name servers and gateways used to communicate with more distant systems.</description></item><item><title>2019年读书记录</title><link>https://zdyxry.github.io/2019/12/09/2019%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</link><pubDate>Mon, 09 Dec 2019 20:07:34 +0000</pubDate><guid>https://zdyxry.github.io/2019/12/09/2019%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</guid><description> 年终总结 链接到标题 2016 计划读 5 本，实际读 13 本。 2017 计划 32 本，实际读完 23 本。 2018 计划 30 本，实际25本。 2019 计划 30 本，实际 43 本。 今年是第 4 年写读书记录了，感觉手上这本 TLPI 年底之前是看不完了，就总结一下。与之前不同的是今年把周末的时间利用的比较好，通常周末两天会拿出一整天的时间来看书，保证自己的精力集中，效率会高很多。
因为博客集成了豆瓣，所以就不列出 在读 和 想读 列表了，想的太多，耽误事。希望接下来读一些经典的技术书，把自己的基础知识补齐。
已读 链接到标题 《用Python写网络爬虫》 《Wireshark网络分析就这么简单》 《如何有效阅读一本书 : 超实用笔记读书法》 《冷场》 《Go程序设计语言》 《爱你就像爱生命》 《Go by Example》 《显微镜下的大明》 《流浪地球》 《情感勒索》 《Go语言实战》 《活着》 《悉达多》 《Go in Practice》 《奈飞文化手册》 《刻意练习》 《软件测试的艺术》 《Redis实战》 《雪崩》 《TCP/IP详解 卷1：协议》 《Structure and Interpretation of Computer Programs - 2nd Edition (MIT)》 《编码的奥秘》 《Kubernetes in Action》 《计算机组成：结构化方法》 《人月神话》 《自己动手写Docker》 《好文案一句话就够了》 《跟老男孩学Linux运维：Web集群实战》 《计算机组成与设计》 《简约至上》 《Go Web编程》 《大话数据结构》 《Python Web开发实战》 《Programming Kubernetes》 《Istio入门与实战》 《刷新》 《奇特的一生》 《图解密码技术（第3版）》 《细节》 《生活大爆炸里的科学》 《操作系统导论》 《RESTful Web APIs中文版》 《正则表达式必知必会》</description></item><item><title>SSH known_hosts 显示 IP 地址</title><link>https://zdyxry.github.io/2019/12/06/SSH-known_hosts-%E6%98%BE%E7%A4%BA-IP-%E5%9C%B0%E5%9D%80/</link><pubDate>Fri, 06 Dec 2019 21:54:25 +0000</pubDate><guid>https://zdyxry.github.io/2019/12/06/SSH-known_hosts-%E6%98%BE%E7%A4%BA-IP-%E5%9C%B0%E5%9D%80/</guid><description>背景 链接到标题 工作上使用的电脑因为各种各样的原因，被我安装为 Ubuntu 19.04，平时使用上没什么问题，但是最近发现它默认的 SSH 配置随着版本升级发生了变化，known_hosts 文件中记录的不再是 IP 地址，而是一串字符，这导致了当我想要删除某个主机的 key 时，无法准确的找到，因此想办法解决这个事情。
SSH 链接到标题 我们使用 Linux 系统的一个最基本的服务应该就是 SSH 了，除了偶尔我们通过 VNC 或者 KVM(Keyboard Virtual Manager)连接控制主机外，都是通过 SSH 到 Linux 主机上进行某些操作。那么 SSH 就是 Secure Shell，安全外壳协议。可在不安全的网络中为网络服务提供安全的传输环境。SSH 通过在网络中建立安全隧道来实现SSH客户端与服务器之间的连接。
SSH 最重要的就是安全，采用的是非对称加密，关于加密相关的部分，可以看我之前写的一篇《图解密码技术》读书笔记 里面有比较完整的相关知识。
这里主要说一下使用密码登陆和密钥登陆的流程。
密码登陆 链接到标题 客户端向服务端发起连接请求 root@test-hostname-ubuntu-s-1804:~# ssh 192.168.67.90 The authenticity of host &amp;#39;192.168.67.90 (192.168.67.90)&amp;#39; can&amp;#39;t be established. ECDSA key fingerprint is SHA256:ca9Zk/7pR4f6rrNP3wi1WK+CQMtG4Ka+kkouwQYU0nY. Are you sure you want to continue connecting (yes/no)? 客户端会提示，知道服务端的唯一标示，确认连接么 确认连接，输入 yes root@test-hostname-ubuntu-s-1804:~# ssh 192.</description></item><item><title>Linux 引导那些事儿</title><link>https://zdyxry.github.io/2019/12/01/Linux-%E5%BC%95%E5%AF%BC%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/</link><pubDate>Sun, 01 Dec 2019 00:32:26 +0000</pubDate><guid>https://zdyxry.github.io/2019/12/01/Linux-%E5%BC%95%E5%AF%BC%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/</guid><description>背景 链接到标题 在平时工作中我自己可能80% 的时间都在使用 Linux 进行工作，无论是软件开发还是环境维护，那么对于 Linux 发行版自然也是有比较熟悉的，比如 RHEL 系列。平时大家可能多多少少都会听到或接触到一些命令（术语），比如：grub,chroot,isolinux,bios 等等。今天打算就用 CentOS 发行版的 ISO 来谈谈自己对于 Linux 系统引导，安装，启动的理解。
CentOS ISO 目录树如下：
├── CentOS_BuildTag ├── EFI ├── EULA ├── GPL ├── images ├── isolinux ├── LiveOS ├── Packages ├── repodata ├── RPM-GPG-KEY-CentOS-7 ├── RPM-GPG-KEY-CentOS-Testing-7 └── TRANS.TBL isolinux 链接到标题 ISO 9660 链接到标题 ISO 9660 是一种文件系统，也是一种规范，它规定了 ISO 文件应该是什么样子，常见的 Linux 发行版 ISO 都符合该规范。
引导 链接到标题 有了 ISO，有了计算机，那么我们需要使用 ISO 安装想要的操作系统，通常我们会将 ISO 通过光盘/USB/网络等方式挂载到计算机上，通过设置 BIOS/UEFI 选项，将启动项设置为 ISO，然后启动进行安装。接下来一个一个来说。</description></item><item><title>Cloud-init 无需重启执行配置</title><link>https://zdyxry.github.io/2019/11/29/Cloud-init-%E6%97%A0%E9%9C%80%E9%87%8D%E5%90%AF%E6%89%A7%E8%A1%8C%E9%85%8D%E7%BD%AE/</link><pubDate>Fri, 29 Nov 2019 21:35:26 +0000</pubDate><guid>https://zdyxry.github.io/2019/11/29/Cloud-init-%E6%97%A0%E9%9C%80%E9%87%8D%E5%90%AF%E6%89%A7%E8%A1%8C%E9%85%8D%E7%BD%AE/</guid><description>背景 链接到标题 最近在折腾 Cluster API 的时候，因为目前社区中比较成熟的方案是通过 Cloud-init 执行 kubeadm 命令部署 k8s ，因此需要使用 Cloud-init 进行功能验证，但是 Cloud-init 通常执行的前提条件是系统初次启动时，自动执行配置，这点对于调试很不友好，因此需要找到一个无需重启即可执行 Cloud-init 配置的方式。
Cloud-init 链接到标题 使用过公有云或者私有云的同学应该都知道在创建虚拟机的时候可以传递一个脚本用于在机器置备的时候执行某些动作，尤其在批量执行的时候，通常会很方便。这个其实就是 Cloud-init 所做的工作，就跟它的名字一样，针对 Cloud 场景执行 init 动作。
引用官网介绍：
Cloud-init is the industry standard multi-distribution method for cross-platform cloud instance initialization. It is supported across all major public cloud providers, provisioning systems for private cloud infrastructure, and bare-metal installations.
NoCloud 链接到标题 Cloud-init 官方支持云平台种类很多常见的公有云如 Aliyun、AWS、Azure，常见的私有云解决方案如 OpenStack、ZStack、OVF 等都有支持。
但是如果我不使用已经支持的私有云，而是自己通过 Libvirt 配合 Ceph 实现了一套虚拟化平台，想要使用 Cloud-init，则可以使用 ConfigDrive 或者 NoCloud 方式。本文采用的是 NoCloud 方式。</description></item><item><title>如何捕捉 Ctrl+C 指令</title><link>https://zdyxry.github.io/2019/11/23/%E5%A6%82%E4%BD%95%E6%8D%95%E6%8D%89-Ctrl-C-%E6%8C%87%E4%BB%A4/</link><pubDate>Sat, 23 Nov 2019 21:23:24 +0000</pubDate><guid>https://zdyxry.github.io/2019/11/23/%E5%A6%82%E4%BD%95%E6%8D%95%E6%8D%89-Ctrl-C-%E6%8C%87%E4%BB%A4/</guid><description>背景 链接到标题 有时候在运行代码的时候，想要程序在接收到 Ctrl+C 指令的时候做一些平滑的处理，来写一下在 Python 和 Golang 中如何接收 Ctrl+C 指令。
Python 链接到标题 import signal import time import sys def run_program(): while True: print(&amp;#34;Test code...&amp;#34;) time.sleep(1) def exit_gracefully(signum, frame): signal.signal(signal.SIGINT, original_sigint) print(&amp;#34;Receive Ctrl+C.&amp;#34;) sys.exit(1) if __name__ == &amp;#39;__main__&amp;#39;: original_sigint = signal.getsignal(signal.SIGINT) signal.signal(signal.SIGINT, exit_gracefully) run_program() Golang 链接到标题 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;os&amp;#34; &amp;#34;os/signal&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) func WaitForCtrlC() { var end_waiter sync.WaitGroup end_waiter.Add(1) var signal_channel chan os.Signal signal_channel = make(chan os.</description></item><item><title>使用 Ansible 传输文件的几种方式</title><link>https://zdyxry.github.io/2019/11/22/%E4%BD%BF%E7%94%A8-Ansible-%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</link><pubDate>Fri, 22 Nov 2019 20:15:17 +0000</pubDate><guid>https://zdyxry.github.io/2019/11/22/%E4%BD%BF%E7%94%A8-Ansible-%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</guid><description>背景 链接到标题 Ansible 作为一款配置管理和应用部署的软件，日常使用的场景很多，我自己也是重度用户。最近在使用 Ansible 进行文件传输的时候踩了个坑，借此机会整理下 Ansible 传输文件的几种方式。
实验环境：
[root@yiran ~]# ansible --version ansible 2.7.12 config file = None configured module search path = [u&amp;#39;/root/.ansible/plugins/modules&amp;#39;, u&amp;#39;/usr/share/ansible/plugins/modules&amp;#39;] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, Aug 7 2019, 00:51:29) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] Template 链接到标题 https://docs.ansible.com/ansible/latest/modules/template_module.html
Ansible 一个常用的功能就是配置管理，通过 Ansible 批量分发配置文件，达到统一版本管理的效果，如果我们想要进行少量的文件传输，从控制节点传输到被管理节点，那么可以采用这种方式来完成。
具体的使用官方文档 已经讲的很详细了，这里不再啰嗦。
因为版本是通过 Jinja2 模板传输，支持模板渲染 虽然我们可以在模版中不制定任何参数，直接将其拷贝，但是相比 Copy/Fetch 模块还是需要有模版渲染的一步，速度要慢一些
Copy/Fetch 模块 链接到标题 https://docs.</description></item><item><title>为什么你的 mdadm 同步这么慢</title><link>https://zdyxry.github.io/2019/11/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E7%9A%84-mdadm-%E5%90%8C%E6%AD%A5%E8%BF%99%E4%B9%88%E6%85%A2/</link><pubDate>Fri, 15 Nov 2019 20:20:03 +0000</pubDate><guid>https://zdyxry.github.io/2019/11/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E7%9A%84-mdadm-%E5%90%8C%E6%AD%A5%E8%BF%99%E4%B9%88%E6%85%A2/</guid><description>背景 链接到标题 自己一直通过 mdadm 在软件层面对多块磁盘进行 RAID1 配置，一个主要的原因是 mdadm 是 KickStart 默认软件。因为只是 RAID1，所以使用起来也是比较方便，虽然有些小坑，但总体来说还好。
最近遇到一个问题， mdadm 在配置 RAID1 时，磁盘同步很慢。
现象 链接到标题 先说下磁盘构成，一般情况下是这样：
[root@yiran 20:23:48 ~]$lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 59.6G 0 disk ├─sda1 8:1 0 256M 0 part /boot/efi └─sda2 8:2 0 512M 0 part /boot sdb 8:16 0 223.6G 0 disk └─sdb1 8:17 0 45G 0 part └─md127 9:127 0 45G 0 raid1 / sdc 8:32 0 223.</description></item><item><title>路由器 vs 交换机</title><link>https://zdyxry.github.io/2019/11/09/%E8%B7%AF%E7%94%B1%E5%99%A8-vs-%E4%BA%A4%E6%8D%A2%E6%9C%BA/</link><pubDate>Sat, 09 Nov 2019 09:59:07 +0000</pubDate><guid>https://zdyxry.github.io/2019/11/09/%E8%B7%AF%E7%94%B1%E5%99%A8-vs-%E4%BA%A4%E6%8D%A2%E6%9C%BA/</guid><description>背景 链接到标题 交换机和路由器大家应该都听说过，大部分也用过，但是它俩有啥联系，又有啥区别？
P.S. 最近看《OSTEP》看的脑子有点短路，趁着周末看点网络的东西。
路由器 链接到标题 路由器（英语：Router，又称路径器）是一种电讯网络设备，提供路由与转送两种重要机制，可以决定封包从来源端到目的端所经过的路由路径（host 到 host 之间的传输路径），这个过程称为路由；将路由器输入端的封包移送至适当的路由器输出端（在路由器内部进行），这称为转送。路由工作在OSI模型的第三层——即网络层，例如网际协议（IP）。
路由器主要具有两个职能：
路由器确保信息不到达不需要到达的位置 路由器确保信息到达所需要的正确目的地 在执行以上这两种职能中，路由器连接两个网络，将信息从一个网络传送至另一个网络。在某些情况下，还执行两个网络间的多种协议的翻译职能。此外它还确保网络之间通信路由的相互独立，预防其中一个网络上的多余流量溢出到另一个网络上。该过程称为路由选择。
路由选择是 OSI 模型第三层（网络层的）一个功能。路由器通过网络层协议头如 IP 头（包含源地址和目的地址）和路由表，选择转发数据包的最佳路径。为选择任意两个主机间的最佳路由，实现路由器间的通信，通常需要应用如 ICMP 这样的路由选择协议。
交换机 链接到标题 网络交换机（Network switch）是一种网络数据转发设备，能够对数据包进行高速的“交换”。二层交换机工作于OSI参考模型的第二层，即数据链路层。
交换机内部的CPU会在每个端口成功连接时，通过将MAC地址和端口对应，形成一张 MAC 表。在今后的通讯中，发往该MAC地址的数据包将仅送往其对应的端口，而不是所有的端口。交换机对数据包的转发是建立在MAC (Media Access Control) 地址&amp;ndash;物理地址基础之上的，对于IP 网络协议来说，它是透明的，即交换机在转发数据包时，不知道也无须知道信源机和信宿机的IP 地址，只需知其物理地址即MAC 地址。
交换机在操作过程当中会不断的收集资料去建立它本身的一个地址表，这个表相当简单，它说明了某个MAC 地址是在哪个端口上被发现的，所以当交换机收到一个TCP/IP 封包时，它便会看一下该数据包的目的 MAC 地址，核对一下自己的地址表以确认应该从哪个端口把数据包发出去。由于这个过程比较简单，加上这功能由一崭新硬件进行——ASIC (Application Specific Integrated Circuit) ，因此速度相当快，一般只需几十微秒，交换机便可决定一个IP 封包该往那里送。
值得一提的是：万一交换机收到一个不认识的封包，就是说如果目的地MAC 地址不能在地址表中找到时，交换机会把IP 封包&amp;quot;扩散&amp;quot;出去，即把它从每一个端口中送出去，就如交换机在处理一个收到的广播封包时一样。
二层交换机的弱点正是它处理广播封包的手法不太有效，比方说，当一个交换机收到一个从TCP/IP 工作站上发出来的广播封包时，他便会把该封包传到所有其他端口去，哪怕有些端口上连的是IPX 或DECnet 工作站。这样一来，非TCP/IP 节点的带宽便会受到负面的影响，就算同样的TCP/IP 节点，如果他们的子网跟发送那个广播封包的工作站的子网相同，那么他们也会无原无故地收到一些与他们毫不相干的网络广播，整个网络的效率因此会大打折扣。
区别 链接到标题 路由器 交换机 OSI 网络层 数据链路层 数据传输地址 IP 地址 MAC 地址 使用范围 局域网/广域网 局域网 存储信息 路由表 MAC 地址与端口映射表 传输方式 全双工 全双工 隔离方式 划分子网 划分 VLAN 具体用途 连接多个网络 连接一个网络内的多个设备 那么路由器和交换机可以互相替换么？</description></item><item><title>ARM 服务器适配记录</title><link>https://zdyxry.github.io/2019/11/01/ARM-%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%80%82%E9%85%8D%E8%AE%B0%E5%BD%95/</link><pubDate>Fri, 01 Nov 2019 22:12:00 +0000</pubDate><guid>https://zdyxry.github.io/2019/11/01/ARM-%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%80%82%E9%85%8D%E8%AE%B0%E5%BD%95/</guid><description>背景 链接到标题 最近各大 2B 厂家都在搞国产化，我司也不例外，花费了些时间折腾了下 ARM 服务器，记录下踩坑和使用感受。
本文所使用的开发环境为 CentOS7.6。
编译 链接到标题 使用的第一步是编译自己的软件，我日常使用的软件发布的最小粒度是 RPM，所以我们需要把自己在 X86 上的软件都重新编译一份 ARM64v8 的。
Python 链接到标题 在预期中，Python 应该是最简单的，直接编译 RPM 就好，我在之前博客《RPM 常用构建方式》 中提到过，对于 Python 来说，最简单的是通过 FPM 来构建 RPM，但是这里有两个坑。
Python 软件是否依赖了 C/C++ ，如果依赖了，那么需要在 ARM 机器上使用 FPM 的时候编译构建 RPM 从网上下载的 noarch.rpm ，是否真的是 noarch 的？需要仔细检查（别问我怎么知道的 在我以为一切搞定的时候，想起来还有个服务是需要机器学习等第三方库的，是使用 conda 安装的。 好嘛，完蛋了，折腾几个小时下来结论是 conda 对于 ARM64 几乎处于不支持的状态。最后也没搞定。
Golang 链接到标题 最简单的莫过于 Golang 了，在 Golang 1.5 及之后版本，只需要设置 GOOS 和 GOARCH 这两个环境变量就能编译出目标平台的 Go binary 文件。
在官网中我们可以找到支持列表：
$GOOS $GOARCH &amp;hellip; &amp;hellip; linux 386 linux amd64 linux arm linux arm64 linux ppc64 linux ppc64le linux mips linux mipsle linux mips64 linux mips64le linux s390x &amp;hellip; &amp;hellip; 比如我的目标平台是 Linux ARM64 ，那么我只需要设置 GOOS=linux GOARCH=arm64 go build 即可。</description></item><item><title>Skopeo 初次体验</title><link>https://zdyxry.github.io/2019/10/26/Skopeo-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/</link><pubDate>Sat, 26 Oct 2019 22:52:06 +0000</pubDate><guid>https://zdyxry.github.io/2019/10/26/Skopeo-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/</guid><description>背景 链接到标题 新一代容器工具体验系列已经完成了 Podman 和 Buildah 的介绍，今天来体验下三剑客中的 Skopeo。
容器工具体验系列：
Podman 初次体验 Buildah 初次体验 Skopeo 初次体验 What 链接到标题 Skopeo 的功能很简单，一句话描述就是：提供远程仓库的镜像管理能力。
功能列表：
复制镜像，无需特殊权限即可从不通仓库复制镜像 无需拉取镜像即可获取远程镜像仓库中的镜像属性（包括 layer） 删除镜像仓库中的镜像 &amp;hellip; 支持镜像仓库类型：
container-storage 本地路径 docker registry 仓库 docker 打包镜像文件 本地 docker 拉取的镜像文件 OCI 镜像 &amp;hellip; 吐槽：Podman 和 Buildah 好歹都有自己的域名： podman.io 和 buildah.io ，Skopeo 虽然用的少但是也得搞个官网吧。。。
How 链接到标题 知道了 Skopeo 主要是对镜像仓库及镜像信息的获取，那么我们来看几个具体的例子，了解下 Skopeo 的使用。
镜像详情 链接到标题 root@yiran-workstation:~ $ skopeo inspect docker://docker.io/fedora { &amp;#34;Name&amp;#34;: &amp;#34;docker.io/library/fedora&amp;#34;, &amp;#34;Digest&amp;#34;: &amp;#34;sha256:8a91dbd4b9d283ca1edc2de5dbeef9267b68bb5dae2335ef64d2db77ddf3aa68&amp;#34;, &amp;#34;RepoTags&amp;#34;: [ &amp;#34;20&amp;#34;, &amp;#34;21&amp;#34;, &amp;#34;22&amp;#34;, &amp;#34;23&amp;#34;, &amp;#34;24&amp;#34;, &amp;#34;25&amp;#34;, &amp;#34;26-modular&amp;#34;, &amp;#34;26&amp;#34;, &amp;#34;27&amp;#34;, &amp;#34;28&amp;#34;, &amp;#34;29&amp;#34;, &amp;#34;30&amp;#34;, &amp;#34;31&amp;#34;, &amp;#34;32&amp;#34;, &amp;#34;branched&amp;#34;, &amp;#34;heisenbug&amp;#34;, &amp;#34;latest&amp;#34;, &amp;#34;modular&amp;#34;, &amp;#34;rawhide&amp;#34; ], &amp;#34;Created&amp;#34;: &amp;#34;2019-09-27T21:20:57.</description></item><item><title>记一次系统被入侵分析过程</title><link>https://zdyxry.github.io/2019/10/25/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%B3%BB%E7%BB%9F%E8%A2%AB%E5%85%A5%E4%BE%B5%E5%88%86%E6%9E%90%E8%BF%87%E7%A8%8B/</link><pubDate>Fri, 25 Oct 2019 22:33:06 +0000</pubDate><guid>https://zdyxry.github.io/2019/10/25/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%B3%BB%E7%BB%9F%E8%A2%AB%E5%85%A5%E4%BE%B5%E5%88%86%E6%9E%90%E8%BF%87%E7%A8%8B/</guid><description>背景 链接到标题 今天早上接到同事报警，环境中两个节点出现了 CPU 使用率告警，通过 top 查看发现是一个叫 iSdqkI 的进程，但是这明显不是常规进程，初步怀疑是系统被入侵了，在同事的协助下最终解决了。这次主要记录遇到这种问题的排查思路，也算是对过程的复述。
分析过程 链接到标题 首先我们得到的信息是 CPU 使用率告警，第一时间是通过 top 来看看是哪个进程在作怪：
可以看到 FnrgiY 这个进程 CPU 使用率为 556%，且这个进程不是我们系统中存在的进程，这里判断是入侵后被植入的软件，通过 ps 命令查看进程的具体执行内容：
可以看到， FnrgiY 应该是一个可执行的程序（可能是脚本，也可能是一个 binary 文件），我非常年轻的想通过 find 查看这个文件在哪，然后 kill 掉进程删除文件就好了：
嗯，果然年轻了，系统下不存在该文件，那么我们尝试在 /proc/15582 下来看看有什么线索，先看看 cmdline ，跟进程名相同，没啥信息
同样 stack 文件也没什么有用的信息
来看看这个进程的 cwd 是啥，可以看到 cwd 是 /usr/bin 路径的软链接，但是我刚刚已经检查过了，在 /usr/bin/ 下没有这个可执行文件
通过 lsof -p 命令，来看看这个进程打开了哪些文件，可以看到它启动的进程文件是 /usr/bin/e6bb0f* ，但是被删掉了，然后它还有一个 TCP 连接（先不管），看到一个存在的文件 /tmp/.X11-unix/1
来看看这个文件是啥，cat 一下发现这个文件其实是 pid 文件，并没有其他信息
既然它用到了这个文件，那么我们来看下这个文件所在路径，引用 StackExchange 里面的回答：
The X11 server (usuall Xorg these days) communicates with clients like xterm, firefox, etc via some kind of reliable stream of bytes.</description></item><item><title>Buildah 初次体验</title><link>https://zdyxry.github.io/2019/10/19/Buildah-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/</link><pubDate>Sat, 19 Oct 2019 10:15:39 +0000</pubDate><guid>https://zdyxry.github.io/2019/10/19/Buildah-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/</guid><description>背景 链接到标题 上周体验了 Podman 来管理容器的构建、生命周期管理等。Podman 自身是可以通过 Dockerfile 来进行容器镜像的构建，并且也支持容器镜像的 pull/push/login 等操作，Buildah 能够带来什么好处，我们为什么要使用它？
容器工具体验系列：
Podman 初次体验 Buildah 初次体验 Skopeo 初次体验 注意：本文章所采用环境为 CentOS7，需要除了 Buildah 工具外，还需要安装 containers-common 用于配置容器。
What 链接到标题 我们现在使用的容器管理工具无论是 Podman 还是 Docker，都是符合 OCI 规范的，他们操作的镜像也需要符合 OCI 规范，Buildah 介绍很简单： A tool that facilitates building OCI images。
Buildah 功能列表：
创建容器 通过 Dockerfile 或者一个处于运行状态的容器（指 Buildah 自身创建的容器，Podman 不可见 挂载/卸载镜像文件系统 使用更新后挂载的镜像文件系统作为文件系统层创建新的镜像 &amp;hellip; Buildah 与 Podman 的关系 链接到标题 在官方说法中，Buildah 与 Podman 是相辅相成的关系，有很多共同点：它们都不需要 root 权限；都可以通过 Dockerfile 来构建容器镜像；都采用 fork-exec 模型；都不需要守护进程等等。 Buildah 主要的优势在于可以在没有 Doclerfiles 的情况下创建容器镜像，这也造成了从 Docker 切换到 Buildah 的用户使用成本会稍微高一些，因为部分概念发生了改变，主要有以下这些对比：</description></item><item><title>Podman 初次体验</title><link>https://zdyxry.github.io/2019/10/12/Podman-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/</link><pubDate>Sat, 12 Oct 2019 21:40:30 +0000</pubDate><guid>https://zdyxry.github.io/2019/10/12/Podman-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/</guid><description>背景 链接到标题 CentOS8 在9月24号正式 Release 了，比 RHEL8 要推迟了4个月。这次的更新感觉比 CentOS7 的更新要来的重要，内核更新到了4.x，网络管理彻底替换了 network.service，防火墙管理等等，还包括去除了 Docker 作为默认的容器化管理工具，使用 Podman、Buildah、Skopeo 进行了替换，这里来体验下 Podman。
容器工具体验系列：
Podman 初次体验 Buildah 初次体验 Skopeo 初次体验 本篇文章所有环境基于 CentOS8。
Podman 链接到标题 为啥不用 Docker 了？我个人觉得 Docker 目前使用上最大的问题就是需要运行一个守护进程，虽然需要 root 用户也是一个问题，但是对于我个人来说还好。随着 K8S 定义 CRI 标准，且 Docker 的稳定性一直是个问题（虽然最近有在往好的趋势发展），但越来越多人使用 CRI-O 来替代 Docker，Docker 在被大家所抛弃（- -
Podman 创建的容器不需要守护进程，且可以用普通用户创建容器。Podman 中的大部分命令的使用方式与 Docker 相同，可以看左 alias docker=podman 。
Podman 的缺点：
仅在 Linux 下支持，无法像 Docker 一样支持 Windows 和 MacOS 缺少 docker-compose 工具替代品，哪怕有 k8s Pod 概念（虽然有 podman-compose，但是他还没有release 1.</description></item><item><title>Golang context 使用</title><link>https://zdyxry.github.io/2019/09/30/Golang-context-%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 30 Sep 2019 18:33:32 +0000</pubDate><guid>https://zdyxry.github.io/2019/09/30/Golang-context-%E4%BD%BF%E7%94%A8/</guid><description>背景 链接到标题 前段时间在写 Cluster API Provider 的时候，经常会使用 context 传递参数，当时只是按照其他项目中的方式快速的实现，并没有认真的了解 context 具体包含什么，为了解决什么问题，这次来聊一下。
P.S. 虽然写了一周的 Golang，但是对于标准库有什么还一无所知，找时间应该认真过一遍的。。
定义与使用 链接到标题 先看定义：
Package context defines the Context type, which carries deadlines, cancellation signals, and other request-scoped values across API boundaries and between processes.
当一个 goroutine 调用其他 goroutine，随着层级变多，我们想要在外层达到控制的效果 在必要场景下传递 必需 的数据 其中 Context 这个 interface 中定义了 4 个方法，具体如下：
type Context interface { Deadline() (deadline time.Time, ok bool) Done() &amp;lt;-chan struct{} Err() error Value(key interface{}) interface{} } 在 context 包中实现了4个函数，平时也都是使用这些函数：</description></item><item><title>像虚拟机一样运行容器</title><link>https://zdyxry.github.io/2019/09/19/%E5%83%8F%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%80%E6%A0%B7%E8%BF%90%E8%A1%8C%E5%AE%B9%E5%99%A8/</link><pubDate>Thu, 19 Sep 2019 19:58:57 +0000</pubDate><guid>https://zdyxry.github.io/2019/09/19/%E5%83%8F%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%80%E6%A0%B7%E8%BF%90%E8%A1%8C%E5%AE%B9%E5%99%A8/</guid><description>背景 链接到标题 平时看过文章标题比较多的都是说“像容器一样运行虚拟机”，大家都想要有虚拟机的隔离性，又想要容器的便捷性，也有一些开源项目比如 Firecracker 或 KataContainer 在做。今天反过来，来看看如何“像虚拟机一样运行容器”。
为啥要把容器搞得像虚拟机一样呢？我平时用到容器比较多的地方就是在 CI 集成部分，通过 docker 快速搭建环境，进行单元测试或集成测试，测试完成后清理镜像，简单方便。但是在CD 部分，就有一点比较头疼的问题，就是调试。zouquan 同学之前在知乎上提了一个问题：容器化环境里如何方便的进行debug和测试？，回答中的一个总结很好的描述了这个问题的关键： 虽然我在本地开发，但我的应用就像在 k8s 里一样。
那怎么在容器中开发像是在本地一样呢？肯定不能每次改了代码都走一遍 build,push,deploy 的流程，上面问题的回答中给出的是借助各种工具来达成这样的效果，我不像要用那些奇奇怪怪的工作（学不动了），那么只能想办法把容器搞的跟虚拟机一样了。
最近看到了 weaveworks/footloose 项目，这个项目的简介就是我的最原始的需求：Containers that look like Virtual Machines。先来看看这个项目的示例（开源项目中examples 写的好真是上手快）。
功能示例 链接到标题 Ansible 远程控制 链接到标题 [root@yiran ansible]# footloose config create --replicas 1 # 指定 machine 副本数为 1 [root@yiran ansible]# footloose create # 创建目标资源 INFO[0000] Creating SSH key: cluster-key ... INFO[0000] Docker Image: quay.io/footloose/centos7:0.6.1 present locally INFO[0000] Creating machine: cluster-node0 ... INFO[0001] Machine cluster-node0 is already created.</description></item><item><title>《图解密码技术》读书笔记</title><link>https://zdyxry.github.io/2019/09/14/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Sat, 14 Sep 2019 17:07:41 +0000</pubDate><guid>https://zdyxry.github.io/2019/09/14/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>背景 链接到标题 自己对于密码技术相关的知识一直都是零散的，刚接触 k8s 的时候遇到了好多证书问题都是靠临时搜索解决的，不成体系。
liqiang 同学推荐了《图解密码技术》，趁着中秋假期看完了做了读书笔记，记录一下。
密码 链接到标题 环游密码世界 链接到标题 口令：password, passcode, pin 编码：encode 密码：cryptography
对称密码是指在加密和解密时使用同一密钥的方式。
公钥密码是指在加密和解密时使用不同密钥的方式，又称为非对称加密。
将对称密码和公钥密码结合起来的密码方式称为混合密码系统。
单项散列函数，用于保证完整性：“数据时正确的而不是伪造的”，没有被篡改过。
数字签名能够保证数据不会被篡改，也防止发送者的否认。
伪随机数生成器是一种能够模拟产生随机数列的算法，同时承担着密钥生成的重要职责。
隐写术隐藏的是消息本身，而密码隐藏的是内容，应用场景：数字水印。
密码与信息安全常识：
不要使用保密的密码算法 使用低强度的密码比不进行任何加密更危险 任何密码总有一天都会被破解 密码只是信息安全的一部分 历史上的密码 链接到标题 凯撒密码，通过平移字母顺序达到加密效果，平移字母个数为密钥。 简单替换密码，通过维护字母对照表达到加密效果。
密钥空间，所有可用密钥的总数就是密钥空间的大小，空间越大，暴力破解越困难。
频率分析破译：通过分析语言中高频使用字母及单词达到破译效果。
Enigma ：通过增加通信密码的方式保证安全性。 问题：
通信密码连续输入2词并加密 通信密码是认为设定的 必须有每日密码本 对称密码 链接到标题 将显示世界中的东西映射为比特序列的操作称为编码。
XOR，异或，相同为0 ，不同为1。
比特序列的异或，将明文 A 用密钥 B 进行加密，得到密文 A XOR B，将密文 A XOR B 用密钥 B 进行解密，得到明文 A。
一次性密码本，又称为维纳没密码，通过生成随机比特序列与明文异或加密。
理论上无法破解的原因：无法判断暴力破解的结果是否是争取的明文。 无法使用的原因：
密钥的发送 密钥的保存，密钥长度与明文长度相等。 密钥的重用 密钥的同步 密钥的生成，需要真正的随机数 DES（Data Encryption Standard），可被短时间破译，不推荐使用。</description></item><item><title>Kubernetes 实战-Operator Finalizers 实现</title><link>https://zdyxry.github.io/2019/09/13/Kubernetes-%E5%AE%9E%E6%88%98-Operator-Finalizers-%E5%AE%9E%E7%8E%B0/</link><pubDate>Fri, 13 Sep 2019 20:24:41 +0000</pubDate><guid>https://zdyxry.github.io/2019/09/13/Kubernetes-%E5%AE%9E%E6%88%98-Operator-Finalizers-%E5%AE%9E%E7%8E%B0/</guid><description>背景 链接到标题 最近在写 k8s Operator，在看示例的时候看到 controller 都会设置 Finalizers，今天来聊一聊 Finalizers 和相关实现。
Finalizers 链接到标题 Finalizers 允许 Operator 控制器实现异步的 pre-delete hook。比如你给 API 类型中的每个对象都创建了对应的外部资源，你希望在 k8s 删除对应资源时同时删除关联的外部资源，那么可以通过 Finalizers 来实现。
Finalizers 是由字符串组成的列表，当 Finalizers 字段存在时，相关资源不允许被强制删除。存在 Finalizers 字段的的资源对象接收的第一个删除请求设置 metadata.deletionTimestamp 字段的值， 但不删除具体资源，在该字段设置后， finalizer 列表中的对象只能被删除，不能做其他操作。
当 metadata.deletionTimestamp 字段非空时，controller watch 对象并执行对应 finalizers 的动作，当所有动作执行完后，需要清空 finalizers ，之后 k8s 会删除真正想要删除的资源。
Operator finalizers 使用 链接到标题 介绍了 Finalizers 概念，那么我们来看看在 Operator 中如何使用，在 Operator Controller 中，最重要的逻辑就是 Reconcile 方法，finalizers 也是在 Reconcile 中实现的。要注意的是，设置了 Finalizers 会导致 k8s 的 delete 动作转为设置 metadata.</description></item><item><title>Kubernetes 实战-Leader 选举</title><link>https://zdyxry.github.io/2019/09/12/Kubernetes-%E5%AE%9E%E6%88%98-Leader-%E9%80%89%E4%B8%BE/</link><pubDate>Thu, 12 Sep 2019 22:05:22 +0000</pubDate><guid>https://zdyxry.github.io/2019/09/12/Kubernetes-%E5%AE%9E%E6%88%98-Leader-%E9%80%89%E4%B8%BE/</guid><description>背景 链接到标题 最近手头上的 Cluster-API 的项目要告一段落， Cluster-API 发布了 v0.2.1 版本 ，正式放出了 YAML 配置文件，看到了点有意思的事情，觉得需要记录一下。
K8S Leader 链接到标题 看过之前 K8S 实战系列的朋友应该记得我写过一篇 K8S 高可用部署的文章，在文章中只是讲了具体的操作步骤，没有提到 k8s 是如何保证自己多个组件之间协作的。
我们这里有一个 3 个master 节点的集群：
[root@node70 21:01:01 ~]$kubectl get node NAME STATUS ROLES AGE VERSION node70 Ready master 64d v1.15.0 node71 Ready master 64d v1.15.0 node72 Ready master 64d v1.15.0 我们都知道 k8s 核心组件，其中 apiserver 只用于接收 api 请求，不会主动进行各种动作，所以他们在每个节点都运行并且都可以接收请求，不会造成异常；kube-proxy 也是一样，只用于做端口转发，不会主动进行动作执行。
但是 scheduler, controller-manager 不同，他们参与了 Pod 的调度及具体的各种资源的管控，如果同时有多个 controller-manager 来对 Pod 资源进行调度，结果太美不敢看，那么 k8s 是如何做到正确运转的呢？</description></item><item><title>httprunner 源码阅读</title><link>https://zdyxry.github.io/2019/09/06/httprunner-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link><pubDate>Fri, 06 Sep 2019 19:50:27 +0000</pubDate><guid>https://zdyxry.github.io/2019/09/06/httprunner-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</guid><description>背景 链接到标题 最近工作上每天疲于应付各种事情，周末实在不想继续做工作相关的事情，想起一直想了解的自动化测试框架 httprunner，就阅读下。之前一直有关注作者 debugtalk 的博客，收获很多。
随着公司的发展，自己也做过很多的工作，其中就包含测试，但是自己当时大部分都是手工测试，虽然会针对其中的部分进行代码编写，但是不成体系。虽然后来就没有继续负责测试工作了，但是对于测试还是很感兴趣，平时开发过程中，最多也就是使用 unittest 或 pytest 来编写单测，这次通过阅读 httprunner 代码来感受下测试框架。
P.S. 在使用及了解 httprunner 之前，最好先了解下 unittest。
httprunner 链接到标题 HttpRunner 是一款面向 HTTP(S) 协议的通用测试框架，只需编写维护一份 YAML/JSON 脚本，即可实现自动化测试、性能测试、线上监控、持续集成等多种测试需求。
一句话总结就是 api 自动化测试，其中用到了以下的开源项目：
requests locust unittest &amp;hellip; requests 和 unittest 可以说是 python 开发者用的比较多的两个项目。locust 是一个 api 压力测试，这个我们公司也有用到。
介绍完了项目，我们来跟着官方文档了解运行流程。
执行流程 链接到标题 文档中的 快速上手 章节与章节名称很配，真心是 快速上手 ，通过一个又一个的示例来了解具体的功能使用，循序渐进，简直完美。不过又一点不好的地方是 demo 示例的代码不再 httprunner 中，而是在 docs 项目中，使用起来不是很方便，如果有 Dockerfile 来支撑，就更好了。
在 httprunner 项目中，项目的包管理是通过 poetry 进行的，比 setuptools 要清晰很多。
首先来看命令，httprunner 随着项目的演进，支持的命令行有 4个，其中 3 个是重复的，1个是压力测试：</description></item><item><title>Linux 下常用故障模拟方法</title><link>https://zdyxry.github.io/2019/08/31/Linux-%E4%B8%8B%E5%B8%B8%E7%94%A8%E6%95%85%E9%9A%9C%E6%A8%A1%E6%8B%9F%E6%96%B9%E6%B3%95/</link><pubDate>Sat, 31 Aug 2019 07:47:00 +0000</pubDate><guid>https://zdyxry.github.io/2019/08/31/Linux-%E4%B8%8B%E5%B8%B8%E7%94%A8%E6%95%85%E9%9A%9C%E6%A8%A1%E6%8B%9F%E6%96%B9%E6%B3%95/</guid><description>背景 链接到标题 在日常开发时，有时候需要保证自己代码的健壮性，需要模拟各种故障测试，比如：磁盘、网络、端口等，今天来汇总一下平时使用最多的几种故障模拟方法
磁盘 链接到标题 插入拔出 链接到标题 服务器的存储控制器如果是直通模式，那么在 OS 中能够直接获取到磁盘插入与拔出事件，有时候我们需要检测到相应的事件来自动化的做某些动作，具体的实现方式见之前的文章 Linux 下磁盘设备自动发现方式 。
那么我们写完了代码想要测试，不想去机房物理操作，怎么模拟呢？
Hypervisor 链接到标题 如果你的代码部署的机器是一台虚拟机，那么在 Hypervisor 层面一般都会有对应的接口来完成相应的操作。
比如 Vsphere ESXi 中可以直接编辑虚拟机，在磁盘选项中有一个“移除”按钮，可以直接移除磁盘：
再比如 KVM 下，可以通过 Libvirt 接口来 detach 磁盘。
当然对于插入动作，Hypervisor 也会提供对应的功能。
物理服务器 链接到标题 如果 OS 不是在 Hypervisor 上，而是直接安装在了物理服务器上，我们怎么做呢？
通常我们服务器上的磁盘都是 SCSI 设备，会实现完整的 SCSI（接口），可以通过修改相应设备的标置文件来达到目的。
示例： 节点存在设备 /dev/sda ，修改标置文件，在系统中会发现磁盘已经被移除了。
[root@yiran ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 10G 0 disk sr0 11:0 1 4.3G 0 rom /run/media/root/CentOS 7 x86_64 vda 252:0 0 100G 0 disk ├─vda1 252:1 0 1G 0 part /boot └─vda2 252:2 0 99G 0 part ├─centos-root 253:0 0 50G 0 lvm / ├─centos-swap 253:1 0 3.</description></item><item><title>Kubernetes 实战-Cluster API v1alpha2</title><link>https://zdyxry.github.io/2019/08/23/Kubernetes-%E5%AE%9E%E6%88%98-Cluster-API-v1alpha2/</link><pubDate>Fri, 23 Aug 2019 20:13:50 +0000</pubDate><guid>https://zdyxry.github.io/2019/08/23/Kubernetes-%E5%AE%9E%E6%88%98-Cluster-API-v1alpha2/</guid><description>背景 链接到标题 今天继续来聊一聊 cluster-api，在上周看 cluster-api-provider-vsphere 代码的时候吐槽过，cluster-api 最近因为 v1alpha2 版本的开发，变化太快，几乎每天都在变，那么我们就来看看 v1alpha2 具体做了什么。
Cluster-API v1alpha2 链接到标题 虽然目前 v1alpha2 还没有正式的 release，但是已经趋于稳定，且两个主要的 provider：aws 和 vsphere 都在进行 v1alpha2 版本的适配（最近每天都有 pr 更新）。我们先来了解下为啥要进行 v1alpha2 改动，改动的目的是啥。
在 v1alpha1 版本中，cluster-api 要求 provider 实现从节点置备到 k8s 部署的全套流程，cluster-api 自身只负责具体的 API 定义及相关控制，在 provider 实现上也不是一个标准的 Operator，（至少）我从概念的理解上比较吃力，每个 provider 需要实现对应 cluster 与 machine 的 actuator ，开发起来要求对 cluster-api 项目本身很熟悉。
其次，每个 provider 都包含了 k8s 集群部署的流程，虽然大部分实现最终都是使用 kubeadm 工具，但是使用方式千差万别，有 cloud-init、有 ssh 配合密钥、有 ssh 配合密码等等。这部分 provider 中的代码完全都是重复的，可以复用的。
上面提到的一些缺点，在 v1alpha2 版本中进行了改进，对各个组件进行了拆分，现在使用 cluster-api 需要 3 个控制器：</description></item><item><title>provider vs provisioner</title><link>https://zdyxry.github.io/2019/08/17/provider-vs-provisioner/</link><pubDate>Sat, 17 Aug 2019 21:08:46 +0000</pubDate><guid>https://zdyxry.github.io/2019/08/17/provider-vs-provisioner/</guid><description>背景 链接到标题 之前 liqiang 同学写了一篇博客：Status 还是 State 用于总结日常工作中遇到的相似词的区别。这两天看代码，经常能够看到两个词：provider 和 provisioner，作为一个英语渣渣，很难准确的理解两个词的区别。
字典解释 链接到标题 provider 字典中的解释为：
供应者（商） 提供者（商） 供养人 &amp;hellip; provisioner 字典中的解释为：
粮食供应者 看上去从字面上也是一个意思，那么我们来找个实际场景看看。
实际场景 链接到标题 Terraform 链接到标题 在 Terraform 概念中，同时存在 provider 和 provisioner 两个概念：
A provider is responsible for understanding API interactions and exposing resources. Providers generally are an IaaS (e.g. AWS, GCP, Microsoft Azure, OpenStack), PaaS (e.g. Heroku), or SaaS services (e.g. Terraform Cloud, DNSimple, CloudFlare). Provisioners are used to execute scripts on a local or remote machine as part of resource creation or destruction.</description></item><item><title>cluster-api-provider-vsphere 源码阅读</title><link>https://zdyxry.github.io/2019/08/16/cluster-api-provider-vsphere-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link><pubDate>Fri, 16 Aug 2019 20:57:25 +0000</pubDate><guid>https://zdyxry.github.io/2019/08/16/cluster-api-provider-vsphere-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</guid><description>背景 链接到标题 上一篇博客讲了 Cluster-API 的相关概念，现在我们来找一个 provider 实现看看具体里面做了啥，因为对 vmware 产品中的概念比较熟悉，就找了 cluster-api-provider-vsphere 。
以下内容均对应 clusterapi v1alpha1 版本。
clusterctl 命令 链接到标题 cluster-api provider 提供了命令行 clusterctl 用于给我们快速创建 bootstrap 集群用于创建目标 k8s 集群，我们来执行一下看看具体做了哪些工作：
root@yiran-workstation:~/go/src/github.com/kubernetes-sigs/cluster-api-provider-vsphere master ✗ $ clusterctl create cluster \ --provider vsphere \ --bootstrap-type kind \ --cluster ./out/management-cluster/cluster.yaml \ --machines ./out/management-cluster/machines.yaml \ --provider-components ./out/management-cluster/provider-components.yaml \ --addon-components ./out/management-cluster/addons.yaml \ --kubeconfig-out ./out/management-cluster/kubeconfig I0816 17:28:05.815156 14562 createbootstrapcluster.go:27] Preparing bootstrap cluster I0816 17:29:15.292547 14562 clusterdeployer.go:78] Applying Cluster API stack to bootstrap cluster I0816 17:29:15.</description></item><item><title>Kubernetes 实战-Cluster API</title><link>https://zdyxry.github.io/2019/08/09/Kubernetes-%E5%AE%9E%E6%88%98-Cluster-API/</link><pubDate>Fri, 09 Aug 2019 19:41:49 +0000</pubDate><guid>https://zdyxry.github.io/2019/08/09/Kubernetes-%E5%AE%9E%E6%88%98-Cluster-API/</guid><description>背景 链接到标题 在当前 Kubernetes 生态中，生命周期管理相关工具官方的有 kubeadm、kubespray（部署集群部分通过 kubeadm） ，开源社区还有很多其他的实现，我们可以通过这类工具来实现 k8s 集群的部署，升级，增删节点，但是使用一个工具的前提是：基础设施已经准备完成。只有当基础设施准备完成后，kubeadm 之类工具才可以正常工作。
当我们在部署 Kubernetes 集群时，节点可能在任何环境上，比如 AWS、OpenStack、Vsphere、Azure 等，那么想要自动化配置基础设施，通常我们根据自己的环境不同，编写不通的代码来支持我们的虚拟化（or 服务器）场景。
基础设施包括不限于：
OS 安装 Load Balance 配置 网络配置 IP 分配 … Cluster-API 链接到标题 Kubernetes 社区针对基础设施问题，发起了一个项目：cluster-api，目前处于 alpha1 版本，项目目标：
使用声明式API管理 Kubernetes 集群的生命周期 支持多种环境，私有云或公有云 使用社区中现有的工具完成相应功能 … 功能简述 链接到标题 无需创建额外基础设施前提下创建 bootstrap cluster 通过 bootstrap cluster 创建目标 k8s 集群 工作流程 链接到标题 cluster-api 使用声明式 API 管理 k8s 集群，需要环境中先存在一个 k8s 集群，通常成为 bootstrap cluster，若不存在，也可通过提供的命令行工具 clusterctl 创建 bootstrap cluster 在 bootstrap cluster 中，部署 CRD 及相应的 cluster api 控制器及 provider 控制器 在 bootstrap cluster 中，开始创建我们真正想要创建的资源：k8s 集群 创建资源类型为 Cluster、Machine 或 MachineDeployment ，对应的控制器会自动为我们创建好虚拟机 在虚拟机创建完成后，通过 kubeadm 创建 k8s 集群 具体实现 链接到标题 虚拟机创建 链接到标题 目前看到的几个 Cluster-API Provider 项目实现，虚拟机均通过克隆的方式创建出来的。</description></item><item><title>代码统计工具 cloc 基本使用</title><link>https://zdyxry.github.io/2019/08/09/%E4%BB%A3%E7%A0%81%E7%BB%9F%E8%AE%A1%E5%B7%A5%E5%85%B7-cloc-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</link><pubDate>Fri, 09 Aug 2019 19:35:14 +0000</pubDate><guid>https://zdyxry.github.io/2019/08/09/%E4%BB%A3%E7%A0%81%E7%BB%9F%E8%AE%A1%E5%B7%A5%E5%85%B7-cloc-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</guid><description>背景 链接到标题 在看一个新项目的时候，通常我都会了解下这个项目的代码量，然后心里给个预期，大概需要多久了解这个项目。
2023/01/11 更新：现在已切换至 loc/tokei ，速度快了许多。
wc 链接到标题 在以前，我一般都是使用 find 配合 wc 来完成，比如：
root@yiran-workstation:/tmp/cloc $ find . -name &amp;#34;*.go&amp;#34; | xargs wc -l {} 81 ./installer.go 81 total 显示有一个 installer.go 的文件，一共有 81行。但是这里有个问题，就是 wc 是不会统计代码里面的具体内容的，比如注释、空白行等。
这时候我们就需要一个更高级的工具了： cloc
cloc 链接到标题 cloc 是一个 Perl 语言实现的项目，用途就像它的名字全称：Count Lines of Code。
使用方法的话最简单的直接加上项目路径：
root@yiran-workstation:~/go/src/github.com/kubermatic/kubeone master ✗ $ pwd /root/go/src/github.com/kubermatic/kubeone root@yiran-workstation:~/go/src/github.com/kubermatic/kubeone master ✗ $ cloc . 292 text files. 274 unique files. 78 files ignored. github.com/AlDanial/cloc v 1.</description></item><item><title>Linux 下磁盘设备自动发现方式</title><link>https://zdyxry.github.io/2019/08/02/Linux-%E4%B8%8B%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0%E6%96%B9%E5%BC%8F/</link><pubDate>Fri, 02 Aug 2019 23:10:04 +0000</pubDate><guid>https://zdyxry.github.io/2019/08/02/Linux-%E4%B8%8B%E7%A3%81%E7%9B%98%E8%AE%BE%E5%A4%87%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0%E6%96%B9%E5%BC%8F/</guid><description>背景 链接到标题 如果在 PC 上安装过 Linux，那么通常会遇到过硬件设备无法发现的问题，这类问题最终都可以通过 google 来解决掉。那么当我们在服务器场景下，如何做到设备自动发现且在设备发现后执行某些动作呢？
最近看了几个关于存储系统的 Operator 部分实现，记录一下。
命令行 链接到标题 最简单的肯定是我们写一个循环，永远检测我们要发现的设备，比如 lsblk 可以列举当前服务器所有 block 设备，那么我们就在循环内部执行 lsblk，diff 每次执行的结果，如果有新的设备，那么执行某些操作。
lsblk 是通过读取 /sys/block 下的具体目录判断的，那么我么也可以直接读取该路径下的目录来实现。
如果是网络设备也是一样，我们可以在循环内部执行 ip link list 来获取所有网络设备。
UDEV 链接到标题 照常先引用维基百科的解释：
udev 是Linux kernel 2.6系列的设备管理器。它主要的功能是管理/dev目錄底下的设备节点。它同时也是用来接替devfs及hotplug的功能，这意味着它要在添加/删除硬件时处理/dev目录以及所有用户空间的行为，包括加载firmware时。
如果你的 OS 是通过 systemd 来管理所有进程的话，那么可以发现一个服务叫做 systemd-udevd ，这个是 udev 的守护进程:
[root@node90 19:58:10 ~]$systemctl status systemd-udevd ● systemd-udevd.service - udev Kernel Device Manager Loaded: loaded (/usr/lib/systemd/system/systemd-udevd.service; static; vendor preset: disabled) Active: active (running) since Fri 2019-06-14 15:25:55 CST; 1 months 18 days ago Docs: man:systemd-udevd.</description></item><item><title>Kubernetes 实战-平滑移除节点</title><link>https://zdyxry.github.io/2019/08/01/Kubernetes-%E5%AE%9E%E6%88%98-%E5%B9%B3%E6%BB%91%E7%A7%BB%E9%99%A4%E8%8A%82%E7%82%B9/</link><pubDate>Thu, 01 Aug 2019 23:07:29 +0000</pubDate><guid>https://zdyxry.github.io/2019/08/01/Kubernetes-%E5%AE%9E%E6%88%98-%E5%B9%B3%E6%BB%91%E7%A7%BB%E9%99%A4%E8%8A%82%E7%82%B9/</guid><description> 背景 链接到标题 自己玩 K8S 以来，搭建的环境没有10几套，也有5，6套了，当环境测试完成后，基本上直接删除掉了，也没有想着一直维护，最近在维护一个集群的时候，想要删除一个节点，发现自己一直不知道如何删除节点，特此记录。
平滑移除 链接到标题 获取节点列表 链接到标题 kubectl get node 设置不可调度 链接到标题 由于节点目前处于正常工作状态，集群中新建资源还是有可能创建到该节点的，所以先将节点设置为不可调度：
kubectl cordon $node_name 将节点上资源调度到其他节点 链接到标题 目前集群已经不会分配新的资源在该节点上了，但是节点还运行着现有的业务，所以我们需要将节点上的业务分配到其他节点：
kubectl drain $node_name 注意：DaemonSet Pod 和 Static Pod 是不会在集群中其他节点重建的。
移除节点 链接到标题 当前集群中已经没有任何资源分配在节点上了，那么我们可以直接移除节点：
kubectl delete $node_name 至此，我们平滑移除了一个 k8s 节点。如果移除的是一个 master 节点，那么记得之后还要添加一个新的 master 节点到集群中，避免集群可靠性降低。
参考链接 链接到标题 https://stackoverflow.com/questions/35757620/how-to-gracefully-remove-a-node-from-kubernetes</description></item><item><title>Heap In Python &amp; Golang</title><link>https://zdyxry.github.io/2019/07/28/Heap-In-Python-Golang/</link><pubDate>Sun, 28 Jul 2019 12:11:45 +0000</pubDate><guid>https://zdyxry.github.io/2019/07/28/Heap-In-Python-Golang/</guid><description>背景 链接到标题 最近使用到了 heap 这个数据结构，记录一下在 Python 和 Golang 中最基本的使用方法～
堆（英语：Heap）是计算机科学中的一種特別的樹狀数据结构。若是滿足以下特性，即可稱為堆積：「給定堆積中任意節點P和C，若P是C的母節點，那麼P的值會小於等於（或大於等於）C的值」。若母節點的值恆小於等於子節點的值，此堆積稱為最小堆積（min heap）；反之，若母節點的值恆大於等於子節點的值，此堆積稱為最大堆積（max heap）。在堆積中最頂端的那一個節點，稱作根節點（root node），根節點本身沒有母節點（parent node）。
Python 链接到标题 create 链接到标题 In [1]: import heapq In [2]: a = [1,3,2,5,4] In [3]: heapq.heapify(a) In [4]: a Out[4]: [1, 3, 2, 5, 4] In [5]: b = [] In [6]: heapq.heappu heapq.heappush heapq.heappushpop In [6]: heapq.heappush(b, 1) In [7]: heapq.heappush(b, 3) In [8]: heapq.heappush(b, 2) In [9]: heapq.heappush(b, 5) In [10]: heapq.heappush(b, 4) In [11]: b Out[11]: [1, 3, 2, 5, 4] read 链接到标题 In [28]: b Out[28]: [1, 3, 2, 5, 4] In [29]: heapq.</description></item><item><title>CentOS定制-软件源错误</title><link>https://zdyxry.github.io/2019/07/21/CentOS%E5%AE%9A%E5%88%B6-%E8%BD%AF%E4%BB%B6%E6%BA%90%E9%94%99%E8%AF%AF/</link><pubDate>Sun, 21 Jul 2019 19:58:43 +0000</pubDate><guid>https://zdyxry.github.io/2019/07/21/CentOS%E5%AE%9A%E5%88%B6-%E8%BD%AF%E4%BB%B6%E6%BA%90%E9%94%99%E8%AF%AF/</guid><description>背景 链接到标题 我一直在维护一个公司内部的 OS 发行版，是基于 CentOS 的，最近接到了一个需求，是需要更新 Kernel 及一些软件包，但是遇到了无法安装 OS 的问题，记录一下解决方式。
定制 OS 链接到标题 关于定制 OS，在之前的博客中已经提到过几次了，CentOS 是比较容易改动的一个发行版，因为有着 RHEL 红（爸）帽（爸），有着完善的文档可以参考。
主要需要注意的是两点：
分区方式 软件包选择 今天遇到的问题是第二点。
先说下前提，由于是 2B 产品，所以对于每次的 BaseOS 版本升级都非常谨慎，每次 BaseOS 版本都会进行各种测试。但是如果仅仅是升级部分所需要的软件包，就不用这么麻烦了，我们可以定制自己所需要的软件组（group），来进行安装/升级。
问题 链接到标题 这次接到的需要是升级 Kernel、libiscsi、qemu 三个软件，后两个是虚拟化相关的，相关依赖较少；kernel 是跟 BaseOS 版本关联性很大的。
比如 CentOS 7.6 中，kernel 版本为：kernel-3.10.0-957.el7.x86_64.rpm，这个版本对 selinux 等相关软件是有依赖要求的，我在这里翻车了。
解决 链接到标题 像往常一样，将对应的 rpm 放置到了对应的 yum 源中，更新 yum 源，制作 ISO，在安装过程中报错：
报错显示是软件源出了问题，但是没有更多的信息了，这时候我们可以通过 console 连接到其他的 pty 中，查看对应的日志，比如 CentOS 默认的日志在： /tmp/packaging.log 中：
我们可以看到日志中提示 kernel 与当前软件源中的 selinux-policy-targeted 冲突，因为安装 OS 所用的软件源就是 ISO ，所以这里肯定是我们打包 ISO 时遗漏了依赖关系导致的，我们将对应的 Kernel 所需依赖更新，重新构建 ISO 就可以了。</description></item><item><title>Kubernetes 实战-踩坑记录（持续更新）</title><link>https://zdyxry.github.io/2019/07/13/Kubernetes-%E5%AE%9E%E6%88%98-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/</link><pubDate>Sat, 13 Jul 2019 09:34:45 +0000</pubDate><guid>https://zdyxry.github.io/2019/07/13/Kubernetes-%E5%AE%9E%E6%88%98-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/</guid><description>背景 链接到标题 在对现有服务进行容器话改造的过程中，随着对 K8S 使用程度越来越深，也渐渐的遇到了一些坑，所以开一篇博客，记录自己所遇到的坑，应该会长期更新。
更新记录 链接到标题 2019.07.13 02:00 来自加班中的 yiran 2019.07.19 06:52 早起不想去公司的 yiran coredns 无法解析域名 链接到标题 在 Kubernetes 环境中，使用 kubeadm 工具部署的集群，会自动部署 coredns 作为集群的域名服务，每当我们创建了自己的 service，都可以通过域名直接访问，不用再考虑自己多个 Pod 的 IP 不同如何连接的问题。
最近遇到多个环境出现无法解析域名的问题，具体现象如下：
集群部署完成后，部署 daemonset 资源，每个节点均运行一个 busybox； 在 busybox 中对 kubernetes 默认域名进行解析，查看解析结果。 正常情况应该是所有的 busybox 都可以正常解析才对，但是最近几个环境中均出现了 3 个node 中1个node 上的 pod 无法解析的问题，示例代码如下：
daemonset.yaml
apiVersion: &amp;#34;extensions/v1beta1&amp;#34; kind: &amp;#34;DaemonSet&amp;#34; metadata: name: &amp;#34;ds&amp;#34; namespace: &amp;#34;default&amp;#34; spec: template: metadata: labels: app: ds spec: tolerations: - key: node-role.</description></item><item><title>关于Ansible的一点经验</title><link>https://zdyxry.github.io/2019/07/05/%E5%85%B3%E4%BA%8EAnsible%E7%9A%84%E4%B8%80%E7%82%B9%E7%BB%8F%E9%AA%8C/</link><pubDate>Fri, 05 Jul 2019 20:55:19 +0000</pubDate><guid>https://zdyxry.github.io/2019/07/05/%E5%85%B3%E4%BA%8EAnsible%E7%9A%84%E4%B8%80%E7%82%B9%E7%BB%8F%E9%AA%8C/</guid><description>背景 链接到标题 先介绍下 Kubespray，Kubespray 是 K8S SIG 下的项目，目标是帮助用户创建 生产环境级别 的 k8s 集群。
是通过 Ansible Playbook 实现的，是的，这又是一个 Ansible 项目，其中 YAML 文件就有 15k 行，名副其实的大项目。
花费了几天时间陆陆续续看完了整个项目，大概了解了其中的工作流程，具体内容不提，感觉 Ansible 90% 的使用例子都可以在这个项目中找到，是一个值得阅读的项目。
之前写过一篇当时理解的最佳实践，今天趁此机会再总结下最近使用 Ansible 的一些经验。
Tag 链接到标题 使用 tag 对 ansible task 进行划分，比如在重启某些服务的时候，我们只希望在初次安装的时候重启，在后续升级的时候不进行重启，那么我们就可以对这个重启服务的 task 进行tag 区分。
tag 使用示例如下：
[root@node111 16:35:56 ansible]$tree . . ├── ansible.cfg ├── inventory ├── templates │ └── src.j2 └── test.yaml 1 directory, 4 files [root@node111 16:35:58 ansible]$cat test.yaml - hosts: cluster gather_facts: no become: yes become_user: root become_method: sudo tasks: - yum: name: &amp;#34;{{ item }}&amp;#34; state: present loop: - httpd - memcached tags: - packages - template: src: templates/src.</description></item><item><title>Kubernetes 实战-Pod 可用性</title><link>https://zdyxry.github.io/2019/06/26/Kubernetes-%E5%AE%9E%E6%88%98-Pod-%E5%8F%AF%E7%94%A8%E6%80%A7/</link><pubDate>Wed, 26 Jun 2019 21:57:31 +0000</pubDate><guid>https://zdyxry.github.io/2019/06/26/Kubernetes-%E5%AE%9E%E6%88%98-Pod-%E5%8F%AF%E7%94%A8%E6%80%A7/</guid><description>背景 链接到标题 Kubernetes 作为一个容器编排系统，负责 Pod 生命周期管理，那么肯定会保证 Pod 的可用性，今天来说下 k8s Pod 可用性相关知识。
K8S 可用性相关参数 链接到标题 k8s 核心组件有 kubelet,kube-apiserver,kube-scheduler,kube-controller-manager，通过阅读官方文档中相关参数说明，我摘取了认为跟可用性相关的参数，具体列表如下：
kubelet 链接到标题 &amp;ndash;housekeeping-interval duration 链接到标题 Default: 10s
Interval between container housekeepings.
kubelet 主动检测容器资源是否达到阈值的周期。
&amp;ndash;node-status-update-frequency duration 链接到标题 Default: 10s
Specifies how often kubelet posts node status to master. Note: be cautious when changing the constant, it must work with nodeMonitorGracePeriod in nodecontroller.
kubelet 上报到 kube-apiserver 频率。
kube-controller-manager 链接到标题 &amp;ndash;node-eviction-rate float32 链接到标题 Default: 0.1</description></item><item><title>Kubernetes 实战-Helm 包管理器</title><link>https://zdyxry.github.io/2019/06/21/Kubernetes-%E5%AE%9E%E6%88%98-Helm-%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8/</link><pubDate>Fri, 21 Jun 2019 20:40:24 +0000</pubDate><guid>https://zdyxry.github.io/2019/06/21/Kubernetes-%E5%AE%9E%E6%88%98-Helm-%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8/</guid><description>简介 链接到标题 Helm 就是k8s 的包管理器 。常见的包管理器有：yum,apt,pip&amp;hellip;
包管理器基础功能有：
安装 依赖安装 升级 回滚 卸载 源管理 搜索 &amp;hellip; 基本概念 链接到标题 Helm: Kubernetes的包管理工具，命令行同名
Tiller: Helmv2 的服务端，用于接收并处理 Helm 发送的请求，默认以 Deployment 形式部署在 k8s 集群中
Chart: Helm 包管理的基础单元，等同于 RPM
Repoistory: Helm的软件源仓库，是一个 Web 服务器，路径下除了响应的软件 Chart 包之外，维护了一个 index.yaml 用于索引
Release: Helm 安装在 Kubernetes 集群中的 Chart 实例
现状 链接到标题 helm 截至06月20日最新稳定版本为 v2.14.1。
在05月16日发布了 v3.0 alpha 版本，根据相关文档描述，v2 无法平滑升级到 v3 版本。
注：存在部分小版本无法平滑升级情况。
helm v3 版本改进：
在 v2 版本设计中，需要单独创建属于 Tiller 的 ServiceAccount，授权 clusteradmin 权限，以为着只要你有 helm 权限，那么你有操作 k8s全集群所有权限。在 v3 版本中删除 Tiller，直接与 k8s api 进行通信，权限管理更清晰 helm 提供 libary 模板引擎切换为 Lua 目前通过 Hook 方式创建的资源，helm 后续不会管理，在 v3 会增加管理 Hook 资源功能 目前所有配置保存在 cm 中，后续考虑保存到 secret v2 需要单独维护仓库，v3 中可以将 Chart 推送到 Docker 镜像仓库中，提供 helm push/login 功能 &amp;hellip; Helm2 基本使用 链接到标题 安装 链接到标题 在 Helm Github Release 下载最新版本二进制文件，并在本地解压。</description></item><item><title>调整 arp 参数提高网络稳定性</title><link>https://zdyxry.github.io/2019/06/17/%E8%B0%83%E6%95%B4-arp-%E5%8F%82%E6%95%B0%E6%8F%90%E9%AB%98%E7%BD%91%E7%BB%9C%E7%A8%B3%E5%AE%9A%E6%80%A7/</link><pubDate>Mon, 17 Jun 2019 21:20:04 +0000</pubDate><guid>https://zdyxry.github.io/2019/06/17/%E8%B0%83%E6%95%B4-arp-%E5%8F%82%E6%95%B0%E6%8F%90%E9%AB%98%E7%BD%91%E7%BB%9C%E7%A8%B3%E5%AE%9A%E6%80%A7/</guid><description>背景 链接到标题 最近发现一直使用的机房网络不稳定，时常出现网络无法联通，过一会又可以联通的情况，今天又遇到了，要彻底解决它。
问题 链接到标题 在机房网络规划中，地区 A 和地区 B 是通过 OpenVPN 连接的，也就是说每个地区的网关是一台虚拟机，提供 DHCP 服务。 今天地区 A 的机器又无法连接地区 B 了，我登陆网关尝试从网关 ping 目标主机，发现直接提示 :
No buffer space available 根据这个提示，感觉像是某些系统参数配置的小了，于是查了一下，发现跟 arp 有关。什么是 arp ？
相信对网络稍微有些概念的同学都不陌生，这里我直接引用维基百科：
地址解析协议（英语：Address Resolution Protocol，缩写：ARP）。在以太网协议中规定，同一局域网中的一台主机要和另一台主机进行直接通信，必须要知道目标主机的MAC地址。而在TCP/IP协议中，网络层和传输层只关心目标主机的IP地址。这就导致在以太网中使用IP协议时，数据链路层的以太网协议接到上层IP协议提供的数据中，只包含目的主机的IP地址。于是需要一种方法，根据目的主机的IP地址，获得其MAC地址。这就是ARP协议要做的事情。所谓地址解析（address resolution）就是主机在发送帧前将目标IP地址转换成目标MAC地址的过程。
另外，当发送主机和目的主机不在同一个局域网中时，即便知道对方的MAC地址，两者也不能直接通信，必须经过路由转发才可以。所以此时，发送主机通过ARP协议获得的将不是目的主机的真实MAC地址，而是一台可以通往局域网外的路由器的MAC地址。于是此后发送主机发往目的主机的所有帧，都将发往该路由器，通过它向外发送。这种情况称为委托ARP或ARP代理（ARP Proxy）。
解决 链接到标题 知道了原因，那么我们来调整参数就好：
gc_thresh1 (since Linux 2.2) The minimum number of entries to keep in the ARP cache. The garbage collector will not run if there are fewer than this number of entries in the cache.</description></item><item><title>Kubernetes 实战-高可用集群部署</title><link>https://zdyxry.github.io/2019/06/15/Kubernetes-%E5%AE%9E%E6%88%98-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</link><pubDate>Sat, 15 Jun 2019 01:44:28 +0000</pubDate><guid>https://zdyxry.github.io/2019/06/15/Kubernetes-%E5%AE%9E%E6%88%98-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</guid><description>准备工作 链接到标题 本文所有节点 OS 均为 CentOS 7.4 。
1.关闭 selinux 链接到标题 所有节点执行：
[root@node211 ~]# cat /etc/selinux/config # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled # SELINUXTYPE= can take one of three two values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy.</description></item><item><title>如何查看磁盘扇区大小</title><link>https://zdyxry.github.io/2019/06/05/%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E7%A3%81%E7%9B%98%E6%89%87%E5%8C%BA%E5%A4%A7%E5%B0%8F/</link><pubDate>Wed, 05 Jun 2019 20:45:06 +0000</pubDate><guid>https://zdyxry.github.io/2019/06/05/%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E7%A3%81%E7%9B%98%E6%89%87%E5%8C%BA%E5%A4%A7%E5%B0%8F/</guid><description>磁盘扇区 链接到标题 引用维基百科：
In computer disk storage, a sector is a subdivision of a track on a magnetic disk or optical disc. Each sector stores a fixed amount of user-accessible data, traditionally 512 bytes for hard disk drives (HDDs) and 2048 bytes for CD-ROMs and DVD-ROMs. Newer HDDs use 4096-byte (4 KiB) sectors, which are known as the Advanced Format (AF).
扇区大小常见的可以分为 512 bytes, 2048 bytes 和 4096 bytes。</description></item><item><title>Kubernetes 实战-集群部署</title><link>https://zdyxry.github.io/2019/05/31/Kubernetes-%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</link><pubDate>Fri, 31 May 2019 21:22:51 +0000</pubDate><guid>https://zdyxry.github.io/2019/05/31/Kubernetes-%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</guid><description>背景 链接到标题 本来计划这周写一下如何定制 UEFI Linux 发行版的，但是计划赶不上变化，加上 UEFI 的改动比想象中的多，这周还是继续 k8s 系列好了。
说起来 k8s 写了 3 篇博客一直没有写集群部署相关的，一是当时对 k8s 了解不多，集群搭建大多是 GitHub 上的开源项目或 Rancher 快速搭建起来的；二是 k8s 官方工具 kubeadm 现在还有很多的不确定性，随着 v1.14 版本的发布，可用性大大提高，虽然还不支持 HA，但是要写一下了。
本文并不会介绍具体的部署步骤，望周知。
Kubernetes 主要组件 链接到标题 因为主要说集群部署相关的，因此只列出 Master 和 Node 的主要组件，k8s 内部资源不再罗列：
Master 链接到标题 apiserver： 集群中所有其他组件通过 apiserver 进行交互
scheduler： 按照 Pod 配置来对 Pod 进行节点调度
controller-manager：负责节点管理，资源的具体创建动作， desired state management 具体实行者
etcd：用于存储集群中数据的键值存储
Node 链接到标题 kubelet：处理 master 及其上运行的 node 之间的所有通信。它与容器运行时配合，负责部署和监控容器
kube-proxy：负责维护 node 的网络规则，还负责处理 Pod,Node和外部之间的通信
容器运行时：在节点上运行容器的具体实现，常见的有 Docker/rkt/CRI-O</description></item><item><title>BIOS vs UEFI</title><link>https://zdyxry.github.io/2019/05/26/BIOS-vs-UEFI/</link><pubDate>Sun, 26 May 2019 08:46:23 +0000</pubDate><guid>https://zdyxry.github.io/2019/05/26/BIOS-vs-UEFI/</guid><description>背景 链接到标题 大家应该都安装过操作系统，PC 或者服务器上。那么我们在安装操作系统时通常需要进入到 BIOS 或 UEFI 界面去安装。之前维护的一个 ISO 版本只支持 BIOS，最近有了支持 UEFI 安装的需求，今天来了解一下其中的差异，之后尝试编写一个支持 UEFI 的 KickStart 配置。
Legacy BIOS 链接到标题 按照惯例，引用维基百科中（不同语言对于名词解释信息可能是完全不同的，最好直接看英文）的解释：
BIOS (/ˈbaɪɒs/ BY-oss; an acronym for Basic Input/Output System and also known as the System BIOS, ROM BIOS or PC BIOS) is non-volatile firmware used to perform hardware initialization during the booting process (power-on startup), and to provide runtime services for operating systems and programs.[1] The BIOS firmware comes pre-installed on a personal computer&amp;rsquo;s system board, and it is the first software to run when powered on.</description></item><item><title>Kubernetes 实战-镜像管理</title><link>https://zdyxry.github.io/2019/05/24/Kubernetes-%E5%AE%9E%E6%88%98-%E9%95%9C%E5%83%8F%E7%AE%A1%E7%90%86/</link><pubDate>Fri, 24 May 2019 07:35:08 +0000</pubDate><guid>https://zdyxry.github.io/2019/05/24/Kubernetes-%E5%AE%9E%E6%88%98-%E9%95%9C%E5%83%8F%E7%AE%A1%E7%90%86/</guid><description>镜像组织形式 链接到标题 镜像默认采用 OverlayFS 方式挂载，最终效果是将多个目录结构合并为一个。
其中 lowerdir 为只读路径，最右层级最深。最终容器运行时会将 lowerdir 和 upperdir 合并挂在为 merged，对应容器中的路径为 / 。 举例： 镜像 testadd:0.5 版本的层级挂载如下：
[root@node111 16:02:24 overlay2]$docker inspect testadd:0.5 |grep Dir &amp;#34;WorkingDir&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;WorkingDir&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;LowerDir&amp;#34;: &amp;#34;/var/lib/docker/overlay2/693c140b9c70744a7a6ce93de56d3ac7549dae84195cbfac3486062d1ceaccf1/diff&amp;#34;, &amp;#34;MergedDir&amp;#34;: &amp;#34;/var/lib/docker/overlay2/e2f2ad8332a9567ad28495b28342b5f5712218e235b0129435abfc3c781be957/merged&amp;#34;, &amp;#34;UpperDir&amp;#34;: &amp;#34;/var/lib/docker/overlay2/e2f2ad8332a9567ad28495b28342b5f5712218e235b0129435abfc3c781be957/diff&amp;#34;, &amp;#34;WorkDir&amp;#34;: &amp;#34;/var/lib/docker/overlay2/e2f2ad8332a9567ad28495b28342b5f5712218e235b0129435abfc3c781be957/work&amp;#34; 运行该容器后，可以看到多了一个 overlay 方式挂载的路径：
[root@node111 16:05:53 overlay2]$mount |grep overlay /dev/md127 on /var/lib/docker/overlay2 type ext4 (rw,relatime,data=ordered) overlay on /var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/merged type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/3NA23BH5OMSSXWTHGPRS6YENB7:/var/lib/docker/overlay2/l/QQVS7UVPGRBVHRZOBDPMMO4EQM:/var/lib/docker/overlay2/l/E7HTYBVD5SXSZRLVTETODOIANT,upperdir=/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/diff,workdir=/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/work) 查看对应关系：
[root@node111 16:05:53 overlay2]$mount |grep overlay /dev/md127 on /var/lib/docker/overlay2 type ext4 (rw,relatime,data=ordered) overlay on /var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/merged type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/3NA23BH5OMSSXWTHGPRS6YENB7:/var/lib/docker/overlay2/l/QQVS7UVPGRBVHRZOBDPMMO4EQM:/var/lib/docker/overlay2/l/E7HTYBVD5SXSZRLVTETODOIANT,upperdir=/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/diff,workdir=/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/work) [root@node111 16:06:07 overlay2]$docker inspect testadd:0.</description></item><item><title>Kubernetes 实战-日志处理</title><link>https://zdyxry.github.io/2019/05/17/Kubernetes-%E5%AE%9E%E6%88%98-%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86/</link><pubDate>Fri, 17 May 2019 08:50:44 +0000</pubDate><guid>https://zdyxry.github.io/2019/05/17/Kubernetes-%E5%AE%9E%E6%88%98-%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86/</guid><description>基础日志处理 链接到标题 在 Kubernetes（简称 k8s）中，所有应用在 Pod（k8s 管理容器最小单位）中运行，标准处理方式为将日志打印到标准日志输出和标准错误输出，这样我们可以通过 kuberctl logs 关键字获取容器运行时日志，根据容器运行时的类型不同，日志保存路径也不同，以 Docker 为例，所有真实日志均在 /var/lib/docker/ 路径下，下面我们来看一个例子：
在 k8s 中创建一个 Pod，Pod 中指定打印当前时间到标准输出中：
apiVersion: v1 kind: Pod metadata: name: counter spec: containers: - name: count image: busybox args: [/bin/sh, -c, &amp;#39;i=0; while true; do echo &amp;#34;$i: $(date)&amp;#34;; i=$((i+1)); sleep 1; done&amp;#39;] 运行该 Pod，通过 kubectl logs 获取当前 Pod 日志：
[root@node1 blog]# kubectl get pod |grep counter counter 1/1 Running 0 9s [root@node1 blog]# kubectl logs counter 0: Fri May 17 00:34:01 UTC 2019 1: Fri May 17 00:34:02 UTC 2019 2: Fri May 17 00:34:03 UTC 2019 3: Fri May 17 00:34:04 UTC 2019 4: Fri May 17 00:34:05 UTC 2019 5: Fri May 17 00:34:06 UTC 2019 6: Fri May 17 00:34:07 UTC 2019 7: Fri May 17 00:34:08 UTC 2019 8: Fri May 17 00:34:09 UTC 2019 9: Fri May 17 00:34:10 UTC 2019 10: Fri May 17 00:34:11 UTC 2019 11: Fri May 17 00:34:12 UTC 2019 12: Fri May 17 00:34:13 UTC 2019 这里如果使用 -f 选项，可以持续输出该 Pod 日志。</description></item><item><title>Kubernetes 实战-微服务</title><link>https://zdyxry.github.io/2019/05/14/Kubernetes-%E5%AE%9E%E6%88%98-%E5%BE%AE%E6%9C%8D%E5%8A%A1/</link><pubDate>Tue, 14 May 2019 22:32:43 +0000</pubDate><guid>https://zdyxry.github.io/2019/05/14/Kubernetes-%E5%AE%9E%E6%88%98-%E5%BE%AE%E6%9C%8D%E5%8A%A1/</guid><description>微服务 链接到标题 在 《Kubernetes In Action》的开始，先要了解 k8s 的需求来自于哪里，为什么我们需要 k8s。
引用维基百科解释：
微服务 (Microservices) 是一种软件架构风格，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的 API 集相互通信。
说一说我的理解，在项目早期，都是单体应用，随着功能越来越多，项目越来越大，虽然保证了部署运维的方便，但对于组内同学并不友好，新同学往往要在一坨代码中找自己想要的一点，本地修改提交跑 CI 也是以项目为单位的执行（前段时间 B 站不小心泄露的 Golang 代码就是这种）。当后续升级产品时，因为是以项目为最小粒度，哪怕无关代码，也要被迫进行代码升级，服务重启等操作，带来了额外的风险。
在 2014年，Martin Fowler 与 James Lewis 共同提出了微服务的概念，把单体应用改为通过接口产生的远程方法调用，将项目拆分，一个项目保证只做一件事情，独立部署和维护。
优点：
高度可维护和可测试 松散耦合 可独立部署 围绕业务能力进行组织 缺点：
服务数量大幅增加，部署维护困难 服务间依赖管理 服务故障处理 容器 链接到标题 那么我们提到了项目演进，在同一时间，容器技术的标准化统一也间接促成了微服务的推广（我猜的），Docker 在 2013.03.13 发布第一个版本，容器化技术让我们产品发布形态有了新的选择，开发直接将容器镜像发布，运维同学通过镜像进行产品上线，确保了环境的统一，无须纠结环境配置相关问题（不用吵架了）。
当我们产品发布采用容器化上线后，我们面临一些其他的问题了：
微服务追求的是将服务解耦，拆分为多个服务，那么最终发布形态对应的也是多个镜像，运维同学管理这些镜像之间的关系难度增加。 同时当镜像运行在不同的物理节点上，对计算资源和网络资源的要求是一致的，运维同学需要做到让镜像无感知。 当产品要进行升级时，镜像之间的依赖关系，故障切换等操作紧靠现有容器功能实现困难。 这么一看，与之前单体应用比也没好哪里去。于是有了各种容器编排系统，比如 Swarm，Mesos等等，但都不是很好用且各家一个标准，这时候老大哥谷歌发话了，我来把我们内部用了很多年要淘汰的东西拿出来给大家解决问题吧，于是有了 Kubernetes。
Kubernetes 功能上提供了解决微服务引入的问题，并更好的配合微服务去提供稳定高可用的统一容器化环境，具体如何解决的我们后续可以通过了解 Pod，ConfigMap，ReplicaSet 等功能去详细了解。
总结 链接到标题 可能是因为我考虑问题都是从运维角度去看的，网上的一些文章讲的带来的好处反而没看太清，可能作为 2C 产品，追求敏捷开发，产品不断快速迭代的目标比较适合，但是如果本身作为一个追求稳定可靠的 2B 产品来说，引入 k8s 带来的好处和维护 k8s 带来的成本真的要仔细的从产品层面考虑清楚，这里感觉跟具体的技术关系不大，而是说从产品面向的客户对象考虑，客户想要的是一个什么产品，而 k8s 作为一个还在不断（频繁）迭代的产品来说（可以去看看 release notes 的更新速度），后续若出现某些 API 不兼容等情况，如何去应对，感觉还是个灾难。</description></item><item><title>Kubernetes 实战-前言</title><link>https://zdyxry.github.io/2019/05/11/Kubernetes-%E5%AE%9E%E6%88%98-%E5%89%8D%E8%A8%80/</link><pubDate>Sat, 11 May 2019 21:00:55 +0000</pubDate><guid>https://zdyxry.github.io/2019/05/11/Kubernetes-%E5%AE%9E%E6%88%98-%E5%89%8D%E8%A8%80/</guid><description>Kubernetes 实战-前言 链接到标题 自从 Kubernetes 大热之后，一直没跟着版本去了解具体的功能及使用，只是大概了解其中概念。之前推特上有人推荐《Kubernetes In Action》这本书，说是对入门同学很友好，利用五一假期和这个周末，终于看完了，打算把学习过程和其中的一些想法记录下来。
《Kubernetes In Action》 链接到标题 就想推荐人说的那样，这本书作为 101 系列来说，是很称职的，你跟着官方示例做，90%以上都是可以成功的，且讲解门槛不高，推荐。
中文版是由七牛团队翻译的，虽然其中有一些小的翻译错误，但是整体读下来还是很顺畅的，不影响阅读，当然现在网上已经有原版资源，想读的同学可以去 SaltTiger 搜索下载。
本书章节较多，分为 3 部分：What？How？Why？首先讲解 k8s 及容器的基本概念，然后讲解 k8s 基本使用，最后介绍了一些 k8s 工作原理及最佳实践。
当你了解了什么是 k8s，及 k8s 能带来什么好处之后，我们去使用 k8s，从而真实的感受到 k8s 带来的便利，这种感觉是很美好的（表面美好的东西肯定会有某些限制），对我来说这种美好截止到第二部分就停止了。在第三部分中，我们在之前感受到的便利隐藏着很多没有考虑到的边界因素，也意味着我们从一个传统的单节点服务切换到微服务架构上，会新增很多需要去考虑的因素，如果 k8s 内部提供了解决方案，那么很简单，我们直接编写 YAML 就可以了，如果 k8s 没有解决方案呢？我不知道，可能当我真正体验过之后才能给出感受吧（即将发生的事）。
下一篇我们来说下什么是微服务。</description></item><item><title>LeetCode Shell 题解</title><link>https://zdyxry.github.io/2019/05/11/LeetCode-Shell-%E9%A2%98%E8%A7%A3/</link><pubDate>Sat, 11 May 2019 20:17:57 +0000</pubDate><guid>https://zdyxry.github.io/2019/05/11/LeetCode-Shell-%E9%A2%98%E8%A7%A3/</guid><description>工作上用 Shell 的频率是很高的，哪怕现在有了 Ansible 或者其他配置工具，Shell 仍是一个以 Linux 作为工作环境的同学的必备技能。 之前写过 GitHub 上的 Pure Bash Bible 的博客，看到 LeetCode 上的 Shell 题目好久不更新了，只有 4 道，今天记录一下题解。
192. Word Frequency 链接到标题 统计文本文件中单词出现次数，倒序输出。
words.txt
the day is sunny the the the sunny is is 利用 tr sort uniq awk 解决。
# Read from the file words.txt and output the word frequency list to stdout. cat words.txt | tr -s &amp;#39; &amp;#39; &amp;#39;\n&amp;#39; | sort | uniq -c | sort -rn | awk &amp;#39;{ print $2, $1 }&amp;#39; 193.</description></item><item><title>PySnooper 源码阅读</title><link>https://zdyxry.github.io/2019/04/27/PySnooper-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link><pubDate>Sat, 27 Apr 2019 20:14:28 +0000</pubDate><guid>https://zdyxry.github.io/2019/04/27/PySnooper-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</guid><description>背景 链接到标题 在 18 年的时候 jiajun 同学发过一篇博客，讲如何调试相关的总结。结合最近自己的经验，紧靠 logging 和 print 就能解决日常的 80%问题，剩下的 20% 也都可以通过review 代码来解决，我只有当确实没什么思路的时候，才会采用 pdb 的方式去调试。之所以先 review 代码再采用 pdb 的方式是想确认自己已经理清了相关代码的上下文和逻辑，不至于在单步调试的时候出现 恍然大悟 （贬义） 的状况。
最近两天 Github 上关于 Python 的项目最火的就是 PySnooper，这个项目的 Slogan 就是 Never use print for debugging again ，这里的 print 替换为 logging 也没啥差。整个代码在初步可用阶段代码量很少，也确实能够给平时写些小脚本带来便利，便抽时间看了看具体的实现。
PySnooper 链接到标题 先来看下目录结构：
yiran@zhouyirandeMacBook-Pro:~/Documents/git-repo/PySnooper 3d0d051 ✗ $ tree . . ├── LICENSE ├── MANIFEST.in ├── README.md ├── make_release.sh ├── misc │ └── IDE\ files │ └── PySnooper.</description></item><item><title>PingCAP tidb-ansible 源码阅读</title><link>https://zdyxry.github.io/2019/04/20/PingCAP-tidb-ansible-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link><pubDate>Sat, 20 Apr 2019 11:50:41 +0000</pubDate><guid>https://zdyxry.github.io/2019/04/20/PingCAP-tidb-ansible-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</guid><description>了解我的同学应该知道，我目前负责公司产品的运维工具开发相关的工作，作为一款 2B 的产品，在产品运维过程中，总是有一些不愉快（又不能让客户知道）的繁琐操作：这些操作可能是为了防止过程中出现错误，而不断添加的检测条件；也有可能是历史问题，随着产品发布迭代而一直遗留至今。
所以我平时也在关注一些开源的 2B 产品的配套运维工具，比如 ZStack、PingCAP 之类的公司。
但是 ZStack 的开源生态不是很好，感觉只是在保持代码更新（不知道哪个分支）的状态。相比之下 PingCAP 就好很多了，可以很直接的从文档中看到差别，而且社区很活跃。
最近看到 PingCAP 的一个关于部署维护的 视频讲解 ，可能时间有限，并没有很深入的讲解细节，有兴趣的同学可以看下。
在讲解过程中，一个比较核心的工具就是 Ansible，通过 Ansible Playbook 来定义各个步骤，我最近也在使用 Ansible 来进行二次开发，特此学习下 PingCAP 的 tidb-ansible 。
安装方式 链接到标题 TiDB 目前支持 4 种安装方式：
Ansible Online Ansible Offline Docker Docker compose 其中最佳实践应该是 Ansible Online 方式，通过控制机联网下载所需依赖及 TiDB binary 文件。当然如果所在环境无法访问互联网，那么只能采用 Offline 方式了。后两种部署方式，感觉只是用于开发测试或者给用户“看看”的情况。
如果要学习的话肯定要学习最佳实践了，那么我们来看看 Ansible Online 方式。
环境准备 链接到标题 TiDB 作为一个 开源分布式关系型数据库 ，所需要的物理环境是很比较苛刻的，官方最佳实践的需求如下：
组件 CPU 内存 硬盘类型 网络 数量(最低要求) TiDB 16 32GB SAS 10GbE * 2 2 PD 4 8GB SSD 10 GbE * 2 3 TiKV 16 32GB SSD 10 GbE * 2 3 监控 8 16GB SAS 1GbE * 1 1 对于 CPU、内存和磁盘的要求我们暂时忽略，这里注意网卡数量都是推荐的 2 块网卡，应该是会做 bonding，到时候看下代码中是否处理。</description></item><item><title>记一次 libcgroup 配置失败</title><link>https://zdyxry.github.io/2019/04/11/%E8%AE%B0%E4%B8%80%E6%AC%A1-libcgroup-%E9%85%8D%E7%BD%AE%E5%A4%B1%E8%B4%A5/</link><pubDate>Thu, 11 Apr 2019 22:04:47 +0000</pubDate><guid>https://zdyxry.github.io/2019/04/11/%E8%AE%B0%E4%B8%80%E6%AC%A1-libcgroup-%E9%85%8D%E7%BD%AE%E5%A4%B1%E8%B4%A5/</guid><description>cgroup 配置失败解决方案 链接到标题 看过之前博客的同学应该知道，我一直使用的 libcgroup 来进行 cgroup 配置，简单方便。 最近遇到了一个报错，很坑，记录一下。
报错 链接到标题 接到反馈说有个环境在产品升级之后， cgconfig.service 无法启动，当时的配置如下：
[root@yiran-test 21:31:59 ~]$cat /etc/cgconfig.conf # yiran cgroups configuration group . { cpuset { cpuset.memory_pressure_enabled = &amp;#34;1&amp;#34;; } } group yiran { cpuset { cpuset.cpus = &amp;#34;0,1,2,3,4,5&amp;#34;; cpuset.mems = &amp;#34;0-1&amp;#34;; cpuset.cpu_exclusive = &amp;#34;1&amp;#34;; cpuset.mem_hardwall = &amp;#34;1&amp;#34;; } } group yiran/bb-main { cpuset { cpuset.cpus = &amp;#34;0&amp;#34;; cpuset.mems = &amp;#34;0-1&amp;#34;; cpuset.cpu_exclusive = &amp;#34;1&amp;#34;; cpuset.mem_hardwall = &amp;#34;1&amp;#34;; } } group yiran/bb-io { cpuset { cpuset.</description></item><item><title>apscheduler 源码阅读</title><link>https://zdyxry.github.io/2019/04/06/apscheduler-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link><pubDate>Sat, 06 Apr 2019 10:58:49 +0000</pubDate><guid>https://zdyxry.github.io/2019/04/06/apscheduler-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</guid><description>简介 链接到标题 apscheduler 全称 Advanced Python Scheduler，调度器，主要功能如下：
动态添加、删除任务 暂停、恢复任务 周期性调度：cron,date,interval &amp;hellip; 那么接下来我们根据官方示例，看看 apscheduler 是如何进行处理任务的。
示例版本为 2.1，因为在 2.1 版本包含目前 master 分支上的主要功能，简单易懂。
代码结构如下：
yiran@zhouyirandeMacBook-Pro:~/Documents/git-repo/apscheduler 2.1 ✔ $ tree apscheduler apscheduler ├── __init__.py ├── events.py ├── job.py ├── jobstores │ ├── __init__.py │ ├── base.py │ ├── mongodb_store.py │ ├── ram_store.py │ ├── redis_store.py │ ├── shelve_store.py │ └── sqlalchemy_store.py ├── scheduler.py ├── threadpool.py ├── triggers │ ├── __init__.py │ ├── cron │ │ ├── __init__.</description></item><item><title>记一次 Python 编码踩坑</title><link>https://zdyxry.github.io/2019/04/02/%E8%AE%B0%E4%B8%80%E6%AC%A1-Python-%E7%BC%96%E7%A0%81%E8%B8%A9%E5%9D%91/</link><pubDate>Tue, 02 Apr 2019 07:37:59 +0000</pubDate><guid>https://zdyxry.github.io/2019/04/02/%E8%AE%B0%E4%B8%80%E6%AC%A1-Python-%E7%BC%96%E7%A0%81%E8%B8%A9%E5%9D%91/</guid><description>背景 链接到标题 一直知道 Python 容易踩编码的坑，尤其是 Python2，昨天第一次遇到，记一下。
起因 链接到标题 产品中有一个账号关联的功能，需要的参数大概有 host,port,user,passwd 这么几个参数，昨天发现一个环境中账号关联失败，看请求应该还没到账号认证那里就失败了，查看 rest-server 日志，并没有发现错误异常，api 也是正常返回的，通过其他方式验证账号是有效的，当时觉得很奇怪，没什么想法。
调查 链接到标题 既然 rest-server 中日志没有报错，那么看看服务是否有什么异常。 这里特意说名下，如果服务使用的是 gunicorn 或者 celery 等第三方库作为守护进程，有一些系统报错是不会记录到你的服务中的，而是会直接打印到系统中（messages or systemd）。
发现 systemctl status 和 journal -u 有报错，报错内容如下：
4月 02 06:20:00 SCVM70 gunicorn[31225]: Traceback (most recent call last): 4月 02 06:20:00 SCVM70 gunicorn[31225]: File &amp;#34;/usr/lib64/python2.7/site-packages/gevent/threadpool.py&amp;#34;, line 207, in _worker 4月 02 06:20:00 SCVM70 gunicorn[31225]: value = func(*args, **kwargs) 4月 02 06:20:00 SCVM70 gunicorn[31225]: error: getaddrinfo() argument 2 must be integer or string 4月 02 06:20:00 SCVM70 gunicorn[31225]: (&amp;lt;ThreadPool at 0x120ae50 0/5/10&amp;gt;, &amp;lt;built-in function getaddrinfo&amp;gt;) failed with error 字面意思是传递参数的类型不对，必须为 int 或者 string。</description></item><item><title>huey 源码阅读</title><link>https://zdyxry.github.io/2019/03/31/huey-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</link><pubDate>Sun, 31 Mar 2019 11:25:48 +0000</pubDate><guid>https://zdyxry.github.io/2019/03/31/huey-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</guid><description>背景 链接到标题 最近读完了 《Redis 实战》对 Redis 有了一些了解，但是没有在实际项目中应用过，就想找一个使用 Redis 的项目来看看，找到 Huey 是因为之前使用过，趁机了解下具体实现。
简介 链接到标题 Huey 的定位是一个轻量级的任务队列，仅依赖于 Redis 作为任务相关信息存储，支持的功能有：
多种 worker 执行方式：thread，process，greenlet 支持多种任务类型：特定时间运行，周期性运行 包含重试机制，可以指定重试次数及重试间隔 支持任务锁 &amp;hellip; 我们根据官方的示例，来看看 Huey 是如何处理任务的，目录结构如下：
master ✔ $ pwd /Users/yiran/Documents/git-repo/huey/examples/simple yiran@zhouyirandeMacBook-Pro:~/Documents/git-repo/huey/examples/simple master ✔ $ tree . . ├── README ├── __init__.py ├── config.py ├── cons.sh ├── main.py └── tasks.py 注意，这个目录结构是 Huey 官方建议的，具体原因为：
Behind-the-scenes when you decorate a function with task() or periodic_task(), the function registers itself with a centralized in-memory registry.</description></item><item><title>LVM 使用总结</title><link>https://zdyxry.github.io/2019/03/29/LVM-%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</link><pubDate>Fri, 29 Mar 2019 22:42:27 +0000</pubDate><guid>https://zdyxry.github.io/2019/03/29/LVM-%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</guid><description>全称 Logical Volume Manager，逻辑卷管理，简单的说就是能将物理磁盘统一管理，在现在这个满大街都在谈论分布式存储的年代，已经很少有人关注和使用它了，毕竟如果买个公有云上的虚拟机，挂载磁盘都已经得到 TP999+ 的稳定性加持，扩容什么的也只是一句话的事，完全没必要使用 LVM 了。
那么我今天为啥要写 LVM 呢，首先肯定是最近要使用它（清理它），其次，现在 RedHat 系列发行版仍将 LVM 作为系统安装的默认磁盘处理方式，对于我这种安装系统家常便饭的人，还是要了解下的。
本文不会包含 LVM 命令的使用。
概念 链接到标题 LVM 中有 3 个最重要的概念，分别是 PV，VG，LV，下面我分别来说一下：
PV 链接到标题 Physical Volumes，物理卷，属于 LVM 中最底层的单元，通常介质为磁盘，或者磁盘上的某个分区，多个 PV 可以组成 VG（卷组）。
VG 链接到标题 Volume Group，卷组，也是我们通常说的“池化”具体表现形式，VG 可以存在多个，我们可以根据具体的用途来划分 VG，来提供相应的性能保证，比如我们可以对 IO 密集型应用使用全 SSD 组成的 VG。
LV 链接到标题 Logical Volume，逻辑卷，也就是 LVM 中的 LV，LVM 暴露出来供我们使用的逻辑（虚拟）卷。我们可以将其当做一个普通的磁盘使用，可以在其上进行分区，格式化，磁盘读写等操作。
优缺点 链接到标题 简单的介绍了 LVM 的概念，那么我们来说下 LVM 的优缺点：
优点： 链接到标题 随意扩（缩）容 在线迁移 LV（平时用处不多，主要在 P2V 场景下使用，也就是通常文章中提到的“企业上云”必要的操作） 快照，RAID 等高级功能 缺点 链接到标题 管理复杂，通常服务器上磁盘数量多，且磁盘类型未必能够统一（考虑大量公司中的利旧场景），那么我们管理起来就比较麻烦了，要针对所有磁盘创建 PV，然后加入到对应的 VG 中，最后再对外提供 LV，往往我们需要维护相应的功能来提供简单的借口供上层应用使用。</description></item><item><title>Wireguard 体验</title><link>https://zdyxry.github.io/2019/03/23/Wireguard-%E4%BD%93%E9%AA%8C/</link><pubDate>Sat, 23 Mar 2019 20:13:38 +0000</pubDate><guid>https://zdyxry.github.io/2019/03/23/Wireguard-%E4%BD%93%E9%AA%8C/</guid><description>从春节假期之后，因为一些原因，就没有再使用 SS 作为访问互联网的工具了，而是使用了 V2ray，使用 2个月下来，感受还是很好的，无论是速度还是稳定性都要比 SS 好很多。最近看到好多新闻说 Wireguard 客户端适配多了起来，比如 Win，Mac，Android，今天尝试一下。
Wireguard 链接到标题 WireGuard is a free and open-source software application and protocol that implements virtual private network (VPN) techniques to create secure point-to-point connections in routed or bridged configurations. It is run as a module inside the Linux kernel and aims for better performance than the IPsec and OpenVPN tunneling protocols.[2]
Linus 的评价： Maybe the code isn't perfect, but I've skimmed it, and compared to the horrors that are OpenVPN and IPSec, it's a work of art.</description></item><item><title>关于 On-Call</title><link>https://zdyxry.github.io/2019/03/16/%E5%85%B3%E4%BA%8E-On-Call/</link><pubDate>Sat, 16 Mar 2019 18:24:00 +0000</pubDate><guid>https://zdyxry.github.io/2019/03/16/%E5%85%B3%E4%BA%8E-On-Call/</guid><description>On-Call 链接到标题 要说具体的 On-Call，早在 2016年还在负责运维工作的时候，就是 On-Call 的状态，那时候虽然没有明确的规定，但是做得事情就是 On-Call。在年会之后，公司正式宣布执行 On-Call，并且我在上周又重新体会了下 On-Call，感觉涉及到的东西可太多了。
售后服务 链接到标题 在一家做 2B 市场的公司，销售所售卖的，或者说客户所购买的，远远不仅是你的软件。如果单论软件，那么有无数的公司产品比你牛，销售比你多，研发比你强，又怎么争得过呢。我理解 2B 公司最大的卖点是服务：软件安装了，产品运行了，业务上线了，之后呢？无穷尽的服务，小到一项报警项，大到节点故障，都是靠着服务堆起来的。
怎么才能服务好呢？ 有一个良好的售后团队，或者说一个良好的售后体系支撑。因为我没有经历过太多的公司，只能就自己接触到的做 2B 公司的目前情况来说，没有见到那种让人眼前一亮的售后服务。
接触到的小公司售后团队（甚至一些国产2B 大厂）大多都是这么做的：
安装实施 定期巡检 故障处理 能做到上述 3 点尤其是第 2 点的并不多。我理解的 3 个阶段：
安装实施：了解客户环境，及时记录并沟通确定环境中不稳定的点，做好 PlanB，最终实施完成也要形成实施报告，无论是交付客户，还是公司内部之后的持续跟踪，都是只有好处没有坏处。
定期巡检：周期性与客户沟通进行巡检，很多客户在使用你的产品，其实他们是没有了解过多的使用上的内容的，毕竟产品说明书（使用文档）几百上千页，应该没有哪些真实用户会一点点的研究了解，大多只是出于使用上。那么这时就需要售后同学定期去进行巡检，帮助客户去发现问题，同时也是在教育用户去了解更多的产品细节。
故障处理：这里就涉及到今天聊得主题，当线上环境出现问题，怎么做？如何做？我理解的故障处理，无论 Bug 多难复现，无论操作多苛刻，都要第一时间恢复线上业务，如果业务不能恢复，其他一切免谈。
为什么 On-Call？ 链接到标题 在我上述提到的 3 点中，1、2通常是由售后同学来完成，最重要的第 3 点通常是由研发同学修复。
在售后同学，遇到了线上故障：
如何去了解这个故障的影响范围？ 如何准确全面的去提供这个故障相关信息？ 如何第一时间找到功能模块负责的相应研发同事？ &amp;hellip; 上述问题在工作中经常遇到，在产品没有完全成熟前，需要售后同学对产品了解不仅限于使用，而需要更多的去了解产品内容，产品通过何种方式提供这个功能。
当然，在一个小公司中，我们无法要求更多，我们需要做的是，第一时间修复问题，恢复业务，于是有了 On-Call。
如何 On-Call？ 链接到标题 轮值表：On-Call 的要求其实是一个售后岗位的基本职责，只是对于研发同学来说可能略微难过，7 * 24 小时 * 365 响应。具体落实下来就可能是以 7 * 24 为周期的轮值。这期间可能有很多要求，比如多久要接通电话，多久要接入远程等等。</description></item><item><title>Python 调用 systemd watchdog 方法</title><link>https://zdyxry.github.io/2019/03/10/Python-%E8%B0%83%E7%94%A8-systemd-watchdog-%E6%96%B9%E6%B3%95/</link><pubDate>Sun, 10 Mar 2019 10:21:19 +0000</pubDate><guid>https://zdyxry.github.io/2019/03/10/Python-%E8%B0%83%E7%94%A8-systemd-watchdog-%E6%96%B9%E6%B3%95/</guid><description>systemd 链接到标题 在之前的博客中介绍过 systemd 的基本使用及通过 timer 来替换 crontab 的方法，今天来说一下如何调用 watchdog。
在 systemd 中，提供 watchdog 来检测服务状态状态，官方文档中描述这个功能为 &amp;ldquo;keep-alive ping&amp;rdquo;，我们可以在服务的启动配置中，添加 WatchdogSec 来指定 timeout 时间，在服务程序中通过发送 WATCHDOG=1 来不断的通知 systemd，服务处于正常状态，当超过 timeout 时间未收到 WATCHDOG=1 信号后，systemd 会根据 Restart 配置，决定是否自动重启服务。
示例 链接到标题 服务程序：
root@yiran-30-250:/usr/lib/systemd/system $ cat /root/project/watchdog/test.py #!/usr/bin/python # coding:utf-8 import os import time import socket import logging print(&amp;#34;Test starting up...&amp;#34;) time.sleep(1) # 模拟执行真实业务 print(&amp;#34;Test startup finished&amp;#34;) try: sock = socket.socket(socket.AF_UNIX, socket.SOCK_DGRAM) addr = os.getenv(&amp;#34;NOTIFY_SOCKET&amp;#34;) # systemd default addr = &amp;#34;/run/systemd/notify&amp;#34; if addr and addr[0] == &amp;#34;@&amp;#34;: addr = &amp;#34;\0&amp;#34; + addr[1:] except Exception: logging.</description></item><item><title>Python 生成器使用</title><link>https://zdyxry.github.io/2019/03/09/Python-%E7%94%9F%E6%88%90%E5%99%A8%E4%BD%BF%E7%94%A8/</link><pubDate>Sat, 09 Mar 2019 21:47:35 +0000</pubDate><guid>https://zdyxry.github.io/2019/03/09/Python-%E7%94%9F%E6%88%90%E5%99%A8%E4%BD%BF%E7%94%A8/</guid><description>背景 链接到标题 在清理 Pocket 列表的时候，发现自己很早之前收藏过 dabeaz 在 2008 年 PyCon 关于生成器的 PPT 讲解，今天读完，有所收获。
在 PPT 中， dabeaz 通过一个具体的文件处理的例子，一步一步的讲解了程序的演进，具体代码可以在 Github 查看。
生成器 链接到标题 使用 yield 关键字的函数就是生成器。生成器在运行时生成值，所以只能迭代一次。生成器可以通过 next 关键字执行，通常我们通过 for 循环来迭代生成器，可以自动处理 StopIteration 情况。
一个简单的生成器例子：
def countdown(n): while n &amp;gt; 0: yield n n -= 1 &amp;gt;&amp;gt;&amp;gt; for i in countdown(5): ... print(i, end=&amp;#39; &amp;#39;) ... 5 4 3 2 1 当我们调用生成器时，仅返回一个生成器对象，不会执行函数内容，只有当执行 __next__() 时函数才会真正执行。yield 会返回给调用者当前值，同时暂停执行，等待下一次调用 __next__() 继续执行。
协程 链接到标题 在 python 中通过生成器的方式来实现协程：</description></item><item><title>Libvirt CPU 配置</title><link>https://zdyxry.github.io/2019/03/02/Libvirt-CPU-%E9%85%8D%E7%BD%AE/</link><pubDate>Sat, 02 Mar 2019 19:40:20 +0000</pubDate><guid>https://zdyxry.github.io/2019/03/02/Libvirt-CPU-%E9%85%8D%E7%BD%AE/</guid><description>Libvirt CPU 配置参数 链接到标题 我们先来看下 Libvirt 关于虚拟机 CPU 配置项：
match check mode model &amp;hellip; 具体配置解释可以去 Libvirt 官方文档中查看，这里主要说一下 mode 参数，看一下 mode 具体含义及可选配置：
host-passthrough 链接到标题 Libvirt 通知 KVM 对 CPU 不做任何配置项修改，直通给虚拟机。因为虚拟机可以使用与物理主机相同 CPU 指令集，性能最好，相反，在虚拟机热迁移过程中，对目标主机 CPU 要求同型号同代。
host-model 链接到标题 本质上是根据物理主机 CPU 从 cpu_map.xml 文件中选择最匹配的 CPU 型号。由于CPU定义是在启动虚拟机之前复制的，因此可以在不同主机上使用完全相同的XML，同时仍然提供每个主机支持的最佳虚拟机 CPU。属于在功能与性能之间的平衡。
custom 链接到标题 不指定 mode 属性时的默认值。此模式使得无论虚拟机启动哪个主机，虚拟机都将看到相同的硬件，兼容性最好。
最佳选择 链接到标题 在不考虑虚拟机兼容性（热迁移）情况下，优先选择 host-passthrough ，综合考虑选择 host-model 。
OpenStack 中如果检测到 hypervisor 是 kvm-qemu ，则默认值为 host-model ；在 hypervisor 是其他类型时，默认值为 none，即由 hypervisor 自己选择。
我查看了自己两台 VPS 的 CPU 信息，如下：</description></item><item><title>学会拒绝</title><link>https://zdyxry.github.io/2019/02/05/%E5%AD%A6%E4%BC%9A%E6%8B%92%E7%BB%9D/</link><pubDate>Tue, 05 Feb 2019 09:33:18 +0000</pubDate><guid>https://zdyxry.github.io/2019/02/05/%E5%AD%A6%E4%BC%9A%E6%8B%92%E7%BB%9D/</guid><description>趁着春节 7 天假期，把 18年所有的年假都请了下来，计划在家里待 20多天，这次假期最大的感受就是父母不懂得拒绝，或者说他们不想拒绝。
我小时候也是这样，可能是因为父母的关系，我一直处于一个周围同学中的“好人”状态，有事情要找人帮忙，一般都会找到我这来，因为我不拒绝。这也给我自身造成了一种假象：“我跟周围的关系不错”。那么我不拒绝的原因是什么呢？
最早可能是我不会拒绝，觉得拒绝会让对方难堪；之后可能是我觉得这段关系是我所看重的，所以我为了维持关系不拒绝，但是根本原因还是第一条；最终可能是我懒。（？
不拒绝，不想拒绝或者说不懂得拒绝，给我造成了很多的困扰，很被动。我这个人是一个喜欢计划的人，无论是生活还是工作，我都希望能够按照我的计划进行（当然如果出现计划外的事情往往我会比较懊恼。但是又因为我不拒绝，导致我的计划经常被中断，甚至是有些时效性的事情，就被彻底的终止了。可能这件事情对我比较重要，但是因为不拒绝，导致事情没完成。
那么我是从什么开始学会拒绝的呢？准确的说是同事教我的（虽然现在这位同事经常被我拒绝 - - 。在 2017年，我负责的工作准确的说是一半在公司内部，另一半在与公司外部的合作上。公司外部的工作优先级比较高，当我在做公司内部工作的时候，经常性的被打断，去处理优先级比较高的工作，造成我的整体工作效率不高，甚至说很低，哪怕我已经尽可能的考虑到部分原因，但是计划永远赶不上变化，我们要针对不同的事情去拒绝，比如当我正在处理公司外部的工作 A，我的老板让我立即做公司内部工作 B，自我评估优先级之后，我们决定是否接受 B，而不是因为那是我的老板，我就毫不犹豫的接受，因为当时接受的结果很有可能会造成 A &amp;amp; B 都做不好。
亲戚、朋友甚至是恋人关系也是一样，这种与工作关系不同，在让你帮忙时，他们往往会带上“情感”上的束缚，会利用“情感”关系去控制你，仿佛你不做这段关系就到此为止一样，这种是最可怕的，要学会拒绝，避免深陷。
当然我现在的拒绝可能比较生硬，导致不愉快，但是终究对我来说是个好事，期望后续能够通过阅读《情感勒索》这部书来改善。</description></item><item><title>聊一聊 ISO 9660</title><link>https://zdyxry.github.io/2019/01/12/%E8%81%8A%E4%B8%80%E8%81%8A-ISO-9660/</link><pubDate>Sat, 12 Jan 2019 22:06:45 +0000</pubDate><guid>https://zdyxry.github.io/2019/01/12/%E8%81%8A%E4%B8%80%E8%81%8A-ISO-9660/</guid><description>ISO 9660 链接到标题 ISO 9660，也被一些硬件和软件供应商称作CDFS（光盘文件系统），是一个由国际标准化组织（ISO）为光盘介质发布的文件系统。其目标是能够在不同的操作系统如Windows、Mac OS以及类Unix系统上交换数据。
我们平时接触到的 ISO 格式文件均为 ISO 9660，我们可以通过 file 命令进行查看，以 RedHat 发行版为例：
[root@node redhat]# file rhel-server-7.6-x86_64-dvd.iso rhel-server-7.6-x86_64-dvd.iso: ISO 9660 CD-ROM filesystem data &amp;#39;RHEL-7.6 Server.x86_64 &amp;#39; (bootable) 用途 链接到标题 安装操作系统，我们可以通过将 ISO 挂载到物理服务器/PC 上，从 ISO 启动进行操作系统的安装； 作为软件安装源，比如红帽系列的版本，在 ISO 中，通常会有 Packages 路径，下面包含了当前版本完整的软件源，我们可以通过本地挂载的方式使用； 作为软件发行方式，常见的有 VMware vmtools, KVM Virtio 等统一打包方式； &amp;hellip; 制作方式 链接到标题 genisoimage mkisofs 第一种方式不常用，主要使用第二种方式进行使用，之前的文章中提到过 LiveCD 制作方式也是通过 mkisofs 命令继续构建的。
这里我们可以参考 VMware 官方文档了解如何定制自己的 ISO。
说一下何时需要定制我们自己的 ISO。当我们获取到各个发行版本的 ISO 后，我们可以正常使用进行安装，但是都是交互式安装，需要我们通过图形化界面/命令行交互的方式进行配置确认及参数设置。如果我们想要 ISO 支持静默安装，那么就需要我们自己定制属于自己的 KickStart 脚本，然后放置到 ISO 中并设置为默认执行项。</description></item><item><title>Shell cat 保存文件方式</title><link>https://zdyxry.github.io/2019/01/05/Shell-cat-%E4%BF%9D%E5%AD%98%E6%96%87%E4%BB%B6%E6%96%B9%E5%BC%8F/</link><pubDate>Sat, 05 Jan 2019 20:12:30 +0000</pubDate><guid>https://zdyxry.github.io/2019/01/05/Shell-cat-%E4%BF%9D%E5%AD%98%E6%96%87%E4%BB%B6%E6%96%B9%E5%BC%8F/</guid><description>背景 链接到标题 在 Shell 中保存文件可以通过 echo 保存一个字符串， cat 保存一个字符片段，最近在用 cat 编写 Nginx 配置文件的时候，想要写入 $test 类似字段，但是 Shell 会自动将其识别为变量而忽略，记录下该方式。
cat 编写文件 链接到标题 root@yiran-30-250:/tmp $ cat cat.sh #!/usr/bin/env bash cat &amp;lt;&amp;lt; EOF &amp;gt; /tmp/yiran aaa bbb ccc ddd $eee $fff EOF root@yiran-30-250:/tmp $ bash cat.sh root@yiran-30-250:/tmp $ cat yiran aaa bbb ccc ddd root@yiran-30-250:/tmp $ cat cat2.sh #!/usr/bin/env bash cat &amp;lt;&amp;lt; &amp;#39;EOF&amp;#39; &amp;gt; /tmp/yiran aaa bbb ccc ddd $eee $fff EOF root@yiran-30-250:/tmp $ bash cat2.</description></item><item><title>Wireshark 远程抓包方法</title><link>https://zdyxry.github.io/2019/01/01/Wireshark-%E8%BF%9C%E7%A8%8B%E6%8A%93%E5%8C%85%E6%96%B9%E6%B3%95/</link><pubDate>Tue, 01 Jan 2019 12:46:50 +0000</pubDate><guid>https://zdyxry.github.io/2019/01/01/Wireshark-%E8%BF%9C%E7%A8%8B%E6%8A%93%E5%8C%85%E6%96%B9%E6%B3%95/</guid><description>背景 链接到标题 最近在看 《Wireshark网络分析就这么简单》，目前读了 1/3，觉得作为一本工具介绍书籍还是不错的，至少可以让我更关注网络相关知识。 书中有大量的实例来讲解 Wireshark 的使用，及网络基础，在阅读的过程中，需要实际动手操作下，由于搜到的教程中没有正确操作的步骤，特此记录。
环境信息 链接到标题 个人 PC Windows 10 服务器 CentOS 7 操作流程 链接到标题 (1)个人 PC 链接到标题 登陆 Wireshark 官网，下载最新版本软件包并安装 打开 Wireshark ，选择本机的网卡，并进行抓取，验证软件是否正常工作 (2)服务器 链接到标题 验证个人 PC 上软件正常后，我们需要在服务器安装 rpcapd，以便让 Wireshark 连接该服务器。
访问 rpcapd github 克隆相应代码 cd /tmp; git clone https://github.com/rpcapd-linux/rpcapd-linux 安装相应依赖 yum install glibc-static flex binutils 编译安装 libpcap cd /tmp/rpcapd-linux/libpcap ; ./configure &amp;amp;&amp;amp; make 编译安装 rpcapd ，注意 README 中的 libcrypt.a in glibc-static is broken in ,remove -static in Makefile ，需要先将 Makefile 中的 -static 删掉，执行 make 即可 执行 .</description></item><item><title>2018年读书记录</title><link>https://zdyxry.github.io/2018/12/30/2018%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</link><pubDate>Sun, 30 Dec 2018 19:16:24 +0000</pubDate><guid>https://zdyxry.github.io/2018/12/30/2018%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</guid><description> 年终总结 链接到标题 计划 30 本，实际25本。 根据 2017 和 2018 两年的状态来看，平均 20本左右是正常状态了，平时很少有长时间的阅读时间，今天这种元旦假期无人打扰的阅读时间更是少的可怜，还是要学会利用片段阅读。 调整下阅读策略，把想读的书调整为 1 本，防止过度堆积导致无法进行，希望 19 年可以有所改变。
“总要有点进步嘛”。
已读 链接到标题 《区块链》 《人工智能》 《哲学家们都干了些什么》 《大数据时代 : 生活、工作与思维的大变革》 《鞋狗 : 耐克创始人菲尔·奈特亲笔自传》 《大话存储（终极版） : 存储系统底层架构原理极限剖析》 《魔法时刻》 《大规模分布式存储系统 : 原理解析与架构实战》 《Python 自动化运维 : 技术与最佳实践》 《支付战争 : 互联网金融创世纪》 《遗落的南境1：湮灭》 《Effective Python : 编写高质量Python代码的59个有效方法》 《精通VMware vSphere 5》 《写给大家看的设计书（第3版）》 《算法图解》 《Fluent Python》 《C 程序设计语言》 《The Hitchhiker&amp;rsquo;s Guide to Python》 《Python Cookbook》 《高效程序员的45个习惯 : 敏捷开发修炼之道》 《Docker 进阶与实战》 《动物农场》 《爆款文案》 《Selenium 2自动化测试实战 : 基于Python语言》 《重新定义公司 : 谷歌是如何运营的》 在读 链接到标题 《HTTP权威指南》 《Go 语言圣经》 想读 链接到标题 《大话数据结构》</description></item><item><title>cgroup 资源预留</title><link>https://zdyxry.github.io/2018/12/18/cgroup-%E8%B5%84%E6%BA%90%E9%A2%84%E7%95%99/</link><pubDate>Tue, 18 Dec 2018 21:15:33 +0000</pubDate><guid>https://zdyxry.github.io/2018/12/18/cgroup-%E8%B5%84%E6%BA%90%E9%A2%84%E7%95%99/</guid><description>cgroup 资源预留 链接到标题 背景 链接到标题 在之前的博客中，提到了 cgroup 中如何为自己的服务配置资源限制，比如 CPU，内存等，当时以为在 cgroup.conf 中配置的服务，那么相应绑定的 CPU 就归属于该服务，也就是资源预留，今天发现并不是这样，记录下如何通过 cgroup 做资源预留。
资源预留 链接到标题 在之前提到的博客中关于资源限制是这么配置的：
[root@node 20:56:49 ~]$cat /etc/cgconfig.conf # yiran cgroups configuration group . { cpuset { cpuset.memory_pressure_enabled = &amp;#34;1&amp;#34;; } } group yiran { cpuset { cpuset.cpus = &amp;#34;0,1,2,3,4,5&amp;#34;; cpuset.mems = &amp;#34;0-1&amp;#34;; cpuset.cpu_exclusive = &amp;#34;1&amp;#34;; cpuset.mem_hardwall = &amp;#34;1&amp;#34;; } } group yiran/test { cpuset { cpuset.cpus = &amp;#34;0&amp;#34;; cpuset.mems = &amp;#34;0-1&amp;#34;; cpuset.cpu_exclusive = &amp;#34;1&amp;#34;; cpuset.</description></item><item><title>剑指-Offer（七）</title><link>https://zdyxry.github.io/2018/12/15/%E5%89%91%E6%8C%87-Offer%E4%B8%83/</link><pubDate>Sat, 15 Dec 2018 08:44:06 +0000</pubDate><guid>https://zdyxry.github.io/2018/12/15/%E5%89%91%E6%8C%87-Offer%E4%B8%83/</guid><description>反转链表 链接到标题 class ListNode(object): def __init__(self, x): self.val = x self.next = None def reverse_list(list_head): if not list_head or not list_head.next: return list_head reverse_node = None node_pre = None node = list_head while node: node_next = node.next if node_next == None: reverse_node = node node.next = node_pre node_pre = node node = node_next return reverse_node node1 = ListNode(10) node2 = ListNode(11) node3 = ListNode(13) node1.next = node2 node2.next = node3 reverse_list(node1) 合并两个排序的链表 链接到标题 class ListNode(object): def __init__(self, x): self.</description></item><item><title>戴尔服务器 iDrac 配置</title><link>https://zdyxry.github.io/2018/12/12/%E6%88%B4%E5%B0%94%E6%9C%8D%E5%8A%A1%E5%99%A8-iDrac-%E9%85%8D%E7%BD%AE/</link><pubDate>Wed, 12 Dec 2018 22:18:15 +0000</pubDate><guid>https://zdyxry.github.io/2018/12/12/%E6%88%B4%E5%B0%94%E6%9C%8D%E5%8A%A1%E5%99%A8-iDrac-%E9%85%8D%E7%BD%AE/</guid><description>背景 链接到标题 之前介绍过超微的 IPMI 配置时提过，超微的 IPMI 是最简陋的，最近在用戴尔服务器的时候碰到了一个比较坑的事情，查了资料解决了，更加坚定之前的结论，IPMI 相应的配置尽量独立。
问题 链接到标题 在戴尔服务器安装 CentOS 后，可见网卡比预期要多出一块，物理服务器安装了两块 PCIe 网卡，一块千兆，一块万兆，每块网卡有两个网口，那么理应在服务器看到的应该是 4个网口，即 ip ad 看到的应该是
root@node11 22:24:49 ~]$ip ad |grep enp 2: enp94s0f0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc mq master ovs-system state UP qlen 1000 3: enp24s0f0: &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; mtu 1500 qdisc mq portid 3cfdfe6c9e10 state DOWN qlen 1000 4: enp24s0f1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc mq master ovs-system portid 3cfdfe6c9e12 state UP qlen 1000 5: enp94s0f1: &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; mtu 1500 qdisc mq state DOWN qlen 1000 但是安装完 OS，发现多出一块网口 eno16 ，通过 ethtool 工具查看，发现该网口为千兆，且处于连接状态，最开始没多想，直接将该网口作为管理网络配置了，一切正常。</description></item><item><title>剑指 Offer（六）</title><link>https://zdyxry.github.io/2018/12/06/%E5%89%91%E6%8C%87-Offer%E5%85%AD/</link><pubDate>Thu, 06 Dec 2018 22:34:54 +0000</pubDate><guid>https://zdyxry.github.io/2018/12/06/%E5%89%91%E6%8C%87-Offer%E5%85%AD/</guid><description>链表中倒数第k个结点 链接到标题 # 使用两个指针，a 先遍历 k-1，之后一起遍历，直到a 指针到最后一个节点，则 b 为倒数 k 节点 class ListNode(object): def __init__(self, x): self.val = x self.next = None class Solution: def find_k_to_tail(self, head, k): if not head and k &amp;lt;= 0: return None a_head = head b_head = None for i in range(k - 1): if a_head.next != None: a_head = a_head.next else: return None b_head = head while a_head.next != None: a_head = a_head.next b_head = b_head.</description></item><item><title>剑指 Offer（五）</title><link>https://zdyxry.github.io/2018/12/05/%E5%89%91%E6%8C%87-Offer%E4%BA%94/</link><pubDate>Wed, 05 Dec 2018 20:25:38 +0000</pubDate><guid>https://zdyxry.github.io/2018/12/05/%E5%89%91%E6%8C%87-Offer%E4%BA%94/</guid><description> 调整数组顺序使奇数位于偶数前面 链接到标题 def reorder(nums, func): left, right = 0, len(nums) - 1 while left &amp;lt; right: while not func(nums[left]): left += 1 while func(nums[right]): right -= 1 if left &amp;lt; right: nums[left], nums[right] = nums[right], nums[left] def is_even(num): return (num &amp;amp; 1) == 0 调整数组顺序使奇数位于偶数前面，保持相对位置不变 链接到标题 def reorder2(nums): left = [num for num in nums if num &amp;amp; 1 != 0] right = [num for num in nums if num &amp;amp; 1 == 0] return left + right nums = [1,2,3,4,5,6,7] print reorder2(nums)</description></item><item><title>剑指 Offer（四）</title><link>https://zdyxry.github.io/2018/12/02/%E5%89%91%E6%8C%87-Offer%E5%9B%9B/</link><pubDate>Sun, 02 Dec 2018 20:11:24 +0000</pubDate><guid>https://zdyxry.github.io/2018/12/02/%E5%89%91%E6%8C%87-Offer%E5%9B%9B/</guid><description>在O(1)时间内删除链表结点 链接到标题 class ListNode(object): def __init__(self, x=None): self.val = x self.next = None def __del__(self): self.val = None self.next = None class Solution(object): def delete_list(self, list_head, to_delete): if not list_head or not to_delete: return False if to_delete.next != None: next_node = to_delete.next to_delete.val = next_node.val to_delete.next = next_node.next next_node.__del__() elif list_head == to_delete: list_head.__del__() to_delete.__del__() else: list_node = list_head while list_node.next != to_delete: list_node = list_node.next list_node.next = None to_delete.</description></item><item><title>个人常用工具</title><link>https://zdyxry.github.io/2018/12/02/%E4%B8%AA%E4%BA%BA%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/</link><pubDate>Sun, 02 Dec 2018 16:35:54 +0000</pubDate><guid>https://zdyxry.github.io/2018/12/02/%E4%B8%AA%E4%BA%BA%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/</guid><description>背景 链接到标题 公司标配 Thinkpad，也曾经折腾过 Linux，最终因为舍不得 Windows 下的各种软件，就老老实实用 Windows 。 周五的时候电脑故障，趁着重新配置开发环境的机会，整理下自己常用的软件|工具。
开发工具 链接到标题 编辑器 链接到标题 VIM 链接到标题 主力编辑器，因为平时写 Python 比较多，所以安装的插件并不多，主要用到的就是函数之间的跳转，具体配置在 github 。
VScode 链接到标题 在写代码的时候通常使用 vim ，但是看代码还是习惯于 VScode，主要是看代码用鼠标控制比较方便。 偶尔会碰到编写配置文件，比如 JSON/YAML 的时候，vim 写起来还是有些吃力，可能是我用的不到家吧。
终端 链接到标题 XShell 链接到标题 在 Windows 用的比较多的应该是 XShell，同时管理多台服务器简单高效，且有配套的 XSFTP，上传/下载文件很方便。
Tmux 链接到标题 在 Linux 上主要用系统自带的 Terminal 配合 Tmux 使用，主要原因是 Tmux 可以在多平台使用，不用针对不同平台记不同的快捷键（没错，说的就是 Jetbrains）。
并没有对 tmux 做太多定制化配置，因为有时候服务器上面不会允许你修改默认配置文件的，所以大部分用的默认配置，平时用的比较多的应该就是 Window &amp;amp; Panel 配合使用。
Hyper 链接到标题 好看。
周边工具 链接到标题 Wox 链接到标题 作为 Windows 下的 alfred， Wox 无疑是一个合格的软件，可以极大的提高效率。</description></item><item><title>Exponential backoff</title><link>https://zdyxry.github.io/2018/12/01/Exponential-backoff/</link><pubDate>Sat, 01 Dec 2018 20:26:02 +0000</pubDate><guid>https://zdyxry.github.io/2018/12/01/Exponential-backoff/</guid><description>背景 链接到标题 昨天看到 Ansible 关于 Linux reboot plugin 相关文章 时，看到了它关于重试等待的设计，了解了下 Exponential backoff，特此记录。
简介 链接到标题 假设存在需求：
获取服务器 A 启动时间 重启服务器 A 获取服务器 A 当前时间 其中第 2 点，我一般会重启服务器 A 后，不断的重连服务器 A 来判断服务器 A 是否正常启动，每次重连后等待，再次重试，设置一个最大超时时间，超过最大超时时间认为服务器 A 启动失败，任务失败。
那么什么是 Exponential backoff 呢？ 中文应该叫“指数退避”，意思就是每次重连失败后，等待的时候随着重试次数的增加而成指数增长，如果我们第1次重试等待时间为2s，则第2次重试等待时间为4s，第三次重试等待时间为8s，以此类推。
我理解最大的好处就是防止短时间内大量的重复错误，有时候当你知道你的操作是短时间无法完成的（比如重启服务器 A），那么该操作执行过程中，短时间内重试多次是没有意义的。当然我们也不能让重试等待时间无限的增长，我们可以设置一个最大的重试时间（不是最大超时时间），如果大于等于最大重试时间，则等待最大重试时间后再次重试。
具体实现 链接到标题 伪代码 链接到标题 Do some asynchronous operation. retries = 0 DO wait for (2^retries * 100) milliseconds status = Get the result of the asynchronous operation. IF status = SUCCESS retry = false ELSE IF status = NOT_READY retry = true ELSE IF status = THROTTLED retry = true ELSE Some other error occurred, so stop calling the API.</description></item><item><title>剑指 Offer（三）</title><link>https://zdyxry.github.io/2018/11/25/%E5%89%91%E6%8C%87-Offer%E4%B8%89/</link><pubDate>Sun, 25 Nov 2018 10:29:46 +0000</pubDate><guid>https://zdyxry.github.io/2018/11/25/%E5%89%91%E6%8C%87-Offer%E4%B8%89/</guid><description> 打印1到最大的n位数 链接到标题 # 将数组转换为字符 def print_number(number): is_beginning_0 = True num_len = len(number) for i in range(num_len): if is_beginning_0 and number[i] != &amp;#34;0&amp;#34;: is_beginning_0 = False if not is_beginning_0: print(&amp;#34;%c&amp;#34; % number[i], end=&amp;#34;&amp;#34;) print(&amp;#34;&amp;#34;) # 边界条件：n &amp;gt; 0 def print_1_to_max_of_n1(n): if n &amp;lt;= 0: return number = [&amp;#34;0&amp;#34;] * n while not increment(number): print_number(number) # 从最后一位开始计算，如果 最后一位增长为10，则重置为 0，且进位；如果首位增长为 10，则溢出 def increment(number): is_carry = 0 is_overflow = False sum = 0 num_len = len(number) for i in range(num_len - 1, -1, -1): sum = int(number[i]) + is_carry if i == num_len - 1: sum += 1 if sum &amp;gt;= 10: if i == 0: is_overflow = True else: sum -= 10 number[i] = str(sum) is_carry = 1 else: number[i] = str(sum) break return is_overflow def print_1_to_max_of_n2(n): if n &amp;lt;= 0: return number = [&amp;#34;0&amp;#34;] * n for i in range(10): number[0] = str(i) print_1_to_max_of_n_recursively(number, n, 0) # 始终找到最后一位，并将其计算 def print_1_to_max_of_n_recursively(number, num_len, index): if index == num_len - 1: print_number(number) return for i in range(10): number[index + 1] = str(i) print_1_to_max_of_n_recursively(number, num_len, index +1) print_number([&amp;#34;0&amp;#34;, &amp;#34;1&amp;#34;, &amp;#34;1&amp;#34;]) print_1_to_max_of_n1(2) print_1_to_max_of_n2(2)</description></item><item><title>Ansible最佳实践</title><link>https://zdyxry.github.io/2018/11/24/Ansible%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Sat, 24 Nov 2018 21:18:28 +0000</pubDate><guid>https://zdyxry.github.io/2018/11/24/Ansible%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>背景 链接到标题 说起来我真正负责过大批量服务器线上管理的时间，还是在16年负责运维的时候，那时候还都是通过 Shell 脚本来完成一些自动化的工作，当时觉得还不错，至少我觉得可定制化上还是很好的。
目前负责公司产品中一部分功能目前是通过 Shell 来完成的，但是 Shell 脚本在使用中存在一些弊端，最近在用 Ansible 来重写这部分功能，在重写过程中感受负责，又爱又恨，也有一些疑惑，特此记录。
Ansible 链接到标题 相信大家都或多或少听过 Ansible,Puppet,SaltStack 等等自动管理工具，它们的功能都很强大，但使用起来又不简单，Ansible 可以说是这里面上手最快的一个。
这里我不讲述 Ansible 具体的使用规则，大家看文档就好，我讲下我常用的几个场景：
批量查看、操作、拷贝 链接到标题 无论是作为一名开发，还是测试、运维，应该都碰到过需要管理多台服务器的情况，比如我们想要查看一个集群中所有节点的负责情况，那么我们可以执行：
$ ansible yiran-cluster -m raw -a &amp;#39;uptime&amp;#39; 192.168.67.39 | SUCCESS | rc=0 &amp;gt;&amp;gt; 20:23:24 up 3 days, 7:32, 4 users, load average: 14.97, 13.81, 12.55 Shared connection to 192.168.67.39 closed. 192.168.67.40 | SUCCESS | rc=0 &amp;gt;&amp;gt; 20:23:24 up 3 days, 7:32, 1 user, load average: 11.</description></item><item><title>剑指 Offer（二）</title><link>https://zdyxry.github.io/2018/11/20/%E5%89%91%E6%8C%87-Offer%E4%BA%8C/</link><pubDate>Tue, 20 Nov 2018 21:08:14 +0000</pubDate><guid>https://zdyxry.github.io/2018/11/20/%E5%89%91%E6%8C%87-Offer%E4%BA%8C/</guid><description> 数值的整数次方 链接到标题 # 给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。 # 考虑边界情况，base = 0, exponent &amp;lt; 0, exponent = 0 场景。 def equal_zero(num): if abs(num - 0.0) &amp;lt; 0.0000001: return True def power(base, exponent): if equal_zero(base): result = False if exponent == 0: result = 1 result = power(base, abs(exponent) &amp;gt;&amp;gt; 1) result *= result if abs(exponent) &amp;amp; 1 == 1: result *= base if exponent &amp;lt; 0: result = 1.0 / result return result power_value(2, 2)</description></item><item><title>Traceroute 简易实现</title><link>https://zdyxry.github.io/2018/11/18/Traceroute-%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0/</link><pubDate>Sun, 18 Nov 2018 12:33:35 +0000</pubDate><guid>https://zdyxry.github.io/2018/11/18/Traceroute-%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0/</guid><description>背景 链接到标题 在平时遇到网络问题时，我们通常会使用 ping,route,ip 等命令去 debug，当我们确定我们本机的网络配置及服务没有问题后，我通常会使用 traceroute 来判断网络走向。
最近公司搬家之后，整体网络架构进行了改进，随着配置的复杂化，稳定性相较于原来有了很大的下降，导致最近频繁使用 traceroute，一直使用它却不知道是怎么工作的，研究了一下，作为总结。
Traceroute 链接到标题 先上维基百科的解释：
traceroute，现代Linux系统称为tracepath，Windows系统称为tracert，是一种计算机网络工具。它可显示数据包在IP网络经过的路由器的IP地址。
我们通常使用无需特殊配置，直接用 traceroute 加上我们的目标地址即可，如：
root@yiran-workstation:~ $ traceroute 192.168.16.1 traceroute to 192.168.16.1 (192.168.16.1), 30 hops max, 60 byte packets 1 gateway (192.168.8.1) 19.469 ms 19.089 ms 18.911 ms 2 192.168.1.201 (192.168.1.201) 11.539 ms 11.423 ms 11.307 ms 3 192.168.16.1 (192.168.16.1) 18.289 ms 18.184 ms 18.064 ms 当我们想设置 TTL 数值时，我们可以使用 -m 参数:
root@yiran-workstation:~ $ traceroute 192.168.16.1 -m 2 traceroute to 192.</description></item><item><title>剑指 Offer（一）</title><link>https://zdyxry.github.io/2018/11/18/%E5%89%91%E6%8C%87-Offer%E4%B8%80/</link><pubDate>Sun, 18 Nov 2018 12:23:07 +0000</pubDate><guid>https://zdyxry.github.io/2018/11/18/%E5%89%91%E6%8C%87-Offer%E4%B8%80/</guid><description>Python 单实例模式 链接到标题 class Singleton(object): _instances = {} def __new__(cls, *args, **kwargs): if cls not in cls._instances: cls._instances[cls] = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls._instances[cls] class MySingleton(Singleton): def __init__(self, val): self.val = val a = MySingleton(1) b = MySingleton(1) print a.val print b.val 二维数组查找 链接到标题 def find_num(matrix, num): if not matrix: return False rows = len(matrix) cols = len(matrix[0]) row, col = rows - 1, 0 while row &amp;gt;= 0 or col &amp;lt;= cols -1: if matrix[row][col] == num: return num elif matrix[row][col] &amp;gt; num: row -= 1 else: col += 1 return False matrix = [[1,2,3,4], [5,6,7,8] ] print find_num(matrix, 7) 打印链表 链接到标题 class Links(self): def __init__(self, x): self.</description></item><item><title>超微服务器 IPMI 连接配置介绍</title><link>https://zdyxry.github.io/2018/11/10/%E8%B6%85%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%99%A8-IPMI-%E8%BF%9E%E6%8E%A5%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D/</link><pubDate>Sat, 10 Nov 2018 19:41:42 +0000</pubDate><guid>https://zdyxry.github.io/2018/11/10/%E8%B6%85%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%99%A8-IPMI-%E8%BF%9E%E6%8E%A5%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D/</guid><description>背景 链接到标题 目前在国内，大部分公司使用的服务器均为国内厂商的，如：华为、浪潮、联想、华三（H3C）、曙光等等。无论是从售后服务角度，还是国企央企招标采购角度，都是比较理想的。 但是还是有些国外的服务器如：惠普、超微、戴尔等等，占有着很大的市场。现在所在的公司提供一体机给客户，OEM 厂商就是超微和戴尔，今天来说说超微服务器 IPMI 连接配置。
IPMI 链接到标题 常规操作，先贴上维基百科的解释：
智能平台管理接口（Intelligent Platform Management Interface）原本是一种Intel架构的企业系统的周边设备所采用的一种工业标准。IPMI亦是一个开放的免费标准，用户无需支付额外的费用即可使用此标准。
就日常使用来说，IPMI 就是规模较大公司中常说的 带外网络 可连接控制的接口。一般用于物理服务器的管理，如：开关机、Web Console、硬件信息获取、硬件故障报警等功能。
大多数服务器厂商对该接口叫法不同，比如超微叫 IPMI，戴尔叫 RACADM ，惠普叫 iLo 等等。大部分厂商都会对该接口进行各种定制化功能，使用户上手更容易。而超微不同，超微的 IPMI 管理界面相当简（丑）陋，除了必备的功能外，没有特色功能。
连接方式 链接到标题 IPMI 接口就是一个普通的 1GbE 网口，常规连接到交换机上配置 IP 就可以正常管理与使用了，下面主要来说下三种不同的配置方式优势及区别。
Dedicated 链接到标题 专用模式，没有其他的乱七八糟配置，最简单的配置 IP 连接网线就可以直接使用。使用的网口就是 IPMI 的网口。
优势
最简配置，无须负责的网络策略。
劣势
需要单独的一根网线连接。在现阶段高密度服务器越来越流行的今天，一台普通的 2U4节点服务器，后面连接的网线可能达到：（1 IPMI + 2 管理 + 2 存储）*4 = 20根。这个数量是极为恐怖的，相信亲手布线过的同学一定深有体会。
Shared 链接到标题 共享模式。允许 IPMI 通过板载网口进行连接。这里要明确下，在有网络要求的公司，应该是不允许配置该模式的，因为客户要求网络要做到带内、带外的完全隔离，不能允许通过带内网络访问带外网络功能。但是小公司或者说一些测试环境，是可以选择该模式的。
优势
可以直接通过板载网口所在网络进行连接，无须为 IPMI 网口连接网线。 劣势 如果客户对网络有严格要求，那么是不允许配置的。
看论坛上有部分用户在进行该配置，且同时配置了 VLAN，出现了部分问题，未解决。 Failover（Default） 链接到标题 故障转移模式，也是服务器默认模式。该模式优先检查 IPMI 网口是否可以连通，如果可以连通，则直接连接，如果不可以连接，则尝试通过板载网口所在网络进行连接。</description></item><item><title>10月杂记</title><link>https://zdyxry.github.io/2018/11/09/10%E6%9C%88%E6%9D%82%E8%AE%B0/</link><pubDate>Fri, 09 Nov 2018 21:51:00 +0000</pubDate><guid>https://zdyxry.github.io/2018/11/09/10%E6%9C%88%E6%9D%82%E8%AE%B0/</guid><description>10 月杂记 链接到标题 上一次写博客还是在 9 月末，感觉 10月份是每年最忙的时候，今年尤其忙。
公司搬家 链接到标题 从 15年底加入公司以来，一直在北四环边上的融科资讯中心写字楼办公。最近融科坐不下了，加上合同到期，为了追求更大（价格更低）的办公环境，只能离开。
之前陆陆续续听说融科在写字楼中属于档次稍高的，一直没什么感觉，最近公司搬离了融科，才知道租金 17元/天/平米比 9元/天/平米真是不知道好到哪里去了。
公司约定好周五晚上收拾东西，周六搬家公司全部搬走，本来没个人什么事情。诡异的责任心作祟，导致周末两天都在公司帮忙，瞎忙。
新办公室的装修如果单独拍照片看上去还不错，但是太糙了，赶工期的各种痕迹暴露无遗。办公室各种味道，感觉都在呼吸着甲醛。
但是老板照常工作了，员工也只能戴着口罩继续工作，也是切身体会了空气净化器对于装修污染来说，作用真是小的可怜，只有通风才是王道。
个人搬家 链接到标题 算起来我来北京3年的时间，已经换了 5 个住处了，这种感觉很不好。想起了某同事 买了房子的感慨：“我每年都要被房东赶“，心酸。
去年为了私人空间，脱离了一起生活 2年的室友，独自跑到回龙观住自如。当时图着房子新，空间大，也就没有考虑最重要的一点：距离。
一直觉得一个人生活，住的远一点没什么所谓。但是真遇到在公司加班到9，10点钟，晚上又叫不到车时，只能去坐75分钟的地铁回家，太痛苦了，已经远远超过了心酸。
这次趁着公司搬家，我也花了 2 周的时间找房子，也约了不少中介看房子。最终选择了距离公司 2 公里的小区，走路 30min，骑车 10min。
第一次体验了步行上下班，哪怕在公司加班再晚，也可以 10min 就回到家里休息，不会对我产生负面的心情，真好。
工作进展 链接到标题 因为公司和个人的搬家，导致整个 10月都很疲惫，无论是身体上的，还是心理上的。
工作上分配给我的功能，在 11月9号，就是今天，老板说要可 demo 的状态，但还没完成，只能周末加班抢救一下，不知道是否能把进度抢救回来。
现在做的功能其实跟 Cobbler 很像，很多功能都是一样的。配合上虚拟化感觉就像 OpenStack Ironic（一直想看却没抽出时间）。都是对物理机进行功能管理，没什么新意。
个人进展 链接到标题 无。（忧伤）</description></item><item><title>Python socket 编程</title><link>https://zdyxry.github.io/2018/09/30/Python-socket-%E7%BC%96%E7%A8%8B/</link><pubDate>Sun, 30 Sep 2018 20:33:00 +0000</pubDate><guid>https://zdyxry.github.io/2018/09/30/Python-socket-%E7%BC%96%E7%A8%8B/</guid><description>背景 链接到标题 平时工作很少涉及到 Socket 相关，基本上都是 HTTP 之上的业务，最近看到 Real Python 的一篇博客，非常详细的讲解了 Python 下的 socket 编程，其中有两个示例觉得很好，帮助我理解了一些要点，记录一下。
多连接情况 链接到标题 Server 链接到标题 multiconn-server.py
#!/usr/bin/env python3 import sys import socket import selectors import types sel = selectors.DefaultSelector() def accept_wrapper(sock): conn, addr = sock.accept() # 前提条件：可读状态 print(&amp;#39;accepted connection from&amp;#39;, addr) conn.setblocking(False) # 置为非阻塞 data = types.SimpleNamespace(addr=addr, inb=b&amp;#39;&amp;#39;, outb=b&amp;#39;&amp;#39;) events = selectors.EVENT_READ | selectors.EVENT_WRITE sel.register(conn, events, data=data) # 注册事件到 select def service_connection(key, mask): sock = key.fileobj data = key.</description></item><item><title>硬件故障坑死人（持续更新）</title><link>https://zdyxry.github.io/2018/09/27/%E7%A1%AC%E4%BB%B6%E6%95%85%E9%9A%9C%E5%9D%91%E6%AD%BB%E4%BA%BA%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/</link><pubDate>Thu, 27 Sep 2018 09:35:44 +0000</pubDate><guid>https://zdyxry.github.io/2018/09/27/%E7%A1%AC%E4%BB%B6%E6%95%85%E9%9A%9C%E5%9D%91%E6%AD%BB%E4%BA%BA%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/</guid><description>背景 链接到标题 因为公司提供的产品不单单是软件形式提供，还对应的提供一体机形式（服务器 &amp;amp; 相应软件）。正式工作2年多也接触到了一些硬件的坑，特此总结。
磁盘 链接到标题 因为公司主要提供的产品是分布式存储和虚拟化相关产品，最直接的影响也是产生范围最大的影响就是磁盘了，会直接导致存储出现单副本等问题，从而产生数据恢复，影响集群稳定性。
固件版本 链接到标题 数据中心级别磁盘，相比于性能的要求，稳定性才是重中之重。大部分厂商的磁盘均支持 S.M.A.R.T. 规范，也就是“Self-Monitoring Analysis and Reporting Technology”，即“自我监测、分析及报告技术”，是一种自动的硬盘状态检测与预警系统和规范。我们可以通过相应命令比如 smartctl 直接获取磁盘相应信息，或者对磁盘进行检测。
S.M.A.R.T. 存在两个问题：
大部分厂商支持，意味着一部分厂商不支持 不同厂商对于自家磁盘的关键字定义不同 针对上述两个问题，我们只能说做到尽量多的测试踩坑，防止出现意外情况。
介绍了 S.M.A.R.T. ，我们来看看这节标题，固件。磁盘固件版本可以通过 smartctl 或者 sg_utils 工具获取：
[root@node 07:47:14 ~]$smartctl -i /dev/sdc smartctl 6.5 2016-05-07 r4318 [x86_64-linux-3.10.0-693.11.6.el7.smartx.1.x86_64] (local build) Copyright (C) 2002-16, Bruce Allen, Christian Franke, www.smartmontools.org === START OF INFORMATION SECTION === Model Family: Intel 730 and DC S35x0/3610/3700 Series SSDs Device Model: INTEL SSDSC2BA400G4 Serial Number: BTHV518009D3400NGN LU WWN Device Id: 5 5cd2e4 04c00728c Firmware Version: G2010160 User Capacity: 400,088,457,216 bytes [400 GB] Sector Sizes: 512 bytes logical, 4096 bytes physical Rotation Rate: Solid State Device Form Factor: 2.</description></item><item><title>OpenvSwitch Active-Backup failback 验证</title><link>https://zdyxry.github.io/2018/09/24/OpenvSwitch-Active-Backup-failback-%E9%AA%8C%E8%AF%81/</link><pubDate>Mon, 24 Sep 2018 17:36:22 +0000</pubDate><guid>https://zdyxry.github.io/2018/09/24/OpenvSwitch-Active-Backup-failback-%E9%AA%8C%E8%AF%81/</guid><description>背景 链接到标题 在虚拟化场景下，我们经常使用 OpenvSwitch 进行虚拟网络配置，最近看到有人问，Open vSwitch 的 bonding 模式 Avtice-Backup ，是否支持 failback 功能？ 虽然一直经常使用该模式，但是不知道当故障恢复后，是否会出现故障恢复？ 看官方文档中描述感觉有些模糊，来验证下。
验证方式 链接到标题 配置 VDS 链接到标题 [root@node 17:14:54 ~]$ovs-vsctl show b9956069-4101-4aab-a8a2-86db4f5ae390 Bridge ovsbr-mgt Port bond-mgt Interface &amp;#34;eno2&amp;#34; Interface &amp;#34;eno1&amp;#34; Port port-mgt tag: 0 Interface port-mgt type: internal Port ovsbr-mgt Interface ovsbr-mgt type: internal ovs_version: &amp;#34;2.3.1&amp;#34; [root@node 17:14:59 ~]$ovs-appctl bond/list bond type recircID slaves bond-mgt active-backup 0 eno1, eno2 故障前流量检测 链接到标题 [root@node 17:15:58 ~]$ifconfig eno1 eno1: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500 inet6 fe80::ec4:7aff:fe0f:8f68 prefixlen 64 scopeid 0x20&amp;lt;link&amp;gt; ether 0c:c4:7a:0f:8f:68 txqueuelen 1000 (Ethernet) RX packets 10046643 bytes 1131705628 (1.</description></item><item><title>cgroups 常用配置</title><link>https://zdyxry.github.io/2018/09/23/cgroups-%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/</link><pubDate>Sun, 23 Sep 2018 11:40:19 +0000</pubDate><guid>https://zdyxry.github.io/2018/09/23/cgroups-%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/</guid><description>背景 链接到标题 在软件运行过程中，我们经常需要限制 CPU 、内存、磁盘的使用，方式程序超出了限定边界范围。在 Linux 中，我们可以通过 cgroups 来进行限制。
cgroups 链接到标题 中文名称为控制组群，具体功能分类为：
资源限制：组可以被设置不超过设定的内存限制；这也包括虚拟内存。 优先级：一些组可能会得到大量的CPU或磁盘IO吞吐量。 结算：用来衡量系统确实把多少资源用到适合的目的上。 控制：冻结组或检查点和重启动。 下面来说下常见的使用方式
CPU 链接到标题 RedHat 官方文档中描述 cgroups 在 RHEL7/CentOS7 之后的版本需要通过 systemd 配置，不再使用 libcgconfig 方式。 但是在 systemd 的配置中，CPU 相关的配置项比较简单，或者说 OS 自动配置了很多，没有暴露出来。所以我们这里还是采用 libcgconfig 的配置方式。
在进行 CPU 限制之前，我们需要了解一下 NUMA 结构。什么是 NUMA？ NUMA 是一种为多处理器的计算机设计的内存，内存访问时间取决于内存相对于处理器的位置。在NUMA下，处理器访问它自己的本地内存的速度比非本地内存快一些。 不同的 Thread 在同一个 Core 上也会发生抢占情况，具体可以通过 sysbench 进行测试。
相关概念定义：
Socket：物理服务器上的 CPU 插槽 Core：物理 CPU 核心数 Thread：超线程 简单的说就是如果你的程序是计算密集型，那么尽可能的要让 CPU 限制在同一个 NUMA node 上。 查看 NUMA node 方式：</description></item><item><title>基于zeroconf实现节点自发现</title><link>https://zdyxry.github.io/2018/08/22/%E5%9F%BA%E4%BA%8Ezeroconf%E5%AE%9E%E7%8E%B0%E8%8A%82%E7%82%B9%E8%87%AA%E5%8F%91%E7%8E%B0/</link><pubDate>Wed, 22 Aug 2018 16:07:11 +0000</pubDate><guid>https://zdyxry.github.io/2018/08/22/%E5%9F%BA%E4%BA%8Ezeroconf%E5%AE%9E%E7%8E%B0%E8%8A%82%E7%82%B9%E8%87%AA%E5%8F%91%E7%8E%B0/</guid><description>背景 链接到标题 通常我们使用联网的电子设备，都会配置一个 IP 地址用于通信，一般采用 DHCP 配置，DHCP 有 lease 时间，如果超过 lease 时间又没有续约的话，产生的 IP 地址有可能发生改变，那么如何 自动识别我们的设备呢？ ZeroConf 是一个好的选择。
ZeroConf 链接到标题 以下介绍摘录自维基百科：
Zero-configuration networking (zeroconf) is a set of technologies that automatically creates a usable computer network based on the Internet Protocol Suite (TCP/IP) when computers or network peripherals are interconnected. It does not require manual operator intervention or special configuration servers. Without zeroconf, a network administrator must set up network services, such as Dynamic Host Configuration Protocol (DHCP) and Domain Name System (DNS), or configure each computer&amp;rsquo;s network settings manually.</description></item><item><title>Ansible 配置 IPv6 连接</title><link>https://zdyxry.github.io/2018/08/17/Ansible-%E9%85%8D%E7%BD%AE-IPv6-%E8%BF%9E%E6%8E%A5/</link><pubDate>Fri, 17 Aug 2018 13:43:40 +0000</pubDate><guid>https://zdyxry.github.io/2018/08/17/Ansible-%E9%85%8D%E7%BD%AE-IPv6-%E8%BF%9E%E6%8E%A5/</guid><description>背景 链接到标题 平时工作中因为通常需要远程操作较多 Linux 环境，引入了 Ansible，但是大都是通过 Ansible 远程命令的方式执行，少数的封装为 Playbook 也是很简单的配置。 最早的时候用过简单的 SaltStack，但是要安装 Agent，觉得不好用，在 16年早期的时候使用 Ansible，简单快捷（当然我对性能没有要求）。 最近需要把之前由 Shell &amp;amp; Python 拼装的一个服务统一用 Ansible 进行重写，又花了些时间看了看相关文档。发现大家操作远程机器无论是通过秘钥还是通过密码，都是基于 IPv4 的地址链接的，而有些机器是没有 IPv4 地址的，于是花费了些时间验证 Ansible IPv6 配置方式。
IPv6 链接到标题 IPv6 维基百科的解释是：网际协议第6版（英文：Internet Protocol version 6，缩写：IPv6）是网际协议（IP）的最新版本，用作互联网的网络层协议，用它来取代IPv4主要是为了解决IPv4地址枯竭问题，不过它也在其他很多方面对IPv4有所改进。我们目前日常中使用的地址都是 IPv4 的地址（比如：192.168.1.1）。 使用 IPv6 有一个好处是，可以通过 NDP（Neighbor Discovery Protocol）扫描二层网络内的所有的 IPv6 地址，方便我们使用，那么我们如何判断 IPv6 是否可以连通呢？ 可以通过 ping6 的方式判断，比如：
[root@node111 14:00:44 ~]$ping6 fe80::2487:93ff:fe9a:c546%port-mgt PING fe80::2487:93ff:fe9a:c546%port-mgt(fe80::2487:93ff:fe9a:c546%port-mgt) 56 data bytes 64 bytes from fe80::2487:93ff:fe9a:c546%port-mgt: icmp_seq=1 ttl=64 time=0.443 ms 64 bytes from fe80::2487:93ff:fe9a:c546%port-mgt: icmp_seq=2 ttl=64 time=0.</description></item><item><title>Pure Bash Bible</title><link>https://zdyxry.github.io/2018/08/11/Pure-Bash-Bible/</link><pubDate>Sat, 11 Aug 2018 11:06:55 +0000</pubDate><guid>https://zdyxry.github.io/2018/08/11/Pure-Bash-Bible/</guid><description>背景 链接到标题 逛 Github Trending 的时候，发现一个叫 pure bash bible 的项目，这个项目主要是介绍一些常用功能的 Bash 实现。 在日常使用中，Bash 作为大部分 Linux 发行版的默认 Shell 是使用最多的，尤其是进行一些简单的自动处理事件上很方便。但是我使用的时候通常会用 Bash、Sed、Awk、cut、timeout 等一些 Linux 命令相互配合使用。 如果你要维护的 Server 是一个比较少见的版本，比如：ESXi 5.0、XenServer 6.0 等版本，那么就会导致有些命令是缺失的，且无法安装，这时候就需要单独使用 Bash 来实现一些其他命令的功能。 pure bash bible 这个项目列举了很多常用常用功能，有一些比较有借鉴意义，在此记录。
字符串 链接到标题 删除字符串前后空格 链接到标题 trim_string（）{ # Ups：trim_string“example string” ： “ $ {1 ＃” $ {1 %% [！[：space：]] * } “ } ” ： “ $ {_ ％” $ {_ ## * [！[：space：]]} “ } ” printf &amp;#39;％s \ n &amp;#39; “ $ _ ” } $ trim_string “ Hello，World ” Hello, World $ name = “ John Black ” $ trim_string “ $ name ” John Black 删除字符串中所有空格 链接到标题 # shellcheck disable=SC2086,SC2048 trim_all() { # Usage: trim_all &amp;#34; example string &amp;#34; set -f set -- $* printf &amp;#39;%s\n&amp;#39; &amp;#34;$*&amp;#34; set +f } $ trim_all &amp;#34; Hello, World &amp;#34; Hello, World $ name=&amp;#34; John Black is my name.</description></item><item><title>Linux 安全清理 /boot 分区</title><link>https://zdyxry.github.io/2018/08/09/Linux-%E5%AE%89%E5%85%A8%E6%B8%85%E7%90%86-/boot-%E5%88%86%E5%8C%BA/</link><pubDate>Thu, 09 Aug 2018 15:00:25 +0000</pubDate><guid>https://zdyxry.github.io/2018/08/09/Linux-%E5%AE%89%E5%85%A8%E6%B8%85%E7%90%86-/boot-%E5%88%86%E5%8C%BA/</guid><description>背景 链接到标题 众多 Linux 发行版中，很多为了稳定性要求，Kernel 的版本还处于比较低的版本，比如：3.10.0-xxx（说的就是 CentOS）。 在工作中难免因为某些需求要升级 Kernel，最近遇到多次升级 Kernel 后导致 /boot 分区被占满的情况，特此查找资料记录。
升级方式 链接到标题 在之前的博客中提到过多次，CentOS 发行版升级一般采用 yum update ，Kernel 因为没有相关依赖，也可以直接 rpm -Uvh 的方式升级。
yum update 链接到标题 举个例子，比如这台 Linux，目前情况如下：
[root@node111 14:25:10 ~]$uname -a Linux node111 3.10.0-693.11.6.el7.smartx.1.x86_64 #1 SMP Tue Jan 16 22:09:10 CST 2018 x86_64 x86_64 x86_64 GNU/Linux [root@node111 14:25:12 ~]$ll /boot/ total 124929 -rw-r--r--. 1 root root 140924 Jan 16 2018 config-3.10.0-693.11.6.el7.smartx.1.x86_64 drwxr-xr-x. 3 root root 1024 Jul 2 07:23 efi drwxr-xr-x.</description></item><item><title>CentOS LiveCD 构建及修改方式</title><link>https://zdyxry.github.io/2018/08/04/CentOS-LiveCD-%E6%9E%84%E5%BB%BA%E5%8F%8A%E4%BF%AE%E6%94%B9%E6%96%B9%E5%BC%8F/</link><pubDate>Sat, 04 Aug 2018 06:39:28 +0000</pubDate><guid>https://zdyxry.github.io/2018/08/04/CentOS-LiveCD-%E6%9E%84%E5%BB%BA%E5%8F%8A%E4%BF%AE%E6%94%B9%E6%96%B9%E5%BC%8F/</guid><description>背景 链接到标题 Linux 作为目前服务器占比超过 60% 的操作系统，日常使用过程中，都是采用官方发布的 DVD ISO 安装，可以选择安装桌面版本还是 Minimal 版本。但是如果我们想要验证服务器硬件是否满足产品需求，就需要通过 Live CD 的方式先在内存中运行操作系统，然后进行硬件检测。通过这种方式可以在最小成本（无需安装操作系统到磁盘中）下完成硬件检测。目前 OpenStack 厂商 Mirantis 及云计算厂商 Nutanix 均采用该种方式进行产品安装前校验。要进行校验的第一步，就是构建属于我们自己的 Live CD ISO，下面以 CentOS 为例介绍如何构建和定制 Live CD ISO。
流程 链接到标题 准备构建工具 编写 KickStart 脚本 准备软件源 构建 构建工具 链接到标题 核心工具 livecd-creator。 构建环境为 CentOS 7。指定官方 yum repo：
root@yiran-30-250:/etc/yum.repos.d $ ll 总用量 56K -rw-r--r-- 1 root root 1.7K 1月 15 2018 CentOS-Base.repo -rw-r--r--. 1 root root 1.3K 12月 9 2015 CentOS-CR.repo -rw-r--r--. 1 root root 649 12月 9 2015 CentOS-Debuginfo.</description></item><item><title>RPM 常用构建方式</title><link>https://zdyxry.github.io/2018/07/28/RPM-%E5%B8%B8%E7%94%A8%E6%9E%84%E5%BB%BA%E6%96%B9%E5%BC%8F/</link><pubDate>Sat, 28 Jul 2018 06:47:40 +0000</pubDate><guid>https://zdyxry.github.io/2018/07/28/RPM-%E5%B8%B8%E7%94%A8%E6%9E%84%E5%BB%BA%E6%96%B9%E5%BC%8F/</guid><description>背景 链接到标题 作为一个标准化的产品，需要提供简单快捷的软件安装方式，比如 Python pip、 Ubuntu apt-get、SUSE zypper 或者是 CentOS/RHEL yum。都可以让用户快速的安装产品并上手使用，极大的节省了软件安装的时间。因为工作中使用的发行版是 CentOS/RHEL 系列，常用的方式是 RPM。 本文介绍下常用的集中构建 RPM 软件包方式，便于快速上手构建属于自己的 RPM。
RPM 介绍 链接到标题 什么是 RPM？ RPM 全称为 RedHat Package Manager，也就是常见的以 .rpm 为后缀的软件包。属于 RedHat 系列发行版的通用软件包解决方式。 在安装 CentOS(RHEL，以下 CentOS 均可适用于 RHEL)操作系统时，我们可以选择要安装的软件包，默认系统安装为 Minimal 模式，只包含系统必要的 RPM。
理论上操作系统上所有的软件都是通过 RPM 的方式安装的，比如常用的 Kernel、GCC、LS 等工具。
RPM 使用 链接到标题 在进行 RPM 安装时，通常会遇到一个问题：依赖。由于某些特定的软件包在使用时，要求系统必须安装其所依赖的软件才可以正常工作，因此我们需要查看要安装的软件包的依赖。
root@yiran-30-250:~/project/Blog master ✔ $ rpm -qR sos-3.2-35.el7.centos.3.noarch /usr/bin/python bzip2 config(sos) = 3.2-35.el7.centos.3 libxml2-python python(abi) = 2.7 python-six rpmlib(CompressedFileNames) &amp;lt;= 3.</description></item><item><title>Python logging 最佳实践-译</title><link>https://zdyxry.github.io/2018/07/22/Python-logging-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-%E8%AF%91/</link><pubDate>Sun, 22 Jul 2018 09:50:47 +0000</pubDate><guid>https://zdyxry.github.io/2018/07/22/Python-logging-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-%E8%AF%91/</guid><description>Python Logging 最佳实践
背景 链接到标题 最近在工作中要新增一个服务，需要处理服务日志，之前每次使用 logging 都是很简单的配置，没有 了解过最佳实践， google 到了 fangpenlin 写的一篇博客（https://fangpenlin.com/posts/2012/08/26/good-logging-practice-in-python/）， 很受用，因此翻译过来便于自己以后回顾使用，也希望大家能够正确配置日志，对运维同学友好些~
Good Logging practice in Python 链接到标题 在显示中，日志是重要的。当你在转账时，它们是转账记录。当飞机起飞时，黑匣子会记录所有事情。 如果某些事情发生了错误，人们可以通过阅读日志有机会弄清楚发生了什么。同样，在系统开发、排查 和运行中日志也是重要的。当你编写了一个服务，日志就是必须品。如果没有日志，我几乎不可能发现 错误如果服务已经挂掉。不仅仅是服务，日志对于桌面应用也是重要的。举个例子，当你的程序在你 客户电脑崩溃了，你可以让他们发送日志文件给你，你才有可能去查找为什么崩溃。相信我，你永远 不知道在不同的电脑环境中会发生什么奇怪的问题.
Print 不是个好主意 链接到标题 尽管日志很重要，但是不是所有的开发者都知道如何正确的使用。我见过一些开发者在开发过程中插入 一些 print ，在开发结束时删除这些 print。向下面这样：
print &amp;#39;Start reading database&amp;#39; records = model.read_recrods() print &amp;#39;# records&amp;#39;, records print &amp;#39;Updating record ...&amp;#39; model.update_records(records) print &amp;#39;done&amp;#39; 当程序是一个简单的脚本时这是工作的，但是对于一个复杂的系统，你最好不要通过这种途径记录日志。 第一，你在日志中无法记录重要的信息，你可能看到很多垃圾信息在日志中，但是没有找到任何有用的。 你也不能通过不修改代码的方式控制日志的输出，还有可能在不使用这些 print 的时候忘记删除掉。 所有的 print 信息都将输出到标准输出中，这个是要禁止的。当然你可以输出到标准错误输出中，但是 这仍不是记录日志的最佳实践。
使用 Python 标准库 Logging 链接到标题 所以，如何正确的记录日志？ 很简单，使用标准库中的 logging 模块。感谢 Python 社区，logging 在标准库中，它被设计的灵活且易用。你可以使用 logging 像下面这样：</description></item><item><title>Flask 流式响应</title><link>https://zdyxry.github.io/2018/07/08/Flask-%E6%B5%81%E5%BC%8F%E5%93%8D%E5%BA%94/</link><pubDate>Sun, 08 Jul 2018 09:44:24 +0000</pubDate><guid>https://zdyxry.github.io/2018/07/08/Flask-%E6%B5%81%E5%BC%8F%E5%93%8D%E5%BA%94/</guid><description>背景 链接到标题 在 web 场景下，经常会碰到下载文件的需求，通常小文件我们会采用 Flask send_file 或者 send_from_directory的方式，下载，但是当下载的文件是一个大压缩文件（&amp;gt;1GiB）时，这种方式就显得不友好了，我们需要采用流式下载的方式返回给客户端。
流式下载 链接到标题 简单实现：
from flask import Response @app.route(&amp;#34;/download/&amp;lt;file_path&amp;gt;&amp;#34;, methods=[&amp;#34;GET&amp;#34;]) def download(file_path): def generate(): if not os.path.exists(file_path): raise &amp;#34;File not found.&amp;#34; with open(file_path, &amp;#34;rb&amp;#34;) as f: while True: chunk = f.read(chunk_size=10 * 1024 * 1024) if not chunk: break yield chunk return Response(generate(), content_type=&amp;#34;application/octet-stream&amp;#34;) 运行 Flask app，可以正确下载文件，但是下载只有实时速度，没有文件总大小，导致无法知道下载进度，也没有文件类型，这些我们都可以通过增加 header 字段实现：
response = Response(generate(), mimetype=&amp;#39;application/gzip&amp;#39;) response.headers[&amp;#39;Content-Disposition&amp;#39;] = &amp;#39;attachment; filename={}.tar.gz&amp;#39;.format(&amp;#34;download_file&amp;#34;) response.headers[&amp;#39;content-length&amp;#39;] = os.stat(str(file_path)).st_size return response 这样，我们下载文件就可以看到文件类型、文件总大小及已下载大小了，其中 mimetype 根据实际压缩文件类型修改匹配即可。</description></item><item><title>将 CSV 文件转换为嵌套 Json 文件</title><link>https://zdyxry.github.io/2018/07/07/%E5%B0%86-CSV-%E6%96%87%E4%BB%B6%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%B5%8C%E5%A5%97-Json-%E6%96%87%E4%BB%B6/</link><pubDate>Sat, 07 Jul 2018 15:40:01 +0000</pubDate><guid>https://zdyxry.github.io/2018/07/07/%E5%B0%86-CSV-%E6%96%87%E4%BB%B6%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%B5%8C%E5%A5%97-Json-%E6%96%87%E4%BB%B6/</guid><description>使用方法 链接到标题 master ✗ $ python csv2json.py --help Usage: csv2json.py [OPTIONS] Convert csv file to json file. Options: --csv_file TEXT Input csv file abspath --json_file TEXT Output json file abspath --help Show this message and exit. 如果执行成功，命令行输出会像下面示例一样。
master ✗ $ python csv2json.py --csv_file ./test.csv --json_file ./yiran-test.json Convert csv file success, json file path is ./yiran-test.json 如果执行失败，则会提示具体失败原因。如：csv 文件无法找到。
master ✗ $ python csv2json.py --csv_file ./tes.csv --json_file ./yiran-test.json Failed to convert csv file with error [Errno 2] No such file or directory: u&amp;#39;.</description></item><item><title>Linux 主机异常信息收集</title><link>https://zdyxry.github.io/2018/07/06/Linux-%E4%B8%BB%E6%9C%BA%E5%BC%82%E5%B8%B8%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86/</link><pubDate>Fri, 06 Jul 2018 15:28:09 +0000</pubDate><guid>https://zdyxry.github.io/2018/07/06/Linux-%E4%B8%BB%E6%9C%BA%E5%BC%82%E5%B8%B8%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86/</guid><description>背景 链接到标题 通常情况下，一个公司内部都会有监控报警平台去支撑业务主机的稳定运行，比如 Nagios，Zabbix 或者 Prometheus 等其他工具。 这些工具，无论是 push 模式还是 pull 模式，都基于一个前提：主机是可访问的，或者说 agent/exporter 是可正常工作的。
如果运维人员在面对一台处于异常状态的主机，应该如何收集该主机的当前状态及相应日志呢？
企业级产品通常会内置工具用来采集异常状态信息，比如：
DELL 服务器如果出现了未知错误，拨打 400 询问问题， 一线客服会告诉你，打开 iDRAC 界面，点击“收集日志” 选项，会自动收集并下载节点信息 如果你是 RedHat RHEL 用户，主机出现异常状态，红帽技术支持工程师进行初始分析时，通常会使用 sosreport 工具 简介 链接到标题 sosreport 命令是一个工具，用来收集 RHEL 系统上的配置信息、系统信息和诊断信息。比如：正在运行的内核版本、已加载的模块，以及系统和服务的配置文件。同时，sosreport 支持用户自己编写 Plugin ，用于收集自己想要收集的服务日志及命令结果。
使用 链接到标题 sosreport 提供了 sosreport 命令行，用户可以直接执行该命令收集信息，默认收集所有 Plugin 信息。
执行流程 链接到标题 通过 which 命令查看提供 sosreport 命令行的文件，可以看到指向 sos.sosreport.main。
root@yiran-30-250:~/project/sos master ✔ $ which sosreport /usr/sbin/sosreport root@yiran-30-250:~/project/sos master ✔ $ cat /usr/sbin/sosreport #!/usr/bin/python import sys try: from sos.</description></item><item><title>使用 systemd timer 替换 crontab</title><link>https://zdyxry.github.io/2018/06/28/%E4%BD%BF%E7%94%A8-systemd-timer-%E6%9B%BF%E6%8D%A2-crontab/</link><pubDate>Thu, 28 Jun 2018 07:04:39 +0000</pubDate><guid>https://zdyxry.github.io/2018/06/28/%E4%BD%BF%E7%94%A8-systemd-timer-%E6%9B%BF%E6%8D%A2-crontab/</guid><description>在日常工作中，经常会用到定时任务配合脚本自动处理一些重复性工作，通常我会选择 crontab &amp;amp; flock &amp;amp; script 这样的组合进行配置， 最近了解了 systemd timer ，发现虽然配置上比 crontab 要麻烦一点（需要编写两个配置文件）， 但是其他的优势是 crontab 不具备的。
systemd timer 优势 链接到标题 systemd 会自动将定时任务事件记录在 systemd 日志中，可以通过 journalctl 轻松查找 可以配置定时器之间的依赖关系 定时器启动/关闭不需要再注释掉 crontab 中的某一行或移除 /etc/cron.d/ 下的某个文件，而是直接 start/stop/enable/disable 控制 自带锁机制，无需通过 flock 或脚本中添加锁文件的方式控制任务执行与否 使用方式 链接到标题 例如，我想要定时备份数据从开发机到服务器上，通常重要的文件采用 inotify &amp;amp; rsync 的方式同步，优先级较低的采用定时同步方式。
crontab 配置方式 链接到标题 编写 crontab 配置文件 链接到标题 crontab -e (或者在 /etc/cron.*/ 对应路径下编写配置文件) 0 1 * * * flock /usr/local/bin/system-backup.sh 手动触发定时任务 链接到标题 /usr/local/bin/system-backup.sh systemd timer 配置方式 链接到标题 编写 timer 配置文件 链接到标题 [Unit] Description=Perform system backup [Timer] OnCalendar=daily [Install] WantedBy=timers.</description></item><item><title>将 Json 转换为 Python Object(二)</title><link>https://zdyxry.github.io/2018/06/17/%E5%B0%86-Json-%E8%BD%AC%E6%8D%A2%E4%B8%BA-Python-Object%E4%BA%8C/</link><pubDate>Sun, 17 Jun 2018 21:00:49 +0000</pubDate><guid>https://zdyxry.github.io/2018/06/17/%E5%B0%86-Json-%E8%BD%AC%E6%8D%A2%E4%B8%BA-Python-Object%E4%BA%8C/</guid><description>最近趁着端午假期，终于把 《流畅的 Python》看完了，收获很大，书中某一章节介绍了 addict 库，可以将 Json 转换为 Python Object 。 今天看了看具体的实现方式，比 Stack Overflow 的回答完整，补发一篇博客学习下。
源码代码很少，补充一些关键变量用于了解整体实现流程。
import copy from pprint import pprint class Dict(dict): def __init__(__self, *args, **kwargs): print &amp;#39;init kwargs is &amp;#39;, kwargs object.__setattr__(__self, &amp;#39;__parent&amp;#39;, kwargs.pop(&amp;#39;__parent&amp;#39;, None)) object.__setattr__(__self, &amp;#39;__key&amp;#39;, kwargs.pop(&amp;#39;__key&amp;#39;, None)) for arg in args: if not arg: continue elif isinstance(arg, dict): for key, val in arg.items(): __self[key] = __self._hook(val) elif isinstance(arg, tuple) and (not isinstance(arg[0], tuple)): __self[arg[0]] = __self._hook(arg[1]) else: for key, val in iter(arg): __self[key] = __self.</description></item><item><title>将 Json 转换为 Python Object(一)</title><link>https://zdyxry.github.io/2018/06/09/%E5%B0%86-Json-%E8%BD%AC%E6%8D%A2%E4%B8%BA-Python-Object%E4%B8%80/</link><pubDate>Sat, 09 Jun 2018 11:43:49 +0000</pubDate><guid>https://zdyxry.github.io/2018/06/09/%E5%B0%86-Json-%E8%BD%AC%E6%8D%A2%E4%B8%BA-Python-Object%E4%B8%80/</guid><description>$ cat example.py import json class JSONObject: def __init__(self, dict): vars(self).update(dict) # this is valid json string data = &amp;#39;{&amp;#34;channel&amp;#34;:{&amp;#34;lastBuild&amp;#34;:&amp;#34;2013-11-12&amp;#34;, &amp;#34;component&amp;#34;:[&amp;#34;test1&amp;#34;, &amp;#34;test2&amp;#34;]}}&amp;#39; jsonobject = json.loads(data, object_hook=JSONObject) print(jsonobject.channel.component[0]) print(jsonobject.channel.lastBuild) $ python example.py test1 2013-11-12</description></item><item><title>奇怪的 Shell 作用域</title><link>https://zdyxry.github.io/2018/06/08/%E5%A5%87%E6%80%AA%E7%9A%84-Shell-%E4%BD%9C%E7%94%A8%E5%9F%9F/</link><pubDate>Fri, 08 Jun 2018 21:51:55 +0000</pubDate><guid>https://zdyxry.github.io/2018/06/08/%E5%A5%87%E6%80%AA%E7%9A%84-Shell-%E4%BD%9C%E7%94%A8%E5%9F%9F/</guid><description>工作中很多脚本都是用 Shell 和 Python 完成的，在上周环境中遇到了一个 Bug，导致部分功能失败，最后发现是 Shell 作用域的问题。
举例 链接到标题 $ tree . . ├── test.sh └── utils.sh 0 directories, 2 files $ cat utils.sh #!/usr/bin/env bash function echo_test { for i in `seq 2 3`;do echo &amp;#34;utils.sh&amp;#34; $i done } $ cat test.sh #!#/usr/bin/env bash . utils.sh for i in `seq 1 5`;do echo &amp;#34;before utils.sh&amp;#34; $i echo_test echo &amp;#34;after utils.sh&amp;#34; $i echo &amp;#34;#################&amp;#34; done $ bash test.sh before utils.</description></item><item><title>Hexo Git 管理</title><link>https://zdyxry.github.io/2018/05/29/Hexo-Git-%E7%AE%A1%E7%90%86/</link><pubDate>Tue, 29 May 2018 21:50:20 +0000</pubDate><guid>https://zdyxry.github.io/2018/05/29/Hexo-Git-%E7%AE%A1%E7%90%86/</guid><description>以A电脑的Hexo博客源文件迁移到B电脑为例：
一、对A电脑的操作如下： 链接到标题 1.在github新建仓库名为blog
2.上传A电脑本地Hexo博客的源文件夹至github的blog仓库，流程如下：
（1）删除根目录和主题目录下的.git文件夹
（2）修改根目录下的.gitignore文件为：
/.deploy_git
/public
（3）依次执行以下指令，同步源文件至github
$ git init $ git add . $ git commit -m &amp;#34;xxxxx&amp;#34; $ git remote add origin git@github.com:/blog_bak.git $ git push -u origin master 二、对B电脑的操作如下： 链接到标题 1.安装Git，并配置github账号下的B电脑的.ssh 2.安装Node.js 3.使用npm指令安装Hexo
$ npm install -g hexo-cli
$ npm install hexo-asset-image &amp;ndash;save 用于创建保存图片的文件夹
4.使用Git bash随便选择一个文件夹,执行git clone
$ git clone git@github.com:/blog.git
三、关于日常的改动流程（A，B两台电脑均使用的情况下）： 链接到标题 1.建议先检查更新git pull，将本地博客源文件更新至最新版本
$ git pull
2.然后可以新建或修改博客内容，进行预览等操作
$ hexo new &amp;#34;新的博客名称&amp;#34; $ hexo server 3.</description></item><item><title>Vim 配置</title><link>https://zdyxry.github.io/2018/05/29/Vim-%E9%85%8D%E7%BD%AE/</link><pubDate>Tue, 29 May 2018 21:46:32 +0000</pubDate><guid>https://zdyxry.github.io/2018/05/29/Vim-%E9%85%8D%E7%BD%AE/</guid><description>Vim 插件 链接到标题 待填坑</description></item><item><title>About Me</title><link>https://zdyxry.github.io/about/</link><pubDate>Tue, 29 May 2018 20:50:29 +0000</pubDate><guid>https://zdyxry.github.io/about/</guid><description>关于我 链接到标题 我是依然，日常使用 ID 是 zdyxry ，如果在其他地方遇到同名 ID 大概率是我。平时就是看书看剧，或者极少数玩玩游戏。 喜欢逛书店，如果看到书店，大概率会买书支持一下，书店还能运营下去不容易，比较喜欢传统书店，比如新华书店、上海书城。（像徐家汇书院、钟书阁的那种环境，虽然也会去，但是拍照的人实在太多，无法安静看书。）可能也不只是书店，逛街逛超市逛商场也是喜欢的，平时都是一个人待着，周末需要感受一下人气。
重度 RSS 用户，日常信息流是通过 RSS/Twitter 获取信息，初筛后通过 Notion Web Clipper 自动保存到 Notion 中（防止 404），定期阅读 Notion 中收藏的文章，整理到 Logseq 笔记中，最后发送到 Blog。
主要使用的操作系统是：
Garuda Linux MacOS Windows CentOS/openEuler 工作主要使用的软件：
Neovim tmux Ansible Packer Terraform govc VSCode 日常主要使用的软件：
Logseq Miniflux 滴答清单 随手记 Notion Onedrive 2015 - 2016 某公有云分布式存储运维（背锅）。
2016 - 2017 存储及虚拟化测试（挖坑）。
2017 - 2023 SRE（填坑）。
email: zdyxry#gmail.com
知识共享协议 链接到标题 关于知识共享协议的说明 链接到标题 Zhou Yiran（以下简称本人），是 “Yiran’s Blog” 博客（以下简称本博客）的拥有者。本博客上创造和发布的内容可用于传播和共享，对于本人发布的原创内容（包含图片、文字、音乐、视频）采用 CreativeCommons 3.</description></item><item><title>CentOS 多网卡多网关配置</title><link>https://zdyxry.github.io/2018/05/29/CentOS-%E5%A4%9A%E7%BD%91%E5%8D%A1%E5%A4%9A%E7%BD%91%E5%85%B3%E9%85%8D%E7%BD%AE/</link><pubDate>Tue, 29 May 2018 19:21:36 +0000</pubDate><guid>https://zdyxry.github.io/2018/05/29/CentOS-%E5%A4%9A%E7%BD%91%E5%8D%A1%E5%A4%9A%E7%BD%91%E5%85%B3%E9%85%8D%E7%BD%AE/</guid><description>背景 链接到标题 日常使用中，开发机通常只配置一块网卡，通常配置为 DHCP 自动获取 IP，这样就可以自动从 DHCP Server 获取 IP，网关，DNS Server 等配置，不用手动配置。
最近在工作中存在一种场景，一台服务器，多块网卡，需要对不同的网卡配置各自网关，查找了一些资料，也踩了一些坑，记录一下过程。
配置过程 链接到标题 官方配置 尝试在 /etc/sysconfig/network-scripts/ifcfg-&amp;lt;device&amp;gt; 中增加 GATEWAY 自动使之生效，实际上来看，多张网卡都配置 GATEWAY 字段会产生冲突，只能放弃通过网卡配置文件方式，尝试通过给网卡配置静态路由方式添加。
在 CentOS 官方网站查找配置静态路由方法，文档中提到通过编写网卡路由配置文件/etc/sysconfig/network-scripts/route-_&amp;lt;interface&amp;gt; ，配置完成后重启网络可以自动生效。
官方这种方式我尝试了两种文件编写方式，一种为192.168.64.0/20 via &amp;lt;gateway&amp;gt; dev &amp;lt;device&amp;gt;，一种为 ADDRESS0=xxxxx; NETMASK0=xxxxx; GATEWAY0=xxxxx。两种配置方式均没有生效，只能放弃。
手动配置 可以通过 route add 命令临时给第二章网卡配置网关，通过 route -n 查看是可以生效。但是因为最终目标是让路由随着网络服务（公司内部未使用 NetworkManager）Network 启动而配置，因此在 /etc/rc.local 中假如 route add 类似命令无法走通。
上述方法要么无法生效，要么存在无法持久化问题，均无法完成需求。 只能通过查看 网卡服务启动脚本来查找，查看 /etc/init.d/network （systemd 服务控制也是执行该文件），该文件是一个 Shell 脚本，找到路由配置相关：
2 # Add non interface-specific static-routes. 1 if [ -f /etc/sysconfig/static-routes ]; then 141 if [ -x /sbin/route ]; then 1 grep &amp;#34;^any&amp;#34; /etc/sysconfig/static-routes | while read ignore args ; do 2 /sbin/route add -$args 3 done 4 else 5 net_log $&amp;#34;Legacy static-route support not available: /sbin/route not found&amp;#34; 6 fi 7 fi 可以看到，在网络服务 network 启动过程中，会判断 /etc/sysconfig/static-routes 文件是否存在，如果存在则会通过 route 命令对该文件中记录以 any 开头的路由进行添加，添加命令为 /sbin/route add -$args。</description></item><item><title>2017年读书记录</title><link>https://zdyxry.github.io/2017/12/31/2017%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</link><pubDate>Sun, 31 Dec 2017 09:35:40 +0000</pubDate><guid>https://zdyxry.github.io/2017/12/31/2017%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</guid><description> 年终总结 链接到标题 计划 32 本，实际读完 23 本。
已读 链接到标题 《软技能*代码之外的生存指南》 《SRE：Google 运维解密》 《Vim 实用技巧》 《谈判力》 《黑客与画家》 《大话存储ⅰ》 《跟老齐学 Python》 《Python编程快速上手 让繁琐工作自动化》 《Think Python》 《奔跑吧 Ansible》 《Python核心编程（第二版）》 《Python 学习手册》 《嫌疑人X的献身》 《图解 HTTP》 《你是那人间的四月天》 《失乐园》 《活出生命的意义》 《Python核心编程（第三版）》 《深度工作》 《深度实践 KVM》 《Shell 脚本学习指南》 《浪潮之巅》 《人间失格》 在读 链接到标题 《Flask Web开发：基于Python的Web应用开发实战》 《哲学家们都干了些什么》 《二手时间》 《Python 算法教程》 想读 链接到标题 《Python Web开发实战》 《problem solving with algorithms and data structure using python 中文版》 《Fluent Python》 《大话数据结构》 《构建高性能WEB站点》 《C和指针》</description></item><item><title>I/O bursts with QEMU 2.6</title><link>https://zdyxry.github.io/2017/11/16/I/O-bursts-with-QEMU-2.6/</link><pubDate>Thu, 16 Nov 2017 22:34:48 +0000</pubDate><guid>https://zdyxry.github.io/2017/11/16/I/O-bursts-with-QEMU-2.6/</guid><description>I/O bursts with QEMU 2.6
近期在工作中要进行存储系统的 QOS 验证.公司 QOS 的实现方式参考了 QEMU 中的实现方式, 找来相关资料学习一下.
基本配置 链接到标题 首先,我将总结 QEMU 早期版本中已有的基本配置. 磁盘 I/O 有两处可以被限制的方式: 每秒钟字节数(bps) 和 每秒钟操作数( IOPS) . 对于它们中的每一种限制,用户既可以进行全局配置,也可以针对读写进行单独限制. 下面列举了总共 6 个不同的参数. I/O 限制可以使用 -dirve 参数中的 throttling ,或者使用 QMP 中的 blocks_set_io_throttle 命令. 下面是两种情况下的参数列举:
{ -DRIVE BLOCK_SET_IO_THROTTLE throttling.iops-total iops throttling.iops-read iops_rd throttling.iops-write iops_wr throttling.bps-total bps throttling.bps-read bps_rd throttling.bps-write bps_wr } 可以同时配置 IOPS 和 bps ,针对不同的场景我们可以选择是否配置读写限制,但是如果设置了 iops-total 参数, 那么不能配置 iops-read 和 iops-write. 这个规则同样适用于 bps-total 和 bps-read/write.</description></item><item><title>2016年读书记录</title><link>https://zdyxry.github.io/2016/12/31/2016%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</link><pubDate>Sat, 31 Dec 2016 09:30:00 +0000</pubDate><guid>https://zdyxry.github.io/2016/12/31/2016%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/</guid><description> 年终总结 链接到标题 初步养成读书习惯。计划读 5 本，实际读 13 本。
已读 链接到标题 《从零到一》 《岛上书店》 《大型网站技术架构 -核心原理与案例分析》 《OpenStack 实战指南》 《腾云-云计算和大数据时代网络技术揭秘》 《银河系搭车客指南》 《最好的我们》 《云计算架构-技术与实践》 《Pro-Git》 《云计算与OpenStack（虚拟机Nova篇）》 《Ceph cookbook 中文版》 《Google 工作整理术》 《信息存储与管理》 想读 链接到标题 《构建高性能WEB站点》 《Linux Shell脚本攻略》</description></item></channel></rss>