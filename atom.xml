<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yiran&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zdyxry.github.io/"/>
  <updated>2019-05-31T14:59:50.326Z</updated>
  <id>https://zdyxry.github.io/</id>
  
  <author>
    <name>yiran</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kubernetes 实战-集群部署</title>
    <link href="https://zdyxry.github.io/2019/05/31/Kubernetes-%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"/>
    <id>https://zdyxry.github.io/2019/05/31/Kubernetes-实战-集群部署/</id>
    <published>2019-05-31T13:22:51.000Z</published>
    <updated>2019-05-31T14:59:50.326Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>本来计划这周写一下如何定制 UEFI Linux 发行版的，但是计划赶不上变化，加上 UEFI 的改动比想象中的多，这周还是继续 k8s 系列好了。</p><p>说起来 k8s 写了 3 篇博客一直没有写集群部署相关的，一是当时对 k8s 了解不多，集群搭建大多是 GitHub 上的开源项目或 Rancher 快速搭建起来的；而是 k8s 官方工具 kubeadm 现在还有很多的不确定性，随着 v1.14 版本的发布，可用性大大提高，虽然还不支持 HA，但是要写一下了。</p><p>本文并不会介绍具体的部署步骤，望周知。</p><h2 id="Kubernetes-主要组件"><a href="#Kubernetes-主要组件" class="headerlink" title="Kubernetes 主要组件"></a>Kubernetes 主要组件</h2><p>因为主要说集群部署相关的，因此只列出 Master 和 Node 的主要组件，k8s 内部资源不再罗列：</p><h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><ul><li><p>apiserver： 集群中所有其他组件通过 apiserver 进行交互</p></li><li><p>scheduler： 按照 Pod 配置来对 Pod 进行节点调度</p></li><li><p>controller-manager：负责节点管理，资源的具体创建动作， <code>desired state management</code> 具体实行者</p></li><li><p>etcd：用于存储集群中数据的键值存储</p></li></ul><h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><ul><li><p>kubelet：处理 master 及其上运行的 node 之间的所有通信。它与容器运行时配合，负责部署和监控容器</p></li><li><p>kube-proxy：负责维护 node 的网络规则，还负责处理 Pod,Node和外部之间的通信</p></li><li><p>容器运行时：在节点上运行容器的具体实现，常见的有 Docker/rkt/CRI-O</p></li></ul><h2 id="Kubernetes-集群准备"><a href="#Kubernetes-集群准备" class="headerlink" title="Kubernetes 集群准备"></a>Kubernetes 集群准备</h2><h3 id="所需资源"><a href="#所需资源" class="headerlink" title="所需资源"></a>所需资源</h3><p>大部分的安装文档中，都会先写明 os 要求，计算 &amp; 存储资源需求，k8s 自身对资源消耗很低，通常的 2c4g + 30GiB 足够运行起来。</p><p>上面说完了硬件资源，那么我们来说下软件资源， k8s 作为一个容器编排系统，它需要的软件资源也是很重要的一部分，这里我们来说一下网络部分。</p><p>假设我们集群中存在 5 个节点，使用 <code>kubeadm init</code> 方式部署集群，那么最基本的，需要 5 个节点的 IP。那如果是高可用的集群呢？我们需要加一个 VIP，也就是 6 个 IP 地址。</p><p>在考虑了 IP 地址之后，我们来说下网段划分，以 flannel 为例，在创建网络时，每个 k8s 节点都会分配一段子网用于 Pod 分配 IP，这里的网段是不可以跟宿主机的网络重叠的，所以这里的网络划分也是一个很重要的资源。</p><p>具体其他网络类型，我会在之后的网络部分详细的写一下。</p><h3 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a>部署方式</h3><p>好了，现在我们已经有了资源了（无论是硬件资源还是软件资源），那么我们可以部署了，那此时采用什么方式部署，或者说怎么部署成了问题。</p><hr><p>首先说下最特殊的服务，kubelet，它作为节点的实际管控者，它如果运行在容器中，那么谁来控制kubelet 容器的启停呢？当节点故障恢复后，又如何自启动呢？最开始我使用 Rancher 部署的时候发现他们是将 kubelet 直接部署在容器中的，那是因为他们在节点上还有其他 Agent 用于管理节点，Rancher 相当于 k8s 集群之外的上帝，管控着一切。</p><p>当我们没有 Rancher 这类管理工具时，还是老老实实将 kubelet 以服务的形式部署在宿主机上吧。</p><hr><p>官方推荐使用 <code>kubeadm</code> 进行集群部署，简单快捷，只是还在快速迭代中，存在较多不确定性，那么现在那些大厂是如何部署的呢？</p><p>我花了点时间阅读了下 Github 上面一些关于 k8s 部署项目，简单的罗列一下：</p><table><thead><tr><th>项目名称</th><th>项目地址</th><th>星</th><th>服务运行方式</th><th>ha </th></tr></thead><tbody><tr><td>ansible-kubeadm</td><td><a href="https://github.com/4admin2root/ansible-kubeadm" target="_blank" rel="noopener">https://github.com/4admin2root/ansible-kubeadm</a></td><td>3</td><td>Static Pod</td><td>- </td></tr><tr><td>ansible-kubeadm-ha-cluster</td><td><a href="https://github.com/sv01a/ansible-kubeadm-ha-cluster" target="_blank" rel="noopener">https://github.com/sv01a/ansible-kubeadm-ha-cluster</a></td><td>5</td><td>Docker</td><td>keepvalied </td></tr><tr><td>kubeadm-playbook</td><td><a href="https://github.com/ReSearchITEng/kubeadm-playbook" target="_blank" rel="noopener">https://github.com/ReSearchITEng/kubeadm-playbook</a></td><td>117</td><td>Static Pod</td><td>keepalived </td></tr><tr><td>Kubernetes-ansible</td><td><a href="https://github.com/zhangguanzhang/Kubernetes-ansible" target="_blank" rel="noopener">https://github.com/zhangguanzhang/Kubernetes-ansible</a></td><td>208</td><td>Service</td><td>keepalived &amp; Haproxy</td></tr><tr><td>kubeadm-ansible</td><td><a href="https://github.com/kairen/kubeadm-ansible" target="_blank" rel="noopener">https://github.com/kairen/kubeadm-ansible</a></td><td>281</td><td>Static Pod</td><td>- </td></tr><tr><td>kubeadm-ha</td><td><a href="https://github.com/cookeem/kubeadm-ha" target="_blank" rel="noopener">https://github.com/cookeem/kubeadm-ha</a></td><td>502</td><td>Service</td><td>keepalived &amp; nginx </td></tr><tr><td>kubeasz</td><td><a href="https://github.com/easzlab/kubeasz" target="_blank" rel="noopener">https://github.com/easzlab/kubeasz</a></td><td>2987</td><td>Service</td><td>keepalived &amp; Haproxy </td></tr></tbody></table><p>可以看到虽然有些细微的差别，但是大家做的都围绕着一个目的，就是把上一节提到的 k8s 所有必要组件部署到集群中，我们根据服务运行方式和 HA 方式来说一下。</p><h2 id="服务运行方式"><a href="#服务运行方式" class="headerlink" title="服务运行方式"></a>服务运行方式</h2><p>根据我上面总结的各个项目，大体分为 3 类，分别是：Host Service、Docker、Static Pod。我们一个一个的过一下。</p><h3 id="Host-Service"><a href="#Host-Service" class="headerlink" title="Host Service"></a>Host Service</h3><p>在没有容器的时代，我们要部署一个服务，都是采用 Host Service 方式，我们在宿主机的 OS 上配置一个服务，管理方式可能是 init.d ，也可能是 systemd 。k8s 所有的服务都可以通过 Host Service 方式运行。</p><p>优点：</p><p>在 systemd 大法加持下，所有服务均可通过 systemd 统一管理，可以配置随着系统进行启停。</p><p>缺点：</p><p>如果通过 systemd 方式部署，那么服务配置修改、服务升级是一个大麻烦。</p><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p>既然我们觉得 Host Service 的方式服务配置修改、升级都比较麻烦，那我们直接通过 Docker 启动就好了，升级直接更新 image 重新启动，一切问题放佛都解决了。</p><p>但是考虑一个问题，当集群全部掉电，系统开机后，k8s 如何自启动？以 Docker 作为容器运行时的基础上，Docker 比较让人诟病的一点就是它是一个 Daemon，在这里反而是优点，我们可以设置 Docker 随开机自启动，并将 k8s 所有服务对应镜像设置为 <code>--restart=always</code>，就可以解决这个问题。</p><p>优点：</p><p>服务配置、升级方便。</p><p>缺点：</p><p>依赖于 Docker，若更换其他 CRI，无法处理极端情况。</p><h3 id="Static-Pod"><a href="#Static-Pod" class="headerlink" title="Static Pod"></a>Static Pod</h3><p>最后我们来说说 Static Pod，这种方式是 kubeadm 目前所采用的方式，也是 k8s 所推荐的方式。</p><p>什么是 Static Pod？其实就是字面意义， <code>静态 Pod</code>，k8s 不去调度的 Pod，而是由 kubelet 直接管理。前面我们在讨论 kubelet 提到，kubelet 是以服务的形式运行在宿主机上的，那么也就是 kubelet 的启停是通过 systemd 控制的，不受 k8s 控制。</p><p>Static Pod 由 kubelet 控制，当 kubelet 启动后，会自动拉起 Static Pod，且 Static Pod 不受 k8s 控制，无论是通过 kubectl 进行删除，还是通过 docker 对该 Pod 进行 stop 动作，kubelet 都会保证 Static Pod 正常运行。</p><p>这个方式很适合我们来处理 k8s 自身的服务，比如 apiserver/scheduler ，每个 master 节点上通过 Static Pod 配置，当 kubelet 启动后，自动拉起 apiserver/scheduler 等服务，那么 k8s 集群也就自启动了，也就解决了我们上面提到的集群全部掉电的情况。</p><p>优点：</p><p>跟随 kubelet 启停，完美适配 k8s 升级场景。</p><p>缺点：</p><p>因为随着 kubelet 启停，所以导致更新 kubelet 配置时需要指定 manifest 文件路径。</p><h2 id="HA-配置"><a href="#HA-配置" class="headerlink" title="HA 配置"></a>HA 配置</h2><p>k8s 作为一个基础架构服务，它的可用性关乎着我们整个业务的稳定，所以一定要保证不会出现单点故障。</p><p>在公有云场景下，由公有云提供 LB 的支持，只要我们部署了多个 master 节点，就不用担心了。</p><p>那在裸机场景下怎么办呢？</p><p>目前通用解决方案是 VIP 配合 LB（也就是 keepalived &amp; haproxy/nginx）。</p><p> keepalived 提供了 VIP。在 k8s 集群部署过程中，所有节点都指定 <code>controlPlaneEndpoint</code> 为 VIP，而 VIP 在集群中的一个 master 节点上。当 VIP 所在节点故障时， VIP 自动漂浮到集群中其他 master 节点上，保证高可用。</p><p> haproxy/nginx 作为 LB，当我们 k8s 集群中所有节点都连接一个 apiserver 时，通过 LB 按照既定策略将请求分发到集群中多个 master 节点上，保证性能。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>关于 k8s 集群的部署大概就是上述这些内容，具体的操作步骤都可以通过官网或者 github 找到相关资料。目前如果个人学习的话，直接通过 kubeadm 部署就好；如果想要在生产环境中部署，那么需要根据自身业务类型，仔细考虑自己是否需要 HA，如何配置 HA。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;本来计划这周写一下如何定制 UEFI Linux 发行版的，但是计划赶不上变化，加上 UEFI 的改动比想象中的多，这周还是继续 k8s 系
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://zdyxry.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>BIOS vs UEFI</title>
    <link href="https://zdyxry.github.io/2019/05/26/BIOS-vs-UEFI/"/>
    <id>https://zdyxry.github.io/2019/05/26/BIOS-vs-UEFI/</id>
    <published>2019-05-26T00:46:23.000Z</published>
    <updated>2019-05-26T00:47:06.498Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>大家应该都安装过操作系统，PC 或者服务器上。那么我们在安装操作系统时通常需要进入到 BIOS 或 UEFI 界面去安装。之前维护的一个 ISO 版本只支持 BIOS，最近有了支持 UEFI 安装的需求，今天来了解一下其中的差异，之后尝试编写一个支持 UEFI 的 KickStart 配置。</p><h2 id="Legacy-BIOS"><a href="#Legacy-BIOS" class="headerlink" title="Legacy BIOS"></a>Legacy BIOS</h2><p>按照惯例，引用维基百科中（不同语言对于名词解释信息可能是完全不同的，最好直接看英文）的解释：</p><blockquote><p>BIOS (/ˈbaɪɒs/ BY-oss; an acronym for Basic Input/Output System and also known as the System BIOS, ROM BIOS or PC BIOS) is non-volatile firmware used to perform hardware initialization during the booting process (power-on startup), and to provide runtime services for operating systems and programs.[1] The BIOS firmware comes pre-installed on a personal computer’s system board, and it is the first software to run when powered on. The name originates from the Basic Input/Output System used in the CP/M operating system in 1975.[2][3] The BIOS originally proprietary to the IBM PC has been reverse engineered by companies looking to create compatible systems. The interface of that original system serves as a de facto standard.</p></blockquote><p>主要功能有：</p><ul><li>POST - 在加载操作系统之前， 检测硬件确保没有错误</li><li>Bootstrap Loader - 寻找引导加载程序，并将控制权转</li><li>BIOS 驱动程序 - 低级驱动程序，使计算机可以对计算机硬件进行基本操作控制</li><li>BIOS/CMOS 设置 - 允许配置硬件设置，包括系统设置，如计算机密码，硬件时钟等</li></ul><h3 id="BIOS-vs-CMOS"><a href="#BIOS-vs-CMOS" class="headerlink" title="BIOS vs CMOS"></a>BIOS vs CMOS</h3><p>更改BIOS配置时，设置不会存储在BIOS芯片本身。相反，它们存储在一个特殊的存储芯片上，称为<code>CMOS</code>。</p><p>与大多数RAM芯片一样，存储BIOS设置的芯片使用CMOS工艺制造。它包含少量数据，通常为256 个字节。CMOS 芯片上的信息包括计算机上安装的磁盘驱动器类型，系统时钟的当前日期和时间以及计算机的引导顺序。</p><p>BIOS是非易失性的：即使计算机没电也会保留其信息，因为即使计算机已关闭，计算机也需要记住其BIOS设置。这就是为什么CMOS有自己的专用电源，即CMOS电池。 通常我们在使用电脑的时候，如果忘记了 BIOS 密码，无法更改 BIOS 设置时， 那么可以通过拔掉 CMOS 电池，再安装即可恢复。</p><h2 id="U-EFI"><a href="#U-EFI" class="headerlink" title="(U)EFI"></a>(U)EFI</h2><blockquote><p>The Unified Extensible Firmware Interface (UEFI) is a specification that defines a software interface between an operating system and platform firmware. UEFI replaces the Basic Input/Output System (BIOS) firmware interface originally present in all IBM PC-compatible personal computers,[1][2] with most UEFI firmware implementations providing legacy support for BIOS services. UEFI can support remote diagnostics and repair of computers, even with no operating system installed.[3]</p></blockquote><p>Intel 为了解决 BIOS 的一些缺点，提出了 EFI ，后来由于各种历史原因，EFI 转变为了 UEFI，其中的 U 是 <code>Unified</code> 。</p><p>那么 BIOS 有啥缺点呢？ 对于服务器级别来说，最大的缺点可能就是不支持 2TiB 以上空间的磁盘引导，关于为什么不支持大家可以自己查阅下 MBR vs GPT 相关资料，这里不详细解释。</p><p>那么老大哥提出了 UEFI，除了解决了引导磁盘的容量限制，还有如下优点（这几点看上去就跟普通用户没啥关系）：</p><ul><li>独立于CPU的架构</li><li>独立于CPU的驱动程序</li><li>灵活的pre-OS环境，包括网络功能</li><li>模块化设计</li><li>向后和向前兼容性</li></ul><h2 id="Linux-安装识别"><a href="#Linux-安装识别" class="headerlink" title="Linux 安装识别"></a>Linux 安装识别</h2><p>了解了大概的概念，那么我们来实际看看 Linux 分别从 BIOS 启动和 UEFI 启动安装有什么不同吧，接下来示例以 CentOS 为例。</p><p>首先我们看下 CentOS ISO 中的目录结构：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@dell-r720xd-1 CentOS-7.4]<span class="comment"># tree . -d 1</span></span><br><span class="line">.</span><br><span class="line">├── EFI <span class="comment"># EFI 模式下引导程序路径</span></span><br><span class="line">│   └── BOOT</span><br><span class="line">│       └── fonts</span><br><span class="line">├── images <span class="comment"># 系统启动镜像</span></span><br><span class="line">│   └── pxeboot</span><br><span class="line">├── isolinux   <span class="comment"># 默认引导程序路径，包括引导选项配置，引导背景图片，引导内核镜像等</span></span><br><span class="line">├── LiveOS    <span class="comment"># 临时加载镜像</span></span><br><span class="line">├── Packages   <span class="comment"># ISO 附带所有软件包，以 RPM 形式存放</span></span><br><span class="line">└── repodata    <span class="comment"># ISO 中 YUM Repo 配置文件，保存了在只做 YUM Repo 时指定的软件组，支持语言等信息</span></span><br><span class="line">1 [error opening dir]</span><br><span class="line"></span><br><span class="line">9 directories</span><br></pre></td></tr></table></figure><h3 id="BIOS"><a href="#BIOS" class="headerlink" title="BIOS"></a>BIOS</h3><p>我们来看下在 BIOS 下如何指定安装 KickStart 配置：</p><p>在 <code>isolinux/isolinux.cfg</code> 中指定即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">label linux</span><br><span class="line">  menu label ^Install yiran&apos;OS</span><br><span class="line">  menu default</span><br><span class="line">  kernel vmlinuz</span><br><span class="line">  append initrd=initrd.img inst.stage2=hd:LABEL=YIRANOS-2 ks=hd:LABEL=YIRANOS-2:/ks_yiranos.cfg quiet</span><br></pre></td></tr></table></figure></p><h3 id="UEFI"><a href="#UEFI" class="headerlink" title="UEFI"></a>UEFI</h3><p>跟 BIOS 一样，只是换了一个配置位置，只需要在 <code>EFI/BOOT/grub.cfg</code> 中指定 KS 配置即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">### BEGIN /etc/grub.d/10_linux ###</span><br><span class="line">menuentry &apos;Install CentOS 7&apos; --class fedora --class gnu-linux --class gnu --class os &#123;</span><br><span class="line">        linuxefi /images/pxeboot/vmlinuz inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 inst.ks=hd:LABEL=YIRANOS-2:/ks_yiranos.cfg quiet</span><br><span class="line">        initrdefi /images/pxeboot/initrd.img</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>随着越来越多服务器厂商将 UEFI 设置为默认模式，哪怕我们没有用到 UEFI 的高级功能，也最好将自己的 ISO 支持到 UEFI，避免因为 BIOS 的一些历史遗留问题导致后续技术支持出现困难。后续找时间写一下关于 UEFI 的 KickStart 配置文件。主要变化应该是在 <code>/boot</code> 分区部分有些变化，之后再说啦。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;大家应该都安装过操作系统，PC 或者服务器上。那么我们在安装操作系统时通常需要进入到 BIOS 或 UEFI 界面去安装。之前维护的一个 I
      
    
    </summary>
    
    
      <category term="Hardware" scheme="https://zdyxry.github.io/tags/Hardware/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 实战-镜像管理</title>
    <link href="https://zdyxry.github.io/2019/05/24/Kubernetes-%E5%AE%9E%E6%88%98-%E9%95%9C%E5%83%8F%E7%AE%A1%E7%90%86/"/>
    <id>https://zdyxry.github.io/2019/05/24/Kubernetes-实战-镜像管理/</id>
    <published>2019-05-23T23:35:08.000Z</published>
    <updated>2019-05-31T13:11:58.483Z</updated>
    
    <content type="html"><![CDATA[<h2 id="镜像组织形式"><a href="#镜像组织形式" class="headerlink" title="镜像组织形式"></a>镜像组织形式</h2><p>镜像默认采用 OverlayFS 方式挂载，最终效果是将多个目录结构合并为一个。</p><p>其中 lowerdir 为只读路径，最右层级最深。最终容器运行时会将 lowerdir 和 upperdir 合并挂在为 merged，对应容器中的路径为 <code>/</code> 。<br>举例：<br>镜像 testadd:0.5 版本的层级挂载如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@node111 16:02:24 overlay2]$docker inspect testadd:0.5 |grep Dir</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">                &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/693c140b9c70744a7a6ce93de56d3ac7549dae84195cbfac3486062d1ceaccf1/diff&quot;,</span><br><span class="line">                &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/e2f2ad8332a9567ad28495b28342b5f5712218e235b0129435abfc3c781be957/merged&quot;,</span><br><span class="line">                &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/e2f2ad8332a9567ad28495b28342b5f5712218e235b0129435abfc3c781be957/diff&quot;,</span><br><span class="line">                &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/e2f2ad8332a9567ad28495b28342b5f5712218e235b0129435abfc3c781be957/work&quot;</span><br></pre></td></tr></table></figure><p>运行该容器后，可以看到多了一个 overlay 方式挂载的路径：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node111 16:05:53 overlay2]$mount |grep overlay</span><br><span class="line">/dev/md127 on /var/lib/docker/overlay2 type ext4 (rw,relatime,data=ordered)</span><br><span class="line">overlay on /var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/merged type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/3NA23BH5OMSSXWTHGPRS6YENB7:/var/lib/docker/overlay2/l/QQVS7UVPGRBVHRZOBDPMMO4EQM:/var/lib/docker/overlay2/l/E7HTYBVD5SXSZRLVTETODOIANT,upperdir=/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/diff,workdir=/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/work)</span><br></pre></td></tr></table></figure><p>查看对应关系：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@node111 16:05:53 overlay2]$mount |grep overlay</span><br><span class="line">/dev/md127 on /var/lib/docker/overlay2 type ext4 (rw,relatime,data=ordered)</span><br><span class="line">overlay on /var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/merged type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/3NA23BH5OMSSXWTHGPRS6YENB7:/var/lib/docker/overlay2/l/QQVS7UVPGRBVHRZOBDPMMO4EQM:/var/lib/docker/overlay2/l/E7HTYBVD5SXSZRLVTETODOIANT,upperdir=/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/diff,workdir=/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/work)</span><br><span class="line">[root@node111 16:06:07 overlay2]$docker inspect testadd:0.5 |grep Dir                                                             </span><br><span class="line">            &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">                &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/693c140b9c70744a7a6ce93de56d3ac7549dae84195cbfac3486062d1ceaccf1/diff&quot;,</span><br><span class="line">                &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/e2f2ad8332a9567ad28495b28342b5f5712218e235b0129435abfc3c781be957/merged&quot;,</span><br><span class="line">                &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/e2f2ad8332a9567ad28495b28342b5f5712218e235b0129435abfc3c781be957/diff&quot;,</span><br><span class="line">                &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/e2f2ad8332a9567ad28495b28342b5f5712218e235b0129435abfc3c781be957/work&quot;</span><br><span class="line">[root@node111 16:06:54 overlay2]$docker ps </span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES</span><br><span class="line">e53180ddcd03        testadd:0.5         &quot;bash&quot;              About a minute ago   Up About a minute                       compassionate_roentgen</span><br><span class="line">[root@node111 16:07:06 overlay2]$docker inspect e53180ddcd03 |grep Dir</span><br><span class="line">                &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00-init/diff:/var/lib/docker/overlay2/e2f2ad8332a9567ad28495b28342b5f5712218e235b0129435abfc3c781be957/diff:/var/lib/docker/overlay2/693c140b9c70744a7a6ce93de56d3ac7549dae84195cbfac3486062d1ceaccf1/diff&quot;,</span><br><span class="line">                &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/merged&quot;,</span><br><span class="line">                &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/diff&quot;,</span><br><span class="line">                &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/work&quot;</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;&quot;,</span><br></pre></td></tr></table></figure><p>查看容器内根分区，并在容器内创建文件，查看容器挂载 merged 路径下文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@e53180ddcd03 /]# ls </span><br><span class="line">anaconda-post.log  bin  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  test  tmp  usr  var</span><br><span class="line">[root@e53180ddcd03 /]# touch yiran</span><br><span class="line">[root@e53180ddcd03 /]# ls anaconda-post.log  bin  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  test  tmp  usr  var  yiran</span><br><span class="line">[root@e53180ddcd03 /]#</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node111 16:07:13 overlay2]$cd e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/merged/</span><br><span class="line">You have mail in /var/spool/mail/root</span><br><span class="line">[root@node111 16:09:31 merged]$ls </span><br><span class="line">anaconda-post.log  bin  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  test  tmp  usr  var  yiran</span><br><span class="line">[root@node111 16:09:32 merged]$pwd</span><br><span class="line">/var/lib/docker/overlay2/e1378dc042b534fe00ca6f4565e399f30d56c81d434a30a6137cfae6b5355d00/merged</span><br></pre></td></tr></table></figure><p>在容器中创建的文件 <code>yiran</code> 在宿主机相应的挂载路径下是可以看到的。</p><h2 id="镜像管理"><a href="#镜像管理" class="headerlink" title="镜像管理"></a>镜像管理</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>默认从 docker.io 获取最新镜像，可以在 /etc/docker/daemon.json 中指定 <code>registry-mirrors</code> 或 <code>insecure-registries</code> 获取私有镜像。</p><p>下载完成后可以看到镜像下载完成后会在 <code>/var/lib/docker/overlay2/</code> 下保存一份镜像真实内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@node111 16:17:15 docker]$docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">[root@node111 16:17:19 docker]$du -sh . </span><br><span class="line">624K    .</span><br><span class="line">[root@node111 16:17:21 docker]$docker pull centos</span><br><span class="line">Using default tag: latest</span><br><span class="line">Trying to pull repository docker.io/library/centos ... </span><br><span class="line">latest: Pulling from docker.io/library/centos</span><br><span class="line">8ba884070f61: Pull complete </span><br><span class="line">Digest: sha256:b5e66c4651870a1ad435cd75922fe2cb943c9e973a9673822d1414824a1d0475</span><br><span class="line">Status: Downloaded newer image for docker.io/centos:latest</span><br><span class="line">[root@node111 16:18:06 docker]$docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">docker.io/centos    latest              9f38484d220f        2 months ago        202 MB</span><br><span class="line">[root@node111 16:18:17 docker]$du -sh . </span><br><span class="line">214M    .</span><br><span class="line">[root@node111 16:18:19 docker]$ll overlay2/*</span><br><span class="line">overlay2/6061bd16e5de86e56298bee1496e02998e6a029c34374b21bc0fa3c30202db55:</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x 16 root root 4096 May 22 16:18 diff</span><br><span class="line">-rw-r--r--  1 root root   26 May 22 16:17 link</span><br><span class="line"></span><br><span class="line">overlay2/l:</span><br><span class="line">total 4</span><br><span class="line">lrwxrwxrwx 1 root root 72 May 22 16:17 A3LUDFNM6LHHPQ6DVXCEI2KFYQ -&gt; ../6061bd16e5de86e56298bee1496e02998e6a029c34374b21bc0fa3c30202db55/diff</span><br></pre></td></tr></table></figure><h3 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h3><p>在不同服务构建镜像时，应保证最小化且合理分层，这样可以在最底层使用相同的 overlay 缓存，比较空间浪费。<br>参考 OpenStack Kolla 项目层级结构，openstack 所有服务镜像均基于 CentOS，60+服务镜像打包占用总空间为 5.48G：</p><p>注意：<br>尽量使用最精简基础镜像，只安装必要软件包<br>合理拆分服务<br>尽量保证 Dockerfile 中上层指令相同，若顺序不同则会构建出不同的层级，无法利用缓存特性<br>保证层级处于最精简状态<br>…</p><h3 id="上传"><a href="#上传" class="headerlink" title="上传"></a>上传</h3><p>当我们本地存在一份镜像，想要将其上传至指定仓库，我们需要先对镜像打 tag，举例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@node111 16:24:55 image]$docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">testadd             0.2                 4e47f016385b        35 seconds ago      202 MB</span><br><span class="line">docker.io/centos    latest              9f38484d220f        2 months ago        202 MB</span><br><span class="line">[root@node111 16:25:07 image]$cat /etc/docker/daemon.json </span><br><span class="line">&#123;</span><br><span class="line">  &quot;insecure-registries&quot;: [</span><br><span class="line">    &quot;192.168.27.146&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">[root@node111 16:25:12 image]$docker tag testadd:0.2 192.168.27.146/testadd:0.2</span><br><span class="line">[root@node111 16:25:28 image]$docker images</span><br><span class="line">REPOSITORY               TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">192.168.27.146/testadd   0.2                 4e47f016385b        58 seconds ago      202 MB</span><br><span class="line">testadd                  0.2                 4e47f016385b        58 seconds ago      202 MB</span><br><span class="line">docker.io/centos         latest              9f38484d220f        2 months ago        202 MB</span><br><span class="line">[root@node111 16:25:31 image]$docker push 192.168.27.146/testadd:0.2</span><br><span class="line">The push refers to a repository [192.168.27.146/testadd]</span><br><span class="line">f5011c15a820: Pushed </span><br><span class="line">d69483a6face: Layer already exists </span><br><span class="line">0.2: digest: sha256:072611b154402d0760d7860374eb5dc706712319331710b4f046e043ba2cc26a size: 736</span><br></pre></td></tr></table></figure><p>上传到指定仓库之后，其他节点可以修改 docker 配置文件，重启 docker 后即可直接下载指定镜像。</p><h2 id="Kubernetes-镜像管理"><a href="#Kubernetes-镜像管理" class="headerlink" title="Kubernetes 镜像管理"></a>Kubernetes 镜像管理</h2><h3 id="下载-1"><a href="#下载-1" class="headerlink" title="下载"></a>下载</h3><p>在 k8s 中，没有针对镜像仓库的集群级别配置，节点各自维护自己的仓库地址，如果需要增加仓库地址，需要修改集群中所有节点配置文件，重启 docker 生效。</p><hr><p><strong>20190531 更新</strong></p><p>针对 k8s 中私有仓库的使用更新：</p><ol><li>当 k8s 想要配置 http 私有仓库时，只能通过在节点上修改 docker 配置文件 /etc/docker/daemon.json ，添加  “insecure-registries” 字段，并重启 docker 后，k8s 可以自动拉取所需镜像；</li><li>当 k8s 配置 https 私有仓库时，只需将根证书拷贝到 k8s 节点的 /etc/docker/certs.d/&lt;domain.com&gt;/ 下，创建 k8s secret docker-registry ，在 YAML 中指定拉取镜像所需的 secret，就可以自动拉取了。</li></ol><hr><p>可以在 k8s 中配置指定仓库的 secret 类型为 docker-registry 来配置私有仓库的用户名密码，在之后创建 Pod 时指定该 secret 名称即可自动下载，具体操作如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@node3 ~]# kubectl create secret docker-registry regsecret --docker-server=192.168.30.111 --docker-username=admin --docker-password=Harbor12345 --docker-email=yiran@smartx.com</span><br><span class="line">[root@node3 ~]# kubectl get secret regsecret -o yaml</span><br><span class="line">[root@node3 ~]# cat private-reg-pod.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: private-reg</span><br><span class="line">spec:</span><br><span class="line">  nodeSelector:</span><br><span class="line">    type: &quot;233&quot;</span><br><span class="line">  containers:</span><br><span class="line">  - name: private-reg-container</span><br><span class="line">    image: 192.168.30.111/test/busybox:latest</span><br><span class="line">    args: [/bin/sh, -c,</span><br><span class="line">           &apos;i=0; while true; do echo &quot;$i: $(date)&quot;; i=$((i+1)); sleep 1; done&apos;]</span><br><span class="line">  imagePullSecrets:</span><br><span class="line">  - name: regsecret</span><br></pre></td></tr></table></figure><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>k8s 自身不提供主动删除节点中无用镜像操作，默认通过配置 GC 参数删除无用镜像。</p><p>不推荐使用其它管理工具或手工进行容器和镜像的清理，因为kubelet需要通过容器来判断pod的运行状态，如果使用其它方式清除容器有可能影响kubelet的正常工作。</p><ul><li><p>–image-gc-high-threshold int32<br>当用于存储镜像的磁盘使用率达到百分之–image-gc-high-threshold时将触发镜像回收(default 85)</p></li><li><p>–image-gc-low-threshold int32<br>删除最近最久未使用（LRU，Least Recently Used）的镜像直到磁盘使用率降为百分之–image-gc-low-threshold或无镜像可删为止 (default 80)</p></li></ul><h2 id="CNCF-Harbor"><a href="#CNCF-Harbor" class="headerlink" title="CNCF-Harbor"></a>CNCF-Harbor</h2><p>Harbor项目是一个具有存储、签署和扫描内容功能的开源云原生registry。Harbor 由 VMware 创建，通过添加用户所需功能（如安全性，身份认证和管理）来扩展开源Docker Distribution，并支持在registry之间复制镜像。Harbor还提供高级安全功能，比如漏洞分析，基于角色的访问控制，活动审计等等。<br>主要功能：</p><ul><li>角色控制/身份校验</li><li>镜像复制</li><li>漏洞扫描</li><li>…</li></ul><p>资源消耗情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node111 11:09:02 harbor]$docker stats --no-stream</span><br><span class="line">CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS</span><br><span class="line">90dcf1505eb0        nginx               0.02%               4.152MiB / 15.51GiB   0.03%               6.53MB / 6.77MB     0B / 0B             7</span><br><span class="line">75945a1aa004        harbor-jobservice   0.12%               9.109MiB / 15.51GiB   0.06%               1.24MB / 15.1MB     0B / 0B             13</span><br><span class="line">000f6f349708        harbor-portal       0.07%               1.676MiB / 15.51GiB   0.01%               200kB / 5.47MB      0B / 0B             2</span><br><span class="line">84635df4fe51        harbor-core         0.53%               12.96MiB / 15.51GiB   0.08%               3.62MB / 2.84MB     0B / 0B             14</span><br><span class="line">c6e53b654127        redis               0.18%               6.816MiB / 15.51GiB   0.04%               15.4MB / 1.41MB     0B / 180kB          5</span><br><span class="line">9048a587cf29        registryctl         0.06%               3.031MiB / 15.51GiB   0.02%               114kB / 87.8kB      0B / 0B             7</span><br><span class="line">d88f7c4b36c5        harbor-db           0.03%               8.09MiB / 15.51GiB    0.05%               929kB / 1.57MB      0B / 4.65MB         11</span><br><span class="line">83c474625566        registry            0.20%               19.45MiB / 15.51GiB   0.12%               1.04MB / 335kB      0B / 1.65MB         16</span><br><span class="line">5a3d2707e96f        harbor-log          0.00%               2.152MiB / 15.51GiB   0.01%               766kB / 147kB       81.9kB / 16.4kB     12</span><br></pre></td></tr></table></figure><p>默认推荐部署方式：docker-composer<br>k8s 推荐部署方式：Helm</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在日常开发过程中，公司内部部署私有仓库（比如 Harbor）可以控制用户角色，方便测试同学快速获取最新版本镜像。<br>在融合产品生命周期中，只有升级场景涉及到镜像的导入、上传、下载、删除操作，因此没必要在集群中持续运行一个仓库服务，浪费资源。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>openstack kolla 项目，目标是通过容器化方式部署 openstack，便于 openstack 滚动升级。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;镜像组织形式&quot;&gt;&lt;a href=&quot;#镜像组织形式&quot; class=&quot;headerlink&quot; title=&quot;镜像组织形式&quot;&gt;&lt;/a&gt;镜像组织形式&lt;/h2&gt;&lt;p&gt;镜像默认采用 OverlayFS 方式挂载，最终效果是将多个目录结构合并为一个。&lt;/p&gt;
&lt;p&gt;其中 low
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://zdyxry.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 实战-日志处理</title>
    <link href="https://zdyxry.github.io/2019/05/17/Kubernetes-%E5%AE%9E%E6%88%98-%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86/"/>
    <id>https://zdyxry.github.io/2019/05/17/Kubernetes-实战-日志处理/</id>
    <published>2019-05-17T00:50:44.000Z</published>
    <updated>2019-05-20T12:48:02.007Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基础日志处理"><a href="#基础日志处理" class="headerlink" title="基础日志处理"></a>基础日志处理</h2><p>在 Kubernetes（简称 k8s）中，所有应用在 Pod（k8s 管理容器最小单位）中运行，标准处理方式为将日志打印到标准日志输出和标准错误输出，这样我们可以通过 <code>kuberctl logs</code> 关键字获取容器运行时日志，根据容器运行时的类型不同，日志保存路径也不同，以 Docker 为例，所有真实日志均在 <code>/var/lib/docker/</code> 路径下，下面我们来看一个例子：</p><p>在 k8s 中创建一个 Pod，Pod 中指定打印当前时间到标准输出中：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">counter</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">count</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    args:</span> <span class="string">[/bin/sh,</span> <span class="bullet">-c,</span></span><br><span class="line">            <span class="string">'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done'</span><span class="string">]</span></span><br></pre></td></tr></table></figure><p>运行该 Pod，通过 <code>kubectl logs</code> 获取当前 Pod 日志：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 blog]<span class="comment"># kubectl get pod |grep counter</span></span><br><span class="line">counter            1/1     Running   0          9s</span><br><span class="line">[root@node1 blog]<span class="comment"># kubectl logs counter</span></span><br><span class="line">0: Fri May 17 00:34:01 UTC 2019</span><br><span class="line">1: Fri May 17 00:34:02 UTC 2019</span><br><span class="line">2: Fri May 17 00:34:03 UTC 2019</span><br><span class="line">3: Fri May 17 00:34:04 UTC 2019</span><br><span class="line">4: Fri May 17 00:34:05 UTC 2019</span><br><span class="line">5: Fri May 17 00:34:06 UTC 2019</span><br><span class="line">6: Fri May 17 00:34:07 UTC 2019</span><br><span class="line">7: Fri May 17 00:34:08 UTC 2019</span><br><span class="line">8: Fri May 17 00:34:09 UTC 2019</span><br><span class="line">9: Fri May 17 00:34:10 UTC 2019</span><br><span class="line">10: Fri May 17 00:34:11 UTC 2019</span><br><span class="line">11: Fri May 17 00:34:12 UTC 2019</span><br><span class="line">12: Fri May 17 00:34:13 UTC 2019</span><br></pre></td></tr></table></figure><p>这里如果使用 <code>-f</code> 选项，可以持续输出该 Pod 日志。</p><p>那么我们如何找到该容器对应的实际日志文件呢？</p><p>我们可以现在 Docker 中找到该容器信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 blog]<span class="comment"># docker ps |grep count</span></span><br><span class="line">012e0352b193        busybox                                             <span class="string">"/bin/sh -c 'i=0; wh…"</span>   2 minutes ago       Up 2 minutes                            k8s_count_counter_default_75792a2a-783b-11e9-a3d9-525400aea01a_0</span><br></pre></td></tr></table></figure><p>可以看到在 Docker 中该容器名称为    <code>k8s_count_counter_default_75792a2a-783b-11e9-a3d9-525400aea01a_0</code>  ，我们先不去管最后的 UUID 是什么含义，先看前几个字段，跟集群信息关联可以看到，分别是：k8s，容器名称，Pod 名称，namespaces 名称。那么我们来看下这个容器在 Docker 中的配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 containers]<span class="comment"># pwd</span></span><br><span class="line">/var/lib/docker/containers</span><br><span class="line">[root@node1 containers]<span class="comment"># ls</span></span><br><span class="line">012e0352b19387170b903aff7c73c02fcd023c2f53cbe5b908392ff4e1a126e2  </span><br><span class="line">...</span><br><span class="line">5c9e765f68a15d5510870179160c59d45d0287b9f92265687d6c37a3557a1017  c563c36b0d3d28ea611b270bc1609ae9c0e720c1c1f85ba669cdab5f7099b77b</span><br></pre></td></tr></table></figure><p>在 Docker 容器路径下，我们看到了很多以不知道什么 ID 明明的子目录，最开始以为是我们 <code>docker ps</code> 中看到的最后 uuid，但是发现对不上，那么我们可以查看下 Pod 的详细信息来试图获取:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 containers]<span class="comment"># kubectl describe pod counter</span></span><br><span class="line">Name:         counter</span><br><span class="line">Namespace:    default</span><br><span class="line">Node:         192.168.27.231/192.168.27.231</span><br><span class="line">Start Time:   Fri, 17 May 2019 08:33:58 +0800</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Status:       Running</span><br><span class="line">IP:           172.20.2.13</span><br><span class="line">Containers:</span><br><span class="line">  count:</span><br><span class="line">    Container ID:  docker://012e0352b19387170b903aff7c73c02fcd023c2f53cbe5b908392ff4e1a126e2</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker-pullable://busybox@sha256:4b6ad3a68d34da29bf7c8ccb5d355ba8b4babcad1f99798204e7abb43e54ee3d</span><br></pre></td></tr></table></figure><p>忽略掉无关信息，我们可以看到 <code>Container ID</code> 字段，这里对应的 ID 就是在 <code>/var/lib/docker/containers/</code> 下的 ID，找到了 ID，我们可以来看看具体的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 012e0352b19387170b903aff7c73c02fcd023c2f53cbe5b908392ff4e1a126e2]# tree .</span><br><span class="line">.</span><br><span class="line">├── 012e0352b19387170b903aff7c73c02fcd023c2f53cbe5b908392ff4e1a126e2-json.log</span><br><span class="line">├── checkpoints</span><br><span class="line">├── config.v2.json</span><br><span class="line">├── hostconfig.json</span><br><span class="line">└── mounts</span><br><span class="line"></span><br><span class="line">2 directories, 3 files</span><br></pre></td></tr></table></figure><p>可以看到有配置文件和日志文件，我们今天只来讨论日志，那么我们看下这个日志文件的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 012e0352b19387170b903aff7c73c02fcd023c2f53cbe5b908392ff4e1a126e2]<span class="comment"># tail 012e0352b19387170b903aff7c73c02fcd023c2f53cbe5b908392ff4e1a126e2-json.log</span></span><br><span class="line">&#123;<span class="string">"log"</span>:<span class="string">"706: Fri May 17 00:45:48 UTC 2019\n"</span>,<span class="string">"stream"</span>:<span class="string">"stdout"</span>,<span class="string">"time"</span>:<span class="string">"2019-05-17T00:45:48.913451073Z"</span>&#125;</span><br><span class="line">&#123;<span class="string">"log"</span>:<span class="string">"707: Fri May 17 00:45:49 UTC 2019\n"</span>,<span class="string">"stream"</span>:<span class="string">"stdout"</span>,<span class="string">"time"</span>:<span class="string">"2019-05-17T00:45:49.915605471Z"</span>&#125;</span><br><span class="line">&#123;<span class="string">"log"</span>:<span class="string">"708: Fri May 17 00:45:50 UTC 2019\n"</span>,<span class="string">"stream"</span>:<span class="string">"stdout"</span>,<span class="string">"time"</span>:<span class="string">"2019-05-17T00:45:50.917823388Z"</span>&#125;,</span><br><span class="line">&#123;<span class="string">"log"</span>:<span class="string">"713: Fri May 17 00:45:55 UTC 2019\n"</span>,<span class="string">"stream"</span>:<span class="string">"stdout"</span>,<span class="string">"time"</span>:<span class="string">"2019-05-17T00:45:55.928645971Z"</span>&#125;</span><br><span class="line">&#123;<span class="string">"log"</span>:<span class="string">"714: Fri May 17 00:45:56 UTC 2019\n"</span>,<span class="string">"stream"</span>:<span class="string">"stdout"</span>,<span class="string">"time"</span>:<span class="string">"2019-05-17T00:45:56.930660054Z"</span>&#125;</span><br><span class="line">&#123;<span class="string">"log"</span>:<span class="string">"715: Fri May 17 00:45:57 UTC 2019\n"</span>,<span class="string">"stream"</span>:<span class="string">"stdout"</span>,<span class="string">"time"</span>:<span class="string">"2019-05-17T00:45:57.932763561Z"</span>&#125;</span><br></pre></td></tr></table></figure><p>可以看到这里日志输出是 JSON 格式的，这里跟 <code>kubectl logs</code> 输出不一致啊，为啥这里是 JSON 呢？ 其实这跟你的 Docker 配置有关，具体的配置可以在 Docker 配置中看到，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 docker]<span class="comment"># pwd</span></span><br><span class="line">/etc/docker</span><br><span class="line">[root@node1 docker]<span class="comment"># cat daemon.json</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"registry-mirrors"</span>: [</span><br><span class="line">    <span class="string">"https://dockerhub.azk8s.cn"</span>,</span><br><span class="line">    <span class="string">"https://docker.mirrors.ustc.edu.cn"</span>,</span><br><span class="line">    <span class="string">"http://hub-mirror.c.163.com"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"max-concurrent-downloads"</span>: 10,</span><br><span class="line">  <span class="string">"log-driver"</span>: <span class="string">"json-file"</span>,</span><br><span class="line">  <span class="string">"log-level"</span>: <span class="string">"warn"</span>,</span><br><span class="line">  <span class="string">"log-opts"</span>: &#123;</span><br><span class="line">    <span class="string">"max-size"</span>: <span class="string">"10m"</span>,</span><br><span class="line">    <span class="string">"max-file"</span>: <span class="string">"3"</span></span><br><span class="line">    &#125;,</span><br><span class="line">  <span class="string">"data-root"</span>: <span class="string">"/var/lib/docker"</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>  Docker 默认的日志格式是 JSON，这里我猜测是 k8s 通过 Docker 接口获取日志类型，然后进行相应的解析输出（希望之后对 k8s 更深入的了解来验证猜想）。</p><p>  在了解了标准日志处理，那么我们来看下节点级别的日志处理是怎样的。</p><h2 id="节点级别日志"><a href="#节点级别日志" class="headerlink" title="节点级别日志"></a>节点级别日志</h2><h3 id="标准处理"><a href="#标准处理" class="headerlink" title="标准处理"></a>标准处理</h3><p>我们现在知道了 Pod 的日志其实是存放在容器真正运行所在节点上的，那么如果 Pod 一直运行，日志会不断增大，占用很多的日志空间，这个在节点上是怎么控制的呢？</p><p>因为这种方式不是 k8s 推荐的方式，这里并没有采用集群级别的控制方式，而是以节点为粒度的，各个节点通过 logrotate 自己处理日志轮询，logrotate 相信大部分同学都使用过，这里不详细说了。</p><h3 id="特殊处理"><a href="#特殊处理" class="headerlink" title="特殊处理"></a>特殊处理</h3><p>如果我们不想将应用日志都输出到标准输出，想将日志打印到 <code>/var/log/</code> 下的自定义路径下怎么办？我们可以在 Pod 启动时挂载一个 Volume，这个 Volume 就是Pod 所在的节点真实路径，这样我们在容器中就可以直接将日志打印到该路径下，哪怕 Pod 被销毁，日志也会一直存在。</p><p>我们创建一个 Deployment 类型的资源，在创建之前，我们需要先创建出指定的挂载路径: <code>/var/log/yiran/</code>，资源配置如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@node1</span> <span class="string">blog]#</span> <span class="string">cat</span> <span class="string">log.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">counter</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        run:</span> <span class="string">helloworldanilhostpath</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">count</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">        args:</span> <span class="string">[/bin/sh,</span> <span class="bullet">-c,</span></span><br><span class="line">              <span class="string">'i=0; while true; do echo "$i: $(date)" &gt;&gt; /var/log/yiran/test.log; i=$((i+1)); sleep 1; done'</span><span class="string">]</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">yiran-test-log</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/var/log/yiran</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">yiran-test-log</span></span><br><span class="line"><span class="attr">        hostPath:</span></span><br><span class="line"><span class="attr">          path:</span> <span class="string">/var/log/yiran</span></span><br><span class="line"><span class="attr">          type:</span> <span class="string">Directory</span></span><br></pre></td></tr></table></figure><p>创建完成后，我们来查看下该 Pod 的日志：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 blog]<span class="comment"># kubectl get pod</span></span><br><span class="line">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">counter-76b584fd8f-7fq99   1/1     Running   0          2m30s</span><br><span class="line">testlog-rs-lwxts           1/1     Running   0          2d1h</span><br><span class="line">[root@node1 blog]<span class="comment"># kubectl logs counter-76b584fd8f-7fq99</span></span><br></pre></td></tr></table></figure><p>可以看到没有标准日志输出，我们按照上面描述，去看下容器对应的 Docker 日志是否为空：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 166103275a89df918b3240ede911192357f7256c1f23b4311b6db44c0f800cc2]<span class="comment"># pwd</span></span><br><span class="line">/var/lib/docker/containers/166103275a89df918b3240ede911192357f7256c1f23b4311b6db44c0f800cc2</span><br><span class="line">[root@node2 166103275a89df918b3240ede911192357f7256c1f23b4311b6db44c0f800cc2]<span class="comment"># ll</span></span><br><span class="line">total 12</span><br><span class="line">-rw-r-----. 1 root root    0 May 18 17:39 166103275a89df918b3240ede911192357f7256c1f23b4311b6db44c0f800cc2-json.log</span><br><span class="line">drwx------. 2 root root    6 May 18 17:39 checkpoints</span><br><span class="line">-rw-------. 1 root root 5173 May 18 17:39 config.v2.json</span><br><span class="line">-rw-r--r--. 1 root root 2064 May 18 17:39 hostconfig.json</span><br><span class="line">drwx------. 2 root root    6 May 18 17:39 mounts</span><br></pre></td></tr></table></figure><p>这里是符合预期的，因为我们将所有的日志输出到指定日志： <code>/var/log/yiran/test.log</code> 中了，我们去看看节点日志是否存在：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 yiran]<span class="comment"># pwd</span></span><br><span class="line">/var/<span class="built_in">log</span>/yiran</span><br><span class="line">[root@node2 yiran]<span class="comment"># tailf test.log</span></span><br><span class="line">327: Sat May 18 09:45:23 UTC 2019</span><br><span class="line">328: Sat May 18 09:45:24 UTC 2019</span><br><span class="line">329: Sat May 18 09:45:25 UTC 2019</span><br><span class="line">330: Sat May 18 09:45:26 UTC 2019</span><br></pre></td></tr></table></figure><p>可以看到这里已经按照预期打印在 Pod 所在节点上了，满足我们的需求。</p><p>接下来是重头戏，集群级别的日志控制。</p><h2 id="集群级别日志"><a href="#集群级别日志" class="headerlink" title="集群级别日志"></a>集群级别日志</h2><p>我们为什么需要日志？对于开发者，可以通过日志进行快速的错误排查；对于运维同学可以根据日志来了解程序运行状态。一句话就是日志非常重要。</p><p>那么既然日志这么重要，那么在 k8s 上如何处理日志，尤其是 k8s 提供了 ReplicaSet/DeploymentSet 这类可以自动缩扩容，自动 ha 的资源，我们如果仅仅通过节点级别的日志管理，集群规模小还好，当集群规模变大之后，对于使用日志的同学简直是灾难。</p><p>在看过了标准日志处理和节点日志处理后，我们来看看一个标准的 k8s 集群是如何处理服务日志和应用日志的。</p><p>这里的前提是，我们有一个日志中心（如 ES)去处理日志，有几种配置方式可以选择：</p><h3 id="节点级别日志代理"><a href="#节点级别日志代理" class="headerlink" title="节点级别日志代理"></a>节点级别日志代理</h3><p>在 k8s 集群中运行一个 DaemonSet，启动的容器运行日志转发器，用于将节点上的日志转发到日志中心，日志转发器可以根据各自资源情况和需求自由选择，如 Logstash,Fluentd,Fluent-bit 等等。</p><p>k8s 标准配置中推荐该方案，无论是从资源使用还是从配置管理上都是最佳方案。</p><p>对应配置在 <code>kubernetes/cluster/addons/fluentd-elasticsearch</code> 路径下，我们可以直接创建部署，部署后状态如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 fluentd-elasticsearch]<span class="comment"># kubectl -n kube-system get rs |grep kibana</span></span><br><span class="line">kibana-logging-f4d99b69f          1         1         1       2d6h</span><br><span class="line">[root@node1 fluentd-elasticsearch]<span class="comment"># kubectl -n kube-system get ds |grep fluent</span></span><br><span class="line">fluentd-es-v2.4.0       3         3         3       3            3           &lt;none&gt;                          2d6h</span><br><span class="line">[root@node1 fluentd-elasticsearch]<span class="comment"># kubectl -n kube-system get statefulset</span></span><br><span class="line">NAME                    READY   AGE</span><br><span class="line">elasticsearch-logging   2/2     2d6h</span><br></pre></td></tr></table></figure><p>可以看到 Fluentd 是以 DaemonSet 方式运行的；ElasticSearch 是以 StatefulSet 方式运行的；Kibana 是以 ReplicaSet 方式运行的。</p><p>其中 Fluentd 配置文件中监控的是 <code>/var/log/container</code> 路径下的所有日志，所以我们理论上可以在 ES 中看到所有应用的日志，那么看到日志之后，我们如何与实际的应用对应呢？这里可以看下具体示例：</p><p>创建 ReplicaSet 类型资源，指定 replica 为 1：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@node1</span> <span class="string">~]#</span> <span class="string">cat</span> <span class="string">log.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1beta2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">testlog-rs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">testlog-label</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">testlog-label</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">testlog-container-name</span></span><br><span class="line"><span class="attr">          image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">          args:</span> <span class="string">[/bin/sh,</span> <span class="bullet">-c,</span></span><br><span class="line">                 <span class="string">'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done'</span><span class="string">]</span></span><br></pre></td></tr></table></figure><p>我们将涉及到名称的字段均加上对应 key，便于在 ES 中查看对应关系，那么接下来看看在 ES 中该容器对应的日志是什么形式的：</p><img src="/2019/05/17/Kubernetes-实战-日志处理/log1.png" title="log1"><p>根据上述对应关系，哪怕 Pod 重建了，我们仍可以通过 container_name 字段来查看对应应用日志，便于调试。</p><h3 id="节点级别日志代理配合伴生容器"><a href="#节点级别日志代理配合伴生容器" class="headerlink" title="节点级别日志代理配合伴生容器"></a>节点级别日志代理配合伴生容器</h3><p>我们知道，标准容器日志应该输出到 stdout 和 stderr 中，那么如果我们一个 Pod 中输出多份日志怎么办？虽然这种情况是我们应该极度避免的，我们应该始终保证一个 Pod 只做一件事情。但是我们有时候迫于代码结构或者其他因素，导致我们会遇到这种情况，那么此时我们需要伴生容器配合使用。</p><p>示例如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">admin/logging/two-files-counter-pod-streaming-sidecar.yaml</span> </span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">counter</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">count</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    args:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/bin/sh</span></span><br><span class="line"><span class="bullet">    -</span> <span class="bullet">-c</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">&gt;</span></span><br><span class="line"><span class="string">      i=0;</span></span><br><span class="line"><span class="string">      while true;</span></span><br><span class="line"><span class="string">      do</span></span><br><span class="line"><span class="string">        echo "$i: $(date)" &gt;&gt; /var/log/1.log;</span></span><br><span class="line"><span class="string">        echo "$(date) INFO $i" &gt;&gt; /var/log/2.log;</span></span><br><span class="line"><span class="string">        i=$((i+1));</span></span><br><span class="line"><span class="string">        sleep 1;</span></span><br><span class="line"><span class="string">      done</span></span><br><span class="line"><span class="string"></span><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">count-log-1</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    args:</span> <span class="string">[/bin/sh,</span> <span class="bullet">-c,</span> <span class="string">'tail -n+1 -f /var/log/1.log'</span><span class="string">]</span></span><br><span class="line"><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">count-log-2</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    args:</span> <span class="string">[/bin/sh,</span> <span class="bullet">-c,</span> <span class="string">'tail -n+1 -f /var/log/2.log'</span><span class="string">]</span></span><br><span class="line"><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">    emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><p>这种方法是极度不推荐的，如果我们配置了 EFK，那么我们 1 份日志相当于写了 3 份，如果我们 ES 的后端存储是一个副本机制的分布式存储，那么我们 1 份日志相当于写了 3 * 2(或 3，存储副本数)份，这是极大的浪费了存储资源的，且会大大影响 SSD 磁盘寿命。</p><h3 id="Pod-级别日志代理"><a href="#Pod-级别日志代理" class="headerlink" title="Pod 级别日志代理"></a>Pod 级别日志代理</h3><p>如果觉得节点级别日志代理粒度太粗，我们也可以选择 Pod 级别，在每个 Pod 中都启动一个伴生容器作为日志代理，将日志直接转发到日志中心。</p><p>若以该形式部署，则我们的应用程序配置不仅要配置应用自身，还要考虑日志处理策略；节点计算能力现在大幅提升，每个节点的 Pod 数量很大，浪费了大量的计算资源。</p><h3 id="应用自处理日志代理"><a href="#应用自处理日志代理" class="headerlink" title="应用自处理日志代理"></a>应用自处理日志代理</h3><p>如标题，我们当然可以在应用中直接将日志转发到指定的日志中心，这种情况也是极度糟糕的， <code>Make each program do one thing well.</code>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里我们关于日志部分的介绍就到这里，总的来说我们需要集中式的日志中心，且推荐以节点级别日志代理方式配置，前提是我们能够预留足够的计算资源和存储资源。后续有机会我们可以了解下日志与事件审计关联使用。</p><p>下一篇我们来看下 Kubernetes 中镜像相关管理与使用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;基础日志处理&quot;&gt;&lt;a href=&quot;#基础日志处理&quot; class=&quot;headerlink&quot; title=&quot;基础日志处理&quot;&gt;&lt;/a&gt;基础日志处理&lt;/h2&gt;&lt;p&gt;在 Kubernetes（简称 k8s）中，所有应用在 Pod（k8s 管理容器最小单位）中运行，标准处理方
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://zdyxry.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 实战-微服务</title>
    <link href="https://zdyxry.github.io/2019/05/14/Kubernetes-%E5%AE%9E%E6%88%98-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    <id>https://zdyxry.github.io/2019/05/14/Kubernetes-实战-微服务/</id>
    <published>2019-05-14T14:32:43.000Z</published>
    <updated>2019-05-14T14:41:31.308Z</updated>
    
    <content type="html"><![CDATA[<h2 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h2><p>在 《Kubernetes In Action》的开始，先要了解 k8s 的需求来自于哪里，为什么我们需要 k8s。</p><p>引用维基百科解释：</p><blockquote><p>微服务 (Microservices) 是一种软件架构风格，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的 API 集相互通信。</p></blockquote><p>说一说我的理解，在项目早期，都是单体应用，随着功能越来越多，项目越来越大，虽然保证了部署运维的方便，但对于组内同学并不友好，新同学往往要在一坨代码中找自己想要的一点，本地修改提交跑 CI 也是以项目为单位的执行（前段时间 B 站不小心泄露的 Golang 代码就是这种）。当后续升级产品时，因为是以项目为最小粒度，哪怕无关代码，也要被迫进行代码升级，服务重启等操作，带来了额外的风险。</p><p>在 2014年，Martin Fowler 与 James Lewis 共同提出了微服务的概念，把单体应用改为通过接口产生的远程方法调用，将项目拆分，一个项目保证只做一件事情，独立部署和维护。</p><p>优点：</p><ul><li>高度可维护和可测试</li><li>松散耦合</li><li>可独立部署</li><li>围绕业务能力进行组织</li></ul><p>缺点：</p><ul><li>服务数量大幅增加，部署维护困难</li><li>服务间依赖管理</li><li>服务故障处理</li></ul><h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><p>那么我们提到了项目演进，在同一时间，容器技术的标准化统一也间接促成了微服务的推广（我猜的），Docker 在 2013.03.13 发布第一个版本，容器化技术让我们产品发布形态有了新的选择，开发直接将容器镜像发布，运维同学通过镜像进行产品上线，确保了环境的统一，无须纠结环境配置相关问题（不用吵架了）。</p><p>当我们产品发布采用容器化上线后，我们面临一些其他的问题了：</p><ul><li>微服务追求的是将服务解耦，拆分为多个服务，那么最终发布形态对应的也是多个镜像，运维同学管理这些镜像之间的关系难度增加。</li><li>同时当镜像运行在不同的物理节点上，对计算资源和网络资源的要求是一致的，运维同学需要做到让镜像无感知。</li><li>当产品要进行升级时，镜像之间的依赖关系，故障切换等操作紧靠现有容器功能实现困难。</li></ul><p>这么一看，与之前单体应用比也没好哪里去。于是有了各种容器编排系统，比如 Swarm，Mesos等等，但都不是很好用且各家一个标准，这时候老大哥谷歌发话了，我来把我们内部用了很多年要淘汰的东西拿出来给大家解决问题吧，于是有了 Kubernetes。</p><p>Kubernetes 功能上提供了解决微服务引入的问题，并更好的配合微服务去提供稳定高可用的统一容器化环境，具体如何解决的我们后续可以通过了解 Pod，ConfigMap，ReplicaSet 等功能去详细了解。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>可能是因为我考虑问题都是从运维角度去看的，网上的一些文章讲的带来的好处反而没看太清，可能作为 2C 产品，追求敏捷开发，产品不断快速迭代的目标比较适合，但是如果本身作为一个追求稳定可靠的 2B 产品来说，引入 k8s 带来的好处和维护 k8s 带来的成本真的要仔细的从产品层面考虑清楚，这里感觉跟具体的技术关系不大，而是说从产品面向的客户对象考虑，客户想要的是一个什么产品，而 k8s 作为一个还在不断（频繁）迭代的产品来说（可以去看看 release notes 的更新速度），后续若出现某些 API 不兼容等情况，如何去应对，感觉还是个灾难。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://zh.wikipedia.org/wiki/%E5%BE%AE%E6%9C%8D%E5%8B%99" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E5%BE%AE%E6%9C%8D%E5%8B%99</a></li><li><a href="https://hoxis.github.io/learn-microservice-from-0.html" target="_blank" rel="noopener">https://hoxis.github.io/learn-microservice-from-0.html</a></li><li><a href="https://www.infoq.cn/article/Rdx-PkjmTpPRA5oox5EM" target="_blank" rel="noopener">https://www.infoq.cn/article/Rdx-PkjmTpPRA5oox5EM</a></li></ul><p>在学习过程中，通过阅读 <a href="https://github.com/cch123" target="_blank" rel="noopener">cch123</a> 的博客对微服务有了更深的了解，这里列一下相关的系列博客链接：</p><ol><li><p><a href="http://xargin.com/disaster-of-microservice-ul/" target="_blank" rel="noopener">微服务的灾难-通用语言</a></p></li><li><p><a href="http://xargin.com/disaster-of-microservice-techstack/" target="_blank" rel="noopener">微服务的灾难-技术栈</a></p></li><li><p><a href="http://xargin.com/disaster-of-microservice-divide/" target="_blank" rel="noopener">微服务的灾难-拆分</a></p></li><li><p><a href="http://xargin.com/disaster-of-microservice-dephell/" target="_blank" rel="noopener">微服务的灾难-依赖地狱</a></p></li><li><p><a href="http://xargin.com/disaster-of-microservice-evconst/" target="_blank" rel="noopener">微服务的灾难-最终一致</a></p></li><li><p><a href="http://xargin.com/disaster-of-microservice-conway-law/" target="_blank" rel="noopener">微服务的灾难-康威定律和 KPI 冲突</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;微服务&quot;&gt;&lt;a href=&quot;#微服务&quot; class=&quot;headerlink&quot; title=&quot;微服务&quot;&gt;&lt;/a&gt;微服务&lt;/h2&gt;&lt;p&gt;在 《Kubernetes In Action》的开始，先要了解 k8s 的需求来自于哪里，为什么我们需要 k8s。&lt;/p&gt;
&lt;p&gt;
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://zdyxry.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 实战-前言</title>
    <link href="https://zdyxry.github.io/2019/05/11/Kubernetes-%E5%AE%9E%E6%88%98-%E5%89%8D%E8%A8%80/"/>
    <id>https://zdyxry.github.io/2019/05/11/Kubernetes-实战-前言/</id>
    <published>2019-05-11T13:00:55.000Z</published>
    <updated>2019-05-11T13:01:18.094Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Kubernetes-实战-前言"><a href="#Kubernetes-实战-前言" class="headerlink" title="Kubernetes 实战-前言"></a>Kubernetes 实战-前言</h2><p>自从 Kubernetes 大热之后，一直没跟着版本去了解具体的功能及使用，只是大概了解其中概念。之前推特上有人推荐《Kubernetes In Action》这本书，说是对入门同学很友好，利用五一假期和这个周末，终于看完了，打算把学习过程和其中的一些想法记录下来。</p><h2 id="《Kubernetes-In-Action》"><a href="#《Kubernetes-In-Action》" class="headerlink" title="《Kubernetes In Action》"></a>《Kubernetes In Action》</h2><p>就想推荐人说的那样，这本书作为 101 系列来说，是很称职的，你跟着官方示例做，90%以上都是可以成功的，且讲解门槛不高，推荐。</p><p>中文版是由七牛团队翻译的，虽然其中有一些小的翻译错误，但是整体读下来还是很顺畅的，不影响阅读，当然现在网上已经有原版资源，想读的同学可以去 SaltTiger 搜索下载。</p><p>本书章节较多，分为 3 部分：What？How？Why？首先讲解 k8s 及容器的基本概念，然后讲解 k8s 基本使用，最后介绍了一些 k8s 工作原理及最佳实践。</p><p>当你了解了什么是 k8s，及 k8s 能带来什么好处之后，我们去使用 k8s，从而真实的感受到 k8s 带来的便利，这种感觉是很美好的（表面美好的东西肯定会有某些限制），对我来说这种美好截止到第二部分就停止了。在第三部分中，我们在之前感受到的便利隐藏着很多没有考虑到的边界因素，也意味着我们从一个传统的单节点服务切换到微服务架构上，会新增很多需要去考虑的因素，如果 k8s 内部提供了解决方案，那么很简单，我们直接编写 YAML 就可以了，如果 k8s 没有解决方案呢？我不知道，可能当我真正体验过之后才能给出感受吧（即将发生的事）。</p><p>下一篇我们来说下什么是微服务。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Kubernetes-实战-前言&quot;&gt;&lt;a href=&quot;#Kubernetes-实战-前言&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes 实战-前言&quot;&gt;&lt;/a&gt;Kubernetes 实战-前言&lt;/h2&gt;&lt;p&gt;自从 Kubernetes 
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://zdyxry.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode Shell 题解</title>
    <link href="https://zdyxry.github.io/2019/05/11/LeetCode-Shell-%E9%A2%98%E8%A7%A3/"/>
    <id>https://zdyxry.github.io/2019/05/11/LeetCode-Shell-题解/</id>
    <published>2019-05-11T12:17:57.000Z</published>
    <updated>2019-05-11T12:30:27.712Z</updated>
    
    <content type="html"><![CDATA[<p>工作上用 Shell 的频率是很高的，哪怕现在有了 Ansible 或者其他配置工具，Shell 仍是一个以 Linux 作为工作环境的同学的必备技能。<br>之前写过 GitHub 上的 <code>Pure Bash Bible</code>  的博客，看到 LeetCode 上的 Shell 题目好久不更新了，只有 4 道，今天记录一下题解。</p><h2 id="192-Word-Frequency"><a href="#192-Word-Frequency" class="headerlink" title="192. Word Frequency"></a>192. Word Frequency</h2><p>统计文本文件中单词出现次数，倒序输出。</p><p>words.txt<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">the day is sunny the the</span><br><span class="line">the sunny is is</span><br></pre></td></tr></table></figure></p><p>利用 <code>tr</code> <code>sort</code> <code>uniq</code> <code>awk</code> 解决。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Read from the file words.txt and output the word frequency list to stdout.</span></span><br><span class="line">cat words.txt | tr -s ' ' '\n' | sort | uniq -c | sort -rn | awk '&#123; print $2, $1 &#125;'</span><br></pre></td></tr></table></figure><h1 id="193-Valid-Phone-Numbers"><a href="#193-Valid-Phone-Numbers" class="headerlink" title="193. Valid Phone Numbers"></a>193. Valid Phone Numbers</h1><p>校验电话号码正确性。</p><p>file.txt<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">987-123-4567</span><br><span class="line">123 456 7890</span><br><span class="line">(123) 456-7890</span><br></pre></td></tr></table></figure></p><p>主要是利用 <code>grep</code> 匹配正则，注意转义符。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Read from the file file.txt and output all valid phone numbers to stdout.</span></span><br><span class="line">grep -P '^(\d&#123;3&#125;-|\(\d&#123;3&#125;\) )\d&#123;3&#125;-\d&#123;4&#125;$' file.txt</span><br></pre></td></tr></table></figure><h1 id="194-Transpose-File"><a href="#194-Transpose-File" class="headerlink" title="194. Transpose File"></a>194. Transpose File</h1><p>行和列转换。</p><p>file.txt<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name age</span><br><span class="line">alice 21</span><br><span class="line">ryan 30</span><br></pre></td></tr></table></figure></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Read from the file file.txt and <span class="built_in">print</span> its transposed content to stdout.</span></span><br><span class="line">ncol=`head -n1 file.txt | wc -w`</span><br><span class="line"></span><br><span class="line">for i in `seq 1 $ncol`</span><br><span class="line">do</span><br><span class="line">    echo `cut -d' ' -f$i file.txt`</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h1 id="195-Tenth-Line"><a href="#195-Tenth-Line" class="headerlink" title="195. Tenth Line"></a>195. Tenth Line</h1><p>显示文件第 10 行。</p><p>file.txt<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Line 1</span><br><span class="line">Line 2</span><br><span class="line">Line 3</span><br><span class="line">Line 4</span><br><span class="line">Line 5</span><br><span class="line">Line 6</span><br><span class="line">Line 7</span><br><span class="line">Line 8</span><br><span class="line">Line 9</span><br><span class="line">Line 10</span><br></pre></td></tr></table></figure></p><p>如果直接使用 <code>head</code> <code>tail</code> 的话不能方便处理文件为空的情况。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Read from the file file.txt and output the tenth line to stdout.</span></span><br><span class="line">sed -n '10p' file.txt</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其实编写 Shell 在熟知 Linux  内置命令就可以处理大部分场景了，如果处理不来，只能求助于 sed 和 awk, 但我脑子可能不太好使，awk 的语法总是记不住，每次写之前都要查一下语法。 - -</p><p>如果不想在代码中充斥着各种转义处理的话，还是老老实实使用 Python 编写脚本吧。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;工作上用 Shell 的频率是很高的，哪怕现在有了 Ansible 或者其他配置工具，Shell 仍是一个以 Linux 作为工作环境的同学的必备技能。&lt;br&gt;之前写过 GitHub 上的 &lt;code&gt;Pure Bash Bible&lt;/code&gt;  的博客，看到 LeetC
      
    
    </summary>
    
    
      <category term="alogrithms" scheme="https://zdyxry.github.io/tags/alogrithms/"/>
    
  </entry>
  
  <entry>
    <title>PySnooper 源码阅读</title>
    <link href="https://zdyxry.github.io/2019/04/27/PySnooper-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>https://zdyxry.github.io/2019/04/27/PySnooper-源码阅读/</id>
    <published>2019-04-27T12:14:28.000Z</published>
    <updated>2019-04-27T12:21:19.455Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在 18 年的时候 jiajun 同学发过一篇<a href="https://jiajunhuang.com/articles/2018_05_08-how_to_debug.md.html" target="_blank" rel="noopener">博客</a>，讲如何调试相关的总结。结合最近自己的经验，紧靠 logging 和 print 就能解决日常的 80%问题，剩下的 20% 也都可以通过review 代码来解决，我只有当确实没什么思路的时候，才会采用 pdb 的方式去调试。之所以先 review 代码再采用 pdb 的方式是想确认自己已经理清了相关代码的上下文和逻辑，不至于在单步调试的时候出现 <code>恍然大悟</code> （贬义） 的状况。</p><p>最近两天 Github 上关于 Python 的项目最火的就是 PySnooper，这个项目的 Slogan 就是 <code>Never use print for debugging again</code> ，这里的 print 替换为 logging 也没啥差。整个代码在初步可用阶段代码量很少，也确实能够给平时写些小脚本带来便利，便抽时间看了看具体的实现。</p><h2 id="PySnooper"><a href="#PySnooper" class="headerlink" title="PySnooper"></a>PySnooper</h2><p>先来看下目录结构：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">yiran@zhouyirandeMacBook-Pro:~/Documents/git-repo/PySnooper</span><br><span class="line">3d0d051 ✗ $ tree .</span><br><span class="line">.</span><br><span class="line">├── LICENSE</span><br><span class="line">├── MANIFEST.in</span><br><span class="line">├── README.md</span><br><span class="line">├── make_release.sh</span><br><span class="line">├── misc</span><br><span class="line">│   └── IDE\ files</span><br><span class="line">│       └── PySnooper.wpr</span><br><span class="line">├── pysnooper</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── pycompat.py</span><br><span class="line">│   ├── pysnooper.py</span><br><span class="line">│   ├── tracer.py</span><br><span class="line">│   └── utils.py</span><br><span class="line">├── requirements.in</span><br><span class="line">├── requirements.txt</span><br><span class="line">├── setup.py</span><br><span class="line">├── test_requirements.txt</span><br><span class="line">└── tests</span><br><span class="line">    ├── __init__.py</span><br><span class="line">    ├── test_pysnooper.py</span><br><span class="line">    └── utils.py</span><br></pre></td></tr></table></figure><p>可以看到最核心部分都在 pysnooper 部分，我们以官方示例来了解具体是如何工作的:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">root@yiran30250:~/backup/PySnooper</span><br><span class="line">master ✗ $ cat a.py</span><br><span class="line"><span class="keyword">import</span> pysnooper</span><br><span class="line"></span><br><span class="line"><span class="meta">@pysnooper.snoop('/var/log/test.log')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">number_to_bits</span><span class="params">(number)</span>:</span></span><br><span class="line">    print(<span class="string">'func starting...'</span>)</span><br><span class="line">    <span class="keyword">if</span> number:</span><br><span class="line">        bits = []</span><br><span class="line">        <span class="keyword">while</span> number:</span><br><span class="line">            number, remainder = divmod(number, <span class="number">2</span>)</span><br><span class="line">            bits.insert(<span class="number">0</span>, remainder)</span><br><span class="line">        <span class="keyword">return</span> bits</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> [<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">print(number_to_bits(<span class="number">6</span>))</span><br></pre></td></tr></table></figure><p>从示例中可以看到， <code>pysnooper.snoop</code> 作为一个装饰器，装饰所需要调试的函数，并可以再装饰器参数中添加对应的输出目的，比如标准输出，或者指定日志等。</p><p>我们看下 <code>snoop</code> 的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">snoop</span><span class="params">(output=None, variables=<span class="params">()</span>, depth=<span class="number">1</span>, prefix=<span class="string">''</span>, overwrite=False)</span>:</span></span><br><span class="line">    write, truncate = get_write_and_truncate_functions(output) <span class="comment"># 通过输出目标获取 write 函数</span></span><br><span class="line">    <span class="keyword">if</span> truncate <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">and</span> overwrite:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"`overwrite=True` can only be used when writing "</span></span><br><span class="line">                        <span class="string">"content to file."</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decorate</span><span class="params">(function)</span>:</span></span><br><span class="line">        target_code_object = function.__code__ <span class="comment"># 函数在 python 解释器编译后的字节码对象</span></span><br><span class="line">        tracer = Tracer(target_code_object=target_code_object, write=write,</span><br><span class="line">                        truncate=truncate, variables=variables, depth=depth,</span><br><span class="line">                        prefix=prefix, overwrite=overwrite)</span><br><span class="line">        <span class="comment"># 实例化 Tracer，将现有参数全部传递</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inner</span><span class="params">(function_, *args, **kwargs)</span>:</span></span><br><span class="line">            <span class="keyword">with</span> tracer: <span class="comment"># 通过 with 关键字调用 tracer，那么 Tracer 内应该实现了上下文管理器的 `__enter__` 和 `__exit__` 方法</span></span><br><span class="line">                <span class="keyword">return</span> function(*args, **kwargs) <span class="comment">#</span></span><br><span class="line">        <span class="keyword">return</span> decorator.decorate(function, inner)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> decorate</span><br></pre></td></tr></table></figure><p>主要功能应该在 Trancer 中实现的，我们看下 Trancer 中做了什么？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__enter__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.original_trace_function = sys.gettrace()</span><br><span class="line">    sys.settrace(self.trace)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__exit__</span><span class="params">(self, exc_type, exc_value, exc_traceback)</span>:</span></span><br><span class="line">    sys.settrace(self.original_trace_function)</span><br></pre></td></tr></table></figure><p>先忽略其他的，我们先看实现上下文管理器的方法:</p><ul><li>进入上下文环境<ul><li>获取当前跟踪器并记录</li><li>设置追踪器为 <code>self.trace</code></li></ul></li><li>退出上下文环境<ul><li>将追踪器设置为原有值</li></ul></li></ul><p>注意：</p><p><code>sys.settrace</code> 官方文档中描述它只用来做调试类工具，不建议在内部实现复杂逻辑。<br>The gettrace() function is intended only for implementing debuggers, profilers, coverage tools and the like.</p><p>其中追踪器要接受 3 个参数，分别是：frame，event 和 arg。我们先记住 frame就是当前的栈帧就好。</p><p>看一下 <code>self.trace</code> 具体是如何工作的，先看第一部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trace</span><span class="params">(self, frame, event, arg)</span>:</span></span><br><span class="line">    <span class="comment"># 这里的注释写的很清楚了，根据当前 frame 是否为指定的函数字节码对象，如果不是且深度为 1，则直接返回 trace，如果指定了追踪深度，则不断循环，直到追踪到指定函数字节码对象</span></span><br><span class="line">    <span class="keyword">if</span> frame.f_code <span class="keyword">is</span> <span class="keyword">not</span> self.target_code_object:</span><br><span class="line">        <span class="keyword">if</span> self.depth == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> self.trace</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            _frame_candidate = frame</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, self.depth):</span><br><span class="line">                _frame_candidate = _frame_candidate.f_back <span class="comment"># f_back 为当前栈帧的上一个栈帧，便于在当前代码执行完成后可以调回之前代码继续执行</span></span><br><span class="line">                <span class="keyword">if</span> _frame_candidate <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                    <span class="keyword">return</span> self.trace</span><br><span class="line">                <span class="keyword">elif</span> _frame_candidate.f_code <span class="keyword">is</span> self.target_code_object:</span><br><span class="line">                    indent = <span class="string">' '</span> * <span class="number">4</span> * i</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> self.trace</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        indent = <span class="string">''</span></span><br></pre></td></tr></table></figure><p>找到了具体的执行对象，我们看下如何获取环境变量的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trace</span><span class="params">(self, frame, event, arg)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    self.frame_to_old_local_reprs[frame] = old_local_reprs = \</span><br><span class="line">                                           self.frame_to_local_reprs[frame] <span class="comment"># 标记当前变量为现有变量</span></span><br><span class="line">    self.frame_to_local_reprs[frame] = local_reprs = \</span><br><span class="line">                           get_local_reprs(frame, variables=self.variables) <span class="comment"># 获取当前变量</span></span><br><span class="line"></span><br><span class="line">    modified_local_reprs = &#123;&#125;</span><br><span class="line">    newish_local_reprs = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> local_reprs.items(): <span class="comment"># 遍历当前本地变量，将其分别放置为新变量和修改变量列表中</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> old_local_reprs:</span><br><span class="line">            newish_local_reprs[key] = value</span><br><span class="line">        <span class="keyword">elif</span> old_local_reprs[key] != value:</span><br><span class="line">            modified_local_reprs[key] = value</span><br><span class="line">    <span class="comment"># 将变量通过 write 函数输出到对应的目标中</span></span><br><span class="line">    newish_string = (<span class="string">'Starting var:.. '</span> <span class="keyword">if</span> event == <span class="string">'call'</span> <span class="keyword">else</span></span><br><span class="line">                                                        <span class="string">'New var:....... '</span>)</span><br><span class="line">    <span class="keyword">for</span> name, value_repr <span class="keyword">in</span> sorted(newish_local_reprs.items()):</span><br><span class="line">        self.write(<span class="string">'&#123;indent&#125;&#123;newish_string&#125;&#123;name&#125; = &#123;value_repr&#125;'</span>.format(</span><br><span class="line">                                                               **locals()))</span><br><span class="line">    <span class="keyword">for</span> name, value_repr <span class="keyword">in</span> sorted(modified_local_reprs.items()):</span><br><span class="line">        self.write(<span class="string">'&#123;indent&#125;Modified var:.. &#123;name&#125; = &#123;value_repr&#125;'</span>.format(</span><br><span class="line">                                                               **locals()))</span><br></pre></td></tr></table></figure><p>在上面可以看到大部分都是判断逻辑，看一下 <code>get_local_reprs</code> 中是如何获取当前变量的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_local_reprs</span><span class="params">(frame, variables=<span class="params">()</span>)</span>:</span></span><br><span class="line">    result = &#123;key: get_shortish_repr(value) <span class="keyword">for</span> key, value</span><br><span class="line">                                                     <span class="keyword">in</span> frame.f_locals.items()&#125;</span><br><span class="line">    <span class="keyword">for</span> variable <span class="keyword">in</span> variables:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            result[variable] = get_shortish_repr(</span><br><span class="line">                eval(variable, frame.f_globals, frame.f_locals)</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>是通过调用 <code>frame.f_locals.items()</code> 获取当前栈帧所具有的本地变量。<br>剩下的部分是对于调试函数为装饰器时，需要特殊处理：跳过装饰器函数，直到找到函数定义部分。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>主题功能就通过上述代码来实现，简单高效，我们再来回顾一下：</p><ol><li>通过 settrace 来设置追踪器<br> a. settrace 的行为是先执行追踪器部分，执行完成后执行函数字节码对应行</li><li>在追踪器中，通过 frame 相关属性来获取所需值，如 f_locals, f_code, f_globals</li><li>打印相关信息到目标中，退出上下文管理器，重新设置外层追踪器</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在 18 年的时候 jiajun 同学发过一篇&lt;a href=&quot;https://jiajunhuang.com/articles/2018_
      
    
    </summary>
    
    
      <category term="Python" scheme="https://zdyxry.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>PingCAP tidb-ansible 源码阅读</title>
    <link href="https://zdyxry.github.io/2019/04/20/PingCAP-tidb-ansible-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>https://zdyxry.github.io/2019/04/20/PingCAP-tidb-ansible-源码阅读/</id>
    <published>2019-04-20T03:50:41.000Z</published>
    <updated>2019-04-20T03:51:44.513Z</updated>
    
    <content type="html"><![CDATA[<p>了解我的同学应该知道，我目前负责公司产品的运维工具开发相关的工作，作为一款 2B 的产品，在产品运维过程中，总是有一些不愉快（又不能让客户知道）的繁琐操作：这些操作可能是为了防止过程中出现错误，而不断添加的检测条件；也有可能是历史问题，随着产品发布迭代而一直遗留至今。</p><p>所以我平时也在关注一些开源的 2B 产品的配套运维工具，比如 ZStack、PingCAP 之类的公司。</p><p>但是 ZStack 的开源生态不是很好，感觉只是在保持代码更新（不知道哪个分支）的状态。相比之下 PingCAP 就好很多了，可以很直接的从文档中看到差别，而且社区很活跃。</p><p>最近看到 PingCAP 的一个关于部署维护的 <a href="https://university.pingcap.com/views/common/audition.html?courseId=240255&amp;courseWareId=330983&amp;designId=270990" target="_blank" rel="noopener">视频讲解</a> ，可能时间有限，并没有很深入的讲解细节，有兴趣的同学可以看下。</p><p>在讲解过程中，一个比较核心的工具就是 Ansible，通过 Ansible Playbook 来定义各个步骤，我最近也在使用 Ansible 来进行二次开发，特此学习下 PingCAP 的 <a href="https://github.com/pingcap/tidb-ansible" target="_blank" rel="noopener">tidb-ansible</a> 。</p><h2 id="安装方式"><a href="#安装方式" class="headerlink" title="安装方式"></a>安装方式</h2><p>TiDB 目前支持 4 种安装方式：</p><ol><li>Ansible Online</li><li>Ansible Offline</li><li>Docker</li><li>Docker compose</li></ol><p>其中最佳实践应该是 Ansible Online 方式，通过控制机联网下载所需依赖及 TiDB binary 文件。当然如果所在环境无法访问互联网，那么只能采用 Offline 方式了。后两种部署方式，感觉只是用于开发测试或者给用户“看看”的情况。</p><p>如果要学习的话肯定要学习最佳实践了，那么我们来看看 Ansible Online 方式。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>TiDB 作为一个 <strong>开源分布式关系型数据库</strong> ，所需要的物理环境是很比较苛刻的，官方最佳实践的需求如下：</p><hr><table><thead><tr><th>组件</th><th>CPU</th><th>内存</th><th>硬盘类型</th><th>网络</th><th>数量(最低要求)</th></tr></thead><tbody><tr><td>TiDB</td><td>16</td><td>32GB</td><td>SAS</td><td>10GbE * 2</td><td>2</td></tr><tr><td>PD</td><td>4</td><td>8GB</td><td>SSD</td><td>10 GbE * 2</td><td>3</td></tr><tr><td>TiKV</td><td>16</td><td>32GB</td><td>SSD</td><td>10 GbE * 2</td><td>3</td></tr><tr><td>监控</td><td>8</td><td>16GB</td><td>SAS</td><td>1GbE * 1</td><td>1</td></tr></tbody></table><p>对于 CPU、内存和磁盘的要求我们暂时忽略，这里注意网卡数量都是推荐的 2 块网卡，应该是会做 bonding，到时候看下代码中是否处理。</p><h2 id="安装部署流程"><a href="#安装部署流程" class="headerlink" title="安装部署流程"></a>安装部署流程</h2><ul><li>控制节点安装依赖</li><li>配置普通用户（tidb）<ul><li>密码</li><li>sudu 权限</li><li>ssh key</li><li>…</li></ul></li><li>配置控制节点到被安装节点 SSH 免密登录<ul><li>tidb 免密</li></ul></li><li>NTP<ul><li>各节点时钟同步</li></ul></li><li>CPU 调节器模式<ul><li>performance</li></ul></li><li>格式化磁盘<ul><li>推荐 ext4，支持 xfs</li><li>挂载参数：nodelalloc 和 noatime </li></ul></li><li>ansible inventory &amp; TiDB 配置修改<ul><li>inventory</li><li>tidb-ansible/conf/*</li></ul></li><li>部署<ul><li>local_prepare.yml</li><li>bootstrap.yml</li><li>deploy.yml</li><li>start.yml</li></ul></li></ul><h2 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h2><h3 id="软件依赖"><a href="#软件依赖" class="headerlink" title="软件依赖"></a>软件依赖</h3><p>这里 TiDB 依赖的第三方组件不多，安装方式猜测之所以直接用 pip 是因为要支持不同的发型版本，python 通用些。<br>其中如果部署 pump 并开启 binlog 的话，是需要安装 Kafka 集群的，这里在安装部署文档中没有见到更多的说明。</p><h3 id="普通用户"><a href="#普通用户" class="headerlink" title="普通用户"></a>普通用户</h3><p>这点很重要，一款软件的运行环境很重要，无须 root 权限的坚决不能给与 root 权限，否则之后的权限控制很难做。</p><h3 id="时钟同步"><a href="#时钟同步" class="headerlink" title="时钟同步"></a>时钟同步</h3><p>这里采用的是 ntpd 同步，不知道为什么没有采用 chronyd，在 RHEL7 之后推荐采用 chronyd 来进行时钟同步，根据这篇<a href="https://www.thegeekdiary.com/centos-rhel-7-chrony-vs-ntp-differences-between-ntpd-and-chronyd/" target="_blank" rel="noopener">博客</a>中提到的，chronyd 应该占有绝对<a href="https://chrony.tuxfamily.org/comparison.html" target="_blank" rel="noopener">优势</a>的，不知道这里是出于什么考虑。</p><h3 id="CPU-调节器模式"><a href="#CPU-调节器模式" class="headerlink" title="CPU 调节器模式"></a>CPU 调节器模式</h3><p>这里 TiDB 推荐采用 performance 模式，但是如果你的 2B 产品卖点中有提到 <strong>节省能耗</strong> 相关字眼的，觉得还是要综合考虑才好。</p><h3 id="格式化磁盘"><a href="#格式化磁盘" class="headerlink" title="格式化磁盘"></a>格式化磁盘</h3><p>推荐采用 ext4，在 RHEL7 之后默认的系统分区均为 xfs，这里出于什么考虑也没有透露。</p><p>在我个人使用过程中，xfs 在处理服务器掉电之后的处理很麻烦，经常是需要手动 xfs_repair 去修复磁盘分区。</p><p>TiDB 挂载参数强制要求 <strong>nodelalloc</strong> ，我们看下这个参数的意义：<br><figure class="highlight plain"><figcaption><span>delayed allocation.  Blocks are allocated</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">when the data is copied from userspace to the page cache, either via the write(2) system call or when an mmap&apos;ed page which was previously unallocated is written for the first time.</span><br></pre></td></tr></table></figure></p><h3 id="TiDB-参数"><a href="#TiDB-参数" class="headerlink" title="TiDB 参数"></a>TiDB 参数</h3><p>因为对 TiDB 无更多了解，此节忽略。</p><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>终于到了我最想了解的地方了：ansible playbook。我们先看下代码结构：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">yiran@zhouyirandeMacBook-Pro:~/Documents/git-repo/tidb-ansible</span><br><span class="line">master ✔ $ tree -L 2 .</span><br><span class="line">.</span><br><span class="line">├── LICENSE</span><br><span class="line">├── README.md</span><br><span class="line">├── ansible.cfg</span><br><span class="line">├── bootstrap.yml</span><br><span class="line">├── clean_log_cron.yml</span><br><span class="line">├── cloud</span><br><span class="line">│   └── aws-ansible</span><br><span class="line">├── collect_diagnosis.yml</span><br><span class="line">├── common_tasks</span><br><span class="line">│   ├── add_evict_leader_scheduler.yml</span><br><span class="line">|   ...</span><br><span class="line">│   └── transfer_pd_leader.yml</span><br><span class="line">├── conf</span><br><span class="line">│   ├── alertmanager.yml</span><br><span class="line">|   ...</span><br><span class="line">│   └── tikv.yml</span><br><span class="line">├── create_users.yml</span><br><span class="line">├── deploy.yml</span><br><span class="line">├── deploy_drainer.yml</span><br><span class="line">├── deploy_ntp.yml</span><br><span class="line">├── excessive_rolling_update.yml</span><br><span class="line">├── filter_plugins</span><br><span class="line">│   └── tags.py</span><br><span class="line">├── graceful_stop.yml</span><br><span class="line">├── group_vars</span><br><span class="line">│   ├── alertmanager_servers.yml</span><br><span class="line">│   ├── all.yml</span><br><span class="line">|   ...</span><br><span class="line">│   ├── tidb_servers.yml</span><br><span class="line">│   └── tikv_servers.yml</span><br><span class="line">├── hosts.ini</span><br><span class="line">├── inventory.ini</span><br><span class="line">├── library</span><br><span class="line">│   ├── coreos_facts</span><br><span class="line">│   ├── docker_facts</span><br><span class="line">│   └── wait_for_pid.py</span><br><span class="line">├── local_prepare.yml</span><br><span class="line">├── <span class="built_in">log</span></span><br><span class="line">├── migrate_monitor.yml</span><br><span class="line">├── requirements.txt</span><br><span class="line">├── roles</span><br><span class="line">│   ├── alertmanager</span><br><span class="line">│   ├── blackbox_exporter</span><br><span class="line">│   ├── bootstrap</span><br><span class="line">|   ...</span><br><span class="line">│   ├── tikv</span><br><span class="line">│   ├── tikv_importer</span><br><span class="line">│   └── tispark</span><br><span class="line">├── rolling_update.yml</span><br><span class="line">├── rolling_update_monitor.yml</span><br><span class="line">├── scripts</span><br><span class="line">│   ...</span><br><span class="line">│   ├── check</span><br><span class="line">│   ├── clsrun.sh</span><br><span class="line">│   ├── disk_performance.json</span><br><span class="line">│   ├── grafana-config-copy.py</span><br><span class="line">|   ...</span><br><span class="line">│   └── tikv_trouble_shooting.json</span><br><span class="line">├── start.yml</span><br><span class="line">├── start_drainer.yml</span><br><span class="line">├── start_spark.yml</span><br><span class="line">├── stop.yml</span><br><span class="line">├── stop_drainer.yml</span><br><span class="line">├── stop_spark.yml</span><br><span class="line">├── templates</span><br><span class="line">│   └── grafana.dest.json.j2</span><br><span class="line">├── unsafe_cleanup.yml</span><br><span class="line">├── unsafe_cleanup_container.yml</span><br><span class="line">└── unsafe_cleanup_data.yml</span><br></pre></td></tr></table></figure><p>一个标准的 Ansible Playbook 结构：在最外层暴露我们需要执行的 YAML 配置，所有具体的操作和配置文件都放到 roles 和 conf 中，下面我们来一点点看具体做了什么，哪些地方是我们需要注意的。</p><h4 id="local-prepare-yml"><a href="#local-prepare-yml" class="headerlink" title="local_prepare.yml"></a>local_prepare.yml</h4><p>在这里一共做了以下这么几件事情：</p><ul><li>准备 binary 下载地址配置</li><li>检查网络(GFW)</li><li>下载 binary</li><li>准备 fio 软件</li><li>清理下载路径</li></ul><p>主要都是做环境准备的工作，其中网络检测这没有用我们日常使用最多的 <code>ping</code> ，而是使用了 <code>curl</code> ，这里猜测是因为有时候机器是可以与互联网通信，但是没有配置 DNS 解析，导致后续的下载也会失败，所以直接 <code>curl baidu.com</code> 是一个不错的选择。</p><p>(这里还检查了 GFW - - )</p><p>用到的 Ansible 模块有：</p><ul><li>file</li><li>shell （果然没人会去用 command 的</li><li>template</li><li>get_url</li><li>…</li></ul><h4 id="bootstrap-yml"><a href="#bootstrap-yml" class="headerlink" title="bootstrap.yml"></a>bootstrap.yml</h4><ul><li>基本环境配置参数检查（机器数、配置、OS发行版）</li><li>python 环境准备，NTP 软件包安装</li><li>设置内核参数</li><li>检查系统配置（cpu 调节器配置如果不是performance， 非开发模式下会强制退出）</li><li>fio 检测<ul><li>psync ,bs=32k,iodepth=4,numjobs=4  randread iops不小于 40k</li><li>psync, bs=32k,iodepth=4,numjobs=4  randrw(100%r,0%w) iops均不低于 10k</li><li>psync, bs=32k, iodepth=1,numjobs=1  randrw(100%r,0%w) lat randread 不高于 0.25ms，write 不高于 30us</li></ul></li></ul><p>内核参数部分修改了如下配置：</p><ul><li>net.core.somaxconn=32768 # 最大 socket 连接数，默认为 128</li><li>vm.swappiness=0 # 禁用 swap 空间</li><li>net.ipv4.tcp_syncookies=0 # 关闭 synccookies，默认为关闭</li><li>net.ipv4.tcp_tw_recycle=0 # TIME_WAIT 快速回收，默认关闭，关于 TIME_WAIT 状态可以在《TCP/IP 详解 卷一 协议》 中了解更多</li><li>fs.file-max=1000000 # 最大文件数，默认为 1024</li><li>irqbalance ONESHOT=yes # irqbalance 不以守护进程方式运行</li></ul><p>关于 fio 检测，嗯，我还是太天真了，这个级别的磁盘延迟要求，估计只有 PCIe SSD 可以满足了吧。</p><h4 id="deploy-yml"><a href="#deploy-yml" class="headerlink" title="deploy.yml"></a>deploy.yml</h4><p>这部分通用的东西比较少，都是内部的一些配置文件和服务。</p><h4 id="start-yml"><a href="#start-yml" class="headerlink" title="start.yml"></a>start.yml</h4><p>貌似 TiDB 服务的启动是有严格的依赖关系的，不知道这里如果启动顺序调整，是否会自动重试直到相应依赖服务启动完成。</p><h2 id="滚动升级"><a href="#滚动升级" class="headerlink" title="滚动升级"></a>滚动升级</h2><p>在视频讲解中，提到 TiDB 支持滚动升级，这一点在一个 2B 产品功能中很重要，随着产品的开发迭代，能够无痛的给客户进行升级是很重要的。</p><p>在官方文档中，看到了两个升级文档，分别为 1.0 升级到 2.0 和 2.0 升级到 2.1。使用的滚动升级 YAML 文件为：rolling_update.yml<br>升级过程为滚动升级，步骤为：</p><ol><li>pre check</li><li>upgrade</li><li>post upgrade</li></ol><p>这里没搞懂为什么 pre check tidb-server 也要顺序执行，看上去只是检测了 TiDB 版本。</p><p>在 YAML 中指定的升级顺序为：</p><ol><li>pd</li><li>tikv</li><li>pump</li><li>tidb</li></ol><p>这里比较遗憾没有找到升级失败的处理方式，升级 PD 过程中检查健康状态连续 1分钟都未恢复正常，此时 Ansible 退出，PD 处于高版本状态，其他组件 tikv，tidb 还处于低版本状态，不知道这时如何处理，也许是产品上保证了兼容性？</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>了解了 TiDB 的安装和升级，着重学习下 Ansible Playbook 的组织形式，在 tidb-ansible 中，所有的功能都拆分的很细，能采用 ansible 的都用 ansible 实现了，但是难免需要一些脚本配合（fio），这里的选择需要根据实际情况来进行相应修改。</p><h2 id="吐槽"><a href="#吐槽" class="headerlink" title="吐槽"></a>吐槽</h2><p>不知道为什么在代码中 scripts 下放置了许多json 配置文件。。。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;了解我的同学应该知道，我目前负责公司产品的运维工具开发相关的工作，作为一款 2B 的产品，在产品运维过程中，总是有一些不愉快（又不能让客户知道）的繁琐操作：这些操作可能是为了防止过程中出现错误，而不断添加的检测条件；也有可能是历史问题，随着产品发布迭代而一直遗留至今。&lt;/p
      
    
    </summary>
    
    
      <category term="Ansible" scheme="https://zdyxry.github.io/tags/Ansible/"/>
    
  </entry>
  
  <entry>
    <title>记一次 libcgroup 配置失败</title>
    <link href="https://zdyxry.github.io/2019/04/11/%E8%AE%B0%E4%B8%80%E6%AC%A1-libcgroup-%E9%85%8D%E7%BD%AE%E5%A4%B1%E8%B4%A5/"/>
    <id>https://zdyxry.github.io/2019/04/11/记一次-libcgroup-配置失败/</id>
    <published>2019-04-11T14:04:47.000Z</published>
    <updated>2019-04-11T14:06:40.805Z</updated>
    
    <content type="html"><![CDATA[<h2 id="cgroup-配置失败解决方案"><a href="#cgroup-配置失败解决方案" class="headerlink" title="cgroup 配置失败解决方案"></a>cgroup 配置失败解决方案</h2><p>看过之前博客的同学应该知道，我一直使用的 libcgroup 来进行 cgroup 配置，简单方便。<br>最近遇到了一个报错，很坑，记录一下。</p><h2 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h2><p>接到反馈说有个环境在产品升级之后， cgconfig.service 无法启动，当时的配置如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">[root@yiran-test 21:31:59 ~]<span class="variable">$cat</span> /etc/cgconfig.conf</span><br><span class="line"><span class="comment"># yiran cgroups configuration</span></span><br><span class="line"></span><br><span class="line">group . &#123;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.memory_pressure_enabled = <span class="string">"1"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">group yiran &#123;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.cpus = <span class="string">"0,1,2,3,4,5"</span>;</span><br><span class="line">        cpuset.mems = <span class="string">"0-1"</span>;</span><br><span class="line">        cpuset.cpu_exclusive = <span class="string">"1"</span>;</span><br><span class="line">        cpuset.mem_hardwall = <span class="string">"1"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">group yiran/bb-main &#123;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.cpus = <span class="string">"0"</span>;</span><br><span class="line">        cpuset.mems = <span class="string">"0-1"</span>;</span><br><span class="line">        cpuset.cpu_exclusive = <span class="string">"1"</span>;</span><br><span class="line">        cpuset.mem_hardwall = <span class="string">"1"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">group yiran/bb-io &#123;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.cpus = <span class="string">"1"</span>;</span><br><span class="line">        cpuset.mems = <span class="string">"0-1"</span>;</span><br><span class="line">        cpuset.cpu_exclusive = <span class="string">"1"</span>;</span><br><span class="line">        cpuset.mem_hardwall = <span class="string">"1"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">group yiran/aa-main &#123;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.cpus = <span class="string">"2"</span>;</span><br><span class="line">        cpuset.mems = <span class="string">"0-1"</span>;</span><br><span class="line">        cpuset.cpu_exclusive = <span class="string">"1"</span>;</span><br><span class="line">        cpuset.mem_hardwall = <span class="string">"1"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">group yiran/others &#123;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.cpus = <span class="string">"3"</span>;</span><br><span class="line">        cpuset.mems = <span class="string">"0-1"</span>;</span><br><span class="line">        cpuset.cpu_exclusive = <span class="string">"1"</span>;</span><br><span class="line">        cpuset.mem_hardwall = <span class="string">"1"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">group yiran/app &#123;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.cpus = <span class="string">"4,5"</span>;</span><br><span class="line">        cpuset.mems = <span class="string">"0-1"</span>;</span><br><span class="line">        cpuset.cpu_exclusive = <span class="string">"0"</span>;</span><br><span class="line">        cpuset.mem_hardwall = <span class="string">"1"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">group qemu &#123;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.cpus = <span class="string">"6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47"</span>;</span><br><span class="line">        cpuset.mems = <span class="string">"0-1"</span>;</span><br><span class="line">        cpuset.cpu_exclusive = <span class="string">"0"</span>;</span><br><span class="line">        cpuset.mem_hardwall = <span class="string">"1"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>咋一看，配置文件看上去是正确的，除了最后一个组的 <code>cpuset.cpus</code> 配置略长，但是也没错，按道理应该服务正常启动才对，尝试重启服务查看服务报错信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@yiran-test 21:33:55 ~]<span class="variable">$systemctl</span> restart cgred</span><br><span class="line">[root@yiran-test 21:33:59 ~]<span class="variable">$systemctl</span> restart cgconfig</span><br><span class="line">Job <span class="keyword">for</span> cgconfig.service failed because the control process exited with error code. See <span class="string">"systemctl status cgconfig.service"</span> and <span class="string">"journalctl -xe"</span> <span class="keyword">for</span> details.</span><br><span class="line">[root@yiran-test 21:34:05 ~]<span class="variable">$systemctl</span> status cgconfig</span><br><span class="line">● cgconfig.service - Control Group configuration service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/cgconfig.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: failed (Result: <span class="built_in">exit</span>-code) since 四 2019-04-11 21:34:05 CST; 4s ago</span><br><span class="line">  Process: 6744 ExecStop=/usr/sbin/cgclear -l /etc/cgconfig.conf -L /etc/cgconfig.d -e (code=exited, status=3)</span><br><span class="line">  Process: 11465 ExecStart=/usr/sbin/cgconfigparser -l /etc/cgconfig.conf -L /etc/cgconfig.d -s 1664 (code=exited, status=109)</span><br><span class="line"> Main PID: 11465 (code=exited, status=109)</span><br><span class="line"></span><br><span class="line">4月 11 21:34:05 yiran-test systemd[1]: Starting Control Group configuration service...</span><br><span class="line">4月 11 21:34:05 yiran-test cgconfigparser[11465]: /usr/sbin/cgconfigparser; error loading /etc/cgconfig.conf: Failed to remove a non-empty group</span><br><span class="line">4月 11 21:34:05 yiran-test cgconfigparser[11465]: Error: failed to <span class="built_in">set</span> /sys/fs/cgroup/cpuset/qemu/cpuset.cpus: Invalid argument</span><br><span class="line">4月 11 21:34:05 yiran-test systemd[1]: cgconfig.service: main process exited, code=exited, status=109/n/a</span><br><span class="line">4月 11 21:34:05 yiran-test systemd[1]: Failed to start Control Group configuration service.</span><br><span class="line">4月 11 21:34:05 yiran-test systemd[1]: Unit cgconfig.service entered failed state.</span><br><span class="line">4月 11 21:34:05 yiran-test systemd[1]: cgconfig.service failed.</span><br></pre></td></tr></table></figure><p>发现在重启 cgconfig 时报错，报错信息如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">4月 11 21:34:05 yiran-test cgconfigparser[11465]: /usr/sbin/cgconfigparser; error loading /etc/cgconfig.conf: Failed to remove a non-empty group</span><br><span class="line">4月 11 21:34:05 yiran-test cgconfigparser[11465]: Error: failed to <span class="built_in">set</span> /sys/fs/cgroup/cpuset/qemu/cpuset.cpus: Invalid argument</span><br></pre></td></tr></table></figure><p>第一行说移除一个非空的 cgroup 失败，下一条提示 <code>/sys/fs/cgroup/cpuset/qemu/cpuset.cpus</code> 也就是我们觉得略微异常的 cgroup 参数无效，可是参数明明是正确配置的，为啥就无效了呢？</p><h2 id="调查"><a href="#调查" class="headerlink" title="调查"></a>调查</h2><p>尝试修改 <code>cpuset.cpus</code> ，将其调整为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@yiran-test 21:36:32 ~]<span class="variable">$tail</span> /etc/cgconfig.conf</span><br><span class="line"></span><br><span class="line">group qemu &#123;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.cpus = <span class="string">"6,7,8,9,10"</span>;</span><br><span class="line">        cpuset.mems = <span class="string">"0-1"</span>;</span><br><span class="line">        cpuset.cpu_exclusive = <span class="string">"0"</span>;</span><br><span class="line">        cpuset.mem_hardwall = <span class="string">"1"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重启 cgconfig 服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@yiran-test 21:36:36 ~]<span class="variable">$systemctl</span> restart cgred</span><br><span class="line">[root@yiran-test 21:36:55 ~]<span class="variable">$systemctl</span> restart cgconfig</span><br><span class="line">[root@yiran-test 21:37:00 ~]<span class="variable">$systemctl</span> status cgconfig</span><br><span class="line">● cgconfig.service - Control Group configuration service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/cgconfig.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (exited) since 四 2019-04-11 21:37:00 CST; 3s ago</span><br><span class="line">  Process: 6744 ExecStop=/usr/sbin/cgclear -l /etc/cgconfig.conf -L /etc/cgconfig.d -e (code=exited, status=3)</span><br><span class="line">  Process: 17491 ExecStart=/usr/sbin/cgconfigparser -l /etc/cgconfig.conf -L /etc/cgconfig.d -s 1664 (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 17491 (code=exited, status=0/SUCCESS)</span><br><span class="line"></span><br><span class="line">4月 11 21:37:00 yiran-test systemd[1]: Starting Control Group configuration service...</span><br><span class="line">4月 11 21:37:00 yiran-test systemd[1]: Started Control Group configuration service.</span><br></pre></td></tr></table></figure><p>服务正常运行了，那么我推测可能是跟 <code>cpuset.cpus</code> 长度有关，这时候只能求助于 Google 啦。</p><p>很容易，我们找到了这个答案，RedHat <a href="https://access.redhat.com/solutions/3364311" target="_blank" rel="noopener">官方 KB</a> 中的介绍：</p><blockquote><p>Root Cause<br>Previously, the internal representation of a value of any cgroup subsystem parameter was limited to have the length of 100 characters at maximum. Consequently, the libcgroup library truncated the values longer than 100 characters before writing them to a file representing matching cgroup subsystem parameter in the kernel.</p></blockquote><blockquote><p>Resolution<br>The maximal length of values of cgroup subsystem parameters in libcgroup has been extended to 4096 characters. As a result, libcgroup now handles values of cgroup subsystem parameters with any length correctly. (BZ#1549175)<br>RHEL 6 <a href="https://access.redhat.com/downloads/content/rhel---6/x86_64/169/libcgroup/0.40.rc1-26.el6/src/fd431d51/package" target="_blank" rel="noopener">https://access.redhat.com/downloads/content/rhel---6/x86_64/169/libcgroup/0.40.rc1-26.el6/src/fd431d51/package</a> (or newer) via RHBA-2018:1861<br>RHEL 7 libcgroup-0.41-20.el7 (or newer) via RHBA-2018:3058</p></blockquote><p>官方给出的解决方式是通过升级 libcgroup 来解决，但是我不想这么做。</p><p>为什么？要知道在生产环境中，我们想要进行第三方软件包的升级是要经过层层测试的，等到测试完成不知道什么时候了，所以我们需要一个快速折中方案。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>我们知道，libcgroup 只是作为一个配置 cgroup 软件的一种，最终操作的都是 cgroup 实际挂载点下的配置文件，比如 CentOS 默认的 <code>/sys/fs/cgroup/</code> 。</p><p>那么我们来看下正常配置下 qemu 组中的 <code>cpuset.cpus</code> 配置长什么样：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@yiran-test 21:37:04 ~]<span class="variable">$cat</span> /sys/fs/cgroup/cpuset/qemu/cpuset.cpus</span><br><span class="line">6-10</span><br></pre></td></tr></table></figure><p>Ok，我们明明在 libcgroup 配置文件中写的是 <code>6,7,8,9,10</code> ,在 cgroup 配置文件中就转换成了 <code>6-10</code>， 那么一切都简单了。</p><p>当我们配置 cgroup 如果 cpu processor id 是连续的，那么我们就可以通过 <code>-</code> 来连接起始和终止 id 就可以了，问题解决。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>libcgroup 作为 RedHat 官方指定的 cgroup 配置工具，没想到会出现这种问题，如果 <code>cpuset.cpus</code> 我们要设置非连续的 cpu processor id 的话，只能通过升级方式解决了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;cgroup-配置失败解决方案&quot;&gt;&lt;a href=&quot;#cgroup-配置失败解决方案&quot; class=&quot;headerlink&quot; title=&quot;cgroup 配置失败解决方案&quot;&gt;&lt;/a&gt;cgroup 配置失败解决方案&lt;/h2&gt;&lt;p&gt;看过之前博客的同学应该知道，我一直使
      
    
    </summary>
    
    
      <category term="cgroups" scheme="https://zdyxry.github.io/tags/cgroups/"/>
    
  </entry>
  
  <entry>
    <title>apscheduler 源码阅读</title>
    <link href="https://zdyxry.github.io/2019/04/06/apscheduler-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>https://zdyxry.github.io/2019/04/06/apscheduler-源码阅读/</id>
    <published>2019-04-06T02:58:49.000Z</published>
    <updated>2019-04-06T02:59:12.905Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>apscheduler 全称 <code>Advanced Python Scheduler</code>，调度器，主要功能如下：</p><ul><li>动态添加、删除任务</li><li>暂停、恢复任务</li><li>周期性调度：cron,date,interval</li><li>…</li></ul><p>那么接下来我们根据官方示例，看看 apscheduler 是如何进行处理任务的。</p><p>示例版本为 2.1，因为在 2.1 版本包含目前 master 分支上的主要功能，简单易懂。</p><p>代码结构如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">yiran@zhouyirandeMacBook-Pro:~/Documents/git-repo/apscheduler</span><br><span class="line">2.1 ✔ $ tree apscheduler</span><br><span class="line">apscheduler</span><br><span class="line">├── __init__.py</span><br><span class="line">├── events.py</span><br><span class="line">├── job.py</span><br><span class="line">├── jobstores</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── base.py</span><br><span class="line">│   ├── mongodb_store.py</span><br><span class="line">│   ├── ram_store.py</span><br><span class="line">│   ├── redis_store.py</span><br><span class="line">│   ├── shelve_store.py</span><br><span class="line">│   └── sqlalchemy_store.py</span><br><span class="line">├── scheduler.py</span><br><span class="line">├── threadpool.py</span><br><span class="line">├── triggers</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── cron</span><br><span class="line">│   │   ├── __init__.py</span><br><span class="line">│   │   ├── expressions.py</span><br><span class="line">│   │   └── fields.py</span><br><span class="line">│   ├── interval.py</span><br><span class="line">│   └── simple.py</span><br><span class="line">└── util.py</span><br></pre></td></tr></table></figure></p><p>示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime, timedelta</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> apscheduler.scheduler <span class="keyword">import</span> Scheduler</span><br><span class="line"><span class="keyword">from</span> apscheduler.jobstores.shelve_store <span class="keyword">import</span> ShelveJobStore</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">alarm</span><span class="params">(time)</span>:</span></span><br><span class="line">    print(<span class="string">'Alarm! This alarm was scheduled at %s.'</span> % time)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    scheduler = Scheduler(standalone=<span class="keyword">True</span>)</span><br><span class="line">    scheduler.add_jobstore(ShelveJobStore(<span class="string">'example.db'</span>), <span class="string">'shelve'</span>)</span><br><span class="line">    alarm_time = datetime.now() + timedelta(seconds=<span class="number">10</span>)</span><br><span class="line">    scheduler.add_date_job(alarm, alarm_time, name=<span class="string">'alarm'</span>,</span><br><span class="line">                           jobstore=<span class="string">'shelve'</span>, args=[datetime.now()])</span><br><span class="line">    print(<span class="string">'To clear the alarms, delete the example.db file.'</span>)</span><br><span class="line">    print(<span class="string">'Press Ctrl+C to exit'</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        scheduler.start()</span><br><span class="line">    <span class="keyword">except</span> (KeyboardInterrupt, SystemExit):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p><h2 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h2><p>上述示例很容易理解，首先对 <code>Scheduler</code> 实例化，然后添加 jobstore，定义一个名为 <code>alarm</code> 的 job，并指定其运行时间为当前时间 + 10s，将该 job 添加到 scheduler 中，添加 job 类型为 <code>date_job</code>，然后启动 scheduler。</p><p>可以看到我们所有的操作都是通过 scheduler 方法实现的，那么我们来看下 <code>Scheduler</code> 类具体实现了哪些功能：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scheduler</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    This class is responsible for scheduling jobs and triggering</span></span><br><span class="line"><span class="string">    their execution.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    _stopped = <span class="keyword">True</span></span><br><span class="line">    _thread = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, gconfig=&#123;&#125;, **options)</span>:</span></span><br><span class="line">        self._wakeup = Event()</span><br><span class="line">        self._jobstores = &#123;&#125;</span><br><span class="line">        self._jobstores_lock = Lock()</span><br><span class="line">        self._listeners = []</span><br><span class="line">        self._listeners_lock = Lock()</span><br><span class="line">        self._pending_jobs = []</span><br><span class="line">        self.configure(gconfig, **options)</span><br></pre></td></tr></table></figure><p>在 <code>Scheduler</code> 构造函数中，对一些变量进行初始化，这里要注意 <code>self._wakeup</code> ，后续的一些主要功能都是通过它来实现的。接下来看看 <code>add_jobstore</code> 方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_jobstore</span><span class="params">(self, jobstore, alias, quiet=False)</span>:</span></span><br><span class="line">    self._jobstores_lock.acquire() <span class="comment"># 请求锁</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> alias <span class="keyword">in</span> self._jobstores:</span><br><span class="line">            <span class="keyword">raise</span> KeyError(<span class="string">'Alias "%s" is already in use'</span> % alias)</span><br><span class="line">        self._jobstores[alias] = jobstore <span class="comment"># 将 jobstore 别名作为 key，添加到 self._jobstores 中</span></span><br><span class="line">        jobstore.load_jobs() <span class="comment"># 加载 jobstore 中所有 job</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        self._jobstores_lock.release() <span class="comment"># 释放锁</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Notify listeners that a new job store has been added</span></span><br><span class="line">    self._notify_listeners(JobStoreEvent(EVENT_JOBSTORE_ADDED, alias)) <span class="comment"># 事件通知</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Notify the scheduler so it can scan the new job store for jobs</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> quiet:</span><br><span class="line">        self._wakeup.set() <span class="comment"># 将 Event 置为 True</span></span><br></pre></td></tr></table></figure><p>在 <code>add_jobstore</code> 中，将 jobstore 添加到 scheduler 中，并加载当前 jobstore 中的所有任务，接下来将具体的 job 添加到 scheduler 中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_date_job</span><span class="params">(self, func, date, args=None, kwargs=None, **options)</span>:</span></span><br><span class="line">    trigger = SimpleTrigger(date)</span><br><span class="line">    <span class="keyword">return</span> self.add_job(trigger, func, args, kwargs, **options)</span><br></pre></td></tr></table></figure><p>这里的 <code>SimpleTrigger</code> 只是多种 Trigger 中的一种，根据 Trigger 类型的不同，最主要的差别在于 <code>get_next_fire_time</code> 计算方式不同。</p><p>如果添加的任务是 interval_job，那么对应 Trigger 为 <code>IntervalTrigger</code> ；如果添加的任务是 cron_job，那么对应的 Trigger 为 <code>CronTrigger</code>。</p><p>可以看到不同的任务只是 Trigger 计算方式不同，最终还是通过 <code>add_job</code> 方法，继续看：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_job</span><span class="params">(self, trigger, func, args, kwargs, jobstore=<span class="string">'default'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">            **options)</span>:</span></span><br><span class="line">    job = Job(trigger, func, args <span class="keyword">or</span> [], kwargs <span class="keyword">or</span> &#123;&#125;,</span><br><span class="line">              options.pop(<span class="string">'misfire_grace_time'</span>, self.misfire_grace_time),</span><br><span class="line">              options.pop(<span class="string">'coalesce'</span>, self.coalesce), **options) <span class="comment"># 将 job 实例化</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.running: <span class="comment"># 如果 scheduler 未启动，那么将其添加到等待队列中</span></span><br><span class="line">        self._pending_jobs.append((job, jobstore))</span><br><span class="line">        logger.info(<span class="string">'Adding job tentatively -- it will be properly '</span></span><br><span class="line">                    <span class="string">'scheduled when the scheduler starts'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self._real_add_job(job, jobstore, <span class="keyword">True</span>) <span class="comment"># 否则添加 job 到 jobstore 中</span></span><br><span class="line">    <span class="keyword">return</span> job</span><br></pre></td></tr></table></figure><p>继续看 <code>_real_add_job</code> 中的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_real_add_job</span><span class="params">(self, job, jobstore, wakeup)</span>:</span></span><br><span class="line">    job.compute_next_run_time(datetime.now()) <span class="comment"># 计算job 下次运行时间</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> job.next_run_time:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Not adding job since it would never be run'</span>)</span><br><span class="line"></span><br><span class="line">    self._jobstores_lock.acquire() <span class="comment"># 请求锁</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            store = self._jobstores[jobstore]</span><br><span class="line">        <span class="keyword">except</span> KeyError:</span><br><span class="line">            <span class="keyword">raise</span> KeyError(<span class="string">'No such job store: %s'</span> % jobstore)</span><br><span class="line">        store.add_job(job) <span class="comment"># 添加 job</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        self._jobstores_lock.release()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Notify listeners that a new job has been added</span></span><br><span class="line">    event = JobStoreEvent(EVENT_JOBSTORE_JOB_ADDED, jobstore, job)</span><br><span class="line">    self._notify_listeners(event) <span class="comment"># 事件通知</span></span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">'Added job "%s" to job store "%s"'</span>, job, jobstore)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Notify the scheduler about the new job</span></span><br><span class="line">    <span class="keyword">if</span> wakeup:</span><br><span class="line">        self._wakeup.set() <span class="comment"># # 将 Event 置为 True</span></span><br></pre></td></tr></table></figure><p>在 <code>_real_add_job</code> 中我们终于看到 <code>store.add_job(job)</code> ，至于 <code>store.add_job</code> 如何实现我们之后看 <code>JobStore</code> 再说。</p><p>现在我们已经给 scheduler 添加了 jobstore 和 job，那么看下 scheduler 是如何运行的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># Schedule all pending jobs</span></span><br><span class="line">    <span class="keyword">for</span> job, jobstore <span class="keyword">in</span> self._pending_jobs: <span class="comment"># 将 scheduler 未运行时添加的 job，即在等待队列中的 job 添加到 jobstore 中</span></span><br><span class="line">        self._real_add_job(job, jobstore, <span class="keyword">False</span>)</span><br><span class="line">    <span class="keyword">del</span> self._pending_jobs[:]</span><br><span class="line"></span><br><span class="line">    self._stopped = <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">if</span> self.standalone:</span><br><span class="line">        self._main_loop()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self._thread = Thread(target=self._main_loop, name=<span class="string">'APScheduler'</span>)</span><br><span class="line">        self._thread.setDaemon(self.daemonic)</span><br><span class="line">        self._thread.start()</span><br></pre></td></tr></table></figure><p>在 scheduler 运行时，会先将所有的 job 加载到 jobstore 中，然后调用 <code>self._main_loop</code> ，如果 Standalone 为 True，则会一直阻塞知道没有 job 需要运行，看看 <code>self._main_loop</code> 做了啥：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_main_loop</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""Executes jobs on schedule."""</span></span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">'Scheduler started'</span>)</span><br><span class="line">    self._notify_listeners(SchedulerEvent(EVENT_SCHEDULER_START)) <span class="comment"># 事件通知 </span></span><br><span class="line"></span><br><span class="line">    self._wakeup.clear()</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> self._stopped:</span><br><span class="line">        logger.debug(<span class="string">'Looking for jobs to run'</span>)</span><br><span class="line">        now = datetime.now()</span><br><span class="line">        next_wakeup_time = self._process_jobs(now) <span class="comment"># 计算下次唤醒时间</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> next_wakeup_time <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            wait_seconds = time_difference(next_wakeup_time, now)</span><br><span class="line">            logger.debug(<span class="string">'Next wakeup is due at %s (in %f seconds)'</span>,</span><br><span class="line">                         next_wakeup_time, wait_seconds)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                self._wakeup.wait(wait_seconds) <span class="comment"># 等待 Event flag</span></span><br><span class="line">            <span class="keyword">except</span> IOError:  <span class="comment"># Catch errno 514 on some Linux kernels</span></span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            self._wakeup.clear()</span><br><span class="line">        <span class="keyword">elif</span> self.standalone:</span><br><span class="line">            logger.debug(<span class="string">'No jobs left; shutting down scheduler'</span>)</span><br><span class="line">            self.shutdown() <span class="comment"># 若 scheduler standalone 为 True 且 jobs 为空，则停止 scheduler</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            logger.debug(<span class="string">'No jobs; waiting until a job is added'</span>)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                self._wakeup.wait() <span class="comment"># 等待 Event flag</span></span><br><span class="line">            <span class="keyword">except</span> IOError:  <span class="comment"># Catch errno 514 on some Linux kernels</span></span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            self._wakeup.clear()</span><br></pre></td></tr></table></figure><p>还记得上面提到的 <code>Scheduler</code> 构造函数中的 <code>self._wakeup</code> 么，它实际上是 <code>threading.Event</code> ，它的 wait 方法会一直 block 直到 Event flag 为 True，也就是我们上面看到的 <code>self._wakeup.set()</code> ，那么我们可以知道在 <code>Scheduler</code> 中有几种场景会置为 True：</p><ol><li>Scheduler.shutdown</li><li>Scheduler.add_jobstore</li><li>Scheduler._real_add_job</li></ol><p>如果没有触发上述场景，则 <code>_main_loop</code> 会根据 jobs 的执行时间一直循环等待。</p><h2 id="JobStore"><a href="#JobStore" class="headerlink" title="JobStore"></a>JobStore</h2><p>在 apscheduler 中，JobStore 只是单纯的实现了 Job 相关的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobStore</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_job</span><span class="params">(self, job)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_job</span><span class="params">(self, job)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">remove_job</span><span class="params">(self, job)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_jobs</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self)</span>:</span></span><br></pre></td></tr></table></figure><p>其中，对 job 的操作会根据 JobStore 类型的不同，而采用不同的序列化方式，比如在 <code>MongoDBJobStore</code> 中采用的是 <code>bson.binary</code>，而在其他 JobStore 比如 <code>RedisJobStore</code> 中采用的都是 <code>pickle</code>。</p><h2 id="Events"><a href="#Events" class="headerlink" title="Events"></a>Events</h2><p>在 <code>Scheduler</code> 中，我们已经看到通过 <code>threading.Event</code> 来实现事件通知的，那么我们通知的 <code>Event</code> 都是在 <code>apscheduler.events</code> 中定义好的，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobEvent</span><span class="params">(SchedulerEvent)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, code, job, scheduled_run_time, retval=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 exception=None, traceback=None)</span>:</span></span><br><span class="line">        SchedulerEvent.__init__(self, code)</span><br><span class="line">        self.job = job</span><br><span class="line">        self.scheduled_run_time = scheduled_run_time</span><br><span class="line">        self.retval = retval</span><br><span class="line">        self.exception = exception</span><br><span class="line">        self.traceback = traceback</span><br></pre></td></tr></table></figure><p>在 <code>JobEvent</code> 中，我们能看到 job 的执行时间，返回值，异常捕获等信息。如果看过之前关于 <a href="https://zdyxry.github.io/2019/03/31/huey-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/">huey 博客</a> 的同学应该知道，在 huey 中是可以直接通过 task id 获取 task 执行结果的，但是在 apscheduler 中，我们并没有直接获取该结果的方法，而是通过在 <code>Scheduler</code> 中的 <code>add_listener</code> 添加监听者，监控指定成功的 Job 获取该 Job 的返回值，感觉这里不太友好。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里我们基本上已经将 apscheduler 的流程走了一遍，具体的 Trigger 计算时间的方法之后有机会单独写一下关于 cron，interval，date 的计算方法。</p><p>与 huey 相比，apscheduler 使用上要简单，但是简单也意味着功能的不足，比如获取 job 执行结果、job retry 机制等等。当然也有比较好的地方，apscheduler 在跟 web 框架比如 Flask，Django 集成的时候有一些第三方插件可以直接使用，不用像 Huey 一样要单独启动一个 consumer 进程，比较方便。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;apscheduler 全称 &lt;code&gt;Advanced Python Scheduler&lt;/code&gt;，调度器，主要功能如下：&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="Python" scheme="https://zdyxry.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>记一次 Python 编码踩坑</title>
    <link href="https://zdyxry.github.io/2019/04/02/%E8%AE%B0%E4%B8%80%E6%AC%A1-Python-%E7%BC%96%E7%A0%81%E8%B8%A9%E5%9D%91/"/>
    <id>https://zdyxry.github.io/2019/04/02/记一次-Python-编码踩坑/</id>
    <published>2019-04-01T23:37:59.000Z</published>
    <updated>2019-04-01T23:53:03.305Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>一直知道 Python 容易踩编码的坑，尤其是 Python2，昨天第一次遇到，记一下。</p><h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>产品中有一个账号关联的功能，需要的参数大概有 host,port,user,passwd 这么几个参数，昨天发现一个环境中账号关联失败，看请求应该还没到账号认证那里就失败了，查看 rest-server 日志，并没有发现错误异常，api 也是正常返回的，通过其他方式验证账号是有效的，当时觉得很奇怪，没什么想法。</p><h2 id="调查"><a href="#调查" class="headerlink" title="调查"></a>调查</h2><p>既然 rest-server 中日志没有报错，那么看看服务是否有什么异常。<br>这里特意说名下，如果服务使用的是 gunicorn 或者 celery 等第三方库作为守护进程，有一些系统报错是不会记录到你的服务中的，而是会直接打印到系统中（messages or systemd）。</p><p>发现 <code>systemctl status</code> 和 <code>journal -u</code> 有报错，报错内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">4月 02 06:20:00 SCVM70 gunicorn[31225]: Traceback (most recent call last):</span><br><span class="line">4月 02 06:20:00 SCVM70 gunicorn[31225]: File <span class="string">"/usr/lib64/python2.7/site-packages/gevent/threadpool.py"</span>, line 207, <span class="keyword">in</span> _worker</span><br><span class="line">4月 02 06:20:00 SCVM70 gunicorn[31225]: value = func(*args, **kwargs)</span><br><span class="line">4月 02 06:20:00 SCVM70 gunicorn[31225]: error: getaddrinfo() argument 2 must be <span class="built_in">integer</span> or string</span><br><span class="line">4月 02 06:20:00 SCVM70 gunicorn[31225]: (&lt;ThreadPool at 0x120ae50 0/5/10&gt;, &lt;built-in <span class="keyword">function</span> getaddrinfo&gt;) failed with error</span><br></pre></td></tr></table></figure><p>字面意思是传递参数的类型不对，必须为 int 或者 string。</p><p>在 Chrome 中查看当时 API 请求参数，所有参数均为 string，我也实际用 int 或者 str 类型进行验证，账号验证都是可以成功的，感觉进入了死胡同。</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>最后发现是编码的问题，传递的 port 参数是 unicode 编码，而 <code>getaddrinfo()</code> 需要的是 int 或者 string。</p><p>在 python2中，str 其实是 bytes，而不是 unicode，在代码中声明了编码方式为 <code>utf-8</code>，并将该参数存入到了 DB 中，导致下次请求传递的还是 DB 中的 <code>utf-8</code> 类型的 port，而不是 int 或者 string。</p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>这里解决的方式很简单，直接将 port 强制转换为 int 或者 string 就好。根本解决方式应该是在之后的代码编写过程中，规范变量类型，比如 port 就使用 int，而不是 str（unicode），防止出现未知错误。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;一直知道 Python 容易踩编码的坑，尤其是 Python2，昨天第一次遇到，记一下。&lt;/p&gt;
&lt;h2 id=&quot;起因&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
    
      <category term="Python" scheme="https://zdyxry.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>huey 源码阅读</title>
    <link href="https://zdyxry.github.io/2019/03/31/huey-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>https://zdyxry.github.io/2019/03/31/huey-源码阅读/</id>
    <published>2019-03-31T03:25:48.000Z</published>
    <updated>2019-03-31T03:45:14.245Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近读完了 《Redis 实战》对 Redis 有了一些了解，但是没有在实际项目中应用过，就想找一个使用 Redis 的项目来看看，找到 Huey 是因为之前使用过，趁机了解下具体实现。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Huey 的定位是一个轻量级的任务队列，仅依赖于 Redis 作为任务相关信息存储，支持的功能有：</p><ul><li>多种 worker 执行方式：thread，process，greenlet</li><li>支持多种任务类型：特定时间运行，周期性运行</li><li>包含重试机制，可以指定重试次数及重试间隔</li><li>支持任务锁</li><li>…</li></ul><p>我们根据官方的<a href="https://github.com/coleifer/huey/blob/master/examples/simple/README" target="_blank" rel="noopener">示例</a>，来看看 Huey 是如何处理任务的，目录结构如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">master ✔ $ <span class="built_in">pwd</span></span><br><span class="line">/Users/yiran/Documents/git-repo/huey/examples/simple</span><br><span class="line">yiran@zhouyirandeMacBook-Pro:~/Documents/git-repo/huey/examples/simple</span><br><span class="line">master ✔ $ tree .</span><br><span class="line">.</span><br><span class="line">├── README</span><br><span class="line">├── __init__.py</span><br><span class="line">├── config.py</span><br><span class="line">├── cons.sh</span><br><span class="line">├── main.py</span><br><span class="line">└── tasks.py</span><br></pre></td></tr></table></figure><p>注意，这个目录结构是 Huey <a href="https://huey.readthedocs.io/en/latest/imports.html" target="_blank" rel="noopener">官方建议</a>的，具体原因为：</p><blockquote><p>Behind-the-scenes when you decorate a function with task() or periodic_task(), the function registers itself with a centralized in-memory registry. When that function is called, a reference is put into the queue (along with the arguments the function was called with, etc), and when that message is consumed, the function is then looked-up in the consumer’s registry. Because of the way this works, it is strongly recommended that all decorated functions be imported when the consumer starts up. </p></blockquote><h2 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h2><p>Huey 支持通过 @task 装饰器的方式创建任务，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> huey <span class="keyword">import</span> RedisHuey</span><br><span class="line"></span><br><span class="line">huey = RedisHuey(<span class="string">'simple.test'</span>, blocking=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@huey.task()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_beans</span><span class="params">(num)</span>:</span></span><br><span class="line">    print(<span class="string">'-- counted %s beans --'</span> % num)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">'Counted %s beans'</span> % num</span><br></pre></td></tr></table></figure><p>从 huey.RedisHuey 创建了 huey 实例，我们看下 RedisHuey 是什么：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisHuey</span><span class="params">(Huey)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_storage</span><span class="params">(self, read_timeout=<span class="number">1</span>, max_errors=<span class="number">1000</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                    connection_pool=None, url=None, **connection_params)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> RedisStorage(</span><br><span class="line">            name=self.name,</span><br><span class="line">            blocking=self.blocking,</span><br><span class="line">            read_timeout=read_timeout,</span><br><span class="line">            max_errors=max_errors,</span><br><span class="line">            connection_pool=connection_pool,</span><br><span class="line">            url=url,</span><br><span class="line">            **connection_params)</span><br></pre></td></tr></table></figure><p>在 huey.storage 中定义了 RedisHuey，继承自 Huey 类，重新实现了 <code>get_storage</code> 方法，我们看下 <code>RedisStorage</code> 是做什么用途的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisStorage</span><span class="params">(BaseStorage)</span>:</span></span><br><span class="line">    redis_client = Redis</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name=<span class="string">'huey'</span>, blocking=False, read_timeout=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 max_errors=<span class="number">1000</span>, connection_pool=None, url=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 client_name=None, **connection_params)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> Redis <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ImportError(<span class="string">'"redis" python module not found, cannot use '</span></span><br><span class="line">                              <span class="string">'Redis storage backend. Run "pip install redis" '</span></span><br><span class="line">                              <span class="string">'to install.'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> sum(<span class="number">1</span> <span class="keyword">for</span> p <span class="keyword">in</span> (url, connection_pool, connection_params) <span class="keyword">if</span> p) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">'The connection configuration is over-determined. '</span></span><br><span class="line">                <span class="string">'Please specify only one of the the following: '</span></span><br><span class="line">                <span class="string">'"url", "connection_pool", or "connection_params"'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> url:</span><br><span class="line">            connection_pool = ConnectionPool.from_url(</span><br><span class="line">                url, decode_components=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">elif</span> connection_pool <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            connection_pool = ConnectionPool(**connection_params)</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clean_name</span><span class="params">(self, name)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">convert_ts</span><span class="params">(self, ts)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">enqueue</span><span class="params">(self, data)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dequeue</span><span class="params">(self)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_errors</span><span class="params">(self, limit=None, offset=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">flush_errors</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">emit</span><span class="params">(self, message)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">listener</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br></pre></td></tr></table></figure><p>RedisStorage 继承自 Storage，主要用于所有任务相关信息的写入及读取，目前 Huey 中只实现了 Storage 介质，如果想使用其他方式（如 MongoDB）就需要自己实现了。</p><p>知道了 RedisHuey 跟 Huey 的主要区别只是在于 <code>get_storage</code> 方法不同，那么看看 <code>task</code> 方法的具体实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task</span><span class="params">(self, retries=<span class="number">0</span>, retry_delay=<span class="number">0</span>, retries_as_argument=False,</span></span></span><br><span class="line"><span class="function"><span class="params">         include_task=False, name=None, **task_settings)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decorator</span><span class="params">(func)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Decorator to execute a function out-of-band via the consumer.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> TaskWrapper(</span><br><span class="line">            self,</span><br><span class="line">            func.func <span class="keyword">if</span> isinstance(func, TaskWrapper) <span class="keyword">else</span> func,</span><br><span class="line">            retries=retries,</span><br><span class="line">            retry_delay=retry_delay,</span><br><span class="line">            retries_as_argument=retries_as_argument,</span><br><span class="line">            include_task=include_task,</span><br><span class="line">            name=name,</span><br><span class="line">            **task_settings)</span><br><span class="line">    <span class="keyword">return</span> decorator</span><br></pre></td></tr></table></figure><p>我们看下 <code>TaskWrapper</code> 做了啥，一些变量复制忽略掉，关键的是这几行:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TaskWrapper</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, huey, func, retries=<span class="number">0</span>, retry_delay=<span class="number">0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 retries_as_argument=False, include_task=False, name=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 task_base=None, **task_settings)</span>:</span></span><br><span class="line">        ...</span><br><span class="line">        self.task_class = create_task(</span><br><span class="line">            QueueTask <span class="keyword">if</span> task_base <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">else</span> task_base,</span><br><span class="line">            func,</span><br><span class="line">            retries_as_argument,</span><br><span class="line">            name,</span><br><span class="line">            include_task,</span><br><span class="line">            **task_settings)</span><br><span class="line">        self.huey.registry.register(self.task_class)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_revoked</span><span class="params">(self, dt=None, peek=True)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.huey.is_revoked(self.task_class, dt, peek)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">revoke</span><span class="params">(self, revoke_until=None, revoke_once=False)</span>:</span></span><br><span class="line">        self.huey.revoke_all(self.task_class, revoke_until, revoke_once)</span><br></pre></td></tr></table></figure><p>将函数 func 创建为一个任务，并将任务注册到 Huey 中。同时实现了一些方法，这些方法最终调用的都是在 Huey 类中实现的。</p><h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">root@yiran30250:~/project/huey/examples/simple</span><br><span class="line">master ✔ $ cat cons.sh</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"HUEY CONSUMER"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"-------------"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"In another terminal, run 'python main.py'"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Stop the consumer using Ctrl+C"</span></span><br><span class="line">PYTHONPATH=.:<span class="variable">$PYTHONPATH</span></span><br><span class="line"><span class="built_in">export</span> WORKER_CLASS=<span class="variable">$&#123;1:-thread&#125;</span></span><br><span class="line">python ../../huey/bin/huey_consumer.py main.huey --workers=2 -v -s 10 -k <span class="variable">$WORKER_CLASS</span> -C</span><br></pre></td></tr></table></figure><p>接下来我们看下 Consumer 是如何实现的，在进程启动脚本里，先忽略其他参数，我们指定了 huey 实例，并指定了 worker 数量为 2，我们看下是如何执行的：</p><p>huey_consumer.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">consumer_main</span><span class="params">()</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    huey_instance = load_huey(args[<span class="number">0</span>])</span><br><span class="line">    config.setup_logger()</span><br><span class="line">    consumer = huey_instance.create_consumer(**config.values)</span><br><span class="line">    consumer.run()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    consumer_main()</span><br></pre></td></tr></table></figure><p>加载 huey 实例，创建相应 Consumer 实例并运行，我们看下 Consumer 做了什么：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Consumer sets up and coordinates the execution of the workers and scheduler</span></span><br><span class="line"><span class="string">    and registers signal handlers.</span></span><br><span class="line"><span class="string">    """</span></span><br></pre></td></tr></table></figure><p>根据注释我们可以知道 Consumer 主要是启动了 worker 和 scheduler，并截获相应的信息进行处理。<br>在 huey/consumer.py 中定义了 <code>Worker</code>,<code>Scheduler</code>,<code>Environment</code> 类，其中 <code>Environment</code> 根据所指定的 worker 类型的不同，分为 thread,process,greenlet。</p><p>我们看下 <code>Worker</code> 是如何执行对应的任务的：</p><h2 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span><span class="params">(self, now=None)</span>:</span></span><br><span class="line">    task = <span class="keyword">None</span></span><br><span class="line">    exc_raised = <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        task = self.huey.dequeue() <span class="comment"># 从 hue 中获取任务，也就是从 redis 中获取任务</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="keyword">if</span> task:</span><br><span class="line">        self.delay = self.default_delay</span><br><span class="line">        self.handle_task(task, now <span class="keyword">or</span> self.get_now()) <span class="comment"># 如果获取到了任务，对任务进行处理</span></span><br><span class="line">    <span class="keyword">elif</span> exc_raised <span class="keyword">or</span> <span class="keyword">not</span> self.huey.blocking:</span><br><span class="line">        self.sleep()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_task</span><span class="params">(self, task, ts)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self.huey.ready_to_run(task, ts):</span><br><span class="line">        self.add_schedule(task) <span class="comment"># 若任务没有到达执行时间，则添加到 schedule 中</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="keyword">not</span> self.is_revoked(task, ts):</span><br><span class="line">        self.process_task(task, ts) <span class="comment"># 若任务没有被取消，则执行任务</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.huey.emit_task(</span><br><span class="line">            EVENT_REVOKED,</span><br><span class="line">            task,</span><br><span class="line">            timestamp=ts)</span><br><span class="line">        self._logger.debug(<span class="string">'Task %s was revoked, not running'</span>, task) <span class="comment"># 任务被取消，通知 event</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_task</span><span class="params">(self, task, ts)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    self.run_pre_execute_hooks(task)   <span class="comment"># 执行 pre hook 动作</span></span><br><span class="line">    ...  </span><br><span class="line">    task_value = self.huey.execute(task) <span class="comment"># 具体执行 task</span></span><br><span class="line">    ...</span><br><span class="line">    self.run_post_execute_hooks(task, task_value, exception) <span class="comment"># 执行 post hook 动作</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>看到 self.huey.execute(task) 我们发现最终还是通过 Huey 中的方法 execute 来执行 task，那么我们看下是如何实现的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute</span><span class="params">(self, task)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(task, QueueTask):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">'Unknown object: %s'</span> % task)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        result = task.execute()</span><br></pre></td></tr></table></figure><p>发现这里调用的是 task.execute，这里的 task 是谁呢，是我们最开始提到的 <code>TaskWrapper</code> 么，在 <code>TaskWrapper</code> 中没有实现 <code>execute</code> 方法，这里其实是上面提到的 <code>create_task</code> 返回的类，我们看下 <code>create_task</code> 的具体实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_task</span><span class="params">(task_class, func, retries_as_argument=False, task_name=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                include_task=False, **kwargs)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">execute</span><span class="params">(self)</span>:</span></span><br><span class="line">        args, kwargs = self.data <span class="keyword">or</span> ((), &#123;&#125;)</span><br><span class="line">        <span class="keyword">if</span> retries_as_argument:</span><br><span class="line">            kwargs[<span class="string">'retries'</span>] = self.retries</span><br><span class="line">        <span class="keyword">if</span> include_task:</span><br><span class="line">            kwargs[<span class="string">'task'</span>] = self</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kwargs)</span><br><span class="line"></span><br><span class="line">    attrs = &#123;</span><br><span class="line">        <span class="string">'execute'</span>: execute,</span><br><span class="line">        <span class="string">'__module__'</span>: func.__module__,</span><br><span class="line">        <span class="string">'__doc__'</span>: func.__doc__&#125;</span><br><span class="line">    attrs.update(kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> task_name:</span><br><span class="line">        task_name = func.__name__</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> type(task_name, (task_class,), attrs)</span><br></pre></td></tr></table></figure><p>可以看到 <code>execute</code> 函数中最终执行的就是 func 自己， <code>func(*args, **kwargs)</code> ，通过 type 返回真正的 task 类，指定父类为 <code>task_class</code> （默认是 QueueTask）。</p><p>到这里我们就完成了整个流程：任务注册，任务调度，任务执行。那么我们再来看看 Huey 中的锁是怎么实现的。</p><h2 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TaskLock</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Utilize the Storage key/value APIs to implement simple locking. For more</span></span><br><span class="line"><span class="string">    details see :py:meth:`Huey.lock_task`.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, huey, name)</span>:</span></span><br><span class="line">        self._huey = huey</span><br><span class="line">        self._name = name</span><br><span class="line">        self._key = <span class="string">'%s.lock.%s'</span> % (self._huey.name, self._name)</span><br><span class="line">        self._huey._locks.add(self._key)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, fn)</span>:</span></span><br><span class="line"><span class="meta">        @wraps(fn)</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inner</span><span class="params">(*args, **kwargs)</span>:</span></span><br><span class="line">            <span class="keyword">with</span> self:</span><br><span class="line">                <span class="keyword">return</span> fn(*args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> inner</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__enter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._huey._put_if_empty(self._key, <span class="string">'1'</span>):</span><br><span class="line">            <span class="keyword">raise</span> TaskLockedException(<span class="string">'unable to set lock: %s'</span> % self._name)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__exit__</span><span class="params">(self, exc_type, exc_val, exc_tb)</span>:</span></span><br><span class="line">        self._huey._get_data(self._key)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">put_if_empty</span><span class="params">(self, key, value)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.conn.hsetnx(self.result_key, key, value)</span><br></pre></td></tr></table></figure><p>在 Huey 中，任务锁的实现非常简单，单纯的利用了下 Redis 中的 HSETNX 机制：</p><blockquote><p>Sets field in the hash stored at key to value, only if field does not yet exist. If key does not exist, a new key holding a hash is created. If field already exists, this operation has no effect.</p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Huey 作为一个任务调度应用，整体代码量不多，但是有很多值得学习的地方，也许过段时间再看会有新的收获。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;最近读完了 《Redis 实战》对 Redis 有了一些了解，但是没有在实际项目中应用过，就想找一个使用 Redis 的项目来看看，找到 H
      
    
    </summary>
    
    
      <category term="Python" scheme="https://zdyxry.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>LVM 使用总结</title>
    <link href="https://zdyxry.github.io/2019/03/29/LVM-%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"/>
    <id>https://zdyxry.github.io/2019/03/29/LVM-使用总结/</id>
    <published>2019-03-29T14:42:27.000Z</published>
    <updated>2019-03-29T14:43:27.508Z</updated>
    
    <content type="html"><![CDATA[<p>全称 Logical Volume Manager，逻辑卷管理，简单的说就是能将物理磁盘统一管理，在现在这个满大街都在谈论分布式存储的年代，已经很少有人关注和使用它了，毕竟如果买个公有云上的虚拟机，挂载磁盘都已经得到 TP999+ 的稳定性加持，扩容什么的也只是一句话的事，完全没必要使用 LVM 了。<br>那么我今天为啥要写 LVM 呢，首先肯定是最近要使用它（清理它），其次，现在 RedHat 系列发行版仍将 LVM 作为系统安装的默认磁盘处理方式，对于我这种安装系统家常便饭的人，还是要了解下的。</p><p>本文不会包含 LVM 命令的使用。</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>LVM 中有 3 个最重要的概念，分别是 PV，VG，LV，下面我分别来说一下：</p><h3 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h3><p>Physical Volumes，物理卷，属于 LVM 中最底层的单元，通常介质为磁盘，或者磁盘上的某个分区，多个 PV 可以组成 VG（卷组）。</p><h3 id="VG"><a href="#VG" class="headerlink" title="VG"></a>VG</h3><p>Volume Group，卷组，也是我们通常说的“池化”具体表现形式，VG 可以存在多个，我们可以根据具体的用途来划分 VG，来提供相应的性能保证，比如我们可以对 IO 密集型应用使用全 SSD 组成的 VG。</p><h3 id="LV"><a href="#LV" class="headerlink" title="LV"></a>LV</h3><p>Logical Volume，逻辑卷，也就是 <code>LVM</code> 中的 <code>LV</code>，LVM 暴露出来供我们使用的逻辑（虚拟）卷。我们可以将其当做一个普通的磁盘使用，可以在其上进行分区，格式化，磁盘读写等操作。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>简单的介绍了 LVM 的概念，那么我们来说下 LVM 的优缺点：</p><h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><ul><li>随意扩（缩）容</li><li>在线迁移 LV（平时用处不多，主要在 P2V 场景下使用，也就是通常文章中提到的“企业上云”必要的操作）</li><li>快照，RAID 等高级功能</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>管理复杂，通常服务器上磁盘数量多，且磁盘类型未必能够统一（考虑大量公司中的利旧场景），那么我们管理起来就比较麻烦了，要针对所有磁盘创建 PV，然后加入到对应的 VG 中，最后再对外提供 LV，往往我们需要维护相应的功能来提供简单的借口供上层应用使用。</p><h2 id="LVM-RAID-vs-mdadm"><a href="#LVM-RAID-vs-mdadm" class="headerlink" title="LVM RAID vs mdadm"></a>LVM RAID vs mdadm</h2><p>在上述的优点中，我们提到了 RAID 功能。相信大部分同学都了解 RAID 的概念，通常我们提到的 RAID 都是由相应硬件（存储控制器）来提供，如果没有硬件怎么办呢？我们可以通过 <code>mdadm</code> 来实现软 RAID， 可以达到相应的效果，只是根据 OS 版本不同，软 RAID 的稳定性堪忧（Ubuntu 18.04 存在 Bug）。</p><p>那么同样都提供了软 RAID 功能，LVM 与 mdadm 相比，有什么不同呢？</p><p>首先，LVM 实现了完整的 RAID 功能，且 RedHat 也提供了完整的文档来描述各个功能的使用，是可以确定获得了官方支持的，那么社区里是怎么评论的呢？</p><p>从使用上来说，LVM 作为一款逻辑卷管理软件，虽然支持完成的软 RAID 功能，但是社区支持并不好，大家还是习惯于（信任）mdadm，毕竟 <code>Do One Thing and Do It Well</code> 准没错。mdadm 虽然我在使用上觉得很糟糕，但是在线上环境的表现，还是很完美的，目前 RAID1 还没出过问题，稳。</p><p>而且从性能上说，有人对 LVM 和 mdadm 进行过<a href="https://www.fibrevillage.com/storage/429-performance-comparison-of-mdadm-raid0-and-lvm-striped-mapping" target="_blank" rel="noopener">性能对比</a>，总体来说 mdadm 综合表现还是要比 LVM 好一些的。</p><p>（最近在对 nvme 磁盘进行分区 raid1 时经常遇到失败的情况，现象是mdadm 进程自己退出，再次执行又 ok，还没仔细调研。）</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虽然现在分布式存储大火，各家云产品都在使用，但是单机磁盘管理上，LVM 还是很好用的，RedHat 也一直在单机磁盘管理上有所投入，比如在 RedHat7.5 上推出的 <a href="https://github.com/dm-vdo/vdo" target="_blank" rel="noopener">VDO 功能</a>，还是要持续关注了解的。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://github.com/dm-vdo/vdo" target="_blank" rel="noopener">https://github.com/dm-vdo/vdo</a></li><li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/logical_volume_manager_administration/" target="_blank" rel="noopener">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/logical_volume_manager_administration/</a></li><li><a href="https://serverfault.com/questions/217666/what-is-better-lvm-on-raid-or-raid-on-lvm" target="_blank" rel="noopener">https://serverfault.com/questions/217666/what-is-better-lvm-on-raid-or-raid-on-lvm</a></li><li><a href="https://www.fibrevillage.com/storage/429-performance-comparison-of-mdadm-raid0-and-lvm-striped-mapping" target="_blank" rel="noopener">https://www.fibrevillage.com/storage/429-performance-comparison-of-mdadm-raid0-and-lvm-striped-mapping</a></li><li><a href="https://www.reddit.com/r/linux/comments/2pkqh2/is_it_better_to_use_mdadm_raid_lvm_or_just/" target="_blank" rel="noopener">https://www.reddit.com/r/linux/comments/2pkqh2/is_it_better_to_use_mdadm_raid_lvm_or_just/</a></li><li><a href="http://www.cyberphoton.com/questions/question/what-is-the-difference-between-lvm-and-raid" target="_blank" rel="noopener">http://www.cyberphoton.com/questions/question/what-is-the-difference-between-lvm-and-raid</a></li><li><a href="https://unix.stackexchange.com/questions/140321/mixed-raid-types/140325#140325" target="_blank" rel="noopener">https://unix.stackexchange.com/questions/140321/mixed-raid-types/140325#140325</a></li><li><a href="https://serverfault.com/questions/126851/linux-lvm-mirror-vs-md-mirror" target="_blank" rel="noopener">https://serverfault.com/questions/126851/linux-lvm-mirror-vs-md-mirror</a></li><li><a href="https://unix.stackexchange.com/questions/150644/raiding-with-lvm-vs-mdraid-pros-and-cons" target="_blank" rel="noopener">https://unix.stackexchange.com/questions/150644/raiding-with-lvm-vs-mdraid-pros-and-cons</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;全称 Logical Volume Manager，逻辑卷管理，简单的说就是能将物理磁盘统一管理，在现在这个满大街都在谈论分布式存储的年代，已经很少有人关注和使用它了，毕竟如果买个公有云上的虚拟机，挂载磁盘都已经得到 TP999+ 的稳定性加持，扩容什么的也只是一句话的事，
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Wireguard 体验</title>
    <link href="https://zdyxry.github.io/2019/03/23/Wireguard-%E4%BD%93%E9%AA%8C/"/>
    <id>https://zdyxry.github.io/2019/03/23/Wireguard-体验/</id>
    <published>2019-03-23T12:13:38.000Z</published>
    <updated>2019-03-28T00:08:24.992Z</updated>
    
    <content type="html"><![CDATA[<p>从春节假期之后，因为一些原因，就没有再使用 SS 作为访问互联网的工具了，而是使用了 V2ray，使用 2个月下来，感受还是很好的，无论是速度还是稳定性都要比 SS 好很多。最近看到好多新闻说 Wireguard 客户端适配多了起来，比如 Win，Mac，Android，今天尝试一下。</p><h2 id="Wireguard"><a href="#Wireguard" class="headerlink" title="Wireguard"></a>Wireguard</h2><blockquote><p>WireGuard is a free and open-source software application and protocol that implements virtual private network (VPN) techniques to create secure point-to-point connections in routed or bridged configurations. It is run as a module inside the Linux kernel and aims for better performance than the IPsec and OpenVPN tunneling protocols.[2] </p></blockquote><p>Linus 的评价： <code>Maybe the code isn&#39;t perfect, but I&#39;ve skimmed it, and comparedto the horrors that are OpenVPN and IPSec, it&#39;s a work of art.</code>  </p><h2 id="服务端配置"><a href="#服务端配置" class="headerlink" title="服务端配置"></a>服务端配置</h2><h3 id="kernel-配置"><a href="#kernel-配置" class="headerlink" title="kernel 配置"></a>kernel 配置</h3><p>环境配置为：<code>CentOS Linux release 7.6.1810 (Core)</code>  </p><p>Kernel 版本： <code>4.20.3-1.el7.elrepo.x86_64</code></p><p>安装 <code>kernel-devel kernel-headers</code>，注意，如果使用的是 <code>elrepo</code> 源，则需要安装对应版本的 <code>kernel-ml-devel kernel-ml-headers</code> ， 安装后状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rpm -qa |grep kernel  |grep "4.20"</span></span><br><span class="line">kernel-ml-4.20.3-1.el7.elrepo.x86_64</span><br><span class="line">kernel-ml-devel-4.20.3-1.el7.elrepo.x86_64</span><br><span class="line">kernel-ml-headers-4.20.3-1.el7.elrepo.x86_64</span><br></pre></td></tr></table></figure><h3 id="安装-wireguard"><a href="#安装-wireguard" class="headerlink" title="安装 wireguard"></a>安装 wireguard</h3><p><code>yum install wireguard-dkms wireguard-tools</code></p><p>加载 Kernel module</p><p><code>modprobe wireguard &amp;&amp; lsmod |grep wire</code></p><h3 id="编辑-wireguard-配置文件"><a href="#编辑-wireguard-配置文件" class="headerlink" title="编辑 wireguard 配置文件"></a>编辑 wireguard 配置文件</h3><p>通过 <code>ip ad</code> 查看本机网卡名称，以 <code>eth0</code> 为例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#mkdir /etc/wireguard &amp;&amp; cd /etc/wireguard</span></span><br><span class="line"><span class="comment"># wg genkey # 生成 Private Key</span></span><br><span class="line"><span class="comment">#cat &gt; /etc/wireguard/wg0.conf &lt;&lt; EOF</span></span><br><span class="line">[Interface]</span><br><span class="line">PrivateKey = &lt;Private Key&gt;</span><br><span class="line">Address = 10.0.0.1/24 <span class="comment"># 服务端 IP 地址</span></span><br><span class="line">ListenPort = 11111 <span class="comment"># 连接端口</span></span><br><span class="line">PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE; ip6tables -A FORWARD -i wg0 -j ACCEPT; ip6tables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</span><br><span class="line">PostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE; ip6tables -D FORWARD -i wg0 -j ACCEPT; ip6tables -t nat -D POSTROUTING -o eth0 -j MASQUERADE</span><br><span class="line">SaveConfig = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#wg-quick up wg0</span></span><br><span class="line"><span class="comment">#wg</span></span><br><span class="line">interface: wg0</span><br><span class="line">  public key: YNyypVL5wmYA/aaaaaa/VOz4c7BGALHgo= <span class="comment"># 后续配置客户端用到</span></span><br><span class="line">  private key: (hidden)</span><br><span class="line">  listening port: 11111</span><br><span class="line"></span><br><span class="line"><span class="comment"># ip ad</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 </span><br><span class="line">3: wg0: &lt;POINTOPOINT,NOARP,UP,LOWER_UP&gt; mtu 1420 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/none</span><br><span class="line">    inet 10.0.0.1/24 scope global wg0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><h2 id="客户端配置"><a href="#客户端配置" class="headerlink" title="客户端配置"></a>客户端配置</h2><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wg genkey # 生成客户端 PublicKey</span></span><br><span class="line">[Interface]</span><br><span class="line">PublicKey = &lt;PublicKey&gt;</span><br><span class="line">Address = 10.0.0.2/24 <span class="comment"># 客户端 IP 地址</span></span><br><span class="line">DNS = 8.8.8.8 <span class="comment"># 指定 DNS Server</span></span><br><span class="line"></span><br><span class="line">[Peer]</span><br><span class="line">PublicKey = YNyypVL5wmYA/aaaaaa/VOz4c7BGALHgo= <span class="comment"># 服务端公钥</span></span><br><span class="line">Endpoint = &lt;Server ip&gt;:11111 <span class="comment"># 服务端公网 IP，端口为服务端配置端口</span></span><br><span class="line">AllowedIPs = 0.0.0.0/0 <span class="comment"># 允许 IP 段</span></span><br></pre></td></tr></table></figure><h3 id="服务端添加客户端信息"><a href="#服务端添加客户端信息" class="headerlink" title="服务端添加客户端信息"></a>服务端添加客户端信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#wg set wg0 peer &lt;客户端公钥&gt; allowed-ips 10.0.0.2/24</span></span><br><span class="line"><span class="comment">## wg</span></span><br><span class="line">interface: wg0</span><br><span class="line">  public key: YNyypVL5wmYA/aaaaaa/VOz4c7BGALHgo=</span><br><span class="line">  private key: (hidden)</span><br><span class="line">  listening port: 11111</span><br><span class="line"></span><br><span class="line">peer: QRcE0sLvJib8MhWxxxxxxxxx61L0IdZis=</span><br><span class="line">  endpoint: xxxxxxx:yyy</span><br><span class="line">  allowed ips: 10.0.0.0/24</span><br><span class="line">  latest handshake: 1 minute, 9 seconds ago</span><br><span class="line">  transfer: 3.61 MiB received, 92.67 MiB sent</span><br></pre></td></tr></table></figure><h2 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h2><p>在服务端查看主机路由信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ip route show</span></span><br><span class="line">default via 111.111.111.1 dev eth0</span><br><span class="line">10.0.0.0/24 dev wg0 proto kernel scope link src 10.0.0.1</span><br></pre></td></tr></table></figure></p><p>可以看到已经添加的 wireguard 网络默认路由是通过 10.0.0.1，所以我们需要开启地址转发功能：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#cat /etc/sysctl.conf</span></span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line"><span class="comment"># sysctl -p</span></span><br></pre></td></tr></table></figure></p><p>此时在服务端 ping 客户端 IP，也就是 10.0.0.2 ，检查状态：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ping 10.0.0.2</span></span><br><span class="line">PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=334 ms</span><br><span class="line">64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=335 ms</span><br></pre></td></tr></table></figure></p><p>已经看到可以联通了。</p><p>整体上来说 Wireguard 配置上很简单，没有过多的配置文件，只是目前非 Linux 客户端都处于开发阶段，不推荐使用，尝鲜还是可以的。</p><h2 id="配置文件示例"><a href="#配置文件示例" class="headerlink" title="配置文件示例"></a>配置文件示例</h2><p>wg0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[Interface]</span><br><span class="line">PrivateKey = 6G2jd1VVCRofQzkLxxxxxxxxxxxxx/3GJFTjzwxz62k=</span><br><span class="line">Address = 10.0.0.1/24</span><br><span class="line">PostUp   = echo 1 &gt; /proc/sys/net/ipv4/ip_forward; iptables -A FORWARD -i wg0 -j ACCEPT; iptables -A FORWARD -o wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</span><br><span class="line">PostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -D FORWARD -o wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE</span><br><span class="line">ListenPort = 11111</span><br><span class="line">DNS = 8.8.8.8</span><br><span class="line">MTU = 1420</span><br><span class="line"></span><br><span class="line">[Peer]</span><br><span class="line">PublicKey = nMUQDNdDMtMLslqmLpe/j9qqGNdJMxxxxxxxxxu5NjA=</span><br><span class="line">AllowedIPs = 10.0.0.3/32</span><br></pre></td></tr></table></figure><p>client.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Interface]</span><br><span class="line">PrivateKey = 8LnMNxNlvxZnnnBkMpd/hFl1xxxxxxxxxxW+5D4qUk=</span><br><span class="line">Address = 10.0.0.3/24</span><br><span class="line">DNS = 8.8.8.8</span><br><span class="line">MTU = 1420</span><br><span class="line"></span><br><span class="line">[Peer]</span><br><span class="line">PublicKey = QWhJChuDG7HdNnSF4ximOoxxxxxxxxxxitl1mzIjo=</span><br><span class="line">Endpoint = 114.187.221.217:11111</span><br><span class="line">AllowedIPs = 0.0.0.0/0, ::0/0</span><br><span class="line">PersistentKeepalive = 25</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;从春节假期之后，因为一些原因，就没有再使用 SS 作为访问互联网的工具了，而是使用了 V2ray，使用 2个月下来，感受还是很好的，无论是速度还是稳定性都要比 SS 好很多。最近看到好多新闻说 Wireguard 客户端适配多了起来，比如 Win，Mac，Android，今
      
    
    </summary>
    
    
      <category term="Wireguard" scheme="https://zdyxry.github.io/tags/Wireguard/"/>
    
  </entry>
  
  <entry>
    <title>关于 On-Call</title>
    <link href="https://zdyxry.github.io/2019/03/16/%E5%85%B3%E4%BA%8E-On-Call/"/>
    <id>https://zdyxry.github.io/2019/03/16/关于-On-Call/</id>
    <published>2019-03-16T10:24:00.000Z</published>
    <updated>2019-03-16T10:27:35.570Z</updated>
    
    <content type="html"><![CDATA[<h2 id="On-Call"><a href="#On-Call" class="headerlink" title="On-Call"></a>On-Call</h2><p>要说具体的 On-Call，早在 2016年还在负责运维工作的时候，就是 On-Call 的状态，那时候虽然没有明确的规定，但是做得事情就是 On-Call。在年会之后，公司正式宣布执行 On-Call，并且我在上周又重新体会了下 On-Call，感觉涉及到的东西可太多了。</p><h2 id="售后服务"><a href="#售后服务" class="headerlink" title="售后服务"></a>售后服务</h2><p>在一家做 2B 市场的公司，销售所售卖的，或者说客户所购买的，远远不仅是你的软件。如果单论软件，那么有无数的公司产品比你牛，销售比你多，研发比你强，又怎么争得过呢。我理解 2B 公司最大的卖点是服务：软件安装了，产品运行了，业务上线了，之后呢？无穷尽的服务，小到一项报警项，大到节点故障，都是靠着服务堆起来的。  </p><p>怎么才能服务好呢？ 有一个良好的售后团队，或者说一个良好的售后体系支撑。因为我没有经历过太多的公司，只能就自己接触到的做 2B 公司的目前情况来说，没有见到那种让人眼前一亮的售后服务。</p><p>接触到的小公司售后团队（甚至一些国产2B 大厂）大多都是这么做的：</p><ol><li>安装实施</li><li>定期巡检</li><li>故障处理</li></ol><p>能做到上述 3 点尤其是第 2 点的并不多。我理解的 3 个阶段：<br>安装实施：了解客户环境，及时记录并沟通确定环境中不稳定的点，做好 PlanB，最终实施完成也要形成实施报告，无论是交付客户，还是公司内部之后的持续跟踪，都是只有好处没有坏处。  </p><p>定期巡检：周期性与客户沟通进行巡检，很多客户在使用你的产品，其实他们是没有了解过多的使用上的内容的，毕竟产品说明书（使用文档）几百上千页，应该没有哪些真实用户会一点点的研究了解，大多只是出于使用上。那么这时就需要售后同学定期去进行巡检，帮助客户去发现问题，同时也是在教育用户去了解更多的产品细节。  </p><p>故障处理：这里就涉及到今天聊得主题，当线上环境出现问题，怎么做？如何做？我理解的故障处理，无论 Bug 多难复现，无论操作多苛刻，都要第一时间恢复线上业务，如果业务不能恢复，其他一切免谈。</p><h2 id="为什么-On-Call？"><a href="#为什么-On-Call？" class="headerlink" title="为什么 On-Call？"></a>为什么 On-Call？</h2><p>在我上述提到的 3 点中，1、2通常是由售后同学来完成，最重要的第 3 点通常是由研发同学修复。</p><p>在售后同学，遇到了线上故障：</p><ul><li>如何去了解这个故障的影响范围？</li><li>如何准确全面的去提供这个故障相关信息？</li><li>如何第一时间找到功能模块负责的相应研发同事？</li><li>…</li></ul><p>上述问题在工作中经常遇到，在产品没有完全成熟前，需要售后同学对产品了解不仅限于使用，而需要更多的去了解产品内容，产品通过何种方式提供这个功能。</p><p>当然，在一个小公司中，我们无法要求更多，我们需要做的是，第一时间修复问题，恢复业务，于是有了 On-Call。</p><h2 id="如何-On-Call？"><a href="#如何-On-Call？" class="headerlink" title="如何 On-Call？"></a>如何 On-Call？</h2><p>轮值表：On-Call 的要求其实是一个售后岗位的基本职责，只是对于研发同学来说可能略微难过，7 <em> 24 小时 </em> 365 响应。具体落实下来就可能是以 7 * 24 为周期的轮值。这期间可能有很多要求，比如多久要接通电话，多久要接入远程等等。</p><p>故障时间线：可能一次故障设计到了多个功能模块的同学，那么我们要根据这个事故，编写文档，记录详细的时间线（当然我们现在做的并不好），至少可以让我们再进行任务交接时，了解到这个任务目前的状态，不至于一脸懵逼。永远保持这个事情处于跟踪状态。永远。哪怕是定了闹钟去提醒自己。</p><p>事故报告：之前没觉得事故报告的编写需要花费很多的时间，这周明显当头一棒，要想写好一份报告，大部分情况下需要花费的时间精力远远要比这次事故的解决方式多得多。这份报告不仅交付给客户，还能让我们针对后续的产品开发设计上避免踩坑。</p><p>后续工作：在恢复线上业务之后，我们针对该问题进行修复，无论是代码修复，还是文档修复，都需要多次验证，保证自己的代码是健全的（当然我往往考虑不周。。。）。</p><h2 id="个人感受"><a href="#个人感受" class="headerlink" title="个人感受"></a>个人感受</h2><p>在上周 On-Call 过程中，占用的时间远远超出预期，整整 2人天的时间。整个人精神紧绷，因为 On-Call 的事情永远是优先级最高的事情，你随时都面临着工作内容被打断的状态，也可能因为太久没有经历这种状态，导致我在 On-Call 期间本职工作的工作进度，工作效率都不能让自己满意，很多时候需要远离工位，进行彻底的放松，才能继续下去。<br>同时也让自己更多的注意代码内容，用更多的时间保证自己代码的稳定性是值得的，无论是对自己，还是对于其他同事都是一种负责的体现。</p><p>人，才是最大的 Bug。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://landing.google.com/sre/sre-book/chapters/being-on-call/" target="_blank" rel="noopener">https://landing.google.com/sre/sre-book/chapters/being-on-call/</a></li><li><a href="https://www.quora.com/What-is-it-like-to-be-on-call-as-a-Google-SRE" target="_blank" rel="noopener">https://www.quora.com/What-is-it-like-to-be-on-call-as-a-Google-SRE</a></li><li><a href="https://henrikwarne.com/2018/12/03/developer-on-call/?utm_source=wanqu.co&amp;utm_campaign=Wanqu+Daily&amp;utm_medium=website" target="_blank" rel="noopener">https://henrikwarne.com/2018/12/03/developer-on-call/?utm_source=wanqu.co&amp;utm_campaign=Wanqu+Daily&amp;utm_medium=website</a></li><li><a href="https://www.zhihu.com/question/39502805/answer/338412620" target="_blank" rel="noopener">https://www.zhihu.com/question/39502805/answer/338412620</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;On-Call&quot;&gt;&lt;a href=&quot;#On-Call&quot; class=&quot;headerlink&quot; title=&quot;On-Call&quot;&gt;&lt;/a&gt;On-Call&lt;/h2&gt;&lt;p&gt;要说具体的 On-Call，早在 2016年还在负责运维工作的时候，就是 On-Call 的状态，那
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Python 调用 systemd watchdog 方法</title>
    <link href="https://zdyxry.github.io/2019/03/10/Python-%E8%B0%83%E7%94%A8-systemd-watchdog-%E6%96%B9%E6%B3%95/"/>
    <id>https://zdyxry.github.io/2019/03/10/Python-调用-systemd-watchdog-方法/</id>
    <published>2019-03-10T02:21:19.000Z</published>
    <updated>2019-03-10T12:09:08.991Z</updated>
    
    <content type="html"><![CDATA[<h2 id="systemd"><a href="#systemd" class="headerlink" title="systemd"></a>systemd</h2><p>在之前的博客中介绍过 systemd 的基本使用及通过 timer 来替换 crontab 的方法，今天来说一下如何调用 watchdog。</p><p>在 systemd 中，提供 watchdog 来检测服务状态状态，官方文档中描述这个功能为 “keep-alive ping”，我们可以在服务的启动配置中，添加 <code>WatchdogSec</code> 来指定 timeout 时间，在服务程序中通过发送 <code>WATCHDOG=1</code> 来不断的通知 systemd，服务处于正常状态，当超过 timeout 时间未收到 <code>WATCHDOG=1</code> 信号后，systemd 会根据 <code>Restart</code> 配置，决定是否自动重启服务。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>服务程序：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">root@yiran<span class="number">-30</span><span class="number">-250</span>:/usr/lib/systemd/system</span><br><span class="line"> $ cat /root/project/watchdog/test.py</span><br><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Test starting up..."</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)  <span class="comment"># 模拟执行真实业务</span></span><br><span class="line">print(<span class="string">"Test startup finished"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    sock = socket.socket(socket.AF_UNIX, socket.SOCK_DGRAM)</span><br><span class="line">    addr = os.getenv(<span class="string">"NOTIFY_SOCKET"</span>)  <span class="comment"># systemd default addr = "/run/systemd/notify"</span></span><br><span class="line">    <span class="keyword">if</span> addr <span class="keyword">and</span> addr[<span class="number">0</span>] == <span class="string">"@"</span>:</span><br><span class="line">        addr = <span class="string">"\0"</span> + addr[<span class="number">1</span>:]</span><br><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">    logging.error(<span class="string">"Failed to get notify socket addr"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> sock <span class="keyword">and</span> addr:</span><br><span class="line">    sock.connect(addr)</span><br><span class="line">    sock.sendall(<span class="string">"READY=1"</span>)  <span class="comment"># 通知 systemd 服务启动完成</span></span><br><span class="line"></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    print(<span class="string">"Running..."</span>)</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">if</span> count &lt;= <span class="number">10</span>:</span><br><span class="line">        sock.sendall(<span class="string">"WATCHDOG=1"</span>)  <span class="comment"># 通知 systemd 服务正常运行</span></span><br><span class="line">        logging.info(<span class="string">"Notify socket addr is:%s"</span>, addr)</span><br><span class="line">        logging.info(<span class="string">"test.service watchdog timestamp update succeeded"</span>)</span><br><span class="line">        count += <span class="number">1</span></span><br></pre></td></tr></table></figure></p><p>服务 systemd 配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:/usr/lib/systemd/system</span><br><span class="line"> $ cat test.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=A <span class="built_in">test</span> service written <span class="keyword">in</span> Python</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Environment=PYTHONUNBUFFERED=<span class="literal">true</span></span><br><span class="line">ExecStart=/usr/bin/python /root/project/watchdog/test.py</span><br><span class="line">Type=notify</span><br><span class="line">Restart=always</span><br><span class="line">WatchdogSec=5</span><br></pre></td></tr></table></figure><p>我们启动服务观察下运行状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:/usr/lib/systemd/system</span><br><span class="line"> $ systemctl daemon-reload</span><br><span class="line">root@yiran-30-250:/usr/lib/systemd/system</span><br><span class="line"> $ systemctl start test.service</span><br><span class="line">root@yiran-30-250:/usr/lib/systemd/system</span><br><span class="line"> $ systemctl status <span class="built_in">test</span></span><br><span class="line">● test.service - A <span class="built_in">test</span> service written <span class="keyword">in</span> Python</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/test.service; static; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since 日 2019-03-10 10:16:39 CST; 21s ago</span><br><span class="line"> Main PID: 12202 (python)</span><br><span class="line">   Memory: 4.0M</span><br><span class="line">   CGroup: /system.slice/test.service</span><br><span class="line">           └─12202 /usr/bin/python /root/project/watchdog/test.py</span><br><span class="line"><span class="comment"># 在 Python 程序中，如果没有指定输出位置，会默认打到系统日志中</span></span><br><span class="line">3月 10 10:16:41 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:43 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:45 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:47 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:49 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:51 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:53 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:55 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:57 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:59 yiran-30-250 python[12202]: Running...</span><br></pre></td></tr></table></figure><p>timeout 导致服务重启：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:/usr/lib/systemd/system</span><br><span class="line"> $ systemctl status <span class="built_in">test</span></span><br><span class="line">● test.service - A <span class="built_in">test</span> service written <span class="keyword">in</span> Python</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/test.service; static; vendor preset: disabled)</span><br><span class="line">   Active: deactivating (stop-sigabrt) (Result: watchdog) since 日 2019-03-10 10:17:06 CST; 2ms ago</span><br><span class="line"> Main PID: 12202 (python)</span><br><span class="line">   Memory: 3.9M</span><br><span class="line">   CGroup: /system.slice/test.service</span><br><span class="line">           └─12202 /usr/bin/python /root/project/watchdog/test.py</span><br><span class="line"></span><br><span class="line">3月 10 10:16:49 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:51 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:53 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:55 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:57 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:16:59 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:17:01 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:17:03 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:17:05 yiran-30-250 python[12202]: Running...</span><br><span class="line">3月 10 10:17:06 yiran-30-250 systemd[1]: test.service watchdog timeout (<span class="built_in">limit</span> 5s)!</span><br></pre></td></tr></table></figure><p>journalctl 查看具体重启原因：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">3月 10 10:19:20 yiran-30-250 python[12303]: Running...</span><br><span class="line">3月 10 10:19:22 yiran-30-250 python[12303]: Running...</span><br><span class="line">3月 10 10:19:24 yiran-30-250 python[12303]: Running...</span><br><span class="line">3月 10 10:19:26 yiran-30-250 python[12303]: Running...</span><br><span class="line">3月 10 10:19:28 yiran-30-250 python[12303]: Running...</span><br><span class="line">3月 10 10:19:29 yiran-30-250 systemd[1]: test.service watchdog timeout (limit 5s)!</span><br><span class="line">3月 10 10:19:29 yiran-30-250 systemd[1]: test.service: main process exited, code=dumped, status=6/ABRT</span><br><span class="line">3月 10 10:19:29 yiran-30-250 systemd[1]: Unit test.service entered failed state.</span><br><span class="line">3月 10 10:19:29 yiran-30-250 systemd[1]: test.service failed.</span><br><span class="line">3月 10 10:19:29 yiran-30-250 systemd[1]: test.service holdoff time over, scheduling restart.</span><br><span class="line">3月 10 10:19:29 yiran-30-250 systemd[1]: Starting A test service written in Python...</span><br><span class="line">3月 10 10:19:29 yiran-30-250 python[12324]: Test starting up...</span><br><span class="line">3月 10 10:19:30 yiran-30-250 python[12324]: Test startup finished</span><br><span class="line">3月 10 10:19:30 yiran-30-250 systemd[1]: Started A test service written in Python.</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://github.com/bb4242/sdnotify" target="_blank" rel="noopener">https://github.com/bb4242/sdnotify</a></li><li><a href="https://gist.github.com/Spindel/1d07533ef94a4589d348" target="_blank" rel="noopener">https://gist.github.com/Spindel/1d07533ef94a4589d348</a></li><li><a href="https://www.freedesktop.org/software/systemd/man/sd_notify.html#" target="_blank" rel="noopener">https://www.freedesktop.org/software/systemd/man/sd_notify.html#</a> </li><li><a href="https://www.freedesktop.org/software/systemd/man/systemd.service.html" target="_blank" rel="noopener">https://www.freedesktop.org/software/systemd/man/systemd.service.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;systemd&quot;&gt;&lt;a href=&quot;#systemd&quot; class=&quot;headerlink&quot; title=&quot;systemd&quot;&gt;&lt;/a&gt;systemd&lt;/h2&gt;&lt;p&gt;在之前的博客中介绍过 systemd 的基本使用及通过 timer 来替换 crontab 的方法，
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
      <category term="Python" scheme="https://zdyxry.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python 生成器使用</title>
    <link href="https://zdyxry.github.io/2019/03/09/Python-%E7%94%9F%E6%88%90%E5%99%A8%E4%BD%BF%E7%94%A8/"/>
    <id>https://zdyxry.github.io/2019/03/09/Python-生成器使用/</id>
    <published>2019-03-09T13:47:35.000Z</published>
    <updated>2019-03-09T13:49:04.349Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在清理 Pocket 列表的时候，发现自己很早之前收藏过 dabeaz 在 2008 年 PyCon 关于生成器的 PPT 讲解，今天读完，有所收获。</p><p>在 PPT 中， dabeaz 通过一个具体的文件处理的例子，一步一步的讲解了程序的演进，具体代码可以在 <a href="https://github.com/dabeaz/generators" target="_blank" rel="noopener">Github</a> 查看。</p><h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><p>使用 yield 关键字的函数就是生成器。生成器在运行时生成值，所以只能迭代一次。生成器可以通过 next 关键字执行，通常我们通过 for 循环来迭代生成器，可以自动处理 StopIteration 情况。</p><p>一个简单的生成器例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">countdown</span><span class="params">(n)</span>:</span></span><br><span class="line">   <span class="keyword">while</span> n &gt; <span class="number">0</span>:</span><br><span class="line">       <span class="keyword">yield</span> n</span><br><span class="line">       n -= <span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> countdown(<span class="number">5</span>):</span><br><span class="line"><span class="meta">... </span>    print(i, end=<span class="string">' '</span>)</span><br><span class="line">...</span><br><span class="line"><span class="number">5</span> <span class="number">4</span> <span class="number">3</span> <span class="number">2</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></p><p>当我们调用生成器时，仅返回一个生成器对象，不会执行函数内容，只有当执行 <code>__next__()</code> 时函数才会真正执行。yield 会返回给调用者当前值，同时暂停执行，等待下一次调用 <code>__next__()</code> 继续执行。</p><h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><p>在 python 中通过生成器的方式来实现协程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">7</span>]: <span class="function"><span class="keyword">def</span> <span class="title">recv_count</span><span class="params">()</span>:</span></span><br><span class="line">   ...:     <span class="keyword">try</span>:</span><br><span class="line">   ...:         <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">   ...:             n = <span class="keyword">yield</span></span><br><span class="line">   ...:             print(<span class="string">"T-minus"</span>, n)</span><br><span class="line">   ...:     <span class="keyword">except</span> GeneratorExit:</span><br><span class="line">   ...:         print(<span class="string">"boom"</span>)</span><br><span class="line">   ...:</span><br><span class="line">In [<span class="number">8</span>]: r = recv_count()</span><br><span class="line">In [<span class="number">9</span>]: r.send(<span class="keyword">None</span>) <span class="comment"># init</span></span><br><span class="line">In [<span class="number">10</span>]: r.next() <span class="comment"># yield 未接收到调用者发送具体值</span></span><br><span class="line">(<span class="string">'T-minus'</span>, <span class="keyword">None</span>)</span><br><span class="line">In [<span class="number">13</span>]: r.send(<span class="number">1</span>) </span><br><span class="line">(<span class="string">'T-minus'</span>, <span class="number">1</span>)</span><br><span class="line">In [<span class="number">14</span>]: r.send(<span class="number">2</span>)</span><br><span class="line">(<span class="string">'T-minus'</span>, <span class="number">2</span>)</span><br><span class="line">In [<span class="number">15</span>]: r.send(<span class="number">3</span>)</span><br><span class="line">(<span class="string">'T-minus'</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>关于为什么要执行 <code>r.send(None)</code> ，可以看 <a href="https://www.python.org/dev/peps/pep-0342/" target="_blank" rel="noopener">PEP-342</a> 中具体解释：</p><blockquote><p>Because generator-iterators begin execution at the top of the generator’s function body, there is no yield expression to receive a value when the generator has just been created. Therefore, calling send() with a non-None argument is prohibited when the generator iterator has just started, and a TypeError is raised if this occurs (presumably due to a logic error of some kind). Thus, before you can communicate with a coroutine you must first call next() or send(None) to advance its execution to the first yield expression.</p></blockquote><p>在此基础上进行扩展，我们写一个生产消费者模型:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">root@yiran<span class="number">-30</span><span class="number">-250</span>:/tmp</span><br><span class="line"> $ cat a.py</span><br><span class="line"><span class="comment">#!/usr/bin/python3</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">consumer</span><span class="params">()</span>:</span></span><br><span class="line">    r = <span class="string">''</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        n = <span class="keyword">yield</span> r</span><br><span class="line">        print(<span class="string">'Consuming %s ...'</span> % n)</span><br><span class="line">        r = <span class="string">'200 OK'</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">producer</span><span class="params">(c)</span>:</span></span><br><span class="line">    c.send(<span class="keyword">None</span>)</span><br><span class="line">    n = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="number">5</span>:</span><br><span class="line">        n += <span class="number">1</span></span><br><span class="line">        print(<span class="string">"Producing %s ..."</span> % n)</span><br><span class="line">        r = c.send(n)</span><br><span class="line">        print(<span class="string">"Consumer return: %s"</span> % r)</span><br><span class="line">    c.close()</span><br><span class="line">c = consumer()</span><br><span class="line">producer(c)</span><br><span class="line"></span><br><span class="line">root@yiran<span class="number">-30</span><span class="number">-250</span>:/tmp</span><br><span class="line"> $ python3 a.py</span><br><span class="line">Producing <span class="number">1</span> ...</span><br><span class="line">Consuming <span class="number">1</span> ...</span><br><span class="line">Consumer <span class="keyword">return</span>: <span class="number">200</span> OK</span><br><span class="line">Producing <span class="number">2</span> ...</span><br><span class="line">Consuming <span class="number">2</span> ...</span><br><span class="line">Consumer <span class="keyword">return</span>: <span class="number">200</span> OK</span><br><span class="line">Producing <span class="number">3</span> ...</span><br><span class="line">Consuming <span class="number">3</span> ...</span><br><span class="line">Consumer <span class="keyword">return</span>: <span class="number">200</span> OK</span><br><span class="line">Producing <span class="number">4</span> ...</span><br><span class="line">Consuming <span class="number">4</span> ...</span><br><span class="line">Consumer <span class="keyword">return</span>: <span class="number">200</span> OK</span><br><span class="line">Producing <span class="number">5</span> ...</span><br><span class="line">Consuming <span class="number">5</span> ...</span><br><span class="line">Consumer <span class="keyword">return</span>: <span class="number">200</span> OK</span><br></pre></td></tr></table></figure><p>在 Python3.3 之后，添加了 <code>yield from</code>, <code>asyncio</code> 等关键字，在之后的博客中单独记录。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="http://www.dabeaz.com/generators/Generators.pdf" target="_blank" rel="noopener">http://www.dabeaz.com/generators/Generators.pdf</a></li><li><a href="https://www.tornadoweb.org/en/stable/guide/coroutines.html" target="_blank" rel="noopener">https://www.tornadoweb.org/en/stable/guide/coroutines.html</a></li><li><a href="https://www.zhihu.com/question/28105502" target="_blank" rel="noopener">https://www.zhihu.com/question/28105502</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在清理 Pocket 列表的时候，发现自己很早之前收藏过 dabeaz 在 2008 年 PyCon 关于生成器的 PPT 讲解，今天读完，
      
    
    </summary>
    
    
      <category term="Python" scheme="https://zdyxry.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Libvirt CPU 配置</title>
    <link href="https://zdyxry.github.io/2019/03/02/Libvirt-CPU-%E9%85%8D%E7%BD%AE/"/>
    <id>https://zdyxry.github.io/2019/03/02/Libvirt-CPU-配置/</id>
    <published>2019-03-02T11:40:20.000Z</published>
    <updated>2019-03-02T11:46:33.989Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Libvirt-CPU-配置参数"><a href="#Libvirt-CPU-配置参数" class="headerlink" title="Libvirt CPU 配置参数"></a>Libvirt CPU 配置参数</h2><p>我们先来看下 Libvirt 关于虚拟机 CPU 配置项：</p><ul><li>match</li><li>check</li><li>mode</li><li>model</li><li>…</li></ul><p>具体配置解释可以去 Libvirt 官方文档中查看，这里主要说一下 <code>mode</code> 参数，看一下 <code>mode</code> 具体含义及可选配置：</p><h3 id="host-passthrough"><a href="#host-passthrough" class="headerlink" title="host-passthrough"></a>host-passthrough</h3><p>Libvirt 通知 KVM 对 CPU 不做任何配置项修改，直通给虚拟机。因为虚拟机可以使用与物理主机相同 CPU 指令集，性能最好，相反，在虚拟机热迁移过程中，对目标主机 CPU 要求同型号同代。</p><h3 id="host-model"><a href="#host-model" class="headerlink" title="host-model"></a>host-model</h3><p>本质上是根据物理主机 CPU 从 <code>cpu_map.xml</code> 文件中选择最匹配的 CPU 型号。由于CPU定义是在启动虚拟机之前复制的，因此可以在不同主机上使用完全相同的XML，同时仍然提供每个主机支持的最佳虚拟机 CPU。属于在功能与性能之间的平衡。</p><h3 id="custom"><a href="#custom" class="headerlink" title="custom"></a>custom</h3><p>不指定 <code>mode</code> 属性时的默认值。此模式使得无论虚拟机启动哪个主机，虚拟机都将看到相同的硬件，兼容性最好。</p><h2 id="最佳选择"><a href="#最佳选择" class="headerlink" title="最佳选择"></a>最佳选择</h2><p>在不考虑虚拟机兼容性（热迁移）情况下，优先选择 <code>host-passthrough</code> ，综合考虑选择 <code>host-model</code> 。  </p><p>OpenStack 中如果检测到 hypervisor 是 kvm-qemu ，则默认值为 <code>host-model</code> ；在 hypervisor 是其他类型时，默认值为 <code>none</code>，即由 hypervisor 自己选择。</p><p>我查看了自己两台 VPS 的 CPU 信息，如下：</p><h3 id="Vultr"><a href="#Vultr" class="headerlink" title="Vultr"></a>Vultr</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@vultr ~]<span class="comment"># lscpu</span></span><br><span class="line">Architecture:          x86_64</span><br><span class="line">厂商 ID：           GenuineIntel</span><br><span class="line">CPU 系列：          6</span><br><span class="line">型号：              60</span><br><span class="line">型号名称：        Virtual CPU 71438xxxxxxx</span><br><span class="line">超管理器厂商：  KVM</span><br><span class="line">虚拟化类型：     完全</span><br><span class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat</span><br></pre></td></tr></table></figure><h3 id="BWH"><a href="#BWH" class="headerlink" title="BWH"></a>BWH</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@bwh ~]<span class="comment"># lscpu</span></span><br><span class="line">Architecture:          x86_64</span><br><span class="line">厂商 ID：           GenuineIntel</span><br><span class="line">CPU 系列：          6</span><br><span class="line">型号：              13</span><br><span class="line">型号名称：        QEMU Virtual CPU version (cpu64-rhel6)</span><br><span class="line">超管理器厂商：  KVM</span><br><span class="line">虚拟化类型：     完全</span><br><span class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm rep_good nopl pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt aes xsave avx f16c rdrand hypervisor lahf_lm fsgsbase smep xsaveopt</span><br></pre></td></tr></table></figure><p>可以看到 BWH 的 CPU 比 Vultr CPU 指令集少了很多，而且 CPU 型号是 <code>QEMU Virtual CPU version (cpu64-rhel6)</code> 推断物理机 libvirt 配置是 <code>custom</code> ，果然便宜无好货。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://docs.openstack.org/juno/config-reference/content/kvm.html" target="_blank" rel="noopener">https://docs.openstack.org/juno/config-reference/content/kvm.html</a></li><li><a href="https://wiki.openstack.org/wiki/LibvirtXMLCPUModel" target="_blank" rel="noopener">https://wiki.openstack.org/wiki/LibvirtXMLCPUModel</a></li><li><a href="https://patchwork.kernel.org/patch/9219601/" target="_blank" rel="noopener">https://patchwork.kernel.org/patch/9219601/</a></li><li><a href="https://lists.gnu.org/archive/html/qemu-devel/2016-06/msg00634.html" target="_blank" rel="noopener">https://lists.gnu.org/archive/html/qemu-devel/2016-06/msg00634.html</a></li><li><a href="http://wsfdl.com/openstack/2018/01/02/libvirt_cpu_mode.html" target="_blank" rel="noopener">http://wsfdl.com/openstack/2018/01/02/libvirt_cpu_mode.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Libvirt-CPU-配置参数&quot;&gt;&lt;a href=&quot;#Libvirt-CPU-配置参数&quot; class=&quot;headerlink&quot; title=&quot;Libvirt CPU 配置参数&quot;&gt;&lt;/a&gt;Libvirt CPU 配置参数&lt;/h2&gt;&lt;p&gt;我们先来看下 Libvirt
      
    
    </summary>
    
    
      <category term="Libvirt" scheme="https://zdyxry.github.io/tags/Libvirt/"/>
    
  </entry>
  
  <entry>
    <title>学会拒绝</title>
    <link href="https://zdyxry.github.io/2019/02/05/%E5%AD%A6%E4%BC%9A%E6%8B%92%E7%BB%9D/"/>
    <id>https://zdyxry.github.io/2019/02/05/学会拒绝/</id>
    <published>2019-02-05T01:33:18.000Z</published>
    <updated>2019-02-05T01:34:07.246Z</updated>
    
    <content type="html"><![CDATA[<p>趁着春节 7 天假期，把 18年所有的年假都请了下来，计划在家里待 20多天，这次假期最大的感受就是父母不懂得拒绝，或者说他们不想拒绝。</p><p>我小时候也是这样，可能是因为父母的关系，我一直处于一个周围同学中的“好人”状态，有事情要找人帮忙，一般都会找到我这来，因为我不拒绝。这也给我自身造成了一种假象：“我跟周围的关系不错”。那么我不拒绝的原因是什么呢？ </p><p>最早可能是我不会拒绝，觉得拒绝会让对方难堪；之后可能是我觉得这段关系是我所看重的，所以我为了维持关系不拒绝，但是根本原因还是第一条；最终可能是我懒。（？</p><p>不拒绝，不想拒绝或者说不懂得拒绝，给我造成了很多的困扰，很被动。我这个人是一个喜欢计划的人，无论是生活还是工作，我都希望能够按照我的计划进行（当然如果出现计划外的事情往往我会比较懊恼。但是又因为我不拒绝，导致我的计划经常被中断，甚至是有些时效性的事情，就被彻底的终止了。可能这件事情对我比较重要，但是因为不拒绝，导致事情没完成。</p><p>那么我是从什么开始学会拒绝的呢？准确的说是同事教我的（虽然现在这位同事经常被我拒绝 - - 。在 2017年，我负责的工作准确的说是一半在公司内部，另一半在与公司外部的合作上。公司外部的工作优先级比较高，当我在做公司内部工作的时候，经常性的被打断，去处理优先级比较高的工作，造成我的整体工作效率不高，甚至说很低，哪怕我已经尽可能的考虑到部分原因，但是计划永远赶不上变化，我们要针对不同的事情去拒绝，比如当我正在处理公司外部的工作 A，我的老板让我立即做公司内部工作 B，自我评估优先级之后，我们决定是否接受 B，而不是因为那是我的老板，我就毫不犹豫的接受，因为当时接受的结果很有可能会造成 A &amp; B 都做不好。</p><p>亲戚、朋友甚至是恋人关系也是一样，这种与工作关系不同，在让你帮忙时，他们往往会带上“情感”上的束缚，会利用“情感”关系去控制你，仿佛你不做这段关系就到此为止一样，这种是最可怕的，要学会拒绝，避免深陷。</p><p>当然我现在的拒绝可能比较生硬，导致不愉快，但是终究对我来说是个好事，期望后续能够通过阅读《情感勒索》这部书来改善。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;趁着春节 7 天假期，把 18年所有的年假都请了下来，计划在家里待 20多天，这次假期最大的感受就是父母不懂得拒绝，或者说他们不想拒绝。&lt;/p&gt;
&lt;p&gt;我小时候也是这样，可能是因为父母的关系，我一直处于一个周围同学中的“好人”状态，有事情要找人帮忙，一般都会找到我这来，因为
      
    
    </summary>
    
    
  </entry>
  
</feed>
